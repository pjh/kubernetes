Log file created at: 2019/04/16 21:02:58
Running on machine: e2e-test-peterhornyack-master
Binary: Built with gc go1.12.1 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0416 21:02:58.018524       1 flags.go:33] FLAG: --address="0.0.0.0"
I0416 21:02:58.018613       1 flags.go:33] FLAG: --allocate-node-cidrs="true"
I0416 21:02:58.018625       1 flags.go:33] FLAG: --allow-untagged-cloud="false"
I0416 21:02:58.018628       1 flags.go:33] FLAG: --alsologtostderr="false"
I0416 21:02:58.018632       1 flags.go:33] FLAG: --attach-detach-reconcile-sync-period="1m0s"
I0416 21:02:58.018637       1 flags.go:33] FLAG: --authentication-kubeconfig=""
I0416 21:02:58.018641       1 flags.go:33] FLAG: --authentication-skip-lookup="false"
I0416 21:02:58.018643       1 flags.go:33] FLAG: --authentication-token-webhook-cache-ttl="10s"
I0416 21:02:58.018650       1 flags.go:33] FLAG: --authentication-tolerate-lookup-failure="false"
I0416 21:02:58.018652       1 flags.go:33] FLAG: --authorization-always-allow-paths="[/healthz]"
I0416 21:02:58.018667       1 flags.go:33] FLAG: --authorization-kubeconfig=""
I0416 21:02:58.018671       1 flags.go:33] FLAG: --authorization-webhook-cache-authorized-ttl="10s"
I0416 21:02:58.018674       1 flags.go:33] FLAG: --authorization-webhook-cache-unauthorized-ttl="10s"
I0416 21:02:58.018676       1 flags.go:33] FLAG: --bind-address="0.0.0.0"
I0416 21:02:58.018679       1 flags.go:33] FLAG: --cert-dir=""
I0416 21:02:58.018685       1 flags.go:33] FLAG: --cidr-allocator-type="CloudAllocator"
I0416 21:02:58.018688       1 flags.go:33] FLAG: --client-ca-file=""
I0416 21:02:58.018690       1 flags.go:33] FLAG: --cloud-config="/etc/gce.conf"
I0416 21:02:58.018692       1 flags.go:33] FLAG: --cloud-provider="gce"
I0416 21:02:58.018695       1 flags.go:33] FLAG: --cloud-provider-gce-lb-src-cidrs="130.211.0.0/22,209.85.152.0/22,209.85.204.0/22,35.191.0.0/16"
I0416 21:02:58.018702       1 flags.go:33] FLAG: --cluster-cidr="10.64.0.0/14"
I0416 21:02:58.018705       1 flags.go:33] FLAG: --cluster-name="e2e-test-peterhornyack"
I0416 21:02:58.018711       1 flags.go:33] FLAG: --cluster-signing-cert-file="/etc/srv/kubernetes/pki/ca.crt"
I0416 21:02:58.018714       1 flags.go:33] FLAG: --cluster-signing-key-file="/etc/srv/kubernetes/pki/ca.key"
I0416 21:02:58.018717       1 flags.go:33] FLAG: --concurrent-deployment-syncs="5"
I0416 21:02:58.018727       1 flags.go:33] FLAG: --concurrent-endpoint-syncs="5"
I0416 21:02:58.018730       1 flags.go:33] FLAG: --concurrent-gc-syncs="20"
I0416 21:02:58.018733       1 flags.go:33] FLAG: --concurrent-namespace-syncs="10"
I0416 21:02:58.018738       1 flags.go:33] FLAG: --concurrent-replicaset-syncs="5"
I0416 21:02:58.018741       1 flags.go:33] FLAG: --concurrent-resource-quota-syncs="5"
I0416 21:02:58.018743       1 flags.go:33] FLAG: --concurrent-service-syncs="1"
I0416 21:02:58.018745       1 flags.go:33] FLAG: --concurrent-serviceaccount-token-syncs="5"
I0416 21:02:58.018747       1 flags.go:33] FLAG: --concurrent-ttl-after-finished-syncs="5"
I0416 21:02:58.018754       1 flags.go:33] FLAG: --concurrent_rc_syncs="5"
I0416 21:02:58.018758       1 flags.go:33] FLAG: --configure-cloud-routes="false"
I0416 21:02:58.018761       1 flags.go:33] FLAG: --contention-profiling="false"
I0416 21:02:58.018766       1 flags.go:33] FLAG: --controller-start-interval="0s"
I0416 21:02:58.018769       1 flags.go:33] FLAG: --controllers="[*]"
I0416 21:02:58.018777       1 flags.go:33] FLAG: --deleting-pods-burst="0"
I0416 21:02:58.018780       1 flags.go:33] FLAG: --deleting-pods-qps="0.1"
I0416 21:02:58.018786       1 flags.go:33] FLAG: --deployment-controller-sync-period="30s"
I0416 21:02:58.018800       1 flags.go:33] FLAG: --disable-attach-detach-reconcile-sync="false"
I0416 21:02:58.018806       1 flags.go:33] FLAG: --enable-dynamic-provisioning="true"
I0416 21:02:58.018809       1 flags.go:33] FLAG: --enable-garbage-collector="true"
I0416 21:02:58.018811       1 flags.go:33] FLAG: --enable-hostpath-provisioner="false"
I0416 21:02:58.018814       1 flags.go:33] FLAG: --enable-taint-manager="true"
I0416 21:02:58.018816       1 flags.go:33] FLAG: --experimental-cluster-signing-duration="8760h0m0s"
I0416 21:02:58.018819       1 flags.go:33] FLAG: --external-cloud-volume-plugin=""
I0416 21:02:58.018823       1 flags.go:33] FLAG: --feature-gates="ExperimentalCriticalPodAnnotation=true"
I0416 21:02:58.018838       1 flags.go:33] FLAG: --flex-volume-plugin-dir="/home/kubernetes/flexvolume"
I0416 21:02:58.018841       1 flags.go:33] FLAG: --help="false"
I0416 21:02:58.018844       1 flags.go:33] FLAG: --horizontal-pod-autoscaler-cpu-initialization-period="5m0s"
I0416 21:02:58.018846       1 flags.go:33] FLAG: --horizontal-pod-autoscaler-downscale-delay="5m0s"
I0416 21:02:58.018849       1 flags.go:33] FLAG: --horizontal-pod-autoscaler-downscale-stabilization="5m0s"
I0416 21:02:58.018852       1 flags.go:33] FLAG: --horizontal-pod-autoscaler-initial-readiness-delay="30s"
I0416 21:02:58.018854       1 flags.go:33] FLAG: --horizontal-pod-autoscaler-sync-period="15s"
I0416 21:02:58.018863       1 flags.go:33] FLAG: --horizontal-pod-autoscaler-tolerance="0.1"
I0416 21:02:58.018869       1 flags.go:33] FLAG: --horizontal-pod-autoscaler-upscale-delay="3m0s"
I0416 21:02:58.018871       1 flags.go:33] FLAG: --horizontal-pod-autoscaler-use-rest-clients="true"
I0416 21:02:58.018874       1 flags.go:33] FLAG: --http2-max-streams-per-connection="0"
I0416 21:02:58.018878       1 flags.go:33] FLAG: --kube-api-burst="30"
I0416 21:02:58.018881       1 flags.go:33] FLAG: --kube-api-content-type="application/vnd.kubernetes.protobuf"
I0416 21:02:58.018887       1 flags.go:33] FLAG: --kube-api-qps="20"
I0416 21:02:58.018890       1 flags.go:33] FLAG: --kubeconfig="/etc/srv/kubernetes/kube-controller-manager/kubeconfig"
I0416 21:02:58.018893       1 flags.go:33] FLAG: --large-cluster-size-threshold="50"
I0416 21:02:58.018896       1 flags.go:33] FLAG: --leader-elect="true"
I0416 21:02:58.018898       1 flags.go:33] FLAG: --leader-elect-lease-duration="15s"
I0416 21:02:58.018901       1 flags.go:33] FLAG: --leader-elect-renew-deadline="10s"
I0416 21:02:58.018907       1 flags.go:33] FLAG: --leader-elect-resource-lock="endpoints"
I0416 21:02:58.018914       1 flags.go:33] FLAG: --leader-elect-retry-period="2s"
I0416 21:02:58.018916       1 flags.go:33] FLAG: --log-backtrace-at=":0"
I0416 21:02:58.018920       1 flags.go:33] FLAG: --log-dir=""
I0416 21:02:58.018923       1 flags.go:33] FLAG: --log-file="/var/log/kube-controller-manager.log"
I0416 21:02:58.018926       1 flags.go:33] FLAG: --log-flush-frequency="5s"
I0416 21:02:58.018929       1 flags.go:33] FLAG: --logtostderr="false"
I0416 21:02:58.018931       1 flags.go:33] FLAG: --master=""
I0416 21:02:58.018938       1 flags.go:33] FLAG: --min-resync-period="3m0s"
I0416 21:02:58.018940       1 flags.go:33] FLAG: --namespace-sync-period="5m0s"
I0416 21:02:58.018943       1 flags.go:33] FLAG: --node-cidr-mask-size="24"
I0416 21:02:58.018950       1 flags.go:33] FLAG: --node-eviction-rate="0.1"
I0416 21:02:58.018954       1 flags.go:33] FLAG: --node-monitor-grace-period="40s"
I0416 21:02:58.018957       1 flags.go:33] FLAG: --node-monitor-period="5s"
I0416 21:02:58.018959       1 flags.go:33] FLAG: --node-startup-grace-period="1m0s"
I0416 21:02:58.018965       1 flags.go:33] FLAG: --node-sync-period="0s"
I0416 21:02:58.018968       1 flags.go:33] FLAG: --pod-eviction-timeout="5m0s"
I0416 21:02:58.018970       1 flags.go:33] FLAG: --port="10252"
I0416 21:02:58.018974       1 flags.go:33] FLAG: --profiling="false"
I0416 21:02:58.018976       1 flags.go:33] FLAG: --pv-recycler-increment-timeout-nfs="30"
I0416 21:02:58.018979       1 flags.go:33] FLAG: --pv-recycler-minimum-timeout-hostpath="60"
I0416 21:02:58.018981       1 flags.go:33] FLAG: --pv-recycler-minimum-timeout-nfs="300"
I0416 21:02:58.018987       1 flags.go:33] FLAG: --pv-recycler-pod-template-filepath-hostpath="/home/kubernetes/kube-manifests/kubernetes/pv-recycler-template.yaml"
I0416 21:02:58.018991       1 flags.go:33] FLAG: --pv-recycler-pod-template-filepath-nfs="/home/kubernetes/kube-manifests/kubernetes/pv-recycler-template.yaml"
I0416 21:02:58.018995       1 flags.go:33] FLAG: --pv-recycler-timeout-increment-hostpath="30"
I0416 21:02:58.018997       1 flags.go:33] FLAG: --pvclaimbinder-sync-period="15s"
I0416 21:02:58.019002       1 flags.go:33] FLAG: --register-retry-count="10"
I0416 21:02:58.019005       1 flags.go:33] FLAG: --requestheader-allowed-names="[]"
I0416 21:02:58.019010       1 flags.go:33] FLAG: --requestheader-client-ca-file=""
I0416 21:02:58.019016       1 flags.go:33] FLAG: --requestheader-extra-headers-prefix="[x-remote-extra-]"
I0416 21:02:58.019026       1 flags.go:33] FLAG: --requestheader-group-headers="[x-remote-group]"
I0416 21:02:58.019033       1 flags.go:33] FLAG: --requestheader-username-headers="[x-remote-user]"
I0416 21:02:58.019040       1 flags.go:33] FLAG: --resource-quota-sync-period="5m0s"
I0416 21:02:58.019043       1 flags.go:33] FLAG: --root-ca-file="/etc/srv/kubernetes/pki/ca-certificates.crt"
I0416 21:02:58.019049       1 flags.go:33] FLAG: --route-reconciliation-period="10s"
I0416 21:02:58.019051       1 flags.go:33] FLAG: --secondary-node-eviction-rate="0.01"
I0416 21:02:58.019058       1 flags.go:33] FLAG: --secure-port="10257"
I0416 21:02:58.019061       1 flags.go:33] FLAG: --service-account-private-key-file="/etc/srv/kubernetes/pki/serviceaccount.key"
I0416 21:02:58.019064       1 flags.go:33] FLAG: --service-cluster-ip-range="10.0.0.0/16"
I0416 21:02:58.019066       1 flags.go:33] FLAG: --skip-headers="false"
I0416 21:02:58.019069       1 flags.go:33] FLAG: --stderrthreshold="2"
I0416 21:02:58.019071       1 flags.go:33] FLAG: --terminated-pod-gc-threshold="100"
I0416 21:02:58.019074       1 flags.go:33] FLAG: --tls-cert-file=""
I0416 21:02:58.019079       1 flags.go:33] FLAG: --tls-cipher-suites="[]"
I0416 21:02:58.019085       1 flags.go:33] FLAG: --tls-min-version=""
I0416 21:02:58.019087       1 flags.go:33] FLAG: --tls-private-key-file=""
I0416 21:02:58.019090       1 flags.go:33] FLAG: --tls-sni-cert-key="[]"
I0416 21:02:58.019095       1 flags.go:33] FLAG: --unhealthy-zone-threshold="0.55"
I0416 21:02:58.019098       1 flags.go:33] FLAG: --use-service-account-credentials="true"
I0416 21:02:58.019101       1 flags.go:33] FLAG: --v="4"
I0416 21:02:58.019106       1 flags.go:33] FLAG: --version="false"
I0416 21:02:58.019112       1 flags.go:33] FLAG: --vmodule=""
Log file created at: 2019/04/16 21:03:02
Running on machine: e2e-test-peterhornyack-master
Binary: Built with gc go1.12.1 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
W0416 21:03:02.292555       1 authentication.go:249] No authentication-kubeconfig provided in order to lookup client-ca-file in configmap/extension-apiserver-authentication in kube-system, so client certificate authentication won't work.
W0416 21:03:02.292728       1 authentication.go:252] No authentication-kubeconfig provided in order to lookup requestheader-client-ca-file in configmap/extension-apiserver-authentication in kube-system, so request-header client certificate authentication won't work.
W0416 21:03:02.292766       1 authorization.go:146] No authorization-kubeconfig provided, so SubjectAccessReview of authorization tokens won't work.
I0416 21:03:00.060028       1 serving.go:319] Generated self-signed cert in-memory
W0416 21:03:02.292555       1 authentication.go:249] No authentication-kubeconfig provided in order to lookup client-ca-file in configmap/extension-apiserver-authentication in kube-system, so client certificate authentication won't work.
W0416 21:03:02.292728       1 authentication.go:252] No authentication-kubeconfig provided in order to lookup requestheader-client-ca-file in configmap/extension-apiserver-authentication in kube-system, so request-header client certificate authentication won't work.
W0416 21:03:02.292766       1 authorization.go:146] No authorization-kubeconfig provided, so SubjectAccessReview of authorization tokens won't work.
I0416 21:03:02.292796       1 controllermanager.go:161] Version: v1.15.0-alpha.0.1887+bae0630ef897d6-dirty
I0416 21:03:02.299485       1 secure_serving.go:116] Serving securely on [::]:10257
I0416 21:03:02.299863       1 deprecated_insecure_serving.go:51] Serving insecurely on [::]:10252
I0416 21:03:02.299923       1 leaderelection.go:217] attempting to acquire leader lease  kube-system/kube-controller-manager...
Log file created at: 2019/04/16 21:03:12
Running on machine: e2e-test-peterhornyack-master
Binary: Built with gc go1.12.1 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
E0416 21:03:12.300459       1 leaderelection.go:306] error retrieving resource lock kube-system/kube-controller-manager: Get https://localhost:443/api/v1/namespaces/kube-system/endpoints/kube-controller-manager?timeout=10s: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
E0416 21:03:12.300459       1 leaderelection.go:306] error retrieving resource lock kube-system/kube-controller-manager: Get https://localhost:443/api/v1/namespaces/kube-system/endpoints/kube-controller-manager?timeout=10s: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
E0416 21:03:12.300459       1 leaderelection.go:306] error retrieving resource lock kube-system/kube-controller-manager: Get https://localhost:443/api/v1/namespaces/kube-system/endpoints/kube-controller-manager?timeout=10s: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
I0416 21:03:12.370581       1 leaderelection.go:222] failed to acquire lease kube-system/kube-controller-manager
I0416 21:03:15.607775       1 wrap.go:47] GET /healthz: (102.48µs) 200 [kube-probe/1.15+ 127.0.0.1:35118]
E0416 21:03:24.713571       1 leaderelection.go:306] error retrieving resource lock kube-system/kube-controller-manager: Get https://localhost:443/api/v1/namespaces/kube-system/endpoints/kube-controller-manager?timeout=10s: net/http: TLS handshake timeout
E0416 21:03:24.713571       1 leaderelection.go:306] error retrieving resource lock kube-system/kube-controller-manager: Get https://localhost:443/api/v1/namespaces/kube-system/endpoints/kube-controller-manager?timeout=10s: net/http: TLS handshake timeout
E0416 21:03:24.713571       1 leaderelection.go:306] error retrieving resource lock kube-system/kube-controller-manager: Get https://localhost:443/api/v1/namespaces/kube-system/endpoints/kube-controller-manager?timeout=10s: net/http: TLS handshake timeout
I0416 21:03:24.713895       1 leaderelection.go:222] failed to acquire lease kube-system/kube-controller-manager
I0416 21:03:25.609216       1 wrap.go:47] GET /healthz: (89.267µs) 200 [kube-probe/1.15+ 127.0.0.1:35402]
I0416 21:03:27.906615       1 leaderelection.go:227] successfully acquired lease kube-system/kube-controller-manager
I0416 21:03:27.907363       1 event.go:258] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"kube-controller-manager", UID:"7dbfc919-2a6b-4d6f-a875-a712730da892", APIVersion:"v1", ResourceVersion:"139", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' e2e-test-peterhornyack-master_0bda5ac0-96e3-465e-81c8-05ae581c5104 became leader
I0416 21:03:27.911127       1 controllermanager.go:210] using dynamic client builder
W0416 21:03:29.277291       1 plugins.go:118] WARNING: gce built-in cloud provider is now deprecated. The GCE provider is deprecated and will be removed in a future release
W0416 21:03:30.169064       1 controllermanager.go:515] Skipping "root-ca-cert-publisher"
W0416 21:03:30.575885       1 controllermanager.go:515] Skipping "ttl-after-finished"
W0416 21:03:30.575903       1 controllermanager.go:515] Skipping "route"
W0416 21:03:31.293890       1 controllermanager.go:502] "tokencleaner" is disabled
I0416 21:03:29.024685       1 request.go:530] Throttling request took 83.873981ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:03:29.074681       1 request.go:530] Throttling request took 133.801868ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:03:29.124835       1 request.go:530] Throttling request took 183.930145ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:03:29.174785       1 request.go:530] Throttling request took 233.873609ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:03:29.224670       1 request.go:530] Throttling request took 283.617129ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:03:29.275343       1 request.go:530] Throttling request took 334.152796ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
W0416 21:03:29.277291       1 plugins.go:118] WARNING: gce built-in cloud provider is now deprecated. The GCE provider is deprecated and will be removed in a future release
I0416 21:03:29.277551       1 gce.go:261] Using GCE provider config &{Global:{TokenURL: TokenBody: ProjectID:peterhornyack-prod-no-enforcer NetworkProjectID:peterhornyack-prod-no-enforcer NetworkName:e2e-test-peterhornyack SubnetworkName:e2e-test-peterhornyack-subnet-default SecondaryRangeName: NodeTags:[e2e-test-peterhornyack-minion] NodeInstancePrefix:e2e-test-peterhornyack-minion Regional:false Multizone:false APIEndpoint: ContainerAPIEndpoint: LocalZone: AlphaFeatures:[]}}
I0416 21:03:29.285388       1 gce.go:872] Using existing Token Source &oauth2.reuseTokenSource{new:google.computeSource{account:""}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
I0416 21:03:29.288453       1 gce.go:872] Using existing Token Source &oauth2.reuseTokenSource{new:google.computeSource{account:""}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(0xc000080b40)}
I0416 21:03:29.288486       1 gce.go:872] Using existing Token Source &oauth2.reuseTokenSource{new:google.computeSource{account:""}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(0xc000080b40)}
I0416 21:03:29.288574       1 gce.go:691] Setting up informers for Cloud
I0416 21:03:29.290327       1 reflector.go:128] Starting reflector *v1.Secret (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:29.290345       1 reflector.go:166] Listing and watching *v1.Secret from k8s.io/client-go/informers/factory.go:133
I0416 21:03:29.292304       1 controller_utils.go:1028] Waiting for caches to sync for tokens controller
I0416 21:03:29.292484       1 reflector.go:128] Starting reflector *v1.Node (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:29.292497       1 reflector.go:166] Listing and watching *v1.Node from k8s.io/client-go/informers/factory.go:133
I0416 21:03:29.292810       1 reflector.go:128] Starting reflector *v1.ServiceAccount (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:29.292828       1 reflector.go:166] Listing and watching *v1.ServiceAccount from k8s.io/client-go/informers/factory.go:133
I0416 21:03:29.307172       1 controllermanager.go:508] Starting "job"
I0416 21:03:29.307634       1 reflector.go:128] Starting reflector *v1.ConfigMap (10m0s) from pkg/cloudprovider/providers/gce/gce_clusterid.go:116
I0416 21:03:29.307650       1 reflector.go:166] Listing and watching *v1.ConfigMap from pkg/cloudprovider/providers/gce/gce_clusterid.go:116
I0416 21:03:29.325550       1 controllermanager.go:523] Started "job"
I0416 21:03:29.325575       1 controllermanager.go:508] Starting "horizontalpodautoscaling"
I0416 21:03:29.325690       1 job_controller.go:143] Starting job controller
I0416 21:03:29.325708       1 controller_utils.go:1028] Waiting for caches to sync for job controller
I0416 21:03:29.340765       1 controllermanager.go:523] Started "horizontalpodautoscaling"
I0416 21:03:29.340777       1 controllermanager.go:508] Starting "cloud-node-lifecycle"
I0416 21:03:29.340904       1 horizontal.go:156] Starting HPA controller
I0416 21:03:29.340923       1 controller_utils.go:1028] Waiting for caches to sync for HPA controller
I0416 21:03:29.346855       1 node_lifecycle_controller.go:77] Sending events to api server
I0416 21:03:29.346923       1 controllermanager.go:523] Started "cloud-node-lifecycle"
I0416 21:03:29.346931       1 controllermanager.go:508] Starting "clusterrole-aggregation"
I0416 21:03:29.353871       1 controllermanager.go:523] Started "clusterrole-aggregation"
I0416 21:03:29.353897       1 controllermanager.go:508] Starting "garbagecollector"
I0416 21:03:29.354022       1 clusterroleaggregation_controller.go:148] Starting ClusterRoleAggregator
I0416 21:03:29.354059       1 controller_utils.go:1028] Waiting for caches to sync for ClusterRoleAggregator controller
I0416 21:03:29.392566       1 shared_informer.go:123] caches populated
I0416 21:03:29.392578       1 controller_utils.go:1035] Caches are synced for tokens controller
I0416 21:03:29.802507       1 gce_clusterid.go:88] Observed new configmap for clusteriD: ingress-uid, map[uid:cc0039cb351b3f22]; setting local values
I0416 21:03:29.813372       1 gce_clusterid.go:107] Observed updated configmap for clusteriD ingress-uid, map[provider-uid:cc0039cb351b3f22 uid:cc0039cb351b3f22]; setting local values
I0416 21:03:30.072772       1 graph_builder.go:179] using a shared informer for resource "batch/v1beta1, Resource=cronjobs", kind "batch/v1beta1, Kind=CronJob"
I0416 21:03:30.072863       1 graph_builder.go:179] using a shared informer for resource "policy/v1beta1, Resource=podsecuritypolicies", kind "policy/v1beta1, Kind=PodSecurityPolicy"
I0416 21:03:30.072923       1 graph_builder.go:179] using a shared informer for resource "rbac.authorization.k8s.io/v1, Resource=clusterroles", kind "rbac.authorization.k8s.io/v1, Kind=ClusterRole"
I0416 21:03:30.072977       1 graph_builder.go:179] using a shared informer for resource "autoscaling/v1, Resource=horizontalpodautoscalers", kind "autoscaling/v1, Kind=HorizontalPodAutoscaler"
I0416 21:03:30.073011       1 graph_builder.go:179] using a shared informer for resource "networking.k8s.io/v1beta1, Resource=ingresses", kind "networking.k8s.io/v1beta1, Kind=Ingress"
I0416 21:03:30.073057       1 graph_builder.go:179] using a shared informer for resource "rbac.authorization.k8s.io/v1, Resource=roles", kind "rbac.authorization.k8s.io/v1, Kind=Role"
I0416 21:03:30.073092       1 graph_builder.go:179] using a shared informer for resource "rbac.authorization.k8s.io/v1, Resource=clusterrolebindings", kind "rbac.authorization.k8s.io/v1, Kind=ClusterRoleBinding"
I0416 21:03:30.075378       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=replicationcontrollers", kind "/v1, Kind=ReplicationController"
I0416 21:03:30.075449       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=configmaps", kind "/v1, Kind=ConfigMap"
I0416 21:03:30.075503       1 graph_builder.go:179] using a shared informer for resource "extensions/v1beta1, Resource=daemonsets", kind "extensions/v1beta1, Kind=DaemonSet"
I0416 21:03:30.075543       1 graph_builder.go:179] using a shared informer for resource "apps/v1, Resource=deployments", kind "apps/v1, Kind=Deployment"
I0416 21:03:30.075593       1 graph_builder.go:179] using a shared informer for resource "admissionregistration.k8s.io/v1beta1, Resource=mutatingwebhookconfigurations", kind "admissionregistration.k8s.io/v1beta1, Kind=MutatingWebhookConfiguration"
I0416 21:03:30.075627       1 graph_builder.go:179] using a shared informer for resource "admissionregistration.k8s.io/v1beta1, Resource=validatingwebhookconfigurations", kind "admissionregistration.k8s.io/v1beta1, Kind=ValidatingWebhookConfiguration"
I0416 21:03:30.075678       1 graph_builder.go:179] using a shared informer for resource "coordination.k8s.io/v1, Resource=leases", kind "coordination.k8s.io/v1, Kind=Lease"
I0416 21:03:30.075711       1 graph_builder.go:179] using a shared informer for resource "extensions/v1beta1, Resource=deployments", kind "extensions/v1beta1, Kind=Deployment"
I0416 21:03:30.075759       1 graph_builder.go:179] using a shared informer for resource "events.k8s.io/v1beta1, Resource=events", kind "events.k8s.io/v1beta1, Kind=Event"
I0416 21:03:30.075820       1 graph_builder.go:179] using a shared informer for resource "node.k8s.io/v1beta1, Resource=runtimeclasses", kind "node.k8s.io/v1beta1, Kind=RuntimeClass"
I0416 21:03:30.075870       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=persistentvolumes", kind "/v1, Kind=PersistentVolume"
I0416 21:03:30.075936       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=persistentvolumeclaims", kind "/v1, Kind=PersistentVolumeClaim"
I0416 21:03:30.075991       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=namespaces", kind "/v1, Kind=Namespace"
I0416 21:03:30.076035       1 graph_builder.go:184] unable to use a shared informer for resource "apiregistration.k8s.io/v1, Resource=apiservices", kind "apiregistration.k8s.io/v1, Kind=APIService": no informer found for apiregistration.k8s.io/v1, Resource=apiservices
I0416 21:03:30.076085       1 graph_builder.go:179] using a shared informer for resource "storage.k8s.io/v1beta1, Resource=csidrivers", kind "storage.k8s.io/v1beta1, Kind=CSIDriver"
I0416 21:03:30.076124       1 graph_builder.go:179] using a shared informer for resource "storage.k8s.io/v1beta1, Resource=csinodes", kind "storage.k8s.io/v1beta1, Kind=CSINode"
I0416 21:03:30.076180       1 graph_builder.go:179] using a shared informer for resource "extensions/v1beta1, Resource=networkpolicies", kind "extensions/v1beta1, Kind=NetworkPolicy"
I0416 21:03:30.076215       1 graph_builder.go:179] using a shared informer for resource "extensions/v1beta1, Resource=ingresses", kind "extensions/v1beta1, Kind=Ingress"
I0416 21:03:30.076263       1 graph_builder.go:179] using a shared informer for resource "apps/v1, Resource=daemonsets", kind "apps/v1, Kind=DaemonSet"
I0416 21:03:30.076325       1 graph_builder.go:179] using a shared informer for resource "policy/v1beta1, Resource=poddisruptionbudgets", kind "policy/v1beta1, Kind=PodDisruptionBudget"
I0416 21:03:30.076368       1 graph_builder.go:179] using a shared informer for resource "scheduling.k8s.io/v1, Resource=priorityclasses", kind "scheduling.k8s.io/v1, Kind=PriorityClass"
I0416 21:03:30.076427       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=serviceaccounts", kind "/v1, Kind=ServiceAccount"
I0416 21:03:30.076504       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=resourcequotas", kind "/v1, Kind=ResourceQuota"
I0416 21:03:30.076534       1 graph_builder.go:179] using a shared informer for resource "settings.k8s.io/v1alpha1, Resource=podpresets", kind "settings.k8s.io/v1alpha1, Kind=PodPreset"
I0416 21:03:30.076586       1 graph_builder.go:179] using a shared informer for resource "storage.k8s.io/v1, Resource=storageclasses", kind "storage.k8s.io/v1, Kind=StorageClass"
I0416 21:03:30.076618       1 graph_builder.go:179] using a shared informer for resource "apps/v1, Resource=replicasets", kind "apps/v1, Kind=ReplicaSet"
I0416 21:03:30.076667       1 graph_builder.go:179] using a shared informer for resource "apps/v1, Resource=controllerrevisions", kind "apps/v1, Kind=ControllerRevision"
I0416 21:03:30.076695       1 graph_builder.go:179] using a shared informer for resource "batch/v1, Resource=jobs", kind "batch/v1, Kind=Job"
I0416 21:03:30.076739       1 graph_builder.go:184] unable to use a shared informer for resource "apiextensions.k8s.io/v1beta1, Resource=customresourcedefinitions", kind "apiextensions.k8s.io/v1beta1, Kind=CustomResourceDefinition": no informer found for apiextensions.k8s.io/v1beta1, Resource=customresourcedefinitions
I0416 21:03:30.076781       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=limitranges", kind "/v1, Kind=LimitRange"
I0416 21:03:30.076836       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=pods", kind "/v1, Kind=Pod"
I0416 21:03:30.079291       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=endpoints", kind "/v1, Kind=Endpoints"
I0416 21:03:30.079377       1 graph_builder.go:179] using a shared informer for resource "extensions/v1beta1, Resource=podsecuritypolicies", kind "extensions/v1beta1, Kind=PodSecurityPolicy"
I0416 21:03:30.079431       1 graph_builder.go:179] using a shared informer for resource "certificates.k8s.io/v1beta1, Resource=certificatesigningrequests", kind "certificates.k8s.io/v1beta1, Kind=CertificateSigningRequest"
I0416 21:03:30.079476       1 graph_builder.go:179] using a shared informer for resource "storage.k8s.io/v1, Resource=volumeattachments", kind "storage.k8s.io/v1, Kind=VolumeAttachment"
I0416 21:03:30.079550       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=services", kind "/v1, Kind=Service"
I0416 21:03:30.079604       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=secrets", kind "/v1, Kind=Secret"
I0416 21:03:30.084488       1 graph_builder.go:179] using a shared informer for resource "apps/v1, Resource=statefulsets", kind "apps/v1, Kind=StatefulSet"
I0416 21:03:30.084574       1 graph_builder.go:179] using a shared informer for resource "rbac.authorization.k8s.io/v1, Resource=rolebindings", kind "rbac.authorization.k8s.io/v1, Kind=RoleBinding"
I0416 21:03:30.084641       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=podtemplates", kind "/v1, Kind=PodTemplate"
I0416 21:03:30.084698       1 graph_builder.go:179] using a shared informer for resource "/v1, Resource=nodes", kind "/v1, Kind=Node"
I0416 21:03:30.084751       1 graph_builder.go:179] using a shared informer for resource "extensions/v1beta1, Resource=replicasets", kind "extensions/v1beta1, Kind=ReplicaSet"
I0416 21:03:30.084786       1 graph_builder.go:179] using a shared informer for resource "networking.k8s.io/v1, Resource=networkpolicies", kind "networking.k8s.io/v1, Kind=NetworkPolicy"
I0416 21:03:30.084803       1 graph_builder.go:248] synced monitors; added 50, kept 0, removed 0
I0416 21:03:30.084921       1 controllermanager.go:523] Started "garbagecollector"
I0416 21:03:30.084929       1 controllermanager.go:508] Starting "deployment"
I0416 21:03:30.085353       1 garbagecollector.go:130] Starting garbage collector controller
I0416 21:03:30.085374       1 controller_utils.go:1028] Waiting for caches to sync for garbage collector controller
I0416 21:03:30.085392       1 graph_builder.go:308] GraphBuilder running
I0416 21:03:30.126699       1 controllermanager.go:523] Started "deployment"
I0416 21:03:30.126731       1 controllermanager.go:508] Starting "ttl"
I0416 21:03:30.126889       1 deployment_controller.go:152] Starting deployment controller
I0416 21:03:30.126923       1 controller_utils.go:1028] Waiting for caches to sync for deployment controller
I0416 21:03:30.164318       1 request.go:530] Throttling request took 68.127132ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:03:30.169044       1 controllermanager.go:523] Started "ttl"
I0416 21:03:30.169057       1 controllermanager.go:508] Starting "root-ca-cert-publisher"
W0416 21:03:30.169064       1 controllermanager.go:515] Skipping "root-ca-cert-publisher"
I0416 21:03:30.169082       1 controllermanager.go:508] Starting "resourcequota"
I0416 21:03:30.169196       1 ttl_controller.go:116] Starting TTL controller
I0416 21:03:30.169215       1 controller_utils.go:1028] Waiting for caches to sync for TTL controller
I0416 21:03:30.215807       1 request.go:530] Throttling request took 119.603949ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:03:30.264284       1 request.go:530] Throttling request took 168.03642ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:03:30.270330       1 shared_informer.go:123] caches populated
I0416 21:03:30.270359       1 controller_utils.go:1035] Caches are synced for TTL controller
I0416 21:03:30.313138       1 request.go:530] Throttling request took 216.897693ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:03:30.350877       1 request.go:530] Throttling request took 93.850317ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:03:30.362957       1 request.go:530] Throttling request took 266.703293ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:03:30.401345       1 request.go:530] Throttling request took 144.274143ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:03:30.413367       1 request.go:530] Throttling request took 316.988134ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:03:30.450942       1 request.go:530] Throttling request took 193.825976ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:03:30.463311       1 request.go:530] Throttling request took 367.057997ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:03:30.500771       1 request.go:530] Throttling request took 243.688905ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:03:30.512917       1 request.go:530] Throttling request took 416.661083ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:03:30.550764       1 request.go:530] Throttling request took 293.673702ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:03:30.552814       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=persistentvolumeclaims"
I0416 21:03:30.552850       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=resourcequotas"
I0416 21:03:30.552866       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=endpoints"
I0416 21:03:30.552894       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for endpoints
I0416 21:03:30.552910       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=services"
I0416 21:03:30.552923       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "batch/v1, Resource=jobs"
I0416 21:03:30.553007       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for jobs.batch
I0416 21:03:30.553027       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "rbac.authorization.k8s.io/v1, Resource=rolebindings"
I0416 21:03:30.553037       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for rolebindings.rbac.authorization.k8s.io
I0416 21:03:30.553067       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "extensions/v1beta1, Resource=networkpolicies"
I0416 21:03:30.553077       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for networkpolicies.extensions
I0416 21:03:30.553087       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "networking.k8s.io/v1beta1, Resource=ingresses"
I0416 21:03:30.553096       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for ingresses.networking.k8s.io
I0416 21:03:30.553104       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=limitranges"
I0416 21:03:30.553115       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for limitranges
I0416 21:03:30.553139       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "batch/v1beta1, Resource=cronjobs"
I0416 21:03:30.553157       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for cronjobs.batch
I0416 21:03:30.553171       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "settings.k8s.io/v1alpha1, Resource=podpresets"
I0416 21:03:30.553185       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for podpresets.settings.k8s.io
I0416 21:03:30.553193       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "autoscaling/v1, Resource=horizontalpodautoscalers"
I0416 21:03:30.553205       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for horizontalpodautoscalers.autoscaling
I0416 21:03:30.553280       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "policy/v1beta1, Resource=poddisruptionbudgets"
I0416 21:03:30.553307       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for poddisruptionbudgets.policy
I0416 21:03:30.553316       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "rbac.authorization.k8s.io/v1, Resource=roles"
I0416 21:03:30.553325       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for roles.rbac.authorization.k8s.io
I0416 21:03:30.553342       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=replicationcontrollers"
I0416 21:03:30.554056       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "extensions/v1beta1, Resource=ingresses"
I0416 21:03:30.554084       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for ingresses.extensions
I0416 21:03:30.554098       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "extensions/v1beta1, Resource=daemonsets"
I0416 21:03:30.554109       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for daemonsets.extensions
I0416 21:03:30.554144       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "apps/v1, Resource=statefulsets"
I0416 21:03:30.554154       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for statefulsets.apps
I0416 21:03:30.554167       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=pods"
I0416 21:03:30.554218       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "extensions/v1beta1, Resource=replicasets"
I0416 21:03:30.554252       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for replicasets.extensions
I0416 21:03:30.554260       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "apps/v1, Resource=deployments"
I0416 21:03:30.554269       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for deployments.apps
I0416 21:03:30.554279       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "networking.k8s.io/v1, Resource=networkpolicies"
I0416 21:03:30.554301       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for networkpolicies.networking.k8s.io
I0416 21:03:30.554311       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "coordination.k8s.io/v1, Resource=leases"
I0416 21:03:30.554333       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for leases.coordination.k8s.io
I0416 21:03:30.554342       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=configmaps"
I0416 21:03:30.554354       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=serviceaccounts"
I0416 21:03:30.554400       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for serviceaccounts
I0416 21:03:30.554408       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "extensions/v1beta1, Resource=deployments"
I0416 21:03:30.554430       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for deployments.extensions
I0416 21:03:30.554443       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "apps/v1, Resource=controllerrevisions"
I0416 21:03:30.554476       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for controllerrevisions.apps
I0416 21:03:30.554493       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "apps/v1, Resource=replicasets"
I0416 21:03:30.554502       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for replicasets.apps
I0416 21:03:30.554514       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "events.k8s.io/v1beta1, Resource=events"
I0416 21:03:30.554522       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for events.events.k8s.io
I0416 21:03:30.554529       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=podtemplates"
I0416 21:03:30.554555       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for podtemplates
I0416 21:03:30.554563       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "/v1, Resource=secrets"
I0416 21:03:30.554610       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "apps/v1, Resource=daemonsets"
I0416 21:03:30.554635       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for daemonsets.apps
I0416 21:03:30.554641       1 resource_quota_monitor.go:243] quota synced monitors; added 32, kept 0, removed 0
I0416 21:03:30.554652       1 controllermanager.go:523] Started "resourcequota"
I0416 21:03:30.554659       1 controllermanager.go:508] Starting "serviceaccount"
I0416 21:03:30.554924       1 resource_quota_controller.go:271] Starting resource quota controller
I0416 21:03:30.554967       1 controller_utils.go:1028] Waiting for caches to sync for resource quota controller
I0416 21:03:30.554991       1 resource_quota_monitor.go:303] QuotaMonitor running
I0416 21:03:30.563108       1 request.go:530] Throttling request took 466.816057ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:03:30.565040       1 controllermanager.go:523] Started "serviceaccount"
I0416 21:03:30.565052       1 controllermanager.go:508] Starting "nodelifecycle"
I0416 21:03:30.565210       1 serviceaccounts_controller.go:115] Starting service account controller
I0416 21:03:30.565252       1 controller_utils.go:1028] Waiting for caches to sync for service account controller
I0416 21:03:30.574812       1 node_lifecycle_controller.go:290] Sending events to api server.
I0416 21:03:30.575006       1 node_lifecycle_controller.go:323] Controller is using taint based evictions.
I0416 21:03:30.575042       1 taint_manager.go:175] Sending events to api server.
I0416 21:03:30.575826       1 node_lifecycle_controller.go:388] Controller will reconcile labels.
I0416 21:03:30.575845       1 node_lifecycle_controller.go:401] Controller will taint node by condition.
I0416 21:03:30.575872       1 controllermanager.go:523] Started "nodelifecycle"
I0416 21:03:30.575880       1 controllermanager.go:508] Starting "ttl-after-finished"
W0416 21:03:30.575885       1 controllermanager.go:515] Skipping "ttl-after-finished"
I0416 21:03:30.575890       1 controllermanager.go:508] Starting "route"
I0416 21:03:30.575898       1 core.go:170] Will not configure cloud provider routes for allocate-node-cidrs: true, configure-cloud-routes: false.
W0416 21:03:30.575903       1 controllermanager.go:515] Skipping "route"
I0416 21:03:30.575905       1 controllermanager.go:508] Starting "persistentvolume-binder"
I0416 21:03:30.576071       1 node_lifecycle_controller.go:425] Starting node controller
I0416 21:03:30.576091       1 controller_utils.go:1028] Waiting for caches to sync for taint controller
I0416 21:03:30.621239       1 request.go:530] Throttling request took 524.913694ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:03:30.625847       1 plugins.go:603] Loaded volume plugin "kubernetes.io/host-path"
I0416 21:03:30.625862       1 plugins.go:603] Loaded volume plugin "kubernetes.io/nfs"
I0416 21:03:30.625871       1 plugins.go:603] Loaded volume plugin "kubernetes.io/glusterfs"
I0416 21:03:30.625882       1 plugins.go:603] Loaded volume plugin "kubernetes.io/rbd"
I0416 21:03:30.625889       1 plugins.go:603] Loaded volume plugin "kubernetes.io/quobyte"
I0416 21:03:30.625896       1 plugins.go:603] Loaded volume plugin "kubernetes.io/azure-file"
I0416 21:03:30.625902       1 plugins.go:603] Loaded volume plugin "kubernetes.io/flocker"
I0416 21:03:30.625926       1 plugins.go:603] Loaded volume plugin "kubernetes.io/portworx-volume"
I0416 21:03:30.625935       1 plugins.go:603] Loaded volume plugin "kubernetes.io/scaleio"
I0416 21:03:30.625955       1 plugins.go:603] Loaded volume plugin "kubernetes.io/local-volume"
I0416 21:03:30.625961       1 plugins.go:603] Loaded volume plugin "kubernetes.io/storageos"
I0416 21:03:30.625967       1 plugins.go:603] Loaded volume plugin "kubernetes.io/aws-ebs"
I0416 21:03:30.625973       1 plugins.go:603] Loaded volume plugin "kubernetes.io/gce-pd"
I0416 21:03:30.625999       1 plugins.go:603] Loaded volume plugin "kubernetes.io/cinder"
I0416 21:03:30.626006       1 plugins.go:603] Loaded volume plugin "kubernetes.io/vsphere-volume"
I0416 21:03:30.626013       1 plugins.go:603] Loaded volume plugin "kubernetes.io/azure-disk"
I0416 21:03:30.626019       1 plugins.go:603] Loaded volume plugin "kubernetes.io/photon-pd"
I0416 21:03:30.626088       1 controllermanager.go:523] Started "persistentvolume-binder"
I0416 21:03:30.626098       1 controllermanager.go:508] Starting "attachdetach"
I0416 21:03:30.626303       1 pv_controller_base.go:270] Starting persistent volume controller
I0416 21:03:30.626322       1 controller_utils.go:1028] Waiting for caches to sync for persistent volume controller
I0416 21:03:30.626345       1 request.go:530] Throttling request took 71.437811ms, request: GET:https://localhost:443/api?timeout=32s
I0416 21:03:30.647735       1 plugins.go:603] Loaded volume plugin "kubernetes.io/aws-ebs"
I0416 21:03:30.647750       1 plugins.go:603] Loaded volume plugin "kubernetes.io/gce-pd"
I0416 21:03:30.647757       1 plugins.go:603] Loaded volume plugin "kubernetes.io/cinder"
I0416 21:03:30.647772       1 plugins.go:603] Loaded volume plugin "kubernetes.io/portworx-volume"
I0416 21:03:30.647779       1 plugins.go:603] Loaded volume plugin "kubernetes.io/vsphere-volume"
I0416 21:03:30.647785       1 plugins.go:603] Loaded volume plugin "kubernetes.io/azure-disk"
I0416 21:03:30.647792       1 plugins.go:603] Loaded volume plugin "kubernetes.io/photon-pd"
I0416 21:03:30.647798       1 plugins.go:603] Loaded volume plugin "kubernetes.io/scaleio"
I0416 21:03:30.647819       1 plugins.go:603] Loaded volume plugin "kubernetes.io/storageos"
I0416 21:03:30.647826       1 plugins.go:603] Loaded volume plugin "kubernetes.io/fc"
I0416 21:03:30.647840       1 plugins.go:603] Loaded volume plugin "kubernetes.io/iscsi"
I0416 21:03:30.647847       1 plugins.go:603] Loaded volume plugin "kubernetes.io/rbd"
I0416 21:03:30.647870       1 plugins.go:603] Loaded volume plugin "kubernetes.io/csi"
I0416 21:03:30.648034       1 controllermanager.go:523] Started "attachdetach"
I0416 21:03:30.648054       1 controllermanager.go:508] Starting "replicaset"
I0416 21:03:30.648194       1 attach_detach_controller.go:323] Starting attach detach controller
I0416 21:03:30.648212       1 controller_utils.go:1028] Waiting for caches to sync for attach detach controller
I0416 21:03:30.649781       1 reflector.go:128] Starting reflector *v1beta1.CSIDriver (1m0s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:30.649797       1 reflector.go:166] Listing and watching *v1beta1.CSIDriver from k8s.io/client-go/informers/factory.go:133
I0416 21:03:30.664506       1 request.go:530] Throttling request took 568.188885ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:03:30.674450       1 controllermanager.go:523] Started "replicaset"
I0416 21:03:30.674465       1 controllermanager.go:508] Starting "statefulset"
I0416 21:03:30.674620       1 replica_set.go:182] Starting replicaset controller
I0416 21:03:30.674651       1 controller_utils.go:1028] Waiting for caches to sync for ReplicaSet controller
I0416 21:03:30.696936       1 controllermanager.go:523] Started "statefulset"
I0416 21:03:30.696972       1 controllermanager.go:508] Starting "cronjob"
I0416 21:03:30.697103       1 stateful_set.go:145] Starting stateful set controller
I0416 21:03:30.697135       1 controller_utils.go:1028] Waiting for caches to sync for stateful set controller
I0416 21:03:30.713351       1 request.go:530] Throttling request took 617.029133ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:03:30.714900       1 controllermanager.go:523] Started "cronjob"
I0416 21:03:30.714911       1 controllermanager.go:508] Starting "csrapproving"
I0416 21:03:30.714978       1 controller.go:96] Starting CronJob Manager
I0416 21:03:30.750784       1 request.go:530] Throttling request took 88.438761ms, request: GET:https://localhost:443/api/v1?timeout=32s
I0416 21:03:30.764173       1 request.go:530] Throttling request took 666.650227ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:03:30.790099       1 request.go:530] Throttling request took 74.907616ms, request: GET:https://localhost:443/api/v1/namespaces/kube-system/serviceaccounts/cronjob-controller
I0416 21:03:30.800748       1 request.go:530] Throttling request took 138.392298ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1?timeout=32s
I0416 21:03:30.813279       1 request.go:530] Throttling request took 716.889234ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:03:30.840948       1 request.go:530] Throttling request took 97.71864ms, request: GET:https://localhost:443/api/v1/namespaces/kube-system
I0416 21:03:30.850784       1 request.go:530] Throttling request took 188.420691ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1beta1?timeout=32s
I0416 21:03:30.863434       1 request.go:530] Throttling request took 766.990379ms, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:03:30.890334       1 request.go:530] Throttling request took 96.620865ms, request: POST:https://localhost:443/api/v1/namespaces/kube-system/serviceaccounts/cronjob-controller/token
I0416 21:03:30.902949       1 request.go:530] Throttling request took 240.576874ms, request: GET:https://localhost:443/apis/extensions/v1beta1?timeout=32s
I0416 21:03:30.939281       1 request.go:530] Throttling request took 842.85384ms, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:03:30.944773       1 controller.go:123] Found 0 jobs
I0416 21:03:30.944981       1 request.go:530] Throttling request took 101.08881ms, request: POST:https://localhost:443/api/v1/namespaces/kube-system/serviceaccounts
I0416 21:03:30.950306       1 controllermanager.go:523] Started "csrapproving"
I0416 21:03:30.950317       1 controllermanager.go:508] Starting "service"
I0416 21:03:30.950345       1 certificate_controller.go:113] Starting certificate controller
I0416 21:03:30.950362       1 controller_utils.go:1028] Waiting for caches to sync for certificate controller
I0416 21:03:30.952043       1 request.go:530] Throttling request took 289.681154ms, request: GET:https://localhost:443/apis/apps/v1?timeout=32s
I0416 21:03:30.953414       1 controller.go:139] Found 0 cronjobs
I0416 21:03:30.953423       1 controller.go:142] Found 0 groups
I0416 21:03:30.963785       1 request.go:530] Throttling request took 867.345674ms, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
I0416 21:03:31.000906       1 request.go:530] Throttling request took 338.517644ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:03:31.013360       1 request.go:530] Throttling request took 916.873992ms, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:03:31.051321       1 request.go:530] Throttling request took 388.928148ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:03:31.063345       1 request.go:530] Throttling request took 966.851025ms, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.096544       1 controllermanager.go:523] Started "service"
I0416 21:03:31.096569       1 controllermanager.go:508] Starting "podgc"
I0416 21:03:31.096599       1 service_controller.go:183] Starting service controller
I0416 21:03:31.096615       1 controller_utils.go:1028] Waiting for caches to sync for service controller
I0416 21:03:31.102011       1 request.go:530] Throttling request took 439.62992ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.113312       1 request.go:530] Throttling request took 1.016825114s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:03:31.150749       1 request.go:530] Throttling request took 488.337352ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:03:31.162946       1 request.go:530] Throttling request took 1.066441302s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:03:31.200808       1 request.go:530] Throttling request took 538.391628ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.213513       1 request.go:530] Throttling request took 1.117002119s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.247038       1 controllermanager.go:523] Started "podgc"
I0416 21:03:31.247064       1 controllermanager.go:508] Starting "csrcleaner"
I0416 21:03:31.247095       1 gc_controller.go:76] Starting GC controller
I0416 21:03:31.247112       1 controller_utils.go:1028] Waiting for caches to sync for GC controller
I0416 21:03:31.253137       1 request.go:530] Throttling request took 590.735775ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:03:31.262782       1 request.go:530] Throttling request took 1.166280365s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.293877       1 controllermanager.go:523] Started "csrcleaner"
W0416 21:03:31.293890       1 controllermanager.go:502] "tokencleaner" is disabled
I0416 21:03:31.293897       1 controllermanager.go:508] Starting "nodeipam"
I0416 21:03:31.293950       1 cleaner.go:81] Starting CSR cleaner controller
I0416 21:03:31.300763       1 request.go:530] Throttling request took 638.330303ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.313373       1 request.go:530] Throttling request took 1.216835758s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.343435       1 node_ipam_controller.go:99] Sending events to api server.
I0416 21:03:31.350746       1 request.go:530] Throttling request took 688.27314ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:03:31.363058       1 request.go:530] Throttling request took 1.266485081s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:03:31.401262       1 request.go:530] Throttling request took 738.792817ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:03:31.413262       1 request.go:530] Throttling request took 1.316678338s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.450682       1 request.go:530] Throttling request took 788.233702ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:03:31.463621       1 request.go:530] Throttling request took 1.367053486s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:03:31.500788       1 request.go:530] Throttling request took 838.308976ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:03:31.513412       1 request.go:530] Throttling request took 1.416838177s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:03:31.550759       1 request.go:530] Throttling request took 888.232897ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:03:31.562920       1 request.go:530] Throttling request took 1.466337682s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.566964       1 garbagecollector.go:201] syncing garbage collector with updated resources from discovery (attempt 1): added: [/v1, Resource=configmaps /v1, Resource=endpoints /v1, Resource=events /v1, Resource=limitranges /v1, Resource=namespaces /v1, Resource=nodes /v1, Resource=persistentvolumeclaims /v1, Resource=persistentvolumes /v1, Resource=pods /v1, Resource=podtemplates /v1, Resource=replicationcontrollers /v1, Resource=resourcequotas /v1, Resource=secrets /v1, Resource=serviceaccounts /v1, Resource=services admissionregistration.k8s.io/v1beta1, Resource=mutatingwebhookconfigurations admissionregistration.k8s.io/v1beta1, Resource=validatingwebhookconfigurations apiextensions.k8s.io/v1beta1, Resource=customresourcedefinitions apiregistration.k8s.io/v1, Resource=apiservices apps/v1, Resource=controllerrevisions apps/v1, Resource=daemonsets apps/v1, Resource=deployments apps/v1, Resource=replicasets apps/v1, Resource=statefulsets autoscaling/v1, Resource=horizontalpodautoscalers batch/v1, Resource=jobs batch/v1beta1, Resource=cronjobs certificates.k8s.io/v1beta1, Resource=certificatesigningrequests coordination.k8s.io/v1, Resource=leases events.k8s.io/v1beta1, Resource=events extensions/v1beta1, Resource=daemonsets extensions/v1beta1, Resource=deployments extensions/v1beta1, Resource=ingresses extensions/v1beta1, Resource=networkpolicies extensions/v1beta1, Resource=podsecuritypolicies extensions/v1beta1, Resource=replicasets networking.k8s.io/v1, Resource=networkpolicies networking.k8s.io/v1beta1, Resource=ingresses node.k8s.io/v1beta1, Resource=runtimeclasses policy/v1beta1, Resource=poddisruptionbudgets policy/v1beta1, Resource=podsecuritypolicies rbac.authorization.k8s.io/v1, Resource=clusterrolebindings rbac.authorization.k8s.io/v1, Resource=clusterroles rbac.authorization.k8s.io/v1, Resource=rolebindings rbac.authorization.k8s.io/v1, Resource=roles scheduling.k8s.io/v1, Resource=priorityclasses settings.k8s.io/v1alpha1, Resource=podpresets storage.k8s.io/v1, Resource=storageclasses storage.k8s.io/v1, Resource=volumeattachments storage.k8s.io/v1beta1, Resource=csidrivers storage.k8s.io/v1beta1, Resource=csinodes], removed: []
I0416 21:03:31.566980       1 garbagecollector.go:207] reset restmapper
I0416 21:03:31.600788       1 request.go:530] Throttling request took 938.255831ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:03:31.651333       1 request.go:530] Throttling request took 988.82819ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.701357       1 request.go:530] Throttling request took 1.038838439s, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:03:31.750709       1 request.go:530] Throttling request took 1.088196049s, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.800733       1 request.go:530] Throttling request took 1.138217306s, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
I0416 21:03:31.850797       1 request.go:530] Throttling request took 1.188170687s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:03:31.900737       1 request.go:530] Throttling request took 1.238182796s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:03:31.950659       1 request.go:530] Throttling request took 1.288102561s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:03:32.000868       1 request.go:530] Throttling request took 1.33829909s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:03:32.050707       1 request.go:530] Throttling request took 1.38813588s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:03:32.100764       1 request.go:530] Throttling request took 1.438184116s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
I0416 21:03:32.150736       1 request.go:530] Throttling request took 1.488152385s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:03:32.200728       1 request.go:530] Throttling request took 1.538138385s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:03:32.251334       1 request.go:530] Throttling request took 1.588732166s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:03:32.301311       1 request.go:530] Throttling request took 1.638692347s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:03:32.350704       1 request.go:530] Throttling request took 1.688079707s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:03:32.400806       1 request.go:530] Throttling request took 1.73817548s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:03:32.403365       1 resource_quota_controller.go:433] syncing resource quota controller with updated resources from discovery: added: [/v1, Resource=configmaps /v1, Resource=endpoints /v1, Resource=events /v1, Resource=limitranges /v1, Resource=persistentvolumeclaims /v1, Resource=pods /v1, Resource=podtemplates /v1, Resource=replicationcontrollers /v1, Resource=resourcequotas /v1, Resource=secrets /v1, Resource=serviceaccounts /v1, Resource=services apps/v1, Resource=controllerrevisions apps/v1, Resource=daemonsets apps/v1, Resource=deployments apps/v1, Resource=replicasets apps/v1, Resource=statefulsets autoscaling/v1, Resource=horizontalpodautoscalers batch/v1, Resource=jobs batch/v1beta1, Resource=cronjobs coordination.k8s.io/v1, Resource=leases events.k8s.io/v1beta1, Resource=events extensions/v1beta1, Resource=daemonsets extensions/v1beta1, Resource=deployments extensions/v1beta1, Resource=ingresses extensions/v1beta1, Resource=networkpolicies extensions/v1beta1, Resource=replicasets networking.k8s.io/v1, Resource=networkpolicies networking.k8s.io/v1beta1, Resource=ingresses policy/v1beta1, Resource=poddisruptionbudgets rbac.authorization.k8s.io/v1, Resource=rolebindings rbac.authorization.k8s.io/v1, Resource=roles settings.k8s.io/v1alpha1, Resource=podpresets], removed: []
I0416 21:03:35.609120       1 wrap.go:47] GET /healthz: (112.001µs) 200 [kube-probe/1.15+ 127.0.0.1:36086]
E0416 21:03:41.665166       1 prometheus.go:55] failed to register depth metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665586       1 prometheus.go:68] failed to register adds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665723       1 prometheus.go:82] failed to register latency metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665836       1 prometheus.go:96] failed to register workDuration metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665949       1 prometheus.go:112] failed to register unfinished metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667408       1 prometheus.go:126] failed to register unfinished metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667589       1 prometheus.go:152] failed to register depth metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667673       1 prometheus.go:164] failed to register adds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667780       1 prometheus.go:176] failed to register latency metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667883       1 prometheus.go:188] failed to register work_duration metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667985       1 prometheus.go:203] failed to register unfinished_work_seconds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668072       1 prometheus.go:216] failed to register longest_running_processor_microseconds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668210       1 prometheus.go:139] failed to register retries metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668300       1 prometheus.go:228] failed to register retries metric certificate: duplicate metrics collector registration attempted
E0416 21:03:42.073186       1 clusterroleaggregation_controller.go:180] edit failed with : Operation cannot be fulfilled on clusterroles.rbac.authorization.k8s.io "edit": the object has been modified; please apply your changes to the latest version and try again
W0416 21:03:41.539474       1 controllermanager.go:502] "bootstrapsigner" is disabled
E0416 21:03:41.665166       1 prometheus.go:55] failed to register depth metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665586       1 prometheus.go:68] failed to register adds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665723       1 prometheus.go:82] failed to register latency metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665836       1 prometheus.go:96] failed to register workDuration metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665949       1 prometheus.go:112] failed to register unfinished metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667408       1 prometheus.go:126] failed to register unfinished metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667589       1 prometheus.go:152] failed to register depth metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667673       1 prometheus.go:164] failed to register adds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667780       1 prometheus.go:176] failed to register latency metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667883       1 prometheus.go:188] failed to register work_duration metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667985       1 prometheus.go:203] failed to register unfinished_work_seconds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668072       1 prometheus.go:216] failed to register longest_running_processor_microseconds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668210       1 prometheus.go:139] failed to register retries metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668300       1 prometheus.go:228] failed to register retries metric certificate: duplicate metrics collector registration attempted
E0416 21:03:42.073186       1 clusterroleaggregation_controller.go:180] edit failed with : Operation cannot be fulfilled on clusterroles.rbac.authorization.k8s.io "edit": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:40.957470       1 controller.go:123] Found 0 jobs
I0416 21:03:40.959851       1 controller.go:139] Found 0 cronjobs
I0416 21:03:40.959862       1 controller.go:142] Found 0 groups
I0416 21:03:41.359821       1 cloud_cidr_allocator.go:92] Sending events to api server.
I0416 21:03:41.359929       1 cloud_cidr_allocator.go:129] Using cloud CIDR allocator (provider: gce)
I0416 21:03:41.359942       1 controllermanager.go:523] Started "nodeipam"
I0416 21:03:41.359952       1 controllermanager.go:508] Starting "persistentvolume-expander"
I0416 21:03:41.360131       1 node_ipam_controller.go:167] Starting ipam controller
I0416 21:03:41.360152       1 controller_utils.go:1028] Waiting for caches to sync for node controller
I0416 21:03:41.369626       1 plugins.go:603] Loaded volume plugin "kubernetes.io/aws-ebs"
I0416 21:03:41.369652       1 plugins.go:603] Loaded volume plugin "kubernetes.io/gce-pd"
I0416 21:03:41.369659       1 plugins.go:603] Loaded volume plugin "kubernetes.io/cinder"
I0416 21:03:41.369672       1 plugins.go:603] Loaded volume plugin "kubernetes.io/portworx-volume"
I0416 21:03:41.369679       1 plugins.go:603] Loaded volume plugin "kubernetes.io/vsphere-volume"
I0416 21:03:41.369685       1 plugins.go:603] Loaded volume plugin "kubernetes.io/glusterfs"
I0416 21:03:41.369692       1 plugins.go:603] Loaded volume plugin "kubernetes.io/rbd"
I0416 21:03:41.369698       1 plugins.go:603] Loaded volume plugin "kubernetes.io/azure-disk"
I0416 21:03:41.369706       1 plugins.go:603] Loaded volume plugin "kubernetes.io/azure-file"
I0416 21:03:41.369712       1 plugins.go:603] Loaded volume plugin "kubernetes.io/photon-pd"
I0416 21:03:41.369731       1 plugins.go:603] Loaded volume plugin "kubernetes.io/scaleio"
I0416 21:03:41.369736       1 plugins.go:603] Loaded volume plugin "kubernetes.io/storageos"
I0416 21:03:41.369743       1 plugins.go:603] Loaded volume plugin "kubernetes.io/fc"
I0416 21:03:41.369883       1 controllermanager.go:523] Started "persistentvolume-expander"
I0416 21:03:41.369891       1 controllermanager.go:508] Starting "endpoint"
I0416 21:03:41.370016       1 expand_controller.go:153] Starting expand controller
I0416 21:03:41.370056       1 controller_utils.go:1028] Waiting for caches to sync for expand controller
I0416 21:03:41.391390       1 controllermanager.go:523] Started "endpoint"
I0416 21:03:41.391404       1 controllermanager.go:508] Starting "replicationcontroller"
I0416 21:03:41.391547       1 endpoints_controller.go:166] Starting endpoint controller
I0416 21:03:41.391569       1 controller_utils.go:1028] Waiting for caches to sync for endpoint controller
I0416 21:03:41.416496       1 controllermanager.go:523] Started "replicationcontroller"
I0416 21:03:41.416517       1 controllermanager.go:508] Starting "namespace"
I0416 21:03:41.416647       1 replica_set.go:182] Starting replicationcontroller controller
I0416 21:03:41.416667       1 controller_utils.go:1028] Waiting for caches to sync for ReplicationController controller
I0416 21:03:41.461129       1 shared_informer.go:123] caches populated
I0416 21:03:41.461142       1 controller_utils.go:1035] Caches are synced for node controller
I0416 21:03:41.461151       1 cloud_cidr_allocator.go:136] Starting cloud CIDR allocator
I0416 21:03:41.461176       1 controller_utils.go:1028] Waiting for caches to sync for cidrallocator controller
I0416 21:03:41.539460       1 controllermanager.go:523] Started "namespace"
W0416 21:03:41.539474       1 controllermanager.go:502] "bootstrapsigner" is disabled
I0416 21:03:41.539482       1 controllermanager.go:508] Starting "pv-protection"
I0416 21:03:41.539676       1 namespace_controller.go:186] Starting namespace controller
I0416 21:03:41.539712       1 controller_utils.go:1028] Waiting for caches to sync for namespace controller
I0416 21:03:41.561587       1 shared_informer.go:123] caches populated
I0416 21:03:41.561597       1 controller_utils.go:1035] Caches are synced for cidrallocator controller
I0416 21:03:41.573826       1 controllermanager.go:523] Started "pv-protection"
I0416 21:03:41.573840       1 controllermanager.go:508] Starting "daemonset"
I0416 21:03:41.573976       1 pv_protection_controller.go:82] Starting PV protection controller
I0416 21:03:41.574009       1 controller_utils.go:1028] Waiting for caches to sync for PV protection controller
I0416 21:03:41.625668       1 controllermanager.go:523] Started "daemonset"
I0416 21:03:41.625682       1 controllermanager.go:508] Starting "disruption"
I0416 21:03:41.625894       1 daemon_controller.go:267] Starting daemon sets controller
I0416 21:03:41.625918       1 controller_utils.go:1028] Waiting for caches to sync for daemon sets controller
I0416 21:03:41.655548       1 controllermanager.go:523] Started "disruption"
I0416 21:03:41.655653       1 controllermanager.go:508] Starting "csrsigning"
I0416 21:03:41.657724       1 disruption.go:286] Starting disruption controller
I0416 21:03:41.657746       1 controller_utils.go:1028] Waiting for caches to sync for disruption controller
E0416 21:03:41.665166       1 prometheus.go:55] failed to register depth metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665586       1 prometheus.go:68] failed to register adds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665723       1 prometheus.go:82] failed to register latency metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665836       1 prometheus.go:96] failed to register workDuration metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.665949       1 prometheus.go:112] failed to register unfinished metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667408       1 prometheus.go:126] failed to register unfinished metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667589       1 prometheus.go:152] failed to register depth metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667673       1 prometheus.go:164] failed to register adds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667780       1 prometheus.go:176] failed to register latency metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667883       1 prometheus.go:188] failed to register work_duration metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.667985       1 prometheus.go:203] failed to register unfinished_work_seconds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668072       1 prometheus.go:216] failed to register longest_running_processor_microseconds metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668210       1 prometheus.go:139] failed to register retries metric certificate: duplicate metrics collector registration attempted
E0416 21:03:41.668300       1 prometheus.go:228] failed to register retries metric certificate: duplicate metrics collector registration attempted
I0416 21:03:41.668400       1 controllermanager.go:523] Started "csrsigning"
I0416 21:03:41.668410       1 controllermanager.go:508] Starting "pvc-protection"
I0416 21:03:41.668616       1 certificate_controller.go:113] Starting certificate controller
I0416 21:03:41.668636       1 controller_utils.go:1028] Waiting for caches to sync for certificate controller
I0416 21:03:41.701847       1 controllermanager.go:523] Started "pvc-protection"
I0416 21:03:41.703632       1 graph_builder.go:280] started 50 new monitors, 50 currently running
I0416 21:03:41.705567       1 pvc_protection_controller.go:100] Starting PVC protection controller
I0416 21:03:41.705588       1 controller_utils.go:1028] Waiting for caches to sync for PVC protection controller
I0416 21:03:41.705887       1 reflector.go:128] Starting reflector *v1.Namespace (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.705900       1 reflector.go:166] Listing and watching *v1.Namespace from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.707912       1 reflector.go:128] Starting reflector *v1beta1.CSIDriver (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.707924       1 reflector.go:166] Listing and watching *v1beta1.CSIDriver from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.708408       1 reflector.go:128] Starting reflector *v1.Service (30s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.708417       1 reflector.go:166] Listing and watching *v1.Service from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.708640       1 reflector.go:128] Starting reflector *v1beta1.ReplicaSet (3m41.331494201s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.708646       1 reflector.go:166] Listing and watching *v1beta1.ReplicaSet from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.708885       1 reflector.go:128] Starting reflector *v1.ConfigMap (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.708891       1 reflector.go:166] Listing and watching *v1.ConfigMap from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.709083       1 reflector.go:128] Starting reflector *v1.Deployment (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.709089       1 reflector.go:166] Listing and watching *v1.Deployment from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.712266       1 reflector.go:128] Starting reflector *v1beta1.Lease (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.712281       1 reflector.go:166] Listing and watching *v1beta1.Lease from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.712631       1 reflector.go:128] Starting reflector *v1.Job (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.712639       1 reflector.go:166] Listing and watching *v1.Job from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.712865       1 reflector.go:128] Starting reflector *v1beta1.Ingress (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.712871       1 reflector.go:166] Listing and watching *v1beta1.Ingress from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713060       1 reflector.go:128] Starting reflector *v1beta1.PodSecurityPolicy (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713073       1 reflector.go:166] Listing and watching *v1beta1.PodSecurityPolicy from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713286       1 reflector.go:128] Starting reflector *v1.PodTemplate (3m20.14256297s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713292       1 reflector.go:166] Listing and watching *v1.PodTemplate from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713473       1 reflector.go:128] Starting reflector *v1beta1.ValidatingWebhookConfiguration (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713479       1 reflector.go:166] Listing and watching *v1beta1.ValidatingWebhookConfiguration from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713705       1 reflector.go:128] Starting reflector *v1beta1.PodDisruptionBudget (30s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713710       1 reflector.go:166] Listing and watching *v1beta1.PodDisruptionBudget from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713907       1 reflector.go:128] Starting reflector *v1beta1.DaemonSet (3m21.739829553s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.713914       1 reflector.go:166] Listing and watching *v1beta1.DaemonSet from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.714105       1 reflector.go:128] Starting reflector *v1.PersistentVolume (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.714111       1 reflector.go:166] Listing and watching *v1.PersistentVolume from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.716960       1 reflector.go:128] Starting reflector *v1beta1.NetworkPolicy (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.716973       1 reflector.go:166] Listing and watching *v1beta1.NetworkPolicy from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.717347       1 reflector.go:128] Starting reflector *v1.StorageClass (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.717355       1 reflector.go:166] Listing and watching *v1.StorageClass from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.717556       1 reflector.go:128] Starting reflector *v1.LimitRange (3m25.453713621s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.717563       1 reflector.go:166] Listing and watching *v1.LimitRange from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.717753       1 reflector.go:128] Starting reflector *v1.Endpoints (3m28.640327449s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.717758       1 reflector.go:166] Listing and watching *v1.Endpoints from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.717948       1 reflector.go:128] Starting reflector *v1.Pod (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.717953       1 reflector.go:166] Listing and watching *v1.Pod from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.718162       1 reflector.go:128] Starting reflector *v1.ReplicationController (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.718167       1 reflector.go:166] Listing and watching *v1.ReplicationController from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.720500       1 reflector.go:128] Starting reflector *v1beta1.PodSecurityPolicy (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.720511       1 reflector.go:166] Listing and watching *v1beta1.PodSecurityPolicy from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.720747       1 reflector.go:128] Starting reflector *v1beta1.Ingress (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.720753       1 reflector.go:166] Listing and watching *v1beta1.Ingress from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.720976       1 reflector.go:128] Starting reflector *v1.Role (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.720982       1 reflector.go:166] Listing and watching *v1.Role from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.721216       1 reflector.go:128] Starting reflector *v1.ClusterRoleBinding (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.721221       1 reflector.go:166] Listing and watching *v1.ClusterRoleBinding from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.721419       1 reflector.go:128] Starting reflector *v1beta1.MutatingWebhookConfiguration (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.721425       1 reflector.go:166] Listing and watching *v1beta1.MutatingWebhookConfiguration from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.721699       1 reflector.go:128] Starting reflector *v1.DaemonSet (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.721707       1 reflector.go:166] Listing and watching *v1.DaemonSet from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.721969       1 reflector.go:128] Starting reflector *v1.ReplicaSet (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.721974       1 reflector.go:166] Listing and watching *v1.ReplicaSet from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.722199       1 reflector.go:128] Starting reflector *v1.RoleBinding (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.722203       1 reflector.go:166] Listing and watching *v1.RoleBinding from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.724538       1 reflector.go:128] Starting reflector *v1beta1.CronJob (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.724548       1 reflector.go:166] Listing and watching *v1beta1.CronJob from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.724777       1 reflector.go:128] Starting reflector *v1beta1.Deployment (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.724783       1 reflector.go:166] Listing and watching *v1beta1.Deployment from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.724965       1 reflector.go:128] Starting reflector *v1beta1.Event (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.724970       1 reflector.go:166] Listing and watching *v1beta1.Event from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.725118       1 reflector.go:128] Starting reflector *v1beta1.RuntimeClass (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.725123       1 reflector.go:166] Listing and watching *v1beta1.RuntimeClass from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.727471       1 reflector.go:128] Starting reflector *v1.ClusterRole (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.727483       1 reflector.go:166] Listing and watching *v1.ClusterRole from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.727635       1 reflector.go:128] Starting reflector *v1.PersistentVolumeClaim (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.727641       1 reflector.go:166] Listing and watching *v1.PersistentVolumeClaim from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.727793       1 reflector.go:128] Starting reflector *v1.PriorityClass (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.727798       1 reflector.go:166] Listing and watching *v1.PriorityClass from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.727938       1 reflector.go:128] Starting reflector *v1alpha1.PodPreset (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.727943       1 reflector.go:166] Listing and watching *v1alpha1.PodPreset from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728060       1 reflector.go:128] Starting reflector *v1.VolumeAttachment (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728069       1 reflector.go:166] Listing and watching *v1.VolumeAttachment from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728218       1 reflector.go:128] Starting reflector *v1.NetworkPolicy (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728222       1 reflector.go:166] Listing and watching *v1.NetworkPolicy from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728376       1 reflector.go:128] Starting reflector *v1.HorizontalPodAutoscaler (15s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728381       1 reflector.go:166] Listing and watching *v1.HorizontalPodAutoscaler from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728511       1 reflector.go:128] Starting reflector *v1.Lease (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728515       1 reflector.go:166] Listing and watching *v1.Lease from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728635       1 reflector.go:128] Starting reflector *v1beta1.CertificateSigningRequest (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728639       1 reflector.go:166] Listing and watching *v1beta1.CertificateSigningRequest from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728752       1 reflector.go:128] Starting reflector *v1.StatefulSet (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728757       1 reflector.go:166] Listing and watching *v1.StatefulSet from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728902       1 reflector.go:128] Starting reflector *v1beta1.CSINode (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.728906       1 reflector.go:166] Listing and watching *v1beta1.CSINode from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.729030       1 reflector.go:128] Starting reflector *v1.ControllerRevision (4m0.568387783s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.729034       1 reflector.go:166] Listing and watching *v1.ControllerRevision from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.732339       1 resource_quota_monitor.go:275] QuotaMonitor started 32 new monitors, 32 currently running
I0416 21:03:41.732429       1 resource_quota_monitor.go:243] quota synced monitors; added 0, kept 32, removed 0
I0416 21:03:41.732437       1 resource_quota_monitor.go:275] QuotaMonitor started 0 new monitors, 32 currently running
I0416 21:03:41.732444       1 controller_utils.go:1028] Waiting for caches to sync for resource quota controller
I0416 21:03:41.732533       1 reflector.go:128] Starting reflector <nil> (0s) from pkg/controller/garbagecollector/graph_builder.go:124
I0416 21:03:41.732542       1 reflector.go:166] Listing and watching <nil> from pkg/controller/garbagecollector/graph_builder.go:124
I0416 21:03:41.732867       1 reflector.go:128] Starting reflector <nil> (0s) from pkg/controller/garbagecollector/graph_builder.go:124
I0416 21:03:41.732872       1 reflector.go:166] Listing and watching <nil> from pkg/controller/garbagecollector/graph_builder.go:124
I0416 21:03:41.733004       1 graph_builder.go:298] garbage controller monitor not yet synced: policy/v1beta1, Resource=podsecuritypolicies
I0416 21:03:41.733090       1 graph_builder.go:248] synced monitors; added 0, kept 50, removed 0
I0416 21:03:41.733099       1 graph_builder.go:280] started 0 new monitors, 50 currently running
I0416 21:03:41.733105       1 garbagecollector.go:222] resynced monitors
I0416 21:03:41.733110       1 controller_utils.go:1028] Waiting for caches to sync for garbage collector controller
I0416 21:03:41.741934       1 reflector.go:128] Starting reflector *v1.ResourceQuota (4m7.759729714s) from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.741949       1 reflector.go:166] Listing and watching *v1.ResourceQuota from k8s.io/client-go/informers/factory.go:133
I0416 21:03:41.745310       1 shared_informer.go:123] caches populated
I0416 21:03:41.745323       1 controller_utils.go:1035] Caches are synced for service controller
I0416 21:03:41.764301       1 shared_informer.go:123] caches populated
I0416 21:03:41.764312       1 controller_utils.go:1035] Caches are synced for namespace controller
I0416 21:03:41.764340       1 shared_informer.go:123] caches populated
I0416 21:03:41.764343       1 controller_utils.go:1035] Caches are synced for GC controller
I0416 21:03:41.764366       1 gc_controller.go:144] GC'ing orphaned
I0416 21:03:41.772932       1 shared_informer.go:123] caches populated
I0416 21:03:41.772943       1 controller_utils.go:1035] Caches are synced for service account controller
I0416 21:03:41.791706       1 shared_informer.go:123] caches populated
I0416 21:03:41.791717       1 controller_utils.go:1035] Caches are synced for endpoint controller
I0416 21:03:41.815789       1 shared_informer.go:123] caches populated
I0416 21:03:41.815800       1 controller_utils.go:1035] Caches are synced for PV protection controller
I0416 21:03:41.815832       1 shared_informer.go:123] caches populated
I0416 21:03:41.815836       1 controller_utils.go:1035] Caches are synced for ReplicaSet controller
I0416 21:03:41.815858       1 shared_informer.go:123] caches populated
I0416 21:03:41.815861       1 controller_utils.go:1035] Caches are synced for taint controller
I0416 21:03:41.815921       1 graph_builder.go:298] garbage controller monitor not yet synced: settings.k8s.io/v1alpha1, Resource=podpresets
I0416 21:03:41.815979       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (6.081µs)
I0416 21:03:41.827124       1 taint_manager.go:198] Starting NoExecuteTaintManager
I0416 21:03:41.827334       1 shared_informer.go:123] caches populated
I0416 21:03:41.827340       1 controller_utils.go:1035] Caches are synced for deployment controller
I0416 21:03:41.854453       1 request.go:530] Throttling request took 129.402644ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1/events?limit=500&resourceVersion=0
I0416 21:03:41.854589       1 shared_informer.go:123] caches populated
I0416 21:03:41.854597       1 controller_utils.go:1035] Caches are synced for ReplicationController controller
I0416 21:03:41.854621       1 shared_informer.go:123] caches populated
I0416 21:03:41.854624       1 controller_utils.go:1035] Caches are synced for job controller
I0416 21:03:41.857851       1 resource_quota_monitor.go:293] quota monitor not synced: events.k8s.io/v1beta1, Resource=events
I0416 21:03:41.857877       1 graph_builder.go:298] garbage controller monitor not yet synced: storage.k8s.io/v1, Resource=volumeattachments
I0416 21:03:41.896326       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:03:41.896843       1 serviceaccounts_controller.go:186] Finished syncing namespace "kube-system" (123.836745ms)
I0416 21:03:41.897030       1 request.go:530] Throttling request took 171.861437ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1/runtimeclasses?limit=500&resourceVersion=0
I0416 21:03:41.900073       1 graph_builder.go:298] garbage controller monitor not yet synced: node.k8s.io/v1beta1, Resource=runtimeclasses
I0416 21:03:41.928770       1 serviceaccounts_controller.go:186] Finished syncing namespace "kube-public" (31.875792ms)
I0416 21:03:41.929095       1 request.go:530] Throttling request took 201.528545ms, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1/clusterroles?limit=500&resourceVersion=0
I0416 21:03:41.933886       1 graph_builder.go:298] garbage controller monitor not yet synced: settings.k8s.io/v1alpha1, Resource=podpresets
I0416 21:03:41.933915       1 resource_quota_monitor.go:293] quota monitor not synced: apps/v1, Resource=statefulsets
I0416 21:03:41.954630       1 shared_informer.go:123] caches populated
I0416 21:03:41.954643       1 controller_utils.go:1035] Caches are synced for ClusterRoleAggregator controller
I0416 21:03:41.960582       1 request.go:530] Throttling request took 232.860453ms, request: GET:https://localhost:443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0
I0416 21:03:41.961022       1 serviceaccounts_controller.go:186] Finished syncing namespace "kube-node-lease" (32.214879ms)
I0416 21:03:41.970497       1 shared_informer.go:123] caches populated
I0416 21:03:41.970509       1 controller_utils.go:1035] Caches are synced for expand controller
I0416 21:03:41.972267       1 serviceaccounts_controller.go:186] Finished syncing namespace "default" (11.208526ms)
I0416 21:03:41.986306       1 graph_builder.go:298] garbage controller monitor not yet synced: storage.k8s.io/v1beta1, Resource=csinodes
I0416 21:03:42.006306       1 request.go:530] Throttling request took 278.409134ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1/priorityclasses?limit=500&resourceVersion=0
I0416 21:03:42.006540       1 shared_informer.go:123] caches populated
I0416 21:03:42.006556       1 controller_utils.go:1035] Caches are synced for PVC protection controller
I0416 21:03:42.027318       1 shared_informer.go:123] caches populated
I0416 21:03:42.027332       1 controller_utils.go:1035] Caches are synced for persistent volume controller
I0416 21:03:42.027347       1 pv_controller_base.go:156] controller initialized
I0416 21:03:42.027427       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:03:42.033521       1 resource_quota_monitor.go:293] quota monitor not synced: coordination.k8s.io/v1, Resource=leases
I0416 21:03:42.033578       1 graph_builder.go:298] garbage controller monitor not yet synced: settings.k8s.io/v1alpha1, Resource=podpresets
I0416 21:03:42.059409       1 shared_informer.go:123] caches populated
I0416 21:03:42.059426       1 controller_utils.go:1035] Caches are synced for attach detach controller
I0416 21:03:42.069742       1 request.go:530] Throttling request took 341.543756ms, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1/podpresets?limit=500&resourceVersion=0
E0416 21:03:42.073186       1 clusterroleaggregation_controller.go:180] edit failed with : Operation cannot be fulfilled on clusterroles.rbac.authorization.k8s.io "edit": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:42.091780       1 graph_builder.go:298] garbage controller monitor not yet synced: /v1, Resource=resourcequotas
I0416 21:03:42.107465       1 request.go:530] Throttling request took 379.306332ms, request: GET:https://localhost:443/apis/storage.k8s.io/v1/volumeattachments?limit=500&resourceVersion=0
I0416 21:03:42.132736       1 resource_quota_monitor.go:293] quota monitor not synced: coordination.k8s.io/v1, Resource=leases
I0416 21:03:42.133340       1 graph_builder.go:298] garbage controller monitor not yet synced: /v1, Resource=resourcequotas
I0416 21:03:42.156315       1 request.go:530] Throttling request took 427.999953ms, request: GET:https://localhost:443/apis/networking.k8s.io/v1/networkpolicies?limit=500&resourceVersion=0
I0416 21:03:42.188563       1 graph_builder.go:298] garbage controller monitor not yet synced: storage.k8s.io/v1beta1, Resource=csinodes
I0416 21:03:42.208509       1 request.go:530] Throttling request took 480.026612ms, request: GET:https://localhost:443/apis/autoscaling/v1/horizontalpodautoscalers?limit=500&resourceVersion=0
I0416 21:03:42.230180       1 gen.go:6086] GCEForwardingRules.Get(context.Background.WithDeadline(2019-04-16 22:03:41.748765415 +0000 UTC m=+3643.902489565 [59m59.518576447s]), Key{"af33e48417b0c47eea9a807f459d0711", region: "us-central1"}) = <nil>, googleapi: Error 404: The resource 'projects/peterhornyack-prod-no-enforcer/regions/us-central1/forwardingRules/af33e48417b0c47eea9a807f459d0711' was not found, notFound
I0416 21:03:42.230300       1 service_controller.go:330] Not persisting unchanged LoadBalancerStatus for service default/kubernetes to registry.
I0416 21:03:42.230327       1 service_controller.go:716] Finished syncing service "default/kubernetes" (481.57974ms)
I0416 21:03:42.233352       1 graph_builder.go:298] garbage controller monitor not yet synced: /v1, Resource=resourcequotas
I0416 21:03:42.233394       1 resource_quota_monitor.go:293] quota monitor not synced: coordination.k8s.io/v1, Resource=leases
I0416 21:03:42.241325       1 shared_informer.go:123] caches populated
I0416 21:03:42.241341       1 controller_utils.go:1035] Caches are synced for HPA controller
I0416 21:03:42.257451       1 request.go:530] Throttling request took 528.835109ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1/leases?limit=500&resourceVersion=0
I0416 21:03:42.286365       1 graph_builder.go:298] garbage controller monitor not yet synced: /v1, Resource=resourcequotas
I0416 21:03:42.306355       1 request.go:530] Throttling request took 577.618556ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1/certificatesigningrequests?limit=500&resourceVersion=0
I0416 21:03:42.333151       1 resource_quota_monitor.go:293] quota monitor not synced: /v1, Resource=resourcequotas
I0416 21:03:42.334324       1 graph_builder.go:298] garbage controller monitor not yet synced: /v1, Resource=resourcequotas
I0416 21:03:42.350651       1 shared_informer.go:123] caches populated
I0416 21:03:42.350675       1 controller_utils.go:1035] Caches are synced for certificate controller
I0416 21:03:42.356267       1 request.go:530] Throttling request took 627.401657ms, request: GET:https://localhost:443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0
I0416 21:03:42.369346       1 shared_informer.go:123] caches populated
I0416 21:03:42.369378       1 controller_utils.go:1035] Caches are synced for certificate controller
I0416 21:03:42.385776       1 graph_builder.go:298] garbage controller monitor not yet synced: /v1, Resource=resourcequotas
I0416 21:03:42.406340       1 request.go:530] Throttling request took 677.3485ms, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1/csinodes?limit=500&resourceVersion=0
I0416 21:03:42.432629       1 resource_quota_monitor.go:293] quota monitor not synced: /v1, Resource=resourcequotas
I0416 21:03:42.433310       1 graph_builder.go:298] garbage controller monitor not yet synced: /v1, Resource=resourcequotas
I0416 21:03:42.456318       1 request.go:530] Throttling request took 727.187335ms, request: GET:https://localhost:443/apis/apps/v1/controllerrevisions?limit=500&resourceVersion=0
I0416 21:03:42.458719       1 shared_informer.go:123] caches populated
I0416 21:03:42.458732       1 controller_utils.go:1035] Caches are synced for disruption controller
I0416 21:03:42.458739       1 disruption.go:294] Sending events to api server.
I0416 21:03:42.486398       1 graph_builder.go:298] garbage controller monitor not yet synced: /v1, Resource=resourcequotas
I0416 21:03:42.497361       1 shared_informer.go:123] caches populated
I0416 21:03:42.497389       1 controller_utils.go:1035] Caches are synced for stateful set controller
I0416 21:03:42.506350       1 request.go:530] Throttling request took 764.305568ms, request: GET:https://localhost:443/api/v1/resourcequotas?limit=500&resourceVersion=0
I0416 21:03:42.526329       1 shared_informer.go:123] caches populated
I0416 21:03:42.526345       1 controller_utils.go:1035] Caches are synced for daemon sets controller
I0416 21:03:42.532668       1 shared_informer.go:123] caches populated
I0416 21:03:42.532685       1 controller_utils.go:1035] Caches are synced for resource quota controller
I0416 21:03:42.532695       1 resource_quota_controller.go:452] synced quota controller
I0416 21:03:42.533322       1 shared_informer.go:123] caches populated
I0416 21:03:42.533336       1 controller_utils.go:1035] Caches are synced for garbage collector controller
I0416 21:03:42.533344       1 garbagecollector.go:242] synced garbage collector
I0416 21:03:42.555396       1 shared_informer.go:123] caches populated
I0416 21:03:42.555412       1 controller_utils.go:1035] Caches are synced for resource quota controller
I0416 21:03:42.555476       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:03:42.586418       1 shared_informer.go:123] caches populated
I0416 21:03:42.586435       1 controller_utils.go:1035] Caches are synced for garbage collector controller
I0416 21:03:42.586444       1 garbagecollector.go:139] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
E0416 21:03:45.020764       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.034179       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.043531       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.055718       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.121345       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.204008       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.219749       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.227151       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.234178       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.248157       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.293782       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.400327       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.400707       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.576416       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.939189       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:46.050861       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:46.781053       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:46.855000       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.020764       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.034179       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.043531       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.055718       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.121345       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.204008       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.219749       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.227151       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.234178       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.248157       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.293782       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.400327       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:45.400707       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.576416       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:45.939189       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:46.050861       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:46.781053       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:46.855000       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:44.440845       1 deployment_controller.go:168] Adding deployment coredns
I0416 21:03:44.440901       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:03:44.440866449 +0000 UTC m=+46.594590599)
I0416 21:03:44.441510       1 deployment_util.go:259] Updating replica set "coredns-5b969f4c88" revision to 1
I0416 21:03:44.459871       1 controller_utils.go:202] Controller kube-system/coredns-5b969f4c88 either never recorded expectations, or the ttl expired.
I0416 21:03:44.459911       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.459991       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/coredns-5b969f4c88, need 1, creating 1
I0416 21:03:44.460811       1 deployment_controller.go:214] ReplicaSet coredns-5b969f4c88 added.
I0416 21:03:44.463303       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"coredns", UID:"91d7e558-6fbf-44e2-84e7-9a55f0101e58", APIVersion:"apps/v1", ResourceVersion:"288", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set coredns-5b969f4c88 to 1
I0416 21:03:44.471704       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:03:44.475371       1 deployment_util.go:795] Deployment "coredns" timed out (false) [last progress check: 2019-04-16 21:03:44.462677146 +0000 UTC m=+46.616401284 - now: 2019-04-16 21:03:44.475357789 +0000 UTC m=+46.629081924]
I0416 21:03:44.486635       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (45.754444ms)
I0416 21:03:44.486654       1 deployment_controller.go:484] Error syncing deployment kube-system/coredns: Operation cannot be fulfilled on deployments.apps "coredns": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:44.486700       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:03:44.486696306 +0000 UTC m=+46.640420443)
I0416 21:03:44.487541       1 deployment_util.go:795] Deployment "coredns" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:44.487534101 +0000 UTC m=+46.641258238]
I0416 21:03:44.496788       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:03:44.499975       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (13.264636ms)
I0416 21:03:44.500029       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:03:44.500024416 +0000 UTC m=+46.653748554)
I0416 21:03:44.500732       1 deployment_util.go:795] Deployment "coredns" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:44.500724916 +0000 UTC m=+46.654449052]
I0416 21:03:44.500760       1 progress.go:193] Queueing up deployment "coredns" for a progress check after 599s
I0416 21:03:44.500772       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (746.106µs)
I0416 21:03:44.505363       1 controller_utils.go:588] Controller coredns-5b969f4c88 created pod coredns-5b969f4c88-zcdpb
I0416 21:03:44.505488       1 replica_set_utils.go:58] Updating status for : kube-system/coredns-5b969f4c88, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:44.506340       1 pvc_protection_controller.go:280] Got event on pod kube-system/coredns-5b969f4c88-zcdpb
I0416 21:03:44.506708       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"coredns-5b969f4c88-zcdpb"}
I0416 21:03:44.506755       1 replica_set.go:275] Pod coredns-5b969f4c88-zcdpb created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"coredns-5b969f4c88-zcdpb", GenerateName:"coredns-5b969f4c88-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb", UID:"cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d", ResourceVersion:"293", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045424, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-dns", "pod-template-hash":"5b969f4c88"}, Annotations:map[string]string{"seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"coredns-5b969f4c88", UID:"791055b4-f507-415a-8d87-24932eef483f", Controller:(*bool)(0xc000c5209f), BlockOwnerDeletion:(*bool)(0xc000c520d0)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0017b8a00), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"coredns-token-8zsdf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0017b8a40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"coredns", Image:"k8s.gcr.io/coredns:1.3.1", Command:[]string(nil), Args:[]string{"-conf", "/etc/coredns/Corefile"}, WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"dns", HostPort:0, ContainerPort:53, Protocol:"UDP", HostIP:""}, v1.ContainerPort{Name:"dns-tcp", HostPort:0, ContainerPort:53, Protocol:"TCP", HostIP:""}, v1.ContainerPort{Name:"metrics", HostPort:0, ContainerPort:9153, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:178257920, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"170Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:73400320, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"70Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"config-volume", ReadOnly:true, MountPath:"/etc/coredns", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"coredns-token-8zsdf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc0019af380), ReadinessProbe:(*v1.Probe)(0xc0019af3b0), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc001909400), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000c521d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"coredns", DeprecatedServiceAccount:"coredns", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0016938c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000c52220)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000c52240)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc000c52248), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000c5224c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:03:44.507278       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.507356       1 disruption.go:326] addPod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:03:44.507372       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:44.507375       1 disruption.go:329] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:03:44.507392       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"coredns-5b969f4c88", UID:"791055b4-f507-415a-8d87-24932eef483f", APIVersion:"apps/v1", ResourceVersion:"290", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: coredns-5b969f4c88-zcdpb
I0416 21:03:44.521762       1 deployment_controller.go:280] ReplicaSet coredns-5b969f4c88 updated.
I0416 21:03:44.521825       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:03:44.521799118 +0000 UTC m=+46.675523255)
I0416 21:03:44.522696       1 deployment_util.go:795] Deployment "coredns" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:44.522689814 +0000 UTC m=+46.676413964]
I0416 21:03:44.522743       1 progress.go:193] Queueing up deployment "coredns" for a progress check after 599s
I0416 21:03:44.522755       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (953.302µs)
I0416 21:03:44.526591       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (66.735675ms)
I0416 21:03:44.526636       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.527266       1 replica_set_utils.go:58] Updating status for : kube-system/coredns-5b969f4c88, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:44.527724       1 pvc_protection_controller.go:280] Got event on pod kube-system/coredns-5b969f4c88-zcdpb
I0416 21:03:44.527910       1 replica_set.go:338] Pod coredns-5b969f4c88-zcdpb updated, objectMeta {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:293 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc000c5209f BlockOwnerDeletion:0xc000c520d0}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:295 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc000c53fdf BlockOwnerDeletion:0xc0018de010}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:44.528172       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:03:44.528200       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:44.528203       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:03:44.536467       1 deployment_controller.go:280] ReplicaSet coredns-5b969f4c88 updated.
I0416 21:03:44.536528       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:03:44.536501196 +0000 UTC m=+46.690225332)
I0416 21:03:44.544564       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (17.913012ms)
I0416 21:03:44.544609       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.544719       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (120.498µs)
I0416 21:03:44.552579       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:03:44.553669       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (17.157491ms)
I0416 21:03:44.553702       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:03:44.553698056 +0000 UTC m=+46.707422207)
I0416 21:03:44.554538       1 deployment_util.go:795] Deployment "coredns" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:44.554533024 +0000 UTC m=+46.708257159]
I0416 21:03:44.554588       1 progress.go:193] Queueing up deployment "coredns" for a progress check after 599s
I0416 21:03:44.554600       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (899.98µs)
I0416 21:03:44.567582       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 0 not ready: 0
I0416 21:03:44.586132       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (18.649274ms)
I0416 21:03:44.598483       1 deployment_controller.go:168] Adding deployment l7-default-backend
I0416 21:03:44.598510       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:03:44.598503965 +0000 UTC m=+46.752228102)
I0416 21:03:44.598780       1 deployment_util.go:259] Updating replica set "l7-default-backend-8f479dd9" revision to 1
I0416 21:03:44.605332       1 controller_utils.go:202] Controller kube-system/l7-default-backend-8f479dd9 either never recorded expectations, or the ttl expired.
I0416 21:03:44.605394       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.605448       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/l7-default-backend-8f479dd9, need 1, creating 1
I0416 21:03:44.605872       1 deployment_controller.go:214] ReplicaSet l7-default-backend-8f479dd9 added.
I0416 21:03:44.609457       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"l7-default-backend", UID:"4483e295-6276-4c3b-bc97-66816fb0eea9", APIVersion:"apps/v1", ResourceVersion:"301", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set l7-default-backend-8f479dd9 to 1
I0416 21:03:44.619636       1 pvc_protection_controller.go:280] Got event on pod kube-system/l7-default-backend-8f479dd9-wbtkw
I0416 21:03:44.619755       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"l7-default-backend-8f479dd9-wbtkw"}
I0416 21:03:44.619790       1 replica_set.go:275] Pod l7-default-backend-8f479dd9-wbtkw created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"l7-default-backend-8f479dd9-wbtkw", GenerateName:"l7-default-backend-8f479dd9-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw", UID:"d2a16c9d-a630-4bdb-a762-209a1b23939f", ResourceVersion:"303", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045424, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"glbc", "name":"glbc", "pod-template-hash":"8f479dd9"}, Annotations:map[string]string{"seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"l7-default-backend-8f479dd9", UID:"eb2d558b-0e11-40f0-8ae2-266c97cd406f", Controller:(*bool)(0xc0017da527), BlockOwnerDeletion:(*bool)(0xc0017da528)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-prrpp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001ce3bc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"default-http-backend", Image:"k8s.gcr.io/defaultbackend-amd64:1.5", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"", HostPort:0, ContainerPort:8080, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:10, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"10m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:10, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"10m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-prrpp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc0016fc7e0), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0017da590), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00175ca80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0017da5d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0017da5f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0017da5f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0017da5fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Guaranteed"}}.
I0416 21:03:44.620104       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.620169       1 disruption.go:326] addPod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:03:44.620187       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:44.620191       1 disruption.go:329] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:03:44.622375       1 controller_utils.go:588] Controller l7-default-backend-8f479dd9 created pod l7-default-backend-8f479dd9-wbtkw
I0416 21:03:44.622470       1 replica_set_utils.go:58] Updating status for : kube-system/l7-default-backend-8f479dd9, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:44.623333       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:03:44.623349       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"l7-default-backend-8f479dd9", UID:"eb2d558b-0e11-40f0-8ae2-266c97cd406f", APIVersion:"apps/v1", ResourceVersion:"302", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: l7-default-backend-8f479dd9-wbtkw
I0416 21:03:44.663487       1 deployment_controller.go:280] ReplicaSet l7-default-backend-8f479dd9 updated.
I0416 21:03:44.664683       1 deployment_util.go:795] Deployment "l7-default-backend" timed out (false) [last progress check: 2019-04-16 21:03:44.609000079 +0000 UTC m=+46.762724215 - now: 2019-04-16 21:03:44.664672411 +0000 UTC m=+46.818396548]
I0416 21:03:44.665036       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (59.758684ms)
I0416 21:03:44.665071       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.665149       1 replica_set_utils.go:58] Updating status for : kube-system/l7-default-backend-8f479dd9, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:44.673640       1 deployment_controller.go:280] ReplicaSet l7-default-backend-8f479dd9 updated.
I0416 21:03:44.675587       1 pvc_protection_controller.go:280] Got event on pod kube-system/l7-default-backend-8f479dd9-wbtkw
I0416 21:03:44.675747       1 replica_set.go:338] Pod l7-default-backend-8f479dd9-wbtkw updated, objectMeta {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:303 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc0017da527 BlockOwnerDeletion:0xc0017da528}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:306 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc001772177 BlockOwnerDeletion:0xc001772178}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:44.675893       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:03:44.675914       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:44.675919       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:03:44.678152       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (13.079973ms)
I0416 21:03:44.678188       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.678280       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (101.411µs)
I0416 21:03:44.682174       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (83.65891ms)
I0416 21:03:44.682192       1 deployment_controller.go:484] Error syncing deployment kube-system/l7-default-backend: Operation cannot be fulfilled on deployments.apps "l7-default-backend": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:44.682242       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:03:44.682221964 +0000 UTC m=+46.835946103)
I0416 21:03:44.690694       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:03:44.691347       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (9.118544ms)
I0416 21:03:44.691379       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:03:44.691376413 +0000 UTC m=+46.845100550)
I0416 21:03:44.691887       1 deployment_util.go:795] Deployment "l7-default-backend" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:44.69186941 +0000 UTC m=+46.845593546]
I0416 21:03:44.691915       1 progress.go:193] Queueing up deployment "l7-default-backend" for a progress check after 599s
I0416 21:03:44.691925       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (547.268µs)
I0416 21:03:44.709099       1 endpoints_controller.go:540] Update endpoints for kube-system/default-http-backend, ready: 0 not ready: 0
I0416 21:03:44.714744       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (5.81023ms)
I0416 21:03:44.792135       1 gen.go:6086] GCEForwardingRules.Get(context.Background.WithDeadline(2019-04-16 22:03:44.568082828 +0000 UTC m=+3646.721806980 [59m59.775940899s]), Key{"a3c731942997a49178973cd06957e5a8", region: "us-central1"}) = <nil>, googleapi: Error 404: The resource 'projects/peterhornyack-prod-no-enforcer/regions/us-central1/forwardingRules/a3c731942997a49178973cd06957e5a8' was not found, notFound
I0416 21:03:44.792206       1 service_controller.go:330] Not persisting unchanged LoadBalancerStatus for service kube-system/kube-dns to registry.
I0416 21:03:44.792216       1 service_controller.go:716] Finished syncing service "kube-system/kube-dns" (224.140148ms)
I0416 21:03:44.811448       1 deployment_controller.go:168] Adding deployment heapster-v1.6.0-beta.1
I0416 21:03:44.811538       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:03:44.811485382 +0000 UTC m=+46.965209520)
I0416 21:03:44.812035       1 deployment_util.go:259] Updating replica set "heapster-v1.6.0-beta.1-5858bf5485" revision to 1
I0416 21:03:44.819849       1 controller_utils.go:202] Controller kube-system/heapster-v1.6.0-beta.1-5858bf5485 either never recorded expectations, or the ttl expired.
I0416 21:03:44.819919       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.819943       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/heapster-v1.6.0-beta.1-5858bf5485, need 1, creating 1
I0416 21:03:44.820447       1 deployment_controller.go:214] ReplicaSet heapster-v1.6.0-beta.1-5858bf5485 added.
I0416 21:03:44.822995       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1", UID:"92819fed-de33-48a3-a4b6-c4a67aa06a5a", APIVersion:"apps/v1", ResourceVersion:"319", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set heapster-v1.6.0-beta.1-5858bf5485 to 1
I0416 21:03:44.830735       1 pvc_protection_controller.go:280] Got event on pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:03:44.830835       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1-5858bf5485-5td9x"}
I0416 21:03:44.830882       1 replica_set.go:275] Pod heapster-v1.6.0-beta.1-5858bf5485-5td9x created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"heapster-v1.6.0-beta.1-5858bf5485-5td9x", GenerateName:"heapster-v1.6.0-beta.1-5858bf5485-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x", UID:"49a1caec-a921-453f-8c62-7a6fa815c59f", ResourceVersion:"321", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045424, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"heapster", "pod-template-hash":"5858bf5485", "version":"v1.6.0-beta.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"heapster-v1.6.0-beta.1-5858bf5485", UID:"089fb806-c80c-46e9-aa5f-09c4c068e23a", Controller:(*bool)(0xc00156d72e), BlockOwnerDeletion:(*bool)(0xc00156d72f)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"heapster-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002217c80), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"heapster-token-qrr2n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002217cc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"heapster", Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", Command:[]string{"/heapster", "--source=kubernetes.summary_api:''"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc00153e4e0), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"heapster-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=80m", "--extra-cpu=0.5m", "--memory=140Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=heapster-v1.6.0-beta.1", "--container=heapster", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0019425c0)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001942600)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00156d928), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"heapster", DeprecatedServiceAccount:"heapster", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001fa31a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00156d9a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00156d9c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc00156d9c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00156d9cc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:03:44.831265       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.831341       1 disruption.go:326] addPod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:03:44.831357       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:44.831360       1 disruption.go:329] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:03:44.835937       1 controller_utils.go:588] Controller heapster-v1.6.0-beta.1-5858bf5485 created pod heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:03:44.836052       1 replica_set_utils.go:58] Updating status for : kube-system/heapster-v1.6.0-beta.1-5858bf5485, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:44.836687       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1-5858bf5485", UID:"089fb806-c80c-46e9-aa5f-09c4c068e23a", APIVersion:"apps/v1", ResourceVersion:"320", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:03:44.839813       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:03:44.841355       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:03:44.822668409 +0000 UTC m=+46.976392560 - now: 2019-04-16 21:03:44.841344407 +0000 UTC m=+46.995068543]
I0416 21:03:44.859204       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-5858bf5485 updated.
I0416 21:03:44.864144       1 pvc_protection_controller.go:280] Got event on pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:03:44.864291       1 replica_set.go:338] Pod heapster-v1.6.0-beta.1-5858bf5485-5td9x updated, objectMeta {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:321 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc00156d72e BlockOwnerDeletion:0xc00156d72f}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:324 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc0014cbf07 BlockOwnerDeletion:0xc0014cbf08}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:44.864531       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:03:44.864564       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:44.864568       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:03:44.866082       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (46.242584ms)
I0416 21:03:44.866138       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.866263       1 replica_set_utils.go:58] Updating status for : kube-system/heapster-v1.6.0-beta.1-5858bf5485, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:44.870869       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (59.359723ms)
I0416 21:03:44.870895       1 deployment_controller.go:484] Error syncing deployment kube-system/heapster-v1.6.0-beta.1: Operation cannot be fulfilled on deployments.apps "heapster-v1.6.0-beta.1": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:44.870933       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:03:44.870929303 +0000 UTC m=+47.024653440)
I0416 21:03:44.871964       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:44.871958359 +0000 UTC m=+47.025682496]
I0416 21:03:44.883517       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (17.379134ms)
I0416 21:03:44.883556       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.883642       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (93.917µs)
I0416 21:03:44.883706       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-5858bf5485 updated.
I0416 21:03:44.886275       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:03:44.889261       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (18.320454ms)
I0416 21:03:44.889298       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:03:44.889293347 +0000 UTC m=+47.043017488)
I0416 21:03:44.895686       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:03:44.897511       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (8.206812ms)
I0416 21:03:44.897546       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:03:44.897542397 +0000 UTC m=+47.051266534)
I0416 21:03:44.898217       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:44.898212284 +0000 UTC m=+47.051936421]
I0416 21:03:44.898295       1 progress.go:193] Queueing up deployment "heapster-v1.6.0-beta.1" for a progress check after 599s
I0416 21:03:44.898309       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (765.076µs)
I0416 21:03:44.920463       1 endpoints_controller.go:540] Update endpoints for kube-system/heapster, ready: 0 not ready: 0
I0416 21:03:44.926658       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (6.301157ms)
I0416 21:03:44.965200       1 deployment_controller.go:168] Adding deployment kubernetes-dashboard
I0416 21:03:44.965246       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:03:44.965240447 +0000 UTC m=+47.118964596)
I0416 21:03:44.965676       1 deployment_util.go:259] Updating replica set "kubernetes-dashboard-85bcf5dbf8" revision to 1
I0416 21:03:44.973601       1 controller_utils.go:202] Controller kube-system/kubernetes-dashboard-85bcf5dbf8 either never recorded expectations, or the ttl expired.
I0416 21:03:44.973654       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac3a08ba25, ext:47127374627, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.973691       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:44.974280       1 deployment_controller.go:214] ReplicaSet kubernetes-dashboard-85bcf5dbf8 added.
I0416 21:03:44.976605       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"kubernetes-dashboard", UID:"ad9e3cff-4ae8-413a-9696-32c0abe837ac", APIVersion:"apps/v1", ResourceVersion:"331", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set kubernetes-dashboard-85bcf5dbf8 to 1
I0416 21:03:44.987812       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:03:44.990454       1 deployment_util.go:795] Deployment "kubernetes-dashboard" timed out (false) [last progress check: 2019-04-16 21:03:44.975975112 +0000 UTC m=+47.129699262 - now: 2019-04-16 21:03:44.990442857 +0000 UTC m=+47.144166999]
I0416 21:03:44.997884       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (32.618206ms)
I0416 21:03:44.997906       1 deployment_controller.go:484] Error syncing deployment kube-system/kubernetes-dashboard: Operation cannot be fulfilled on deployments.apps "kubernetes-dashboard": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:44.997939       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:03:44.997935331 +0000 UTC m=+47.151659467)
I0416 21:03:44.998681       1 deployment_util.go:795] Deployment "kubernetes-dashboard" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:44.998674863 +0000 UTC m=+47.152399019]
I0416 21:03:44.999268       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:44.999286       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac3a08ba25, ext:47127374627, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:44.999346       1 replica_set_utils.go:58] Updating status for : kube-system/kubernetes-dashboard-85bcf5dbf8, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:45.002072       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"332", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.009305       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:03:45.012980       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (15.030516ms)
I0416 21:03:45.013032       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:03:45.013027247 +0000 UTC m=+47.166751382)
I0416 21:03:45.013679       1 deployment_util.go:795] Deployment "kubernetes-dashboard" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:45.013672483 +0000 UTC m=+47.167396634]
I0416 21:03:45.013711       1 progress.go:193] Queueing up deployment "kubernetes-dashboard" for a progress check after 598s
I0416 21:03:45.013722       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (692.954µs)
I0416 21:03:45.015870       1 deployment_controller.go:280] ReplicaSet kubernetes-dashboard-85bcf5dbf8 updated.
I0416 21:03:45.015907       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:03:45.015902216 +0000 UTC m=+47.169626352)
I0416 21:03:45.016860       1 deployment_util.go:795] Deployment "kubernetes-dashboard" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:45.016838807 +0000 UTC m=+47.170562943]
I0416 21:03:45.020740       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (47.161266ms)
E0416 21:03:45.020764       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.021146       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac3a08ba25, ext:47127374627, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.021222       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac4143c5b6, ext:47174942900, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.021257       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:45.026520       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:03:45.030584       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (14.667839ms)
I0416 21:03:45.030635       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:03:45.030631377 +0000 UTC m=+47.184355513)
I0416 21:03:45.032105       1 deployment_util.go:795] Deployment "kubernetes-dashboard" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:45.032089233 +0000 UTC m=+47.185813370]
I0416 21:03:45.032186       1 progress.go:193] Queueing up deployment "kubernetes-dashboard" for a progress check after 598s
I0416 21:03:45.032216       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (1.582252ms)
I0416 21:03:45.034062       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:45.034091       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac4143c5b6, ext:47174942900, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.034159       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (13.015845ms)
E0416 21:03:45.034179       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.034517       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac4143c5b6, ext:47174942900, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.034601       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac420fef41, ext:47188322883, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.034624       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:45.038934       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.043441       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:45.043458       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac420fef41, ext:47188322883, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.043516       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (9.006572ms)
E0416 21:03:45.043531       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.043906       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.046079       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac420fef41, ext:47188322883, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.046172       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac42c0784c, ext:47199892301, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.046198       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:45.049991       1 gen.go:6086] GCEForwardingRules.Get(context.Background.WithDeadline(2019-04-16 22:03:44.792265585 +0000 UTC m=+3646.945989720 [59m59.742267622s]), Key{"ac7be869c1aed416e8ac4a6e115b6045", region: "us-central1"}) = <nil>, googleapi: Error 404: The resource 'projects/peterhornyack-prod-no-enforcer/regions/us-central1/forwardingRules/ac7be869c1aed416e8ac4a6e115b6045' was not found, notFound
I0416 21:03:45.050081       1 service_controller.go:330] Not persisting unchanged LoadBalancerStatus for service kube-system/default-http-backend to registry.
I0416 21:03:45.050093       1 service_controller.go:716] Finished syncing service "kube-system/default-http-backend" (257.834188ms)
I0416 21:03:45.055607       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:45.055624       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac42c0784c, ext:47199892301, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.055700       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (9.658572ms)
E0416 21:03:45.055718       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.056075       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.098216       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac42c0784c, ext:47199892301, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.098371       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac45dcf716, ext:47252091414, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.098386       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:45.115217       1 endpoints_controller.go:540] Update endpoints for kube-system/kubernetes-dashboard, ready: 0 not ready: 0
I0416 21:03:45.121246       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:45.121263       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac45dcf716, ext:47252091414, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.121329       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (23.172771ms)
E0416 21:03:45.121345       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.122224       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.125033       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (9.922143ms)
I0416 21:03:45.163760       1 deployment_controller.go:168] Adding deployment kube-dns-autoscaler
I0416 21:03:45.163821       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:03:45.163781053 +0000 UTC m=+47.317505204)
I0416 21:03:45.164216       1 deployment_util.go:259] Updating replica set "kube-dns-autoscaler-97df449df" revision to 1
I0416 21:03:45.173524       1 controller_utils.go:202] Controller kube-system/kube-dns-autoscaler-97df449df either never recorded expectations, or the ttl expired.
I0416 21:03:45.173591       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4a58b85a, ext:47327310680, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.173652       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:45.174267       1 deployment_controller.go:214] ReplicaSet kube-dns-autoscaler-97df449df added.
I0416 21:03:45.176173       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"kube-dns-autoscaler", UID:"094146ba-de5f-44de-8c4a-012af08f2401", APIVersion:"apps/v1", ResourceVersion:"340", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set kube-dns-autoscaler-97df449df to 1
I0416 21:03:45.188823       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:45.188854       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4a58b85a, ext:47327310680, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.188914       1 replica_set_utils.go:58] Updating status for : kube-system/kube-dns-autoscaler-97df449df, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:45.189396       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:03:45.189593       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"341", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.190889       1 deployment_util.go:795] Deployment "kube-dns-autoscaler" timed out (false) [last progress check: 2019-04-16 21:03:45.17580786 +0000 UTC m=+47.329532011 - now: 2019-04-16 21:03:45.190877106 +0000 UTC m=+47.344601257]
I0416 21:03:45.200368       1 deployment_controller.go:280] ReplicaSet kube-dns-autoscaler-97df449df updated.
I0416 21:03:45.202348       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac45dcf716, ext:47252091414, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.202448       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac4c1112e8, ext:47356169704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.202478       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:45.203986       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (30.509743ms)
E0416 21:03:45.204008       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.204359       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4a58b85a, ext:47327310680, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.204658       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4c328551, ext:47358361704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.204724       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:45.212692       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (48.898025ms)
I0416 21:03:45.212713       1 deployment_controller.go:484] Error syncing deployment kube-system/kube-dns-autoscaler: Operation cannot be fulfilled on deployments.apps "kube-dns-autoscaler": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:45.212764       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:03:45.212759676 +0000 UTC m=+47.366483826)
I0416 21:03:45.213348       1 deployment_util.go:795] Deployment "kube-dns-autoscaler" timed out (false) [last progress check: 2019-04-16 21:03:45 +0000 UTC - now: 2019-04-16 21:03:45.213329837 +0000 UTC m=+47.367053976]
I0416 21:03:45.219624       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:45.219639       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac4c1112e8, ext:47356169704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.219721       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (17.418213ms)
E0416 21:03:45.219749       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.220587       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.222598       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:03:45.226489       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (13.718267ms)
I0416 21:03:45.226534       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:03:45.226530377 +0000 UTC m=+47.380254527)
I0416 21:03:45.226923       1 deployment_util.go:795] Deployment "kube-dns-autoscaler" timed out (false) [last progress check: 2019-04-16 21:03:45 +0000 UTC - now: 2019-04-16 21:03:45.226918248 +0000 UTC m=+47.380642390]
I0416 21:03:45.226969       1 progress.go:193] Queueing up deployment "kube-dns-autoscaler" for a progress check after 599s
I0416 21:03:45.226981       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (448.814µs)
I0416 21:03:45.227104       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:45.227113       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4c328551, ext:47358361704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.227139       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (22.813047ms)
E0416 21:03:45.227151       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.227433       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4c328551, ext:47358361704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.227494       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4d8f3df4, ext:47381215478, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.227504       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:45.227828       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.234094       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:45.234108       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4d8f3df4, ext:47381215478, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.234165       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (6.736334ms)
E0416 21:03:45.234178       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.234448       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.238336       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4d8f3df4, ext:47381215478, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.238442       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4e364921, ext:47392162847, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.238463       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:45.248068       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:45.248084       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4e364921, ext:47392162847, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.248144       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (9.84172ms)
E0416 21:03:45.248157       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.249006       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.269131       1 gen.go:6086] GCEForwardingRules.Get(context.Background.WithDeadline(2019-04-16 22:03:45.050144407 +0000 UTC m=+3647.203868558 [59m59.781007272s]), Key{"a937a7425ac034fa49907ccbfd7f97d4", region: "us-central1"}) = <nil>, googleapi: Error 404: The resource 'projects/peterhornyack-prod-no-enforcer/regions/us-central1/forwardingRules/a937a7425ac034fa49907ccbfd7f97d4' was not found, notFound
I0416 21:03:45.271108       1 service_controller.go:330] Not persisting unchanged LoadBalancerStatus for service kube-system/heapster to registry.
I0416 21:03:45.271120       1 service_controller.go:716] Finished syncing service "kube-system/heapster" (220.985422ms)
I0416 21:03:45.289369       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac4e364921, ext:47392162847, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.289477       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac514104b7, ext:47443197906, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.289501       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:45.293695       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:45.293709       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac514104b7, ext:47443197906, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.293768       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (5.077676ms)
E0416 21:03:45.293782       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.294507       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.310405       1 deployment_controller.go:168] Adding deployment event-exporter-v0.2.4
I0416 21:03:45.310431       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:03:45.310426468 +0000 UTC m=+47.464150618)
I0416 21:03:45.310856       1 deployment_util.go:259] Updating replica set "event-exporter-v0.2.4-65d8d98768" revision to 1
I0416 21:03:45.318532       1 controller_utils.go:202] Controller kube-system/event-exporter-v0.2.4-65d8d98768 either never recorded expectations, or the ttl expired.
I0416 21:03:45.318587       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.318625       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/event-exporter-v0.2.4-65d8d98768, need 1, creating 1
I0416 21:03:45.319055       1 deployment_controller.go:214] ReplicaSet event-exporter-v0.2.4-65d8d98768 added.
I0416 21:03:45.321339       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"event-exporter-v0.2.4", UID:"f774ce00-71e3-4bfe-8fda-d6079ca76cfc", APIVersion:"apps/v1", ResourceVersion:"349", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set event-exporter-v0.2.4-65d8d98768 to 1
I0416 21:03:45.331423       1 pvc_protection_controller.go:280] Got event on pod kube-system/event-exporter-v0.2.4-65d8d98768-n6vvr
I0416 21:03:45.331553       1 controller_utils.go:588] Controller event-exporter-v0.2.4-65d8d98768 created pod event-exporter-v0.2.4-65d8d98768-n6vvr
I0416 21:03:45.331627       1 replica_set_utils.go:58] Updating status for : kube-system/event-exporter-v0.2.4-65d8d98768, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:45.332084       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"event-exporter-v0.2.4-65d8d98768-n6vvr"}
I0416 21:03:45.332127       1 replica_set.go:275] Pod event-exporter-v0.2.4-65d8d98768-n6vvr created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"event-exporter-v0.2.4-65d8d98768-n6vvr", GenerateName:"event-exporter-v0.2.4-65d8d98768-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr", UID:"32a8d941-90a9-4e4a-9748-a1acdd38a2e0", ResourceVersion:"351", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"event-exporter", "pod-template-hash":"65d8d98768", "version":"v0.2.4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"event-exporter-v0.2.4-65d8d98768", UID:"a8ddd8df-17da-4437-afac-e1ee83ceb388", Controller:(*bool)(0xc001436f57), BlockOwnerDeletion:(*bool)(0xc001436f58)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"ssl-certs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc000c95ba0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"event-exporter-sa-token-8th4r", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001474b00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"event-exporter", Image:"k8s.gcr.io/event-exporter:v0.2.4", Command:[]string{"/event-exporter", "-sink-opts=-stackdriver-resource-model=old"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"event-exporter-sa-token-8th4r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=event_exporter:http://localhost:80?whitelisted=stackdriver_sink_received_entry_count,stackdriver_sink_request_count,stackdriver_sink_successfully_sent_entry_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000c95c00)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000c95c40)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"event-exporter-sa-token-8th4r", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001437008), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"event-exporter-sa", DeprecatedServiceAccount:"event-exporter-sa", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0014786c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001437030)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001437060)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001437068), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00143706c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"BestEffort"}}.
I0416 21:03:45.334496       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.335113       1 disruption.go:326] addPod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:03:45.335143       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:45.335146       1 disruption.go:329] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:03:45.335438       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"event-exporter-v0.2.4-65d8d98768", UID:"a8ddd8df-17da-4437-afac-e1ee83ceb388", APIVersion:"apps/v1", ResourceVersion:"350", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: event-exporter-v0.2.4-65d8d98768-n6vvr
I0416 21:03:45.339595       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:03:45.344465       1 deployment_util.go:795] Deployment "event-exporter-v0.2.4" timed out (false) [last progress check: 2019-04-16 21:03:45.320922837 +0000 UTC m=+47.474646988 - now: 2019-04-16 21:03:45.344450567 +0000 UTC m=+47.498174705]
I0416 21:03:45.352600       1 deployment_controller.go:280] ReplicaSet event-exporter-v0.2.4-65d8d98768 updated.
I0416 21:03:45.359972       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (41.471183ms)
I0416 21:03:45.360018       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.360134       1 replica_set_utils.go:58] Updating status for : kube-system/event-exporter-v0.2.4-65d8d98768, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:45.360497       1 pvc_protection_controller.go:280] Got event on pod kube-system/event-exporter-v0.2.4-65d8d98768-n6vvr
I0416 21:03:45.360592       1 replica_set.go:338] Pod event-exporter-v0.2.4-65d8d98768-n6vvr updated, objectMeta {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:351 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc001436f57 BlockOwnerDeletion:0xc001436f58}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:354 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc0014cccb7 BlockOwnerDeletion:0xc0014cccb8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:45.360693       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:03:45.360707       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:45.360711       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:03:45.366244       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (55.788845ms)
I0416 21:03:45.366261       1 deployment_controller.go:484] Error syncing deployment kube-system/event-exporter-v0.2.4: Operation cannot be fulfilled on deployments.apps "event-exporter-v0.2.4": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:45.366291       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:03:45.366287646 +0000 UTC m=+47.520011783)
I0416 21:03:45.366970       1 deployment_util.go:795] Deployment "event-exporter-v0.2.4" timed out (false) [last progress check: 2019-04-16 21:03:45 +0000 UTC - now: 2019-04-16 21:03:45.366964862 +0000 UTC m=+47.520688999]
I0416 21:03:45.373619       1 deployment_controller.go:280] ReplicaSet event-exporter-v0.2.4-65d8d98768 updated.
I0416 21:03:45.374817       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (14.801271ms)
I0416 21:03:45.374850       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.374926       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (83.457µs)
I0416 21:03:45.374984       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac514104b7, ext:47443197906, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.375006       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac565a1a60, ext:47528727904, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.375054       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:45.378317       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:03:45.380741       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac4c1112e8, ext:47356169704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.380822       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac56b2d7d5, ext:47534543563, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.380836       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:45.382833       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (16.53756ms)
I0416 21:03:45.382879       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:03:45.382873561 +0000 UTC m=+47.536597698)
I0416 21:03:45.395767       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:03:45.397065       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (14.182288ms)
I0416 21:03:45.397115       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:03:45.397110994 +0000 UTC m=+47.550835133)
I0416 21:03:45.397712       1 deployment_util.go:795] Deployment "event-exporter-v0.2.4" timed out (false) [last progress check: 2019-04-16 21:03:45 +0000 UTC - now: 2019-04-16 21:03:45.397708006 +0000 UTC m=+47.551432142]
I0416 21:03:45.397756       1 progress.go:193] Queueing up deployment "event-exporter-v0.2.4" for a progress check after 599s
I0416 21:03:45.397771       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (654.069µs)
I0416 21:03:45.400223       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:45.400254       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac56b2d7d5, ext:47534543563, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.400300       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (19.588376ms)
E0416 21:03:45.400327       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.400654       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:45.400660       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac565a1a60, ext:47528727904, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.400698       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (25.71639ms)
E0416 21:03:45.400707       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.400862       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.400882       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.467326       1 gen.go:6086] GCEForwardingRules.Get(context.Background.WithDeadline(2019-04-16 22:03:45.27115812 +0000 UTC m=+3647.424882272 [59m59.803822632s]), Key{"a096eb4cb216645108bdd82dd1d3e2e1", region: "us-central1"}) = <nil>, googleapi: Error 404: The resource 'projects/peterhornyack-prod-no-enforcer/regions/us-central1/forwardingRules/a096eb4cb216645108bdd82dd1d3e2e1' was not found, notFound
I0416 21:03:45.467394       1 service_controller.go:330] Not persisting unchanged LoadBalancerStatus for service kube-system/kubernetes-dashboard to registry.
I0416 21:03:45.467402       1 service_controller.go:716] Finished syncing service "kube-system/kubernetes-dashboard" (196.255861ms)
I0416 21:03:45.473421       1 daemon_controller.go:177] Adding daemon set fluentd-gcp-v3.2.0
I0416 21:03:45.493933       1 controller_utils.go:202] Controller kube-system/fluentd-gcp-v3.2.0 either never recorded expectations, or the ttl expired.
I0416 21:03:45.493993       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeac5d71af8f, ext:47647713932, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.494019       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:45.494115       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:45.494121       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeac5d71af8f, ext:47647713932, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.494141       1 update.go:396] Getting unavailable numbers
I0416 21:03:45.494148       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:03:45.494154       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:45.494159       1 update.go:68] Marking old pods for deletion
I0416 21:03:45.494162       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeac5d744c86, ext:47647885166, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.494168       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:45.494187       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:45.494200       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:45.494582       1 daemon_controller.go:387] ControllerRevision fluentd-gcp-v3.2.0-6487f7bdb4 added.
I0416 21:03:45.500986       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:03:45.501909       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (28.41563ms)
I0416 21:03:45.502566       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeac5d744c86, ext:47647885166, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.502618       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeac5df54a56, ext:47656338776, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.502642       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:45.502702       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:45.502723       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeac5df54a56, ext:47656338776, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.502741       1 update.go:396] Getting unavailable numbers
I0416 21:03:45.502747       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:03:45.502752       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:45.502756       1 update.go:68] Marking old pods for deletion
I0416 21:03:45.502759       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeac5df77a3e, ext:47656482086, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.502767       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:45.502802       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:45.502815       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:45.502826       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (868.331µs)
I0416 21:03:45.562747       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac565a1a60, ext:47528727904, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.562834       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac618c20a6, ext:47716555687, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.562848       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:45.576311       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:45.576335       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac618c20a6, ext:47716555687, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.576400       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (13.678175ms)
E0416 21:03:45.576416       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.577528       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:45.602972       1 daemon_controller.go:177] Adding daemon set metadata-proxy-v0.1
I0416 21:03:45.609279       1 wrap.go:47] GET /healthz: (139.396µs) 200 [kube-probe/1.15+ 127.0.0.1:36204]
I0416 21:03:45.613581       1 daemon_controller.go:387] ControllerRevision metadata-proxy-v0.1-7467df7b5b added.
I0416 21:03:45.614505       1 controller_utils.go:202] Controller kube-system/metadata-proxy-v0.1 either never recorded expectations, or the ttl expired.
I0416 21:03:45.614576       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeac64a15a87, ext:47768278406, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.614598       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:45.614658       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:45.614663       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeac64a15a87, ext:47768278406, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.614681       1 update.go:396] Getting unavailable numbers
I0416 21:03:45.614687       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:03:45.614693       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:45.614696       1 update.go:68] Marking old pods for deletion
I0416 21:03:45.614699       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeac64a38d36, ext:47768422443, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.614707       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:45.614738       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:45.614751       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:45.620550       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:03:45.622711       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (19.672657ms)
I0416 21:03:45.623274       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeac64a38d36, ext:47768422443, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.623354       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeac6527940b, ext:47777074953, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.623366       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:45.623417       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:45.623422       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeac6527940b, ext:47777074953, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.623437       1 update.go:396] Getting unavailable numbers
I0416 21:03:45.623443       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:03:45.623449       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:45.623452       1 update.go:68] Marking old pods for deletion
I0416 21:03:45.623455       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeac6529278b, ext:47777178242, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.623464       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:45.623499       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:45.623511       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:45.623522       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (766.697µs)
I0416 21:03:45.721354       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac56b2d7d5, ext:47534543563, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.721445       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac6b00551f, ext:47875166239, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.721460       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:45.897365       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac618c20a6, ext:47716555687, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.897461       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac757e203b, ext:48051182396, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.897476       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:45.939096       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:45.939111       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac6b00551f, ext:47875166239, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:45.939175       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (217.844659ms)
E0416 21:03:45.939189       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:45.940057       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:46.050758       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:46.050774       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac757e203b, ext:48051182396, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.050848       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (153.516415ms)
E0416 21:03:46.050861       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:46.051186       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:46.580377       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeac6b00551f, ext:47875166239, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.580457       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeaca299077b, ext:48734178427, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.580471       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:46.659526       1 deployment_controller.go:168] Adding deployment metrics-server-v0.3.1
I0416 21:03:46.659568       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:03:46.659545259 +0000 UTC m=+48.813269410)
I0416 21:03:46.659971       1 deployment_util.go:259] Updating replica set "metrics-server-v0.3.1-677c578bdf" revision to 1
I0416 21:03:46.692384       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeac757e203b, ext:48051182396, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.692458       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeaca9460560, ext:48846178912, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.692472       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:46.730141       1 controller_utils.go:202] Controller kube-system/metrics-server-v0.3.1-677c578bdf either never recorded expectations, or the ttl expired.
I0416 21:03:46.730214       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.730257       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/metrics-server-v0.3.1-677c578bdf, need 1, creating 1
I0416 21:03:46.730760       1 deployment_controller.go:214] ReplicaSet metrics-server-v0.3.1-677c578bdf added.
I0416 21:03:46.750101       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"metrics-server-v0.3.1", UID:"c815ba23-a2bf-4fc3-b5fc-f8f3d4010eaa", APIVersion:"apps/v1", ResourceVersion:"385", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set metrics-server-v0.3.1-677c578bdf to 1
I0416 21:03:46.780950       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:46.780965       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeaca299077b, ext:48734178427, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.781039       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (200.704203ms)
E0416 21:03:46.781053       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:46.781908       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:46.802527       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:03:46.804678       1 pvc_protection_controller.go:280] Got event on pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:03:46.804810       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"metrics-server-v0.3.1-677c578bdf-xl48c"}
I0416 21:03:46.804840       1 replica_set.go:275] Pod metrics-server-v0.3.1-677c578bdf-xl48c created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metrics-server-v0.3.1-677c578bdf-xl48c", GenerateName:"metrics-server-v0.3.1-677c578bdf-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c", UID:"224fe499-97c1-4296-b944-d6862030a620", ResourceVersion:"388", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045426, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"metrics-server", "pod-template-hash":"677c578bdf", "version":"v0.3.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"metrics-server-v0.3.1-677c578bdf", UID:"eb987e4f-a31f-4799-b1ca-cc8d0261c511", Controller:(*bool)(0xc0021685b7), BlockOwnerDeletion:(*bool)(0xc0021685b8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"metrics-server-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc001ca31c0), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"metrics-server-token-q95tp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001ca3200), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metrics-server", Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", Command:[]string{"/metrics-server", "--metric-resolution=30s", "--kubelet-port=10255", "--deprecated-kubelet-completely-insecure=true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"https", HostPort:0, ContainerPort:443, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"metrics-server-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=40m", "--extra-cpu=0.5m", "--memory=40Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=metrics-server-v0.3.1", "--container=metrics-server", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00145d580)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00145d5e0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:314572800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"300Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:5, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"5m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0021686c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"metrics-server", DeprecatedServiceAccount:"metrics-server", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ccc060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002168720)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002168740)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc002168748), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00216874c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:03:46.805160       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.805223       1 disruption.go:326] addPod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:03:46.805251       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:46.805254       1 disruption.go:329] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:03:46.807452       1 controller_utils.go:588] Controller metrics-server-v0.3.1-677c578bdf created pod metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:03:46.807535       1 replica_set_utils.go:58] Updating status for : kube-system/metrics-server-v0.3.1-677c578bdf, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:46.807951       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:03:46.749261891 +0000 UTC m=+48.902986042 - now: 2019-04-16 21:03:46.807945053 +0000 UTC m=+48.961669192]
I0416 21:03:46.808179       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"metrics-server-v0.3.1-677c578bdf", UID:"eb987e4f-a31f-4799-b1ca-cc8d0261c511", APIVersion:"apps/v1", ResourceVersion:"386", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:03:46.854913       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:46.854927       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeaca9460560, ext:48846178912, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.854986       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (162.632382ms)
E0416 21:03:46.855000       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:46.855354       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:46.858649       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-677c578bdf updated.
I0416 21:03:46.874294       1 pvc_protection_controller.go:280] Got event on pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:03:46.874438       1 replica_set.go:338] Pod metrics-server-v0.3.1-677c578bdf-xl48c updated, objectMeta {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:388 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc0021685b7 BlockOwnerDeletion:0xc0021685b8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:390 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc0022322b7 BlockOwnerDeletion:0xc0022322b8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:46.874574       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:03:46.874591       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:46.874594       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:03:46.875790       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (216.223406ms)
I0416 21:03:46.875804       1 deployment_controller.go:484] Error syncing deployment kube-system/metrics-server-v0.3.1: Operation cannot be fulfilled on deployments.apps "metrics-server-v0.3.1": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:46.875832       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:03:46.875828615 +0000 UTC m=+49.029552767)
I0416 21:03:46.876515       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:03:46 +0000 UTC - now: 2019-04-16 21:03:46.876511081 +0000 UTC m=+49.030235231]
I0416 21:03:46.878649       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (148.529107ms)
I0416 21:03:46.878685       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.878789       1 replica_set_utils.go:58] Updating status for : kube-system/metrics-server-v0.3.1-677c578bdf, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:46.920534       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:03:46.943622       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-677c578bdf updated.
I0416 21:03:46.945499       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (69.660396ms)
I0416 21:03:46.945547       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:03:46.945543309 +0000 UTC m=+49.099267461)
I0416 21:03:46.946620       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (67.938026ms)
I0416 21:03:46.946669       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:46.946745       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (82.756µs)
I0416 21:03:46.987546       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:03:47.003704       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (58.149243ms)
I0416 21:03:47.003755       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:03:47.003750715 +0000 UTC m=+49.157474865)
I0416 21:03:47.006245       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:03:46 +0000 UTC - now: 2019-04-16 21:03:47.006214613 +0000 UTC m=+49.159938752]
I0416 21:03:47.006294       1 progress.go:193] Queueing up deployment "metrics-server-v0.3.1" for a progress check after 598s
I0416 21:03:47.006326       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (2.573607ms)
I0416 21:03:47.056700       1 endpoints_controller.go:540] Update endpoints for kube-system/metrics-server, ready: 0 not ready: 0
I0416 21:03:47.073766       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (17.198618ms)
I0416 21:03:47.286166       1 gen.go:6086] GCEForwardingRules.Get(context.Background.WithDeadline(2019-04-16 22:03:47.057066537 +0000 UTC m=+3649.210790674 [59m59.770807334s]), Key{"a93fd09a94fb64d1e8a529a73e53f53d", region: "us-central1"}) = <nil>, googleapi: Error 404: The resource 'projects/peterhornyack-prod-no-enforcer/regions/us-central1/forwardingRules/a93fd09a94fb64d1e8a529a73e53f53d' was not found, notFound
I0416 21:03:47.286315       1 service_controller.go:330] Not persisting unchanged LoadBalancerStatus for service kube-system/metrics-server to registry.
I0416 21:03:47.286339       1 service_controller.go:716] Finished syncing service "kube-system/metrics-server" (229.277611ms)
E0416 21:03:48.067249       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:48.153306       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
E0416 21:03:48.067249       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
E0416 21:03:48.153306       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:48.061689       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeaca299077b, ext:48734178427, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:48.061807       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aead03af10a9, ext:50215528873, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:48.061821       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:48.067144       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8
I0416 21:03:48.067157       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aead03af10a9, ext:50215528873, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:48.067220       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (5.556266ms)
E0416 21:03:48.067249       1 replica_set.go:450] Sync "kube-system/kubernetes-dashboard-85bcf5dbf8" failed with pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:48.067893       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kubernetes-dashboard-85bcf5dbf8-" is forbidden: error looking up service account kube-system/kubernetes-dashboard: serviceaccount "kubernetes-dashboard" not found
I0416 21:03:48.135722       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeaca9460560, ext:48846178912, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:48.135811       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aead08184451, ext:50289532241, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:48.135825       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:48.153174       1 replica_set.go:505] Slow-start failure. Skipping creation of 1 pods, decrementing expectations for ReplicaSet kube-system/kube-dns-autoscaler-97df449df
I0416 21:03:48.153188       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aead08184451, ext:50289532241, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:48.153278       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (17.581601ms)
E0416 21:03:48.153306       1 replica_set.go:450] Sync "kube-system/kube-dns-autoscaler-97df449df" failed with pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:48.153853       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Warning' reason: 'FailedCreate' Error creating: pods "kube-dns-autoscaler-97df449df-" is forbidden: error looking up service account kube-system/kube-dns-autoscaler: serviceaccount "kube-dns-autoscaler" not found
I0416 21:03:48.958407       1 deployment_controller.go:168] Adding deployment fluentd-gcp-scaler
I0416 21:03:48.958452       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:03:48.958447181 +0000 UTC m=+51.112171316)
I0416 21:03:48.958726       1 deployment_util.go:259] Updating replica set "fluentd-gcp-scaler-7db4984bf4" revision to 1
I0416 21:03:48.963883       1 controller_utils.go:202] Controller kube-system/fluentd-gcp-scaler-7db4984bf4 either never recorded expectations, or the ttl expired.
I0416 21:03:48.963951       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:48.963985       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/fluentd-gcp-scaler-7db4984bf4, need 1, creating 1
I0416 21:03:48.964504       1 deployment_controller.go:214] ReplicaSet fluentd-gcp-scaler-7db4984bf4 added.
I0416 21:03:48.967021       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"fluentd-gcp-scaler", UID:"22de5f4e-504e-4d9d-b12a-0f6f1fb94b9c", APIVersion:"apps/v1", ResourceVersion:"426", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set fluentd-gcp-scaler-7db4984bf4 to 1
I0416 21:03:48.976602       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-scaler-7db4984bf4-26sjq
I0416 21:03:48.976720       1 controller_utils.go:588] Controller fluentd-gcp-scaler-7db4984bf4 created pod fluentd-gcp-scaler-7db4984bf4-26sjq
I0416 21:03:48.976776       1 replica_set_utils.go:58] Updating status for : kube-system/fluentd-gcp-scaler-7db4984bf4, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:48.977173       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-scaler-7db4984bf4-26sjq"}
I0416 21:03:48.977214       1 replica_set.go:275] Pod fluentd-gcp-scaler-7db4984bf4-26sjq created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-scaler-7db4984bf4-26sjq", GenerateName:"fluentd-gcp-scaler-7db4984bf4-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq", UID:"646aa3ab-46d8-46d1-8b1b-13596b4d3371", ResourceVersion:"428", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045428, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp-scaler", "pod-template-hash":"7db4984bf4"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"fluentd-gcp-scaler-7db4984bf4", UID:"9d4ec846-d076-4c91-9456-3f2fae399385", Controller:(*bool)(0xc00260c36e), BlockOwnerDeletion:(*bool)(0xc00260c36f)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"fluentd-gcp-scaler-token-6cb2b", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0024bf440), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp-scaler", Image:"k8s.gcr.io/fluentd-gcp-scaler:0.5.1", Command:[]string{"/scaler.sh", "--ds-name=fluentd-gcp-v3.2.0", "--scaling-policy=fluentd-gcp-scaling-policy"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"CPU_REQUEST", Value:"100m", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"MEMORY_REQUEST", Value:"200Mi", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CPU_LIMIT", Value:"1", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"MEMORY_LIMIT", Value:"500Mi", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"fluentd-gcp-scaler-token-6cb2b", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00260c408), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"fluentd-gcp-scaler", DeprecatedServiceAccount:"fluentd-gcp-scaler", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002606420), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00260c430)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00260c450)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00260c458), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00260c45c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"BestEffort"}}.
I0416 21:03:48.978664       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:48.978752       1 disruption.go:326] addPod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:03:48.978768       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:48.978772       1 disruption.go:329] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:03:48.979063       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"fluentd-gcp-scaler-7db4984bf4", UID:"9d4ec846-d076-4c91-9456-3f2fae399385", APIVersion:"apps/v1", ResourceVersion:"427", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: fluentd-gcp-scaler-7db4984bf4-26sjq
I0416 21:03:48.980625       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:03:48.983840       1 deployment_util.go:795] Deployment "fluentd-gcp-scaler" timed out (false) [last progress check: 2019-04-16 21:03:48.966607923 +0000 UTC m=+51.120332075 - now: 2019-04-16 21:03:48.983817212 +0000 UTC m=+51.137541363]
I0416 21:03:48.999286       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-scaler-7db4984bf4-26sjq
I0416 21:03:48.999466       1 replica_set.go:338] Pod fluentd-gcp-scaler-7db4984bf4-26sjq updated, objectMeta {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:428 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc00260c36e BlockOwnerDeletion:0xc00260c36f}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:430 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc00260d4ae BlockOwnerDeletion:0xc00260d4af}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:48.999622       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:03:48.999639       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:48.999657       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:03:49.005332       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (41.445262ms)
I0416 21:03:49.005381       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:49.005504       1 replica_set_utils.go:58] Updating status for : kube-system/fluentd-gcp-scaler-7db4984bf4, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:03:49.005958       1 deployment_controller.go:280] ReplicaSet fluentd-gcp-scaler-7db4984bf4 updated.
I0416 21:03:49.020927       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (62.467672ms)
I0416 21:03:49.020948       1 deployment_controller.go:484] Error syncing deployment kube-system/fluentd-gcp-scaler: Operation cannot be fulfilled on deployments.apps "fluentd-gcp-scaler": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:49.020991       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:03:49.020987289 +0000 UTC m=+51.174711423)
I0416 21:03:49.021491       1 deployment_util.go:795] Deployment "fluentd-gcp-scaler" timed out (false) [last progress check: 2019-04-16 21:03:48 +0000 UTC - now: 2019-04-16 21:03:49.02148171 +0000 UTC m=+51.175205847]
I0416 21:03:49.036813       1 replica_set_utils.go:58] Updating status for : kube-system/fluentd-gcp-scaler-7db4984bf4, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:49.044473       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:03:49.047472       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (26.474219ms)
I0416 21:03:49.047524       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:03:49.047520952 +0000 UTC m=+51.201245093)
I0416 21:03:49.049617       1 deployment_util.go:795] Deployment "fluentd-gcp-scaler" timed out (false) [last progress check: 2019-04-16 21:03:48 +0000 UTC - now: 2019-04-16 21:03:49.04960349 +0000 UTC m=+51.203327632]
I0416 21:03:49.049678       1 progress.go:193] Queueing up deployment "fluentd-gcp-scaler" for a progress check after 598s
I0416 21:03:49.049697       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (2.173961ms)
I0416 21:03:49.050786       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (45.407236ms)
I0416 21:03:49.050836       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:49.050942       1 replica_set_utils.go:58] Updating status for : kube-system/fluentd-gcp-scaler-7db4984bf4, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:49.051468       1 deployment_controller.go:280] ReplicaSet fluentd-gcp-scaler-7db4984bf4 updated.
I0416 21:03:49.051500       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:03:49.051495733 +0000 UTC m=+51.205219870)
I0416 21:03:49.059835       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:03:49.062171       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (10.663888ms)
I0416 21:03:49.062209       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:03:49.062204725 +0000 UTC m=+51.215928863)
I0416 21:03:49.062759       1 deployment_util.go:795] Deployment "fluentd-gcp-scaler" timed out (false) [last progress check: 2019-04-16 21:03:49 +0000 UTC - now: 2019-04-16 21:03:49.062752745 +0000 UTC m=+51.216476897]
I0416 21:03:49.062790       1 progress.go:193] Queueing up deployment "fluentd-gcp-scaler" for a progress check after 599s
I0416 21:03:49.062801       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (595.496µs)
I0416 21:03:49.064024       1 replica_set_utils.go:58] Updating status for : kube-system/fluentd-gcp-scaler-7db4984bf4, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:49.067691       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (16.854806ms)
I0416 21:03:49.067757       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:49.067852       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (106.307µs)
I0416 21:03:50.627788       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aead03af10a9, ext:50215528873, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.627875       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.627889       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kubernetes-dashboard-85bcf5dbf8, need 1, creating 1
I0416 21:03:50.635460       1 controller_utils.go:588] Controller kubernetes-dashboard-85bcf5dbf8 created pod kubernetes-dashboard-85bcf5dbf8-t5nl6
I0416 21:03:50.635594       1 replica_set_utils.go:58] Updating status for : kube-system/kubernetes-dashboard-85bcf5dbf8, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:50.636101       1 pvc_protection_controller.go:280] Got event on pod kube-system/kubernetes-dashboard-85bcf5dbf8-t5nl6
I0416 21:03:50.636117       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", APIVersion:"apps/v1", ResourceVersion:"335", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: kubernetes-dashboard-85bcf5dbf8-t5nl6
I0416 21:03:50.636210       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8-t5nl6"}
I0416 21:03:50.636256       1 replica_set.go:275] Pod kubernetes-dashboard-85bcf5dbf8-t5nl6 created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kubernetes-dashboard-85bcf5dbf8-t5nl6", GenerateName:"kubernetes-dashboard-85bcf5dbf8-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6", UID:"8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf", ResourceVersion:"447", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045430, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kubernetes-dashboard", "pod-template-hash":"85bcf5dbf8"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"kubernetes-dashboard-85bcf5dbf8", UID:"e9a8d0af-38ae-4c87-bb65-9510ad003870", Controller:(*bool)(0xc0027097ee), BlockOwnerDeletion:(*bool)(0xc0027097ef)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kubernetes-dashboard-certs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0027172c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"tmp-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(0xc001d79580), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"kubernetes-dashboard-token-kvhz6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002717300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kubernetes-dashboard", Image:"k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1", Command:[]string(nil), Args:[]string{"--auto-generate-certificates"}, WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"", HostPort:0, ContainerPort:8443, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:314572800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"300Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:104857600, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kubernetes-dashboard-certs", ReadOnly:false, MountPath:"/certs", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"tmp-volume", ReadOnly:false, MountPath:"/tmp", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"kubernetes-dashboard-token-kvhz6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc00279a720), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002709898), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"kubernetes-dashboard", DeprecatedServiceAccount:"kubernetes-dashboard", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0026f18c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0027098d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0027098f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc0027098f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0027098fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:03:50.637493       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.637636       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (54.993µs)
I0416 21:03:50.637663       1 disruption.go:326] addPod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:03:50.637689       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:50.637693       1 disruption.go:329] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:03:50.648466       1 pvc_protection_controller.go:280] Got event on pod kube-system/kubernetes-dashboard-85bcf5dbf8-t5nl6
I0416 21:03:50.648628       1 replica_set.go:338] Pod kubernetes-dashboard-85bcf5dbf8-t5nl6 updated, objectMeta {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:447 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc0027097ee BlockOwnerDeletion:0xc0027097ef}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:448 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc0027ac32e BlockOwnerDeletion:0xc0027ac32f}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:50.648771       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:03:50.648792       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:50.648796       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:03:50.665974       1 deployment_controller.go:280] ReplicaSet kubernetes-dashboard-85bcf5dbf8 updated.
I0416 21:03:50.665999       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:03:50.665994524 +0000 UTC m=+52.819718660)
I0416 21:03:50.673520       1 deployment_util.go:795] Deployment "kubernetes-dashboard" timed out (false) [last progress check: 2019-04-16 21:03:44 +0000 UTC - now: 2019-04-16 21:03:50.673509614 +0000 UTC m=+52.827233769]
I0416 21:03:50.698868       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (71.127747ms)
I0416 21:03:50.698934       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.700845       1 replica_set_utils.go:58] Updating status for : kube-system/kubernetes-dashboard-85bcf5dbf8, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:50.715055       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:03:50.715249       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aead08184451, ext:50289532241, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.715359       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.715375       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/kube-dns-autoscaler-97df449df, need 1, creating 1
I0416 21:03:50.719203       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (53.200821ms)
I0416 21:03:50.722602       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:03:50.722587057 +0000 UTC m=+52.876311194)
I0416 21:03:50.740855       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (41.930041ms)
I0416 21:03:50.740900       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.741045       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (152.215µs)
I0416 21:03:50.742965       1 deployment_controller.go:280] ReplicaSet kubernetes-dashboard-85bcf5dbf8 updated.
I0416 21:03:50.744159       1 pvc_protection_controller.go:280] Got event on pod kube-system/kube-dns-autoscaler-97df449df-4ggmd
I0416 21:03:50.746759       1 controller_utils.go:588] Controller kube-dns-autoscaler-97df449df created pod kube-dns-autoscaler-97df449df-4ggmd
I0416 21:03:50.746892       1 replica_set_utils.go:58] Updating status for : kube-system/kube-dns-autoscaler-97df449df, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:50.749110       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df-4ggmd"}
I0416 21:03:50.751206       1 replica_set.go:275] Pod kube-dns-autoscaler-97df449df-4ggmd created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-dns-autoscaler-97df449df-4ggmd", GenerateName:"kube-dns-autoscaler-97df449df-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd", UID:"50ee9110-be9e-4c36-8d01-00b5a25b69d9", ResourceVersion:"452", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045430, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-dns-autoscaler", "pod-template-hash":"97df449df"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", Controller:(*bool)(0xc002846140), BlockOwnerDeletion:(*bool)(0xc002846141)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-dns-autoscaler-token-7pj77", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00280f900), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"autoscaler", Image:"k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0", Command:[]string{"/cluster-proportional-autoscaler", "--namespace=kube-system", "--configmap=kube-dns-autoscaler", "--target=Deployment/coredns", "--default-params={\"linear\":{\"coresPerReplica\":256,\"nodesPerReplica\":16,\"preventSinglePointFailure\":true}}", "--logtostderr=true", "--v=2"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:20, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:10485760, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"10Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-dns-autoscaler-token-7pj77", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002846188), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"kube-dns-autoscaler", DeprecatedServiceAccount:"kube-dns-autoscaler", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0028287e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0028461d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0028461f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc0028461f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0028461fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:03:50.751761       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.763082       1 disruption.go:326] addPod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:03:50.763122       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:50.763135       1 disruption.go:329] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:03:50.765257       1 pvc_protection_controller.go:280] Got event on pod kube-system/kube-dns-autoscaler-97df449df-4ggmd
I0416 21:03:50.765517       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:03:50.765532       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df", UID:"8f66681d-ed44-4c71-bafd-e0213837e6f4", APIVersion:"apps/v1", ResourceVersion:"343", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: kube-dns-autoscaler-97df449df-4ggmd
I0416 21:03:50.765715       1 replica_set.go:338] Pod kube-dns-autoscaler-97df449df-4ggmd updated, objectMeta {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:452 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc002846140 BlockOwnerDeletion:0xc002846141}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:454 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc002846cd0 BlockOwnerDeletion:0xc002846cd1}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:50.765896       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:03:50.765914       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:50.765918       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:03:50.771776       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (49.177577ms)
I0416 21:03:50.771818       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:03:50.771814022 +0000 UTC m=+52.925538158)
I0416 21:03:50.777054       1 deployment_util.go:795] Deployment "kubernetes-dashboard" timed out (false) [last progress check: 2019-04-16 21:03:50 +0000 UTC - now: 2019-04-16 21:03:50.77704371 +0000 UTC m=+52.930767846]
I0416 21:03:50.779083       1 progress.go:193] Queueing up deployment "kubernetes-dashboard" for a progress check after 599s
I0416 21:03:50.779114       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (7.29705ms)
I0416 21:03:50.779986       1 deployment_controller.go:280] ReplicaSet kube-dns-autoscaler-97df449df updated.
I0416 21:03:50.780105       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:03:50.780007505 +0000 UTC m=+52.933731640)
I0416 21:03:50.786604       1 deployment_util.go:795] Deployment "kube-dns-autoscaler" timed out (false) [last progress check: 2019-04-16 21:03:45 +0000 UTC - now: 2019-04-16 21:03:50.786590617 +0000 UTC m=+52.940314754]
I0416 21:03:50.797687       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (82.545265ms)
I0416 21:03:50.797739       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.797892       1 replica_set_utils.go:58] Updating status for : kube-system/kube-dns-autoscaler-97df449df, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:03:50.806373       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:03:50.809501       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (29.478188ms)
I0416 21:03:50.809541       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:03:50.80953743 +0000 UTC m=+52.963261567)
I0416 21:03:50.812679       1 deployment_util.go:795] Deployment "kube-dns-autoscaler" timed out (false) [last progress check: 2019-04-16 21:03:45 +0000 UTC - now: 2019-04-16 21:03:50.812661943 +0000 UTC m=+52.966386080]
I0416 21:03:50.812749       1 progress.go:193] Queueing up deployment "kube-dns-autoscaler" for a progress check after 594s
I0416 21:03:50.812769       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (3.229456ms)
I0416 21:03:50.813163       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (15.425454ms)
I0416 21:03:50.813319       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:50.813457       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (144.975µs)
I0416 21:03:50.813644       1 deployment_controller.go:280] ReplicaSet kube-dns-autoscaler-97df449df updated.
I0416 21:03:50.813659       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:03:50.813654868 +0000 UTC m=+52.967379010)
I0416 21:03:50.821928       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (8.261901ms)
I0416 21:03:50.822155       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:03:50.822170       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:03:50.822165178 +0000 UTC m=+52.975889313)
I0416 21:03:50.824196       1 deployment_util.go:795] Deployment "kube-dns-autoscaler" timed out (false) [last progress check: 2019-04-16 21:03:50 +0000 UTC - now: 2019-04-16 21:03:50.824183701 +0000 UTC m=+52.977907858]
I0416 21:03:50.824355       1 progress.go:193] Queueing up deployment "kube-dns-autoscaler" for a progress check after 599s
I0416 21:03:50.824373       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (2.20559ms)
I0416 21:03:50.964273       1 controller.go:123] Found 0 jobs
I0416 21:03:50.966694       1 controller.go:139] Found 0 cronjobs
I0416 21:03:50.966719       1 controller.go:142] Found 0 groups
E0416 21:03:54.177119       1 daemon_controller.go:302] kube-system/metadata-proxy-v0.1 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metadata-proxy-v0.1", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/metadata-proxy-v0.1", UID:"42862d28-8b1c-4254-8477-23a0fd36a8bb", ResourceVersion:"374", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"},\"name\":\"metadata-proxy-v0.1\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"metadata-proxy\",\"version\":\"v0.1\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"}},\"spec\":{\"containers\":[{\"image\":\"k8s.gcr.io/metadata-proxy:v0.1.11\",\"name\":\"metadata-proxy\",\"resources\":{\"limits\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"},\"requests\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"}},\"securityContext\":{\"privileged\":true}},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\",\"resources\":{\"limits\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"},\"requests\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"}}}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/metadata-proxy-ready\":\"true\",\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"metadata-proxy\",\"terminationGracePeriodSeconds\":30,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc000423800), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metadata-proxy", Image:"k8s.gcr.io/metadata-proxy:v0.1.11", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc0020a5d60), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000423840)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000423880)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001e4c368), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/metadata-proxy-ready":"true", "beta.kubernetes.io/os":"linux"}, ServiceAccountName:"metadata-proxy", DeprecatedServiceAccount:"metadata-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ff7860), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00000e4d8)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc001e4c3cc)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:1, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "metadata-proxy-v0.1": the object has been modified; please apply your changes to the latest version and try again
E0416 21:03:54.192078       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"363", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc0011ecfa0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0011ecfc0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0011ecfe0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0021bdd40), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed000)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc000a04510), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed0a0)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed0e0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00170f418), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ce9980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0004afe20)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00170f700)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:1, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
W0416 21:03:54.030645       1 actual_state_of_world.go:503] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="e2e-test-peterhornyack-master" does not exist
E0416 21:03:54.177119       1 daemon_controller.go:302] kube-system/metadata-proxy-v0.1 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metadata-proxy-v0.1", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/metadata-proxy-v0.1", UID:"42862d28-8b1c-4254-8477-23a0fd36a8bb", ResourceVersion:"374", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"},\"name\":\"metadata-proxy-v0.1\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"metadata-proxy\",\"version\":\"v0.1\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"}},\"spec\":{\"containers\":[{\"image\":\"k8s.gcr.io/metadata-proxy:v0.1.11\",\"name\":\"metadata-proxy\",\"resources\":{\"limits\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"},\"requests\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"}},\"securityContext\":{\"privileged\":true}},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\",\"resources\":{\"limits\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"},\"requests\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"}}}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/metadata-proxy-ready\":\"true\",\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"metadata-proxy\",\"terminationGracePeriodSeconds\":30,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc000423800), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metadata-proxy", Image:"k8s.gcr.io/metadata-proxy:v0.1.11", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc0020a5d60), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000423840)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000423880)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001e4c368), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/metadata-proxy-ready":"true", "beta.kubernetes.io/os":"linux"}, ServiceAccountName:"metadata-proxy", DeprecatedServiceAccount:"metadata-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ff7860), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00000e4d8)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc001e4c3cc)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:1, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "metadata-proxy-v0.1": the object has been modified; please apply your changes to the latest version and try again
E0416 21:03:54.192078       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"363", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc0011ecfa0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0011ecfc0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0011ecfe0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0021bdd40), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed000)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc000a04510), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed0a0)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed0e0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00170f418), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ce9980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0004afe20)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00170f700)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:1, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
W0416 21:03:56.817138       1 node_lifecycle_controller.go:831] Missing timestamp for Node e2e-test-peterhornyack-master. Assuming now as a timestamp.
I0416 21:03:54.022159       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeac5df77a3e, ext:47656482086, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.024310       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae81727c49, ext:56178004338, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.024397       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [e2e-test-peterhornyack-master], creating 1
I0416 21:03:54.030070       1 taint_manager.go:441] Noticed node update: scheduler.nodeUpdateItem{nodeName:"e2e-test-peterhornyack-master"}
I0416 21:03:54.030090       1 taint_manager.go:446] Updating known taints on node e2e-test-peterhornyack-master: []
I0416 21:03:54.030631       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
W0416 21:03:54.030645       1 actual_state_of_world.go:503] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="e2e-test-peterhornyack-master" does not exist
I0416 21:03:54.030681       1 cloud_cidr_allocator.go:237] Putting node e2e-test-peterhornyack-master into the work queue
I0416 21:03:54.031517       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeac6529278b, ext:47777178242, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.031625       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae81e283b0, ext:56185346224, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.031637       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [e2e-test-peterhornyack-master], creating 1
I0416 21:03:54.068943       1 controller_utils.go:588] Controller metadata-proxy-v0.1 created pod metadata-proxy-v0.1-ll5kc
I0416 21:03:54.069005       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.069020       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae81e283b0, ext:56185346224, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.069092       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.069842       1 event.go:258] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"metadata-proxy-v0.1", UID:"42862d28-8b1c-4254-8477-23a0fd36a8bb", APIVersion:"apps/v1", ResourceVersion:"374", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: metadata-proxy-v0.1-ll5kc
I0416 21:03:54.072053       1 controller_utils.go:588] Controller fluentd-gcp-v3.2.0 created pod fluentd-gcp-v3.2.0-vqwbk
I0416 21:03:54.072098       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.072111       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae81727c49, ext:56178004338, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.072182       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.072582       1 event.go:258] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", APIVersion:"apps/v1", ResourceVersion:"363", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: fluentd-gcp-v3.2.0-vqwbk
I0416 21:03:54.074167       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-vqwbk
I0416 21:03:54.074255       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-vqwbk"}
I0416 21:03:54.074315       1 daemon_controller.go:506] Pod fluentd-gcp-v3.2.0-vqwbk added.
I0416 21:03:54.074321       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae81727c49, ext:56178004338, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.074343       1 disruption.go:326] addPod called on pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:03:54.074364       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-vqwbk, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.074368       1 disruption.go:329] No matching pdb for pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:03:54.074493       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:03:54.074502       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.074505       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:03:54.074510       1 pvc_protection_controller.go:280] Got event on pod kube-system/coredns-5b969f4c88-zcdpb
I0416 21:03:54.074548       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"metadata-proxy-v0.1-ll5kc"}
I0416 21:03:54.074565       1 replica_set.go:338] Pod coredns-5b969f4c88-zcdpb updated, objectMeta {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:295 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc000c53fdf BlockOwnerDeletion:0xc0018de010}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:466 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc002168e77 BlockOwnerDeletion:0xc002168e78}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:54.074625       1 pvc_protection_controller.go:280] Got event on pod kube-system/metadata-proxy-v0.1-ll5kc
I0416 21:03:54.074641       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.074707       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (70.224µs)
I0416 21:03:54.074731       1 daemon_controller.go:506] Pod metadata-proxy-v0.1-ll5kc added.
I0416 21:03:54.074734       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae81e283b0, ext:56185346224, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.074742       1 disruption.go:326] addPod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:03:54.074752       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.074755       1 disruption.go:329] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:03:54.104118       1 controller_utils.go:200] Added [&Taint{Key:node.kubernetes.io/network-unavailable,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:03:54.030444654 +0000 UTC m=+56.184168814,} &Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:03:54.030444835 +0000 UTC m=+56.184168972,}] Taint to Node e2e-test-peterhornyack-master
I0416 21:03:54.104196       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-master has no [] Taint
I0416 21:03:54.107450       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (76.438705ms)
I0416 21:03:54.108100       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae81e283b0, ext:56185346224, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.108211       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae86731def, ext:56261931759, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.108224       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:54.108274       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.108279       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae86731def, ext:56261931759, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.108300       1 update.go:396] Getting unavailable numbers
I0416 21:03:54.108343       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:03:54.108348       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:54.108353       1 update.go:68] Marking old pods for deletion
I0416 21:03:54.108356       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae86755b85, ext:56262078588, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.108363       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:54.108384       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.108412       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.108940       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:03:54.108967       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-master is already in a process of CIDR assignment.
I0416 21:03:54.114266       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (92.645145ms)
I0416 21:03:54.114922       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae81727c49, ext:56178004338, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.115026       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae86db18c8, ext:56268746184, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.115050       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:54.115085       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.115089       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae86db18c8, ext:56268746184, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.115123       1 update.go:396] Getting unavailable numbers
I0416 21:03:54.115151       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:03:54.115156       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:54.115160       1 update.go:68] Marking old pods for deletion
I0416 21:03:54.115163       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae86dd3b9b, ext:56268886161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.115169       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:54.115202       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.115218       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.117478       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:03:54.117540       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:03:54.142820       1 ttl_controller.go:271] Changed ttl annotation for node e2e-test-peterhornyack-master to 0 seconds
I0416 21:03:54.142979       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:03:54.143008       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-master is already in a process of CIDR assignment.
I0416 21:03:54.155819       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-vqwbk"}
I0416 21:03:54.156703       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-vqwbk updated.
I0416 21:03:54.156723       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:03:54.156744       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-vqwbk, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.156747       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:03:54.177100       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (69.607945ms)
E0416 21:03:54.177119       1 daemon_controller.go:302] kube-system/metadata-proxy-v0.1 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metadata-proxy-v0.1", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/metadata-proxy-v0.1", UID:"42862d28-8b1c-4254-8477-23a0fd36a8bb", ResourceVersion:"374", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"},\"name\":\"metadata-proxy-v0.1\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"metadata-proxy\",\"version\":\"v0.1\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"}},\"spec\":{\"containers\":[{\"image\":\"k8s.gcr.io/metadata-proxy:v0.1.11\",\"name\":\"metadata-proxy\",\"resources\":{\"limits\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"},\"requests\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"}},\"securityContext\":{\"privileged\":true}},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\",\"resources\":{\"limits\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"},\"requests\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"}}}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/metadata-proxy-ready\":\"true\",\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"metadata-proxy\",\"terminationGracePeriodSeconds\":30,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc000423800), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metadata-proxy", Image:"k8s.gcr.io/metadata-proxy:v0.1.11", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc0020a5d60), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000423840)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000423880)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001e4c368), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/metadata-proxy-ready":"true", "beta.kubernetes.io/os":"linux"}, ServiceAccountName:"metadata-proxy", DeprecatedServiceAccount:"metadata-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ff7860), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00000e4d8)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc001e4c3cc)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:1, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "metadata-proxy-v0.1": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:54.180933       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae86755b85, ext:56262078588, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.181088       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae8acb2292, ext:56334809006, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.181100       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:54.181162       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.181168       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae8acb2292, ext:56334809006, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.181290       1 update.go:396] Getting unavailable numbers
I0416 21:03:54.181320       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:03:54.181326       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:54.181330       1 update.go:68] Marking old pods for deletion
I0416 21:03:54.181334       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae8acee8db, ext:56335056337, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.184396       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:54.184512       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.184590       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.192059       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (77.755648ms)
E0416 21:03:54.192078       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"363", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc0011ecfa0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0011ecfc0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0011ecfe0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0021bdd40), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed000)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc000a04510), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed0a0)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0011ed0e0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00170f418), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ce9980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0004afe20)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00170f700)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:1, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
I0416 21:03:54.198549       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae86dd3b9b, ext:56268886161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.198719       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae8bd828f3, ext:56352439820, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.198732       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:54.198787       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.198793       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae8bd828f3, ext:56352439820, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.198814       1 update.go:396] Getting unavailable numbers
I0416 21:03:54.198865       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:03:54.198872       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:54.198877       1 update.go:68] Marking old pods for deletion
I0416 21:03:54.198880       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae8bdaa668, ext:56352602960, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.198888       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:54.198909       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.198930       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.199710       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"metadata-proxy-v0.1-ll5kc"}
I0416 21:03:54.199821       1 daemon_controller.go:554] Pod metadata-proxy-v0.1-ll5kc updated.
I0416 21:03:54.199834       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:03:54.199851       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.199856       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:03:54.234538       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:03:54.243575       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (66.364735ms)
I0416 21:03:54.244119       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae8acee8db, ext:56335056337, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.244264       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae8e8f2092, ext:56397985167, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.244277       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:54.244310       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.244315       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae8e8f2092, ext:56397985167, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.244351       1 update.go:396] Getting unavailable numbers
I0416 21:03:54.244379       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:03:54.244384       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:54.244388       1 update.go:68] Marking old pods for deletion
I0416 21:03:54.244391       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae8e911883, ext:56398114162, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.244412       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:54.244434       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.244450       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.244512       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (899.263µs)
I0416 21:03:54.277705       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:03:54.300132       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (107.954994ms)
I0416 21:03:54.300801       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae8bdaa668, ext:56352602960, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.300921       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae91efa561, ext:56454642272, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.300934       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:54.300966       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.300970       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae91efa561, ext:56454642272, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.300992       1 update.go:396] Getting unavailable numbers
I0416 21:03:54.301020       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:03:54.301026       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:54.301030       1 update.go:68] Marking old pods for deletion
I0416 21:03:54.301033       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae91f16197, ext:56454755970, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.301040       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:54.301063       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.301077       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.301109       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (939.518µs)
I0416 21:03:54.302628       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 22:03:54.03072519 +0000 UTC m=+3656.184449331 [59m59.72809115s]), Key{"e2e-test-peterhornyack-master", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:00:36.904-07:00 DeletionProtection:false Description: Disks:[0xc002112620 0xc002112700] GuestAccelerators:[] Id:1640292650120379548 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-1 Metadata:0xc00039a070 MinCpuPlatform: Name:e2e-test-peterhornyack-master NetworkInterfaces:[0xc0011766c0] Scheduling:0xc00039a150 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-master ServiceAccounts:[0xc001898540] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc0018984e0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:03:54 GMT] Etag:["pT_iPn2dfgymmciEXiy6Dv2xbP4=/mDwLdsvO4js_TkKQ6EGvYNJMEWU="] Expires:[Tue, 16 Apr 2019 21:03:54 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 21:03:54.318290       1 pvc_protection_controller.go:280] Got event on pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:03:54.318484       1 replica_set.go:338] Pod metrics-server-v0.3.1-677c578bdf-xl48c updated, objectMeta {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:390 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc0022322b7 BlockOwnerDeletion:0xc0022322b8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:476 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc0013f1687 BlockOwnerDeletion:0xc0013f1688}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:54.318624       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.318742       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (125.533µs)
I0416 21:03:54.318815       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:03:54.318844       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.318849       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:03:54.394628       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-vqwbk updated.
I0416 21:03:54.395356       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae91f16197, ext:56454755970, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.395487       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae979267b9, ext:56549194938, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.395510       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:54.395544       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.395548       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae979267b9, ext:56549194938, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.395583       1 update.go:396] Getting unavailable numbers
I0416 21:03:54.395620       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:03:54.395625       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:54.395629       1 update.go:68] Marking old pods for deletion
I0416 21:03:54.395649       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae9794da19, ext:56549355267, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.395656       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:03:54.395674       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:03:54.395690       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.395743       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.090803ms)
I0416 21:03:54.395783       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:03:54.395815       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-vqwbk, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.395819       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:03:54.412512       1 pvc_protection_controller.go:280] Got event on pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:03:54.412630       1 replica_set.go:338] Pod heapster-v1.6.0-beta.1-5858bf5485-5td9x updated, objectMeta {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:324 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc0014cbf07 BlockOwnerDeletion:0xc0014cbf08}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:480 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc0012c28e7 BlockOwnerDeletion:0xc0012c28e8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:54.412711       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.412812       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (107.494µs)
I0416 21:03:54.412867       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:03:54.412879       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.412883       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:03:54.435604       1 daemon_controller.go:554] Pod metadata-proxy-v0.1-ll5kc updated.
I0416 21:03:54.436113       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae8e911883, ext:56398114162, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.436279       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae9a010401, ext:56589998334, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.436309       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:54.436346       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.436350       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae9a010401, ext:56589998334, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.436389       1 update.go:396] Getting unavailable numbers
I0416 21:03:54.436418       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:03:54.436423       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:03:54.436428       1 update.go:68] Marking old pods for deletion
I0416 21:03:54.436432       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae9a03640e, ext:56590154358, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.436455       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:03:54.436472       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:03:54.436490       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:03:54.436569       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (943.332µs)
I0416 21:03:54.436591       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:03:54.436622       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.436626       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:03:54.448443       1 pvc_protection_controller.go:280] Got event on pod kube-system/kubernetes-dashboard-85bcf5dbf8-t5nl6
I0416 21:03:54.448602       1 replica_set.go:338] Pod kubernetes-dashboard-85bcf5dbf8-t5nl6 updated, objectMeta {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:448 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc0027ac32e BlockOwnerDeletion:0xc0027ac32f}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:482 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc0012c38ae BlockOwnerDeletion:0xc0012c38af}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:54.448697       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.448991       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (298.57µs)
I0416 21:03:54.449052       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:03:54.449081       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.449085       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:03:54.468165       1 pvc_protection_controller.go:280] Got event on pod kube-system/kube-dns-autoscaler-97df449df-4ggmd
I0416 21:03:54.468350       1 replica_set.go:338] Pod kube-dns-autoscaler-97df449df-4ggmd updated, objectMeta {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:454 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc002846cd0 BlockOwnerDeletion:0xc002846cd1}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:483 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc0017e6237 BlockOwnerDeletion:0xc0017e6238}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:54.468453       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.468577       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (118.4µs)
I0416 21:03:54.468631       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:03:54.468662       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.468665       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:03:54.541665       1 pvc_protection_controller.go:280] Got event on pod kube-system/event-exporter-v0.2.4-65d8d98768-n6vvr
I0416 21:03:54.541815       1 replica_set.go:338] Pod event-exporter-v0.2.4-65d8d98768-n6vvr updated, objectMeta {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:354 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc0014cccb7 BlockOwnerDeletion:0xc0014cccb8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:484 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc0017e6fc7 BlockOwnerDeletion:0xc0017e6fc8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:54.541927       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.542032       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (111.942µs)
I0416 21:03:54.542115       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:03:54.542143       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.542146       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:03:54.615571       1 gen.go:9971] GCEBetaInstances.Get(context.Background.WithDeadline(2019-04-16 22:03:54.030720811 +0000 UTC m=+3656.184444965 [59m59.415139377s]), Key{"e2e-test-peterhornyack-master", zone: "us-central1-b"}) = &{AllocationAffinity:<nil> CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:00:36.904-07:00 DeletionProtection:false Description: Disks:[0xc002113180 0xc002113260] DisplayDevice:<nil> GuestAccelerators:[] Hostname: Id:1640292650120379548 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-1 Metadata:0xc0007872d0 MinCpuPlatform: Name:e2e-test-peterhornyack-master NetworkInterfaces:[0xc001176a80] Scheduling:0xc0007873b0 SelfLink:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-master ServiceAccounts:[0xc000b02660] ShieldedVmConfig:<nil> ShieldedVmIntegrityPolicy:<nil> StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc000ea9980 Zone:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:03:54 GMT] Etag:["eYW32uJxuGvS7pKsPbyPMpio-xo=/cvhMq1R2s50ObonWM2OBl9Z1Dog="] Expires:[Tue, 16 Apr 2019 21:03:54 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 21:03:54.676704       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 22:03:54.349532462 +0000 UTC m=+3656.503256615 [59m59.672815841s]), Key{"e2e-test-peterhornyack-master", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:00:36.904-07:00 DeletionProtection:false Description: Disks:[0xc002113340 0xc002113420] GuestAccelerators:[] Id:1640292650120379548 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-1 Metadata:0xc000787420 MinCpuPlatform: Name:e2e-test-peterhornyack-master NetworkInterfaces:[0xc001176b40] Scheduling:0xc000787500 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-master ServiceAccounts:[0xc000885740] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc0008856e0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:03:54 GMT] Etag:["LOkgr64OzNdLCa2EsiN8hLefmJ0=/Ucl9cdpHyk1-YlvcHJghF2QioZo="] Expires:[Tue, 16 Apr 2019 21:03:54 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 21:03:54.677103       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:03:54.677136       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-master is already in a process of CIDR assignment.
I0416 21:03:54.687665       1 pvc_protection_controller.go:280] Got event on pod kube-system/l7-default-backend-8f479dd9-wbtkw
I0416 21:03:54.687824       1 cloud_cidr_allocator.go:282] Set node e2e-test-peterhornyack-master PodCIDR to 10.64.0.0/24
I0416 21:03:54.688204       1 replica_set.go:338] Pod l7-default-backend-8f479dd9-wbtkw updated, objectMeta {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:306 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc001772177 BlockOwnerDeletion:0xc001772178}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:486 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc001698257 BlockOwnerDeletion:0xc001698258}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:54.690413       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.695192       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (4.770683ms)
I0416 21:03:54.695352       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:03:54.695376       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.695379       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:03:54.724343       1 cloud_cidr_allocator.go:159] Updated CIDR for "e2e-test-peterhornyack-master"
I0416 21:03:54.724791       1 controller_utils.go:200] Added [] Taint to Node e2e-test-peterhornyack-master
I0416 21:03:54.725762       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:03:54.725846       1 cloud_cidr_allocator.go:237] Putting node e2e-test-peterhornyack-master into the work queue
I0416 21:03:54.773087       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:03:54.786771       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-scaler-7db4984bf4-26sjq
I0416 21:03:54.786905       1 replica_set.go:338] Pod fluentd-gcp-scaler-7db4984bf4-26sjq updated, objectMeta {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:430 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc00260d4ae BlockOwnerDeletion:0xc00260d4af}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:489 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc0014cc23e BlockOwnerDeletion:0xc0014cc23f}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:03:54.786998       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:03:54.787093       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (101.022µs)
I0416 21:03:54.787212       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:03:54.787242       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:03:54.787246       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:03:54.807879       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-master has no [&Taint{Key:node.kubernetes.io/network-unavailable,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:03:54 +0000 UTC,}] Taint
I0416 21:03:54.893091       1 controller_utils.go:200] Added [] Taint to Node e2e-test-peterhornyack-master
I0416 21:03:54.894358       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:03:54.964785       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 22:03:54.72586153 +0000 UTC m=+3656.879585671 [59m59.76106581s]), Key{"e2e-test-peterhornyack-master", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:00:36.904-07:00 DeletionProtection:false Description: Disks:[0xc001539b20 0xc001539c00] GuestAccelerators:[] Id:1640292650120379548 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-1 Metadata:0xc000384850 MinCpuPlatform: Name:e2e-test-peterhornyack-master NetworkInterfaces:[0xc001176c00] Scheduling:0xc0003849a0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-master ServiceAccounts:[0xc001452f60] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001452f00 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:03:54 GMT] Etag:["4GUlHB4ie2r3s7T-WhhuSuaxss4=/qgHrpKtxjpCVIR3QyhKR0Dy35PU="] Expires:[Tue, 16 Apr 2019 21:03:54 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 21:03:54.983614       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:03:54.983889       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-master has no [&Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:03:54 +0000 UTC,}] Taint
I0416 21:03:55.251838       1 gen.go:9971] GCEBetaInstances.Get(context.Background.WithDeadline(2019-04-16 22:03:54.725857403 +0000 UTC m=+3656.879581540 [59m59.47400959s]), Key{"e2e-test-peterhornyack-master", zone: "us-central1-b"}) = &{AllocationAffinity:<nil> CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:00:36.904-07:00 DeletionProtection:false Description: Disks:[0xc001539dc0 0xc001539ea0] DisplayDevice:<nil> GuestAccelerators:[] Hostname: Id:1640292650120379548 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-1 Metadata:0xc000384f50 MinCpuPlatform: Name:e2e-test-peterhornyack-master NetworkInterfaces:[0xc001176cc0] Scheduling:0xc000385110 SelfLink:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-master ServiceAccounts:[0xc001453620] ShieldedVmConfig:<nil> ShieldedVmIntegrityPolicy:<nil> StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc0014535c0 Zone:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:03:55 GMT] Etag:["CBhFf8QbO3ZyiR-bjDEUDu_e3Ao=/sHuVoqOYpUWJcBsSfhKW-bEFc70="] Expires:[Tue, 16 Apr 2019 21:03:55 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 21:03:55.251979       1 cloud_cidr_allocator.go:269] Node e2e-test-peterhornyack-master already has allocated CIDR 10.64.0.0/24. It matches the proposed one.
I0416 21:03:55.268685       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:03:55.271914       1 cloud_cidr_allocator.go:159] Updated CIDR for "e2e-test-peterhornyack-master"
I0416 21:03:55.608624       1 wrap.go:47] GET /healthz: (147.331µs) 200 [kube-probe/1.15+ 127.0.0.1:36264]
I0416 21:03:56.816996       1 node_lifecycle_controller.go:642] Controller observed a new Node: "e2e-test-peterhornyack-master"
I0416 21:03:56.817027       1 controller_utils.go:164] Recording Registered Node e2e-test-peterhornyack-master in Controller event message for node e2e-test-peterhornyack-master
I0416 21:03:56.817061       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
W0416 21:03:56.817138       1 node_lifecycle_controller.go:831] Missing timestamp for Node e2e-test-peterhornyack-master. Assuming now as a timestamp.
I0416 21:03:56.817568       1 event.go:258] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"e2e-test-peterhornyack-master", UID:"e4e1c41a-2b5a-4e37-a602-af2ce7b9ab61", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node e2e-test-peterhornyack-master event: Registered Node e2e-test-peterhornyack-master in Controller
I0416 21:03:57.027614       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:03:57.212683       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:04:00.970181       1 controller.go:123] Found 0 jobs
I0416 21:04:00.976759       1 controller.go:139] Found 0 cronjobs
I0416 21:04:00.976770       1 controller.go:142] Found 0 groups
I0416 21:04:01.157109       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:04:01.817442       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:01.896603       1 gc_controller.go:144] GC'ing orphaned
I0416 21:04:01.900843       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:04:05.608523       1 wrap.go:47] GET /healthz: (111.571µs) 200 [kube-probe/1.15+ 127.0.0.1:36330]
I0416 21:04:06.817719       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:06.968405       1 daemon_controller.go:554] Pod metadata-proxy-v0.1-ll5kc updated.
I0416 21:04:06.968841       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeae9a03640e, ext:56590154358, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:06.968946       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeb1b9c0e7e6, ext:69122667746, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:06.968958       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:04:06.968991       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:04:06.968996       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeb1b9c0e7e6, ext:69122667746, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:06.969023       1 update.go:396] Getting unavailable numbers
I0416 21:04:06.969050       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:04:06.969055       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:04:06.969059       1 update.go:68] Marking old pods for deletion
I0416 21:04:06.969062       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeb1b9c2b206, ext:69122785007, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:06.969068       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:04:06.969087       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:04:06.969103       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:04:06.973944       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:04:06.973995       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:06.973999       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:04:06.985037       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:04:06.989976       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (21.532667ms)
I0416 21:04:06.990777       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeb1b9c2b206, ext:69122785007, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:06.990918       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeb1bb0ff0bb, ext:69144624573, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:06.990943       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:04:06.990981       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:04:06.991003       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeb1bb0ff0bb, ext:69144624573, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:06.991040       1 update.go:396] Getting unavailable numbers
I0416 21:04:06.991067       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:04:06.991101       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:04:06.991105       1 update.go:68] Marking old pods for deletion
I0416 21:04:06.991109       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeb1bb1318e2, ext:69144831449, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:06.991117       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:04:06.991140       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:04:06.991159       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:04:06.991219       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.185432ms)
I0416 21:04:10.986926       1 controller.go:123] Found 0 jobs
I0416 21:04:10.989598       1 controller.go:139] Found 0 cronjobs
I0416 21:04:10.989609       1 controller.go:142] Found 0 groups
I0416 21:04:11.480939       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-vqwbk updated.
I0416 21:04:11.481954       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeae9794da19, ext:56549355267, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:11.482085       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeb2dcbbfa83, ext:73635805574, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:11.482098       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:04:11.482132       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:04:11.482137       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeb2dcbbfa83, ext:73635805574, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:11.482164       1 update.go:396] Getting unavailable numbers
I0416 21:04:11.482185       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:04:11.482190       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:04:11.482193       1 update.go:68] Marking old pods for deletion
I0416 21:04:11.482196       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeb2dcbdb6d2, ext:73635919290, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:11.482203       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:04:11.482221       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:04:11.482252       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:04:11.482604       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:04:11.482625       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-vqwbk, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:11.482629       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:04:11.492473       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:04:11.492661       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (11.698599ms)
I0416 21:04:11.493312       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeb2dcbdb6d2, ext:73635919290, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:11.493440       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeb2dd694204, ext:73647161605, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:11.493454       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:04:11.493501       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:04:11.493505       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeb2dd694204, ext:73647161605, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:11.493528       1 update.go:396] Getting unavailable numbers
I0416 21:04:11.493551       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:04:11.493556       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:04:11.493561       1 update.go:68] Marking old pods for deletion
I0416 21:04:11.493564       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeb2dd6b2ab3, ext:73647286684, loc:(*time.Location)(0x71c51c0)}}
I0416 21:04:11.493584       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:04:11.493605       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:04:11.493620       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:04:11.493699       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.012715ms)
I0416 21:04:11.737461       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:04:11.741790       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:04:11.818066       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:12.027846       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:04:12.212972       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:04:12.633145       1 request.go:530] Throttling request took 88.467569ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:04:12.635698       1 request.go:530] Throttling request took 87.064418ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:04:12.683138       1 request.go:530] Throttling request took 138.452681ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:04:12.685692       1 request.go:530] Throttling request took 137.043008ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:04:12.733178       1 request.go:530] Throttling request took 188.483283ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:04:12.735727       1 request.go:530] Throttling request took 187.078488ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:04:12.783358       1 request.go:530] Throttling request took 238.656207ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:04:12.785719       1 request.go:530] Throttling request took 237.046156ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:04:12.833163       1 request.go:530] Throttling request took 288.452281ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:04:12.835754       1 request.go:530] Throttling request took 287.087166ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
E0416 21:04:12.985944       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:04:12.985944       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:04:12.883203       1 request.go:530] Throttling request took 338.480599ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:04:12.885671       1 request.go:530] Throttling request took 336.998762ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:04:12.933166       1 request.go:530] Throttling request took 388.437889ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:04:12.935625       1 request.go:530] Throttling request took 386.943883ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:04:12.983184       1 request.go:530] Throttling request took 438.431102ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
E0416 21:04:12.985944       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:04:12.986360       1 resource_quota_controller.go:433] syncing resource quota controller with updated resources from discovery: added: [scalingpolicy.kope.io/v1alpha1, Resource=scalingpolicies], removed: []
I0416 21:04:12.986538       1 resource_quota_monitor.go:176] QuotaMonitor using a shared informer for resource "scalingpolicy.kope.io/v1alpha1, Resource=scalingpolicies"
I0416 21:04:12.986582       1 resource_quota_monitor.go:228] QuotaMonitor created object count evaluator for scalingpolicies.scalingpolicy.kope.io
I0416 21:04:12.986603       1 resource_quota_monitor.go:243] quota synced monitors; added 1, kept 32, removed 0
I0416 21:04:12.986628       1 resource_quota_monitor.go:275] QuotaMonitor started 1 new monitors, 33 currently running
I0416 21:04:12.986635       1 controller_utils.go:1028] Waiting for caches to sync for resource quota controller
I0416 21:04:12.986836       1 reflector.go:128] Starting reflector *unstructured.Unstructured (3m0.140559741s) from k8s.io/client-go/dynamic/dynamicinformer/informer.go:90
I0416 21:04:12.986846       1 reflector.go:166] Listing and watching *unstructured.Unstructured from k8s.io/client-go/dynamic/dynamicinformer/informer.go:90
I0416 21:04:12.988340       1 request.go:530] Throttling request took 439.633171ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:04:13.087180       1 shared_informer.go:123] caches populated
I0416 21:04:13.087195       1 controller_utils.go:1035] Caches are synced for resource quota controller
I0416 21:04:13.087203       1 resource_quota_controller.go:452] synced quota controller
I0416 21:04:13.185439       1 request.go:530] Throttling request took 96.847123ms, request: GET:https://localhost:443/api/v1?timeout=32s
I0416 21:04:13.235455       1 request.go:530] Throttling request took 146.830393ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1?timeout=32s
I0416 21:04:13.285657       1 request.go:530] Throttling request took 197.024467ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1beta1?timeout=32s
I0416 21:04:13.335440       1 request.go:530] Throttling request took 246.794273ms, request: GET:https://localhost:443/apis/extensions/v1beta1?timeout=32s
I0416 21:04:13.385469       1 request.go:530] Throttling request took 296.823874ms, request: GET:https://localhost:443/apis/apps/v1?timeout=32s
I0416 21:04:13.435493       1 request.go:530] Throttling request took 346.836801ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:04:13.489150       1 request.go:530] Throttling request took 400.494764ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:04:13.535866       1 request.go:530] Throttling request took 447.19835ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:04:13.585434       1 request.go:530] Throttling request took 496.750081ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:04:13.635421       1 request.go:530] Throttling request took 546.713579ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:04:13.685415       1 request.go:530] Throttling request took 596.708285ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:04:13.735431       1 request.go:530] Throttling request took 646.715707ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:04:13.785509       1 request.go:530] Throttling request took 696.788946ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:04:13.835544       1 request.go:530] Throttling request took 746.745456ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:04:13.885556       1 request.go:530] Throttling request took 796.782193ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:04:13.935511       1 request.go:530] Throttling request took 846.769258ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:04:13.985534       1 request.go:530] Throttling request took 896.787431ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:04:14.035537       1 request.go:530] Throttling request took 946.775832ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:04:14.085505       1 request.go:530] Throttling request took 996.724713ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:04:14.135526       1 request.go:530] Throttling request took 1.046679579s, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:04:14.185554       1 request.go:530] Throttling request took 1.096707032s, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:04:14.235507       1 request.go:530] Throttling request took 1.146707054s, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
I0416 21:04:14.285499       1 request.go:530] Throttling request took 1.196689267s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:04:14.335459       1 request.go:530] Throttling request took 1.246641965s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:04:14.385437       1 request.go:530] Throttling request took 1.296615763s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:04:14.435430       1 request.go:530] Throttling request took 1.346602102s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:04:14.485432       1 request.go:530] Throttling request took 1.396583575s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:04:14.535431       1 request.go:530] Throttling request took 1.446573963s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
E0416 21:04:15.390661       1 memcache.go:199] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:04:15.439994       1 memcache.go:111] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
W0416 21:04:14.937609       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
E0416 21:04:15.390661       1 memcache.go:199] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:04:15.439994       1 memcache.go:111] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:04:14.585462       1 request.go:530] Throttling request took 1.496591717s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:04:14.635419       1 request.go:530] Throttling request took 1.546540704s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:04:14.685404       1 request.go:530] Throttling request took 1.596523609s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:04:14.735448       1 request.go:530] Throttling request took 1.646542826s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:04:14.785424       1 request.go:530] Throttling request took 1.696519409s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:04:14.835418       1 request.go:530] Throttling request took 1.746509476s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:04:14.885434       1 request.go:530] Throttling request took 1.796501908s, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:04:14.935472       1 request.go:530] Throttling request took 1.846531702s, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
W0416 21:04:14.937609       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:04:14.937784       1 garbagecollector.go:201] syncing garbage collector with updated resources from discovery (attempt 1): added: [scalingpolicy.kope.io/v1alpha1, Resource=scalingpolicies], removed: []
I0416 21:04:14.937803       1 garbagecollector.go:207] reset restmapper
E0416 21:04:15.390661       1 memcache.go:199] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:04:15.439994       1 memcache.go:111] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:04:15.442596       1 graph_builder.go:184] unable to use a shared informer for resource "scalingpolicy.kope.io/v1alpha1, Resource=scalingpolicies", kind "scalingpolicy.kope.io/v1alpha1, Kind=ScalingPolicy": no informer found for scalingpolicy.kope.io/v1alpha1, Resource=scalingpolicies
I0416 21:04:15.442634       1 graph_builder.go:248] synced monitors; added 1, kept 50, removed 0
I0416 21:04:15.442677       1 graph_builder.go:280] started 1 new monitors, 51 currently running
I0416 21:04:15.442683       1 garbagecollector.go:222] resynced monitors
I0416 21:04:15.442690       1 controller_utils.go:1028] Waiting for caches to sync for garbage collector controller
I0416 21:04:15.442840       1 reflector.go:128] Starting reflector <nil> (0s) from pkg/controller/garbagecollector/graph_builder.go:124
I0416 21:04:15.442849       1 reflector.go:166] Listing and watching <nil> from pkg/controller/garbagecollector/graph_builder.go:124
I0416 21:04:15.542953       1 shared_informer.go:123] caches populated
I0416 21:04:15.542970       1 controller_utils.go:1035] Caches are synced for garbage collector controller
I0416 21:04:15.542979       1 garbagecollector.go:242] synced garbage collector
I0416 21:04:15.608121       1 wrap.go:47] GET /healthz: (99.439µs) 200 [kube-probe/1.15+ 127.0.0.1:36452]
I0416 21:04:16.105816       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kube-scheduler-e2e-test-peterhornyack-master"}
I0416 21:04:16.106121       1 disruption.go:326] addPod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:04:16.106135       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:16.106140       1 disruption.go:329] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:04:16.818344       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:17.114360       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kube-controller-manager-e2e-test-peterhornyack-master"}
I0416 21:04:17.114677       1 disruption.go:326] addPod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:04:17.114691       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:17.114695       1 disruption.go:329] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:04:20.104354       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kube-apiserver-e2e-test-peterhornyack-master"}
I0416 21:04:20.104677       1 disruption.go:326] addPod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:04:20.104691       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:20.104695       1 disruption.go:329] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:04:20.993699       1 controller.go:123] Found 0 jobs
I0416 21:04:20.996432       1 controller.go:139] Found 0 cronjobs
I0416 21:04:20.996445       1 controller.go:142] Found 0 groups
I0416 21:04:21.123966       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:04:21.123989       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:21.123993       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:04:21.155754       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:04:21.155777       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:21.155782       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:04:21.195220       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:04:21.195259       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:21.195263       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:04:21.818692       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:21.901087       1 gc_controller.go:144] GC'ing orphaned
I0416 21:04:21.904533       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:04:24.102528       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"etcd-server-events-e2e-test-peterhornyack-master"}
I0416 21:04:24.102637       1 disruption.go:326] addPod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:04:24.102644       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:24.102753       1 disruption.go:329] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:04:24.197310       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:04:25.105144       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kube-addon-manager-e2e-test-peterhornyack-master"}
I0416 21:04:25.105807       1 disruption.go:326] addPod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:04:25.105830       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:25.105833       1 disruption.go:329] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:04:25.609482       1 wrap.go:47] GET /healthz: (103.155µs) 200 [kube-probe/1.15+ 127.0.0.1:36486]
I0416 21:04:26.819047       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:26.819111       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:04:27.028128       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:04:27.213214       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:04:29.106904       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"etcd-server-e2e-test-peterhornyack-master"}
I0416 21:04:29.107018       1 disruption.go:326] addPod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:04:29.107026       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:29.107029       1 disruption.go:329] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:04:31.000376       1 controller.go:123] Found 0 jobs
I0416 21:04:31.002816       1 controller.go:139] Found 0 cronjobs
I0416 21:04:31.002829       1 controller.go:142] Found 0 groups
I0416 21:04:31.115688       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"}
I0416 21:04:31.115918       1 disruption.go:326] addPod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:04:31.115932       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:31.115935       1 disruption.go:329] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:04:31.124879       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:04:31.124894       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:31.124899       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:04:31.144841       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:04:31.144871       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:31.144876       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:04:31.171385       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:04:31.171400       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:31.171404       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:04:31.819443       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:35.608379       1 wrap.go:47] GET /healthz: (82.252µs) 200 [kube-probe/1.15+ 127.0.0.1:36518]
I0416 21:04:36.819812       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:40.100965       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"}
I0416 21:04:40.101192       1 disruption.go:326] addPod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:04:40.101211       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:40.101215       1 disruption.go:329] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:04:41.006858       1 controller.go:123] Found 0 jobs
I0416 21:04:41.008962       1 controller.go:139] Found 0 cronjobs
I0416 21:04:41.008978       1 controller.go:142] Found 0 groups
I0416 21:04:41.116696       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:04:41.116713       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:41.116717       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:04:41.138520       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:04:41.138539       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:04:41.138543       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:04:41.737760       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:04:41.742276       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:04:41.820193       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:41.905043       1 gc_controller.go:144] GC'ing orphaned
I0416 21:04:41.908534       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:04:42.030551       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:04:42.213461       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
E0416 21:04:43.543164       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:04:43.543164       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:04:43.191183       1 request.go:530] Throttling request took 83.642576ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:04:43.241351       1 request.go:530] Throttling request took 133.802699ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:04:43.290589       1 request.go:530] Throttling request took 182.981176ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:04:43.340641       1 request.go:530] Throttling request took 233.037126ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:04:43.391151       1 request.go:530] Throttling request took 283.555645ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:04:43.440519       1 request.go:530] Throttling request took 332.930284ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:04:43.490576       1 request.go:530] Throttling request took 382.988077ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:04:43.540547       1 request.go:530] Throttling request took 432.950753ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
E0416 21:04:43.543164       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:04:43.543529       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:04:45.608623       1 wrap.go:47] GET /healthz: (91.557µs) 200 [kube-probe/1.15+ 127.0.0.1:36564]
I0416 21:04:45.643548       1 request.go:530] Throttling request took 90.35591ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:04:45.693599       1 request.go:530] Throttling request took 140.397442ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:04:45.743568       1 request.go:530] Throttling request took 190.346488ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:04:45.793513       1 request.go:530] Throttling request took 240.28266ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:04:45.843636       1 request.go:530] Throttling request took 290.389028ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:04:45.893525       1 request.go:530] Throttling request took 340.276808ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:04:45.943757       1 request.go:530] Throttling request took 390.457605ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:04:45.993588       1 request.go:530] Throttling request took 440.302207ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:04:46.193602       1 request.go:530] Throttling request took 97.980069ms, request: GET:https://localhost:443/api/v1?timeout=32s
I0416 21:04:46.243659       1 request.go:530] Throttling request took 148.028461ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1?timeout=32s
I0416 21:04:46.293533       1 request.go:530] Throttling request took 197.89516ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1beta1?timeout=32s
I0416 21:04:46.343576       1 request.go:530] Throttling request took 247.934251ms, request: GET:https://localhost:443/apis/extensions/v1beta1?timeout=32s
I0416 21:04:46.393581       1 request.go:530] Throttling request took 297.932517ms, request: GET:https://localhost:443/apis/apps/v1?timeout=32s
I0416 21:04:46.443598       1 request.go:530] Throttling request took 347.941598ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:04:46.493599       1 request.go:530] Throttling request took 397.934881ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:04:46.543627       1 request.go:530] Throttling request took 447.952717ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:04:46.593639       1 request.go:530] Throttling request took 497.912134ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:04:46.643619       1 request.go:530] Throttling request took 547.894809ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:04:46.693657       1 request.go:530] Throttling request took 597.924306ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:04:46.743616       1 request.go:530] Throttling request took 647.850263ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:04:46.793589       1 request.go:530] Throttling request took 697.815425ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:04:46.821526       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:46.843549       1 request.go:530] Throttling request took 747.798501ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:04:46.893578       1 request.go:530] Throttling request took 797.792745ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:04:46.943575       1 request.go:530] Throttling request took 847.814564ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:04:46.993579       1 request.go:530] Throttling request took 897.783897ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:04:47.043573       1 request.go:530] Throttling request took 947.766584ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:04:47.098338       1 request.go:530] Throttling request took 1.002502395s, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:04:47.143540       1 request.go:530] Throttling request took 1.047720171s, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:04:47.193589       1 request.go:530] Throttling request took 1.097756594s, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:04:47.243583       1 request.go:530] Throttling request took 1.147744824s, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
I0416 21:04:47.293548       1 request.go:530] Throttling request took 1.197705998s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:04:47.343777       1 request.go:530] Throttling request took 1.247851595s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:04:47.393571       1 request.go:530] Throttling request took 1.297695944s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:04:47.443576       1 request.go:530] Throttling request took 1.347673905s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:04:47.493637       1 request.go:530] Throttling request took 1.397688952s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:04:47.543633       1 request.go:530] Throttling request took 1.44771501s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
I0416 21:04:47.593575       1 request.go:530] Throttling request took 1.497649044s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:04:47.643604       1 request.go:530] Throttling request took 1.547623638s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:04:47.693562       1 request.go:530] Throttling request took 1.597612368s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:04:47.743672       1 request.go:530] Throttling request took 1.647673711s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:04:47.793501       1 request.go:530] Throttling request took 1.697521451s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:04:47.843512       1 request.go:530] Throttling request took 1.747504895s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
W0416 21:04:47.946257       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:04:47.893519       1 request.go:530] Throttling request took 1.797505021s, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:04:47.943638       1 request.go:530] Throttling request took 1.847602448s, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
W0416 21:04:47.946257       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:04:51.012902       1 controller.go:123] Found 0 jobs
I0416 21:04:51.015345       1 controller.go:139] Found 0 cronjobs
I0416 21:04:51.015357       1 controller.go:142] Found 0 groups
I0416 21:04:51.821859       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:55.608479       1 wrap.go:47] GET /healthz: (114.673µs) 200 [kube-probe/1.15+ 127.0.0.1:36600]
I0416 21:04:56.822284       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:04:57.031193       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:04:57.213743       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:05:01.019424       1 controller.go:123] Found 0 jobs
I0416 21:05:01.021903       1 controller.go:139] Found 0 cronjobs
I0416 21:05:01.021914       1 controller.go:142] Found 0 groups
I0416 21:05:01.822690       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:01.908827       1 gc_controller.go:144] GC'ing orphaned
I0416 21:05:01.913451       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:05:05.608803       1 wrap.go:47] GET /healthz: (85.459µs) 200 [kube-probe/1.15+ 127.0.0.1:36634]
I0416 21:05:06.823157       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:11.026165       1 controller.go:123] Found 0 jobs
I0416 21:05:11.028963       1 controller.go:139] Found 0 cronjobs
I0416 21:05:11.028976       1 controller.go:142] Found 0 groups
I0416 21:05:11.738112       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:05:11.742730       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:05:11.823608       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:12.031488       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:05:12.214089       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
E0416 21:05:13.996595       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:05:13.996595       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:05:13.644068       1 request.go:530] Throttling request took 90.746859ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:05:13.694089       1 request.go:530] Throttling request took 140.770098ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:05:13.744110       1 request.go:530] Throttling request took 190.777129ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:05:13.794087       1 request.go:530] Throttling request took 240.749835ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:05:13.844095       1 request.go:530] Throttling request took 290.746509ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:05:13.894122       1 request.go:530] Throttling request took 340.752053ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:05:13.944122       1 request.go:530] Throttling request took 390.740682ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:05:13.994158       1 request.go:530] Throttling request took 440.769304ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
E0416 21:05:13.996595       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:05:13.997009       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:05:15.608517       1 wrap.go:47] GET /healthz: (99.495µs) 200 [kube-probe/1.15+ 127.0.0.1:36682]
I0416 21:05:16.823892       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:18.046803       1 request.go:530] Throttling request took 92.721566ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:05:18.096900       1 request.go:530] Throttling request took 142.819752ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:05:18.146811       1 request.go:530] Throttling request took 192.717865ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:05:18.196864       1 request.go:530] Throttling request took 242.765719ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:05:18.246874       1 request.go:530] Throttling request took 292.765471ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:05:18.296778       1 request.go:530] Throttling request took 342.658015ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:05:18.346822       1 request.go:530] Throttling request took 390.495515ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:05:18.396810       1 request.go:530] Throttling request took 440.469618ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:05:18.596835       1 request.go:530] Throttling request took 97.685591ms, request: GET:https://localhost:443/api/v1?timeout=32s
I0416 21:05:18.646766       1 request.go:530] Throttling request took 147.646434ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1?timeout=32s
I0416 21:05:18.696789       1 request.go:530] Throttling request took 197.650864ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1beta1?timeout=32s
I0416 21:05:18.746844       1 request.go:530] Throttling request took 247.701258ms, request: GET:https://localhost:443/apis/extensions/v1beta1?timeout=32s
I0416 21:05:18.796826       1 request.go:530] Throttling request took 297.605702ms, request: GET:https://localhost:443/apis/apps/v1?timeout=32s
I0416 21:05:18.846826       1 request.go:530] Throttling request took 347.655359ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:05:18.896829       1 request.go:530] Throttling request took 397.661087ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:05:18.946710       1 request.go:530] Throttling request took 447.535428ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:05:18.996873       1 request.go:530] Throttling request took 497.690946ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:05:19.046880       1 request.go:530] Throttling request took 547.677882ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:05:19.096904       1 request.go:530] Throttling request took 597.680916ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:05:19.146742       1 request.go:530] Throttling request took 647.511717ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:05:19.196835       1 request.go:530] Throttling request took 697.597601ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:05:19.246736       1 request.go:530] Throttling request took 747.491688ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:05:19.296810       1 request.go:530] Throttling request took 797.559316ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:05:19.346819       1 request.go:530] Throttling request took 847.560915ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:05:19.396879       1 request.go:530] Throttling request took 897.586945ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:05:19.446694       1 request.go:530] Throttling request took 947.382578ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:05:19.496782       1 request.go:530] Throttling request took 997.467114ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:05:19.546899       1 request.go:530] Throttling request took 1.047583713s, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:05:19.596842       1 request.go:530] Throttling request took 1.097517536s, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:05:19.646754       1 request.go:530] Throttling request took 1.147424829s, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
W0416 21:05:20.349252       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:05:19.696763       1 request.go:530] Throttling request took 1.197398374s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:05:19.746789       1 request.go:530] Throttling request took 1.24740356s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:05:19.796803       1 request.go:530] Throttling request took 1.2974128s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:05:19.846830       1 request.go:530] Throttling request took 1.347371019s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:05:19.896791       1 request.go:530] Throttling request took 1.397377608s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:05:19.946771       1 request.go:530] Throttling request took 1.447336079s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
I0416 21:05:19.996893       1 request.go:530] Throttling request took 1.497444935s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:05:20.046831       1 request.go:530] Throttling request took 1.547378854s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:05:20.097023       1 request.go:530] Throttling request took 1.597433194s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:05:20.146851       1 request.go:530] Throttling request took 1.647383573s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:05:20.196817       1 request.go:530] Throttling request took 1.697341217s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:05:20.246775       1 request.go:530] Throttling request took 1.747282721s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:05:20.296789       1 request.go:530] Throttling request took 1.797281775s, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:05:20.346766       1 request.go:530] Throttling request took 1.847241568s, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
W0416 21:05:20.349252       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:05:21.033363       1 controller.go:123] Found 0 jobs
I0416 21:05:21.036173       1 controller.go:139] Found 0 cronjobs
I0416 21:05:21.036187       1 controller.go:142] Found 0 groups
I0416 21:05:21.824293       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:21.913808       1 gc_controller.go:144] GC'ing orphaned
I0416 21:05:21.917937       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:05:24.305689       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:05:25.608570       1 wrap.go:47] GET /healthz: (97.458µs) 200 [kube-probe/1.15+ 127.0.0.1:36714]
I0416 21:05:26.824738       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:26.824811       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:05:27.031840       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:05:27.214422       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:05:31.040029       1 controller.go:123] Found 0 jobs
I0416 21:05:31.042571       1 controller.go:139] Found 0 cronjobs
I0416 21:05:31.042586       1 controller.go:142] Found 0 groups
I0416 21:05:31.825246       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:35.609299       1 wrap.go:47] GET /healthz: (115.68µs) 200 [kube-probe/1.15+ 127.0.0.1:36748]
I0416 21:05:36.825677       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:41.046614       1 controller.go:123] Found 0 jobs
I0416 21:05:41.049360       1 controller.go:139] Found 0 cronjobs
I0416 21:05:41.049372       1 controller.go:142] Found 0 groups
I0416 21:05:41.738480       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:05:41.743104       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:05:41.826076       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:41.918211       1 gc_controller.go:144] GC'ing orphaned
I0416 21:05:41.922553       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:05:42.032137       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:05:42.214737       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
E0416 21:05:44.449823       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:05:44.449823       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:05:44.097751       1 request.go:530] Throttling request took 91.538641ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:05:44.147576       1 request.go:530] Throttling request took 141.359916ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:05:44.197446       1 request.go:530] Throttling request took 191.228622ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:05:44.247500       1 request.go:530] Throttling request took 241.274293ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:05:44.297540       1 request.go:530] Throttling request took 291.303836ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:05:44.347637       1 request.go:530] Throttling request took 341.393857ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:05:44.397639       1 request.go:530] Throttling request took 391.388504ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:05:44.447590       1 request.go:530] Throttling request took 441.245089ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
E0416 21:05:44.449823       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:05:44.450254       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:05:45.608793       1 wrap.go:47] GET /healthz: (95.384µs) 200 [kube-probe/1.15+ 127.0.0.1:36796]
I0416 21:05:46.826408       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
W0416 21:05:52.752610       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:05:50.450032       1 request.go:530] Throttling request took 91.336982ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:05:50.500069       1 request.go:530] Throttling request took 141.365576ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:05:50.550140       1 request.go:530] Throttling request took 191.388664ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:05:50.600210       1 request.go:530] Throttling request took 241.485815ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:05:50.649992       1 request.go:530] Throttling request took 291.259005ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:05:50.700488       1 request.go:530] Throttling request took 341.740109ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:05:50.750275       1 request.go:530] Throttling request took 391.502503ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:05:50.800129       1 request.go:530] Throttling request took 441.300461ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:05:51.004818       1 request.go:530] Throttling request took 101.130368ms, request: GET:https://localhost:443/api/v1?timeout=32s
I0416 21:05:51.051963       1 request.go:530] Throttling request took 148.254154ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1?timeout=32s
I0416 21:05:51.062529       1 controller.go:123] Found 0 jobs
I0416 21:05:51.071018       1 controller.go:139] Found 0 cronjobs
I0416 21:05:51.071031       1 controller.go:142] Found 0 groups
I0416 21:05:51.100159       1 request.go:530] Throttling request took 196.379546ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1beta1?timeout=32s
I0416 21:05:51.150264       1 request.go:530] Throttling request took 246.534541ms, request: GET:https://localhost:443/apis/extensions/v1beta1?timeout=32s
I0416 21:05:51.200131       1 request.go:530] Throttling request took 296.341627ms, request: GET:https://localhost:443/apis/apps/v1?timeout=32s
I0416 21:05:51.251484       1 request.go:530] Throttling request took 347.744945ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:05:51.300324       1 request.go:530] Throttling request took 396.586336ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:05:51.350148       1 request.go:530] Throttling request took 446.400701ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:05:51.400215       1 request.go:530] Throttling request took 496.405941ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:05:51.450035       1 request.go:530] Throttling request took 546.24283ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:05:51.500152       1 request.go:530] Throttling request took 596.339071ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:05:51.550569       1 request.go:530] Throttling request took 646.765739ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:05:51.600114       1 request.go:530] Throttling request took 696.279716ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:05:51.650084       1 request.go:530] Throttling request took 746.234583ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:05:51.700037       1 request.go:530] Throttling request took 796.166912ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:05:51.750104       1 request.go:530] Throttling request took 846.245673ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:05:51.800121       1 request.go:530] Throttling request took 896.237579ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:05:51.826736       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:51.850124       1 request.go:530] Throttling request took 946.244607ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:05:51.900114       1 request.go:530] Throttling request took 996.223661ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:05:51.950092       1 request.go:530] Throttling request took 1.046188941s, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:05:52.000141       1 request.go:530] Throttling request took 1.096217426s, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:05:52.050435       1 request.go:530] Throttling request took 1.146504573s, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
I0416 21:05:52.100132       1 request.go:530] Throttling request took 1.196192087s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:05:52.150543       1 request.go:530] Throttling request took 1.246597866s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:05:52.200131       1 request.go:530] Throttling request took 1.296158526s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:05:52.250074       1 request.go:530] Throttling request took 1.346111661s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:05:52.300084       1 request.go:530] Throttling request took 1.396102954s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:05:52.350066       1 request.go:530] Throttling request took 1.44607123s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
I0416 21:05:52.400127       1 request.go:530] Throttling request took 1.496112946s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:05:52.450170       1 request.go:530] Throttling request took 1.546109735s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:05:52.500212       1 request.go:530] Throttling request took 1.596162717s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:05:52.550137       1 request.go:530] Throttling request took 1.646098396s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:05:52.600117       1 request.go:530] Throttling request took 1.696066671s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:05:52.650042       1 request.go:530] Throttling request took 1.745988556s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:05:52.700085       1 request.go:530] Throttling request took 1.796022955s, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:05:52.750139       1 request.go:530] Throttling request took 1.846046329s, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
W0416 21:05:52.752610       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:05:55.608639       1 wrap.go:47] GET /healthz: (91.764µs) 200 [kube-probe/1.15+ 127.0.0.1:36832]
I0416 21:05:56.827059       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:05:57.032540       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:05:57.215159       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:06:01.075254       1 controller.go:123] Found 0 jobs
I0416 21:06:01.078658       1 controller.go:139] Found 0 cronjobs
I0416 21:06:01.078672       1 controller.go:142] Found 0 groups
I0416 21:06:01.827470       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:01.922883       1 gc_controller.go:144] GC'ing orphaned
I0416 21:06:01.927039       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:06:05.608421       1 wrap.go:47] GET /healthz: (97.186µs) 200 [kube-probe/1.15+ 127.0.0.1:36866]
I0416 21:06:06.827819       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:11.082680       1 controller.go:123] Found 0 jobs
I0416 21:06:11.085286       1 controller.go:139] Found 0 cronjobs
I0416 21:06:11.085297       1 controller.go:142] Found 0 groups
I0416 21:06:11.738770       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:06:11.743547       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:06:11.828187       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:12.032744       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:06:12.215460       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:06:14.550880       1 request.go:530] Throttling request took 91.403645ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:06:14.600837       1 request.go:530] Throttling request took 141.365218ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:06:14.651123       1 request.go:530] Throttling request took 191.642201ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:06:14.700850       1 request.go:530] Throttling request took 241.359281ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
E0416 21:06:14.903281       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:06:14.903281       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:06:14.750772       1 request.go:530] Throttling request took 291.273548ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:06:14.800817       1 request.go:530] Throttling request took 341.29794ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:06:14.850810       1 request.go:530] Throttling request took 391.297114ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:06:14.900857       1 request.go:530] Throttling request took 441.275493ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
E0416 21:06:14.903281       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:06:14.903751       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:06:15.608703       1 wrap.go:47] GET /healthz: (138.13µs) 200 [kube-probe/1.15+ 127.0.0.1:36904]
I0416 21:06:16.828606       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:21.093752       1 controller.go:123] Found 0 jobs
I0416 21:06:21.104388       1 controller.go:139] Found 0 cronjobs
I0416 21:06:21.104413       1 controller.go:142] Found 0 groups
I0416 21:06:21.828932       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:21.927321       1 gc_controller.go:144] GC'ing orphaned
I0416 21:06:21.932347       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:06:22.853244       1 request.go:530] Throttling request took 91.332784ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:06:22.903344       1 request.go:530] Throttling request took 141.446756ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:06:22.953265       1 request.go:530] Throttling request took 191.337278ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:06:23.003341       1 request.go:530] Throttling request took 241.427558ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:06:23.055586       1 request.go:530] Throttling request took 293.669392ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:06:23.105874       1 request.go:530] Throttling request took 343.937801ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:06:23.153309       1 request.go:530] Throttling request took 391.369474ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:06:23.203197       1 request.go:530] Throttling request took 441.248227ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:06:23.403267       1 request.go:530] Throttling request took 97.926585ms, request: GET:https://localhost:443/api/v1?timeout=32s
I0416 21:06:23.453304       1 request.go:530] Throttling request took 147.966303ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1?timeout=32s
I0416 21:06:23.504378       1 request.go:530] Throttling request took 199.038446ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1beta1?timeout=32s
I0416 21:06:23.553746       1 request.go:530] Throttling request took 248.340561ms, request: GET:https://localhost:443/apis/extensions/v1beta1?timeout=32s
I0416 21:06:23.603821       1 request.go:530] Throttling request took 298.464695ms, request: GET:https://localhost:443/apis/apps/v1?timeout=32s
I0416 21:06:23.653334       1 request.go:530] Throttling request took 347.968203ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:06:23.703285       1 request.go:530] Throttling request took 397.890426ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:06:23.753292       1 request.go:530] Throttling request took 447.915627ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:06:23.803296       1 request.go:530] Throttling request took 497.901221ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:06:23.853379       1 request.go:530] Throttling request took 547.98461ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:06:23.903317       1 request.go:530] Throttling request took 597.905694ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:06:23.953346       1 request.go:530] Throttling request took 647.939177ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:06:24.003389       1 request.go:530] Throttling request took 697.962164ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:06:24.053354       1 request.go:530] Throttling request took 747.913827ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:06:24.103571       1 request.go:530] Throttling request took 798.123757ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:06:24.153780       1 request.go:530] Throttling request took 848.346017ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:06:24.203276       1 request.go:530] Throttling request took 897.812071ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:06:24.253317       1 request.go:530] Throttling request took 947.870072ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:06:24.303260       1 request.go:530] Throttling request took 997.772451ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:06:24.353278       1 request.go:530] Throttling request took 1.047786209s, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:06:24.403306       1 request.go:530] Throttling request took 1.097817516s, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:06:24.428548       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:06:24.453454       1 request.go:530] Throttling request took 1.147978197s, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
I0416 21:06:24.503340       1 request.go:530] Throttling request took 1.197850259s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:06:24.553339       1 request.go:530] Throttling request took 1.24783879s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:06:24.603276       1 request.go:530] Throttling request took 1.297741924s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:06:24.653208       1 request.go:530] Throttling request took 1.347691676s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:06:24.703262       1 request.go:530] Throttling request took 1.397723145s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:06:24.753254       1 request.go:530] Throttling request took 1.447710325s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
W0416 21:06:25.155488       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:06:24.803254       1 request.go:530] Throttling request took 1.497694244s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:06:24.853265       1 request.go:530] Throttling request took 1.547694892s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:06:24.903330       1 request.go:530] Throttling request took 1.597770375s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:06:24.953295       1 request.go:530] Throttling request took 1.647700442s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:06:25.003306       1 request.go:530] Throttling request took 1.697742099s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:06:25.053343       1 request.go:530] Throttling request took 1.747771613s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:06:25.103199       1 request.go:530] Throttling request took 1.797620254s, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:06:25.153343       1 request.go:530] Throttling request took 1.847744959s, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
W0416 21:06:25.155488       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:06:25.608932       1 wrap.go:47] GET /healthz: (118.71µs) 200 [kube-probe/1.15+ 127.0.0.1:36936]
I0416 21:06:26.829242       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:26.829297       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:06:27.033068       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:06:27.215740       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:06:31.115222       1 controller.go:123] Found 0 jobs
I0416 21:06:31.120926       1 controller.go:139] Found 0 cronjobs
I0416 21:06:31.120940       1 controller.go:142] Found 0 groups
I0416 21:06:31.829599       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:35.608484       1 wrap.go:47] GET /healthz: (74.984µs) 200 [kube-probe/1.15+ 127.0.0.1:36970]
I0416 21:06:36.830217       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:41.128960       1 controller.go:123] Found 0 jobs
I0416 21:06:41.133677       1 controller.go:139] Found 0 cronjobs
I0416 21:06:41.133691       1 controller.go:142] Found 0 groups
I0416 21:06:41.739102       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:06:41.744014       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:06:41.830570       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:41.933368       1 gc_controller.go:144] GC'ing orphaned
I0416 21:06:41.937864       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:06:42.033436       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:06:42.216076       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
E0416 21:06:45.356834       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:06:45.356834       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:06:45.004658       1 request.go:530] Throttling request took 91.028747ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:06:45.054508       1 request.go:530] Throttling request took 140.879185ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:06:45.104425       1 request.go:530] Throttling request took 190.781276ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:06:45.154515       1 request.go:530] Throttling request took 240.872868ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:06:45.204613       1 request.go:530] Throttling request took 290.951289ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:06:45.254863       1 request.go:530] Throttling request took 341.200764ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:06:45.304568       1 request.go:530] Throttling request took 390.877665ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:06:45.354378       1 request.go:530] Throttling request took 440.680225ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
E0416 21:06:45.356834       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:06:45.357180       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:06:45.608711       1 wrap.go:47] GET /healthz: (85.058µs) 200 [kube-probe/1.15+ 127.0.0.1:37018]
I0416 21:06:46.834782       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
W0416 21:06:52.685601       1 actual_state_of_world.go:503] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="e2e-test-peterhornyack-minion-group-06gd" does not exist
I0416 21:06:51.138985       1 controller.go:123] Found 0 jobs
I0416 21:06:51.141487       1 controller.go:139] Found 0 cronjobs
I0416 21:06:51.141505       1 controller.go:142] Found 0 groups
I0416 21:06:51.835162       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:52.279985       1 certificate_controller.go:77] Adding certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:06:52.280087       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (20.167µs)
I0416 21:06:52.280142       1 certificate_controller.go:77] Adding certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:06:52.308556       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:06:52.313271       1 log.go:172] [INFO] signed certificate with serial number 389119063056342699433081878852827551947576146306
I0416 21:06:52.313738       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:06:52.313841       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (33.659089ms)
I0416 21:06:52.313882       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (6.617µs)
I0416 21:06:52.318178       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:06:52.318275       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:06:52.318288       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.064µs)
I0416 21:06:52.318802       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (10.215375ms)
I0416 21:06:52.318824       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (1.677µs)
I0416 21:06:52.678077       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aeb2dd6b2ab3, ext:73647286684, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.680372       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb288d77ca, ext:234834084068, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.680470       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [e2e-test-peterhornyack-minion-group-06gd], creating 1
I0416 21:06:52.685122       1 taint_manager.go:441] Noticed node update: scheduler.nodeUpdateItem{nodeName:"e2e-test-peterhornyack-minion-group-06gd"}
I0416 21:06:52.685138       1 taint_manager.go:446] Updating known taints on node e2e-test-peterhornyack-minion-group-06gd: []
I0416 21:06:52.685589       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
W0416 21:06:52.685601       1 actual_state_of_world.go:503] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="e2e-test-peterhornyack-minion-group-06gd" does not exist
I0416 21:06:52.685630       1 cloud_cidr_allocator.go:237] Putting node e2e-test-peterhornyack-minion-group-06gd into the work queue
I0416 21:06:52.688877       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aeb1bb1318e2, ext:69144831449, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.689021       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb29119478, ext:234842742137, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.689081       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [e2e-test-peterhornyack-minion-group-06gd], creating 1
I0416 21:06:52.708481       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:52.708523       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-minion-group-06gd is already in a process of CIDR assignment.
I0416 21:06:52.713687       1 ttl_controller.go:271] Changed ttl annotation for node e2e-test-peterhornyack-minion-group-06gd to 0 seconds
I0416 21:06:52.726651       1 taint_manager.go:463] All taints were removed from the Node e2e-test-peterhornyack-minion-group-06gd. Cancelling all evictions...
I0416 21:06:52.728320       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kube-dns-autoscaler-97df449df-4ggmd"}
I0416 21:06:52.728494       1 replica_set.go:338] Pod kube-dns-autoscaler-97df449df-4ggmd updated, objectMeta {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:483 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc0017e6237 BlockOwnerDeletion:0xc0017e6238}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:822 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc0028c03a0 BlockOwnerDeletion:0xc0028c03a1}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:52.728593       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.728713       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (125.914µs)
I0416 21:06:52.728938       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:06:52.728953       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.728957       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:06:52.729078       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kubernetes-dashboard-85bcf5dbf8-t5nl6"}
I0416 21:06:52.729127       1 replica_set.go:338] Pod kubernetes-dashboard-85bcf5dbf8-t5nl6 updated, objectMeta {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:482 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc0012c38ae BlockOwnerDeletion:0xc0012c38af}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:824 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc0028c04be BlockOwnerDeletion:0xc0028c04bf}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:52.729188       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.731477       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (2.287218ms)
I0416 21:06:52.731701       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (83.762µs)
I0416 21:06:52.731768       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:06:52.731786       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.731790       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:06:52.732665       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"metrics-server-v0.3.1-677c578bdf-xl48c"}
I0416 21:06:52.732732       1 replica_set.go:338] Pod metrics-server-v0.3.1-677c578bdf-xl48c updated, objectMeta {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:476 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc0013f1687 BlockOwnerDeletion:0xc0013f1688}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:825 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc0028c0b87 BlockOwnerDeletion:0xc0028c0b88}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:52.732820       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.733683       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (867.396µs)
I0416 21:06:52.733839       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (71.63µs)
I0416 21:06:52.733866       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:06:52.733895       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.733898       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:06:52.740507       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:52.740540       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-minion-group-06gd is already in a process of CIDR assignment.
I0416 21:06:52.741744       1 controller_utils.go:200] Added [&Taint{Key:node.kubernetes.io/network-unavailable,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:06:52.685456442 +0000 UTC m=+234.839180598,} &Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:06:52.685456595 +0000 UTC m=+234.839180732,}] Taint to Node e2e-test-peterhornyack-minion-group-06gd
I0416 21:06:52.741796       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-minion-group-06gd has no [] Taint
I0416 21:06:52.757775       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"coredns-5b969f4c88-zcdpb"}
I0416 21:06:52.757880       1 replica_set.go:338] Pod coredns-5b969f4c88-zcdpb updated, objectMeta {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:466 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc002168e77 BlockOwnerDeletion:0xc002168e78}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:826 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc0028c1527 BlockOwnerDeletion:0xc0028c1528}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:52.757979       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.758150       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (178.799µs)
I0416 21:06:52.760276       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (1.996552ms)
I0416 21:06:52.760379       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:06:52.760401       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.760405       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:06:52.760568       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-scaler-7db4984bf4-26sjq"}
I0416 21:06:52.760642       1 replica_set.go:338] Pod fluentd-gcp-scaler-7db4984bf4-26sjq updated, objectMeta {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:489 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc0014cc23e BlockOwnerDeletion:0xc0014cc23f}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:828 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc0028c16fe BlockOwnerDeletion:0xc0028c16ff}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:52.760732       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.761016       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (290.2µs)
I0416 21:06:52.761105       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:06:52.761116       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.761119       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:06:52.762781       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1-5858bf5485-5td9x"}
I0416 21:06:52.762862       1 replica_set.go:338] Pod heapster-v1.6.0-beta.1-5858bf5485-5td9x updated, objectMeta {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:480 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc0012c28e7 BlockOwnerDeletion:0xc0012c28e8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:829 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc0028c1d97 BlockOwnerDeletion:0xc0028c1d98}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:52.762968       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.763083       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (133.184µs)
I0416 21:06:52.763223       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (68.031µs)
I0416 21:06:52.764720       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:06:52.764743       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.764747       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:06:52.765210       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"event-exporter-v0.2.4-65d8d98768-n6vvr"}
I0416 21:06:52.765284       1 replica_set.go:338] Pod event-exporter-v0.2.4-65d8d98768-n6vvr updated, objectMeta {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:484 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc0017e6fc7 BlockOwnerDeletion:0xc0017e6fc8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:830 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc002b182d7 BlockOwnerDeletion:0xc002b182d8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:52.765368       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.767437       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (2.0715ms)
I0416 21:06:52.767548       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:06:52.767563       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.767568       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:06:52.770453       1 controller_utils.go:588] Controller fluentd-gcp-v3.2.0 created pod fluentd-gcp-v3.2.0-4tl8c
I0416 21:06:52.770513       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.770528       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb288d77ca, ext:234834084068, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.770613       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.771565       1 event.go:258] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", APIVersion:"apps/v1", ResourceVersion:"525", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: fluentd-gcp-v3.2.0-4tl8c
I0416 21:06:52.774720       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"l7-default-backend-8f479dd9-wbtkw"}
I0416 21:06:52.774806       1 replica_set.go:338] Pod l7-default-backend-8f479dd9-wbtkw updated, objectMeta {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:486 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc001698257 BlockOwnerDeletion:0xc001698258}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:831 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc002b18b37 BlockOwnerDeletion:0xc002b18b38}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:52.774893       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.774982       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (93.594µs)
I0416 21:06:52.775142       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (76.35µs)
I0416 21:06:52.775172       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:06:52.775197       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.775201       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:06:52.775355       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:52.775381       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-minion-group-06gd is already in a process of CIDR assignment.
I0416 21:06:52.777840       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-4tl8c
I0416 21:06:52.777926       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-4tl8c"}
I0416 21:06:52.778003       1 daemon_controller.go:506] Pod fluentd-gcp-v3.2.0-4tl8c added.
I0416 21:06:52.778010       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb288d77ca, ext:234834084068, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.778035       1 disruption.go:326] addPod called on pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:06:52.778079       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-4tl8c, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.778082       1 disruption.go:329] No matching pdb for pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:06:52.796333       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:06:52.802208       1 pvc_protection_controller.go:280] Got event on pod kube-system/metadata-proxy-v0.1-m4h7x
I0416 21:06:52.802338       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"metadata-proxy-v0.1-m4h7x"}
I0416 21:06:52.802431       1 daemon_controller.go:506] Pod metadata-proxy-v0.1-m4h7x added.
I0416 21:06:52.802447       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb29119478, ext:234842742137, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.802486       1 disruption.go:326] addPod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:06:52.802511       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.802515       1 disruption.go:329] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:06:52.804221       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (126.930171ms)
I0416 21:06:52.805123       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb288d77ca, ext:234834084068, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.807215       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb301cf8d8, ext:234960929281, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.807272       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:52.807313       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.807333       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb301cf8d8, ext:234960929281, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.807379       1 update.go:396] Getting unavailable numbers
I0416 21:06:52.807975       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:52.807984       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:52.807988       1 update.go:68] Marking old pods for deletion
I0416 21:06:52.807994       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb3028f906, ext:234961715693, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.808019       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:52.808060       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.808117       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.808755       1 controller_utils.go:588] Controller metadata-proxy-v0.1 created pod metadata-proxy-v0.1-m4h7x
I0416 21:06:52.808790       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:52.808800       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb29119478, ext:234842742137, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.808862       1 update.go:396] Getting unavailable numbers
I0416 21:06:52.808957       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:52.808962       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:52.808965       1 update.go:68] Marking old pods for deletion
I0416 21:06:52.808969       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb3037dd8d, ext:234962691716, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.808991       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:52.809016       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:52.809035       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.812442       1 event.go:258] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"metadata-proxy-v0.1", UID:"42862d28-8b1c-4254-8477-23a0fd36a8bb", APIVersion:"apps/v1", ResourceVersion:"515", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: metadata-proxy-v0.1-m4h7x
I0416 21:06:52.820881       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-4tl8c"}
I0416 21:06:52.821075       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-4tl8c updated.
I0416 21:06:52.821093       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:06:52.821111       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-4tl8c, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.821115       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:06:52.823583       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"kube-proxy-e2e-test-peterhornyack-minion-group-06gd"}
I0416 21:06:52.823858       1 disruption.go:326] addPod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:52.823870       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.823886       1 disruption.go:329] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:52.830799       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"metadata-proxy-v0.1-m4h7x"}
I0416 21:06:52.830969       1 daemon_controller.go:554] Pod metadata-proxy-v0.1-m4h7x updated.
I0416 21:06:52.830997       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:06:52.831016       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:52.831020       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:06:52.848969       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (44.673132ms)
I0416 21:06:52.849685       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb3028f906, ext:234961715693, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.849885       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb32a82bdf, ext:235003606240, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.849911       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:52.849949       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.849953       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb32a82bdf, ext:235003606240, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.849989       1 update.go:396] Getting unavailable numbers
I0416 21:06:52.850075       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:52.850080       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:52.850084       1 update.go:68] Marking old pods for deletion
I0416 21:06:52.850087       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb32ab46ae, ext:235003809686, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.850095       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:52.850111       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.850145       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.852008       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (163.553441ms)
I0416 21:06:52.854307       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb3037dd8d, ext:234962691716, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.855412       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb32eef606, ext:235008245503, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.855461       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:52.855504       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:52.855511       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb32eef606, ext:235008245503, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.855581       1 update.go:396] Getting unavailable numbers
I0416 21:06:52.855694       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:52.855700       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:52.855703       1 update.go:68] Marking old pods for deletion
I0416 21:06:52.855707       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb33010a0e, ext:235009430263, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.855714       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:52.855734       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:52.855758       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.856195       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:06:52.857823       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
E0416 21:06:52.890951       1 daemon_controller.go:302] kube-system/metadata-proxy-v0.1 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metadata-proxy-v0.1", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/metadata-proxy-v0.1", UID:"42862d28-8b1c-4254-8477-23a0fd36a8bb", ResourceVersion:"515", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"},\"name\":\"metadata-proxy-v0.1\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"metadata-proxy\",\"version\":\"v0.1\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"}},\"spec\":{\"containers\":[{\"image\":\"k8s.gcr.io/metadata-proxy:v0.1.11\",\"name\":\"metadata-proxy\",\"resources\":{\"limits\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"},\"requests\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"}},\"securityContext\":{\"privileged\":true}},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\",\"resources\":{\"limits\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"},\"requests\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"}}}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/metadata-proxy-ready\":\"true\",\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"metadata-proxy\",\"terminationGracePeriodSeconds\":30,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00080eaa0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metadata-proxy", Image:"k8s.gcr.io/metadata-proxy:v0.1.11", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc000bf64b0), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00080eae0)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00080eb20)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00036ec38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/metadata-proxy-ready":"true", "beta.kubernetes.io/os":"linux"}, ServiceAccountName:"metadata-proxy", DeprecatedServiceAccount:"metadata-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020a0cc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00000f520)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00036ec9c)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:1, NumberMisscheduled:0, DesiredNumberScheduled:1, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:1, NumberAvailable:1, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "metadata-proxy-v0.1": the object has been modified; please apply your changes to the latest version and try again
E0416 21:06:52.894952       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"834", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc001cf9140), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001cf9160), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001cf9180), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002770f00), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf91a0)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc002052720), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf9240)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf9280)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002b19858), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00205a0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc002b16fd0)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc002b198c0)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:1, NumberMisscheduled:0, DesiredNumberScheduled:2, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:1, NumberAvailable:1, NumberUnavailable:1, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
E0416 21:06:52.890951       1 daemon_controller.go:302] kube-system/metadata-proxy-v0.1 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metadata-proxy-v0.1", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/metadata-proxy-v0.1", UID:"42862d28-8b1c-4254-8477-23a0fd36a8bb", ResourceVersion:"515", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"},\"name\":\"metadata-proxy-v0.1\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"metadata-proxy\",\"version\":\"v0.1\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"}},\"spec\":{\"containers\":[{\"image\":\"k8s.gcr.io/metadata-proxy:v0.1.11\",\"name\":\"metadata-proxy\",\"resources\":{\"limits\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"},\"requests\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"}},\"securityContext\":{\"privileged\":true}},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\",\"resources\":{\"limits\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"},\"requests\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"}}}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/metadata-proxy-ready\":\"true\",\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"metadata-proxy\",\"terminationGracePeriodSeconds\":30,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00080eaa0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metadata-proxy", Image:"k8s.gcr.io/metadata-proxy:v0.1.11", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc000bf64b0), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00080eae0)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00080eb20)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00036ec38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/metadata-proxy-ready":"true", "beta.kubernetes.io/os":"linux"}, ServiceAccountName:"metadata-proxy", DeprecatedServiceAccount:"metadata-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020a0cc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00000f520)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00036ec9c)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:1, NumberMisscheduled:0, DesiredNumberScheduled:1, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:1, NumberAvailable:1, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "metadata-proxy-v0.1": the object has been modified; please apply your changes to the latest version and try again
E0416 21:06:52.894952       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"834", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc001cf9140), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001cf9160), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001cf9180), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002770f00), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf91a0)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc002052720), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf9240)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf9280)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002b19858), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00205a0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc002b16fd0)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc002b198c0)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:1, NumberMisscheduled:0, DesiredNumberScheduled:2, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:1, NumberAvailable:1, NumberUnavailable:1, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
I0416 21:06:52.873322       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (21.265842ms)
E0416 21:06:52.890951       1 daemon_controller.go:302] kube-system/metadata-proxy-v0.1 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metadata-proxy-v0.1", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/metadata-proxy-v0.1", UID:"42862d28-8b1c-4254-8477-23a0fd36a8bb", ResourceVersion:"515", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"},\"name\":\"metadata-proxy-v0.1\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"metadata-proxy\",\"version\":\"v0.1\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"metadata-proxy\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v0.1\"}},\"spec\":{\"containers\":[{\"image\":\"k8s.gcr.io/metadata-proxy:v0.1.11\",\"name\":\"metadata-proxy\",\"resources\":{\"limits\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"},\"requests\":{\"cpu\":\"30m\",\"memory\":\"25Mi\"}},\"securityContext\":{\"privileged\":true}},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\",\"resources\":{\"limits\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"},\"requests\":{\"cpu\":\"2m\",\"memory\":\"20Mi\"}}}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/metadata-proxy-ready\":\"true\",\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"metadata-proxy\",\"terminationGracePeriodSeconds\":30,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00080eaa0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"metadata-proxy", "kubernetes.io/cluster-service":"true", "version":"v0.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metadata-proxy", Image:"k8s.gcr.io/metadata-proxy:v0.1.11", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:30, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"30m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:26214400, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"25Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc000bf64b0), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=metadata_proxy:http://127.0.0.1:989?whitelisted=request_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00080eae0)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00080eb20)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:20971520, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"20Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00036ec38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/metadata-proxy-ready":"true", "beta.kubernetes.io/os":"linux"}, ServiceAccountName:"metadata-proxy", DeprecatedServiceAccount:"metadata-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020a0cc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00000f520)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00036ec9c)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:1, NumberMisscheduled:0, DesiredNumberScheduled:1, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:1, NumberAvailable:1, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "metadata-proxy-v0.1": the object has been modified; please apply your changes to the latest version and try again
I0416 21:06:52.891986       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb33010a0e, ext:235009430263, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.893052       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb353a9b5d, ext:235046757450, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.893095       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:52.893137       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:52.893144       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb353a9b5d, ext:235046757450, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.893223       1 update.go:396] Getting unavailable numbers
I0416 21:06:52.893344       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:52.893350       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:52.893354       1 update.go:68] Marking old pods for deletion
I0416 21:06:52.893357       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb353f8822, ext:235047080202, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.893364       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:52.893406       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:52.893425       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.893597       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (2.146047ms)
I0416 21:06:52.873722       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (24.716868ms)
E0416 21:06:52.894952       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"834", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc001cf9140), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001cf9160), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001cf9180), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002770f00), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf91a0)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc002052720), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf9240)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001cf9280)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002b19858), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00205a0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc002b16fd0)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc002b198c0)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:1, NumberMisscheduled:0, DesiredNumberScheduled:2, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:1, NumberAvailable:1, NumberUnavailable:1, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
I0416 21:06:52.895972       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb32ab46ae, ext:235003809686, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.896146       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb356a100b, ext:235049867531, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.896158       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:52.896207       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.896212       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb356a100b, ext:235049867531, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.896304       1 update.go:396] Getting unavailable numbers
I0416 21:06:52.896372       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:52.896381       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:52.896385       1 update.go:68] Marking old pods for deletion
I0416 21:06:52.896390       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb356dccd9, ext:235050112464, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.896397       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:52.896418       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.896454       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.896532       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.16401ms)
I0416 21:06:52.897425       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb353f8822, ext:235047080202, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.897618       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb35808719, ext:235051339802, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.897630       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:52.897701       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:52.897706       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb35808719, ext:235051339802, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.897745       1 update.go:396] Getting unavailable numbers
I0416 21:06:52.897816       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:52.897821       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:52.897825       1 update.go:68] Marking old pods for deletion
I0416 21:06:52.897828       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb3583bfe6, ext:235051550927, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.897834       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:52.897858       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:52.897874       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.897949       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.387044ms)
I0416 21:06:52.901359       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb356dccd9, ext:235050112464, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.901490       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb35bb9c25, ext:235055211815, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.901500       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:52.901530       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.901534       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb35bb9c25, ext:235055211815, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.901559       1 update.go:396] Getting unavailable numbers
I0416 21:06:52.901603       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:52.901608       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:52.901612       1 update.go:68] Marking old pods for deletion
I0416 21:06:52.901614       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb35bd8750, ext:235055337564, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:52.901620       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:52.901640       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:52.901657       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:52.901720       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (928.111µs)
I0416 21:06:52.938382       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 22:06:52.685646834 +0000 UTC m=+3834.839370971 [59m59.747242232s]), Key{"e2e-test-peterhornyack-minion-group-06gd", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:05:10.344-07:00 DeletionProtection:false Description: Disks:[0xc000e3fb20] GuestAccelerators:[] Id:2158717802865491306 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00077bdc0 MinCpuPlatform: Name:e2e-test-peterhornyack-minion-group-06gd NetworkInterfaces:[0xc0011769c0] Scheduling:0xc00077bea0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-minion-group-06gd ServiceAccounts:[0xc002b4a540] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc002b4a4e0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:06:52 GMT] Etag:["1tA3-HRcphdxl6MpokmJmoum2KA=/J7k1gTF0xApRIcoHnGLrjYXLk30="] Expires:[Tue, 16 Apr 2019 21:06:52 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 21:06:53.175585       1 gen.go:9971] GCEBetaInstances.Get(context.Background.WithDeadline(2019-04-16 22:06:52.685642449 +0000 UTC m=+3834.839366610 [59m59.510031304s]), Key{"e2e-test-peterhornyack-minion-group-06gd", zone: "us-central1-b"}) = &{AllocationAffinity:<nil> CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:05:10.344-07:00 DeletionProtection:false Description: Disks:[0xc000e3fdc0] DisplayDevice:<nil> GuestAccelerators:[] Hostname: Id:2158717802865491306 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00077bf10 MinCpuPlatform: Name:e2e-test-peterhornyack-minion-group-06gd NetworkInterfaces:[0xc001176a80] Scheduling:0xc000769180 SelfLink:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-minion-group-06gd ServiceAccounts:[0xc002b4a7e0] ShieldedVmConfig:<nil> ShieldedVmIntegrityPolicy:<nil> StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc002b4a780 Zone:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:06:53 GMT] Etag:["LGqADwT9OwB0dMRsrCgVcv6KF0c=/S047eHSKlJvyU65zbtwcespyW80="] Expires:[Tue, 16 Apr 2019 21:06:53 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 21:06:53.183157       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:53.183199       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-minion-group-06gd is already in a process of CIDR assignment.
I0416 21:06:53.185246       1 cloud_cidr_allocator.go:282] Set node e2e-test-peterhornyack-minion-group-06gd PodCIDR to 10.64.2.0/24
I0416 21:06:53.192011       1 controller_utils.go:200] Added [] Taint to Node e2e-test-peterhornyack-minion-group-06gd
I0416 21:06:53.193127       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:53.193201       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-minion-group-06gd is already in a process of CIDR assignment.
I0416 21:06:53.193371       1 cloud_cidr_allocator.go:159] Updated CIDR for "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:53.204253       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-minion-group-06gd has no [&Taint{Key:node.kubernetes.io/network-unavailable,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:06:52 +0000 UTC,}] Taint
I0416 21:06:53.204828       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:53.244432       1 controller_utils.go:200] Added [] Taint to Node e2e-test-peterhornyack-minion-group-06gd
I0416 21:06:53.244770       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:53.255592       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:53.257209       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-minion-group-06gd has no [&Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:06:52 +0000 UTC,}] Taint
W0416 21:06:56.835717       1 node_lifecycle_controller.go:831] Missing timestamp for Node e2e-test-peterhornyack-minion-group-06gd. Assuming now as a timestamp.
W0416 21:06:57.558739       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:06:55.256256       1 request.go:530] Throttling request took 73.993019ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:06:55.306197       1 request.go:530] Throttling request took 121.712519ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:06:55.356213       1 request.go:530] Throttling request took 169.804265ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:06:55.406189       1 request.go:530] Throttling request took 219.702809ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:06:55.456218       1 request.go:530] Throttling request took 269.652429ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:06:55.506221       1 request.go:530] Throttling request took 319.566746ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:06:55.556222       1 request.go:530] Throttling request took 369.447802ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:06:55.606379       1 request.go:530] Throttling request took 419.517199ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:06:55.608712       1 wrap.go:47] GET /healthz: (137.716µs) 200 [kube-probe/1.15+ 127.0.0.1:37056]
I0416 21:06:55.735586       1 replica_set.go:338] Pod kube-dns-autoscaler-97df449df-4ggmd updated, objectMeta {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:822 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc0028c03a0 BlockOwnerDeletion:0xc0028c03a1}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:852 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc002bbc1f7 BlockOwnerDeletion:0xc002bbc1f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:55.735705       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:55.735877       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (179.1µs)
I0416 21:06:55.736014       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:06:55.736028       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:55.736031       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:06:55.806187       1 request.go:530] Throttling request took 97.727358ms, request: GET:https://localhost:443/api/v1?timeout=32s
I0416 21:06:55.856145       1 request.go:530] Throttling request took 147.679713ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1?timeout=32s
I0416 21:06:55.906314       1 request.go:530] Throttling request took 197.832289ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1beta1?timeout=32s
I0416 21:06:55.956253       1 request.go:530] Throttling request took 247.737152ms, request: GET:https://localhost:443/apis/extensions/v1beta1?timeout=32s
I0416 21:06:56.006198       1 request.go:530] Throttling request took 297.689386ms, request: GET:https://localhost:443/apis/apps/v1?timeout=32s
I0416 21:06:56.056197       1 request.go:530] Throttling request took 347.679204ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:06:56.106338       1 request.go:530] Throttling request took 397.813215ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:06:56.131578       1 replica_set.go:338] Pod kubernetes-dashboard-85bcf5dbf8-t5nl6 updated, objectMeta {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:824 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc0028c04be BlockOwnerDeletion:0xc0028c04bf}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:854 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc002b649be BlockOwnerDeletion:0xc002b649bf}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:56.131679       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:56.131829       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (157.486µs)
I0416 21:06:56.131912       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:06:56.131928       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:56.131932       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:06:56.156406       1 request.go:530] Throttling request took 447.876538ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:06:56.206197       1 request.go:530] Throttling request took 497.659384ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:06:56.256291       1 request.go:530] Throttling request took 547.737431ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:06:56.306309       1 request.go:530] Throttling request took 597.674234ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:06:56.356200       1 request.go:530] Throttling request took 647.614266ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:06:56.406306       1 request.go:530] Throttling request took 697.701759ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:06:56.456270       1 request.go:530] Throttling request took 747.651059ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:06:56.506290       1 request.go:530] Throttling request took 797.690257ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:06:56.531450       1 replica_set.go:338] Pod metrics-server-v0.3.1-677c578bdf-xl48c updated, objectMeta {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:825 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc0028c0b87 BlockOwnerDeletion:0xc0028c0b88}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:855 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc002b65e97 BlockOwnerDeletion:0xc002b65e98}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:56.531567       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:56.531735       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (174.091µs)
I0416 21:06:56.531805       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:06:56.531821       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:56.531825       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:06:56.556646       1 request.go:530] Throttling request took 848.038638ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:06:56.606216       1 request.go:530] Throttling request took 897.60728ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:06:56.656176       1 request.go:530] Throttling request took 947.55289ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:06:56.706135       1 request.go:530] Throttling request took 997.506199ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:06:56.758738       1 request.go:530] Throttling request took 1.050083405s, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:06:56.806195       1 request.go:530] Throttling request took 1.097536727s, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:06:56.835559       1 node_lifecycle_controller.go:1157] Initializing eviction metric for zone: us-central1: :us-central1-b
I0416 21:06:56.835584       1 node_lifecycle_controller.go:642] Controller observed a new Node: "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:06:56.835595       1 controller_utils.go:164] Recording Registered Node e2e-test-peterhornyack-minion-group-06gd in Controller event message for node e2e-test-peterhornyack-minion-group-06gd
W0416 21:06:56.835717       1 node_lifecycle_controller.go:831] Missing timestamp for Node e2e-test-peterhornyack-minion-group-06gd. Assuming now as a timestamp.
I0416 21:06:56.835735       1 node_lifecycle_controller.go:1057] Controller detected that zone us-central1: :us-central1-b is now in state Normal.
I0416 21:06:56.836362       1 event.go:258] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"e2e-test-peterhornyack-minion-group-06gd", UID:"927063ff-cfd8-4bc8-bc94-c8d331dc7826", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node e2e-test-peterhornyack-minion-group-06gd event: Registered Node e2e-test-peterhornyack-minion-group-06gd in Controller
I0416 21:06:56.856219       1 request.go:530] Throttling request took 1.147555843s, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
I0416 21:06:56.906209       1 request.go:530] Throttling request took 1.197537369s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:06:56.931781       1 replica_set.go:338] Pod coredns-5b969f4c88-zcdpb updated, objectMeta {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:826 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc0028c1527 BlockOwnerDeletion:0xc0028c1528}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:856 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc002aef8bf BlockOwnerDeletion:0xc002aef8f0}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:56.931894       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:56.932072       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (184.711µs)
I0416 21:06:56.932146       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:06:56.932162       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:56.932165       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:06:56.956344       1 request.go:530] Throttling request took 1.247660607s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:06:57.006181       1 request.go:530] Throttling request took 1.297495583s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:06:57.033738       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:06:57.056267       1 request.go:530] Throttling request took 1.347541444s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:06:57.106134       1 request.go:530] Throttling request took 1.39743551s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:06:57.156273       1 request.go:530] Throttling request took 1.447537235s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
I0416 21:06:57.206165       1 request.go:530] Throttling request took 1.497448384s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:06:57.216400       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:06:57.256278       1 request.go:530] Throttling request took 1.547515271s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:06:57.306327       1 request.go:530] Throttling request took 1.597579827s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:06:57.332779       1 replica_set.go:338] Pod fluentd-gcp-scaler-7db4984bf4-26sjq updated, objectMeta {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:828 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc0028c16fe BlockOwnerDeletion:0xc0028c16ff}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:858 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc0029f35ee BlockOwnerDeletion:0xc0029f35ef}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:57.332931       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:57.333085       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (161.09µs)
I0416 21:06:57.333157       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:06:57.333626       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:57.333632       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:06:57.356193       1 request.go:530] Throttling request took 1.647444921s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:06:57.406369       1 request.go:530] Throttling request took 1.697611165s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:06:57.456583       1 request.go:530] Throttling request took 1.747817555s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:06:57.506179       1 request.go:530] Throttling request took 1.797413394s, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:06:57.556403       1 request.go:530] Throttling request took 1.847617268s, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
W0416 21:06:57.558739       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:06:57.735711       1 replica_set.go:338] Pod heapster-v1.6.0-beta.1-5858bf5485-5td9x updated, objectMeta {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:829 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc0028c1d97 BlockOwnerDeletion:0xc0028c1d98}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:860 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc002384897 BlockOwnerDeletion:0xc002384898}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:57.735901       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:57.736050       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (155.269µs)
I0416 21:06:57.736122       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:06:57.736136       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:57.736140       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:06:58.132892       1 replica_set.go:338] Pod event-exporter-v0.2.4-65d8d98768-n6vvr updated, objectMeta {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:830 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc002b182d7 BlockOwnerDeletion:0xc002b182d8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:862 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc0022b2697 BlockOwnerDeletion:0xc0022b2698}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:58.133020       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:58.133167       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (154.433µs)
I0416 21:06:58.133261       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:06:58.133276       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:58.133279       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:06:58.532371       1 replica_set.go:338] Pod l7-default-backend-8f479dd9-wbtkw updated, objectMeta {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:831 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc002b18b37 BlockOwnerDeletion:0xc002b18b38}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:864 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc0022b2b97 BlockOwnerDeletion:0xc0022b2b98}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:06:58.532506       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:58.532642       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (145.411µs)
I0416 21:06:58.532716       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:06:58.532731       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:58.533533       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:06:58.933949       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-4tl8c updated.
I0416 21:06:58.934614       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedb35bd8750, ext:235055337564, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:58.934892       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedcb7b94251, ext:241088612202, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:58.934957       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:58.934989       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:58.934994       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedcb7b94251, ext:241088612202, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:58.935036       1 update.go:396] Getting unavailable numbers
I0416 21:06:58.935088       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:58.935094       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:58.935098       1 update.go:68] Marking old pods for deletion
I0416 21:06:58.935119       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedcb7bc7e28, ext:241088824081, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:58.935127       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:06:58.935146       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:06:58.935165       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:58.936514       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.529298ms)
I0416 21:06:58.936549       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:06:58.936586       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-4tl8c, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:58.936589       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:06:59.332493       1 daemon_controller.go:554] Pod metadata-proxy-v0.1-m4h7x updated.
I0416 21:06:59.333055       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedb3583bfe6, ext:235051550927, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:59.333444       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedcd3dfd7e9, ext:241487161156, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:59.333517       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:59.333566       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:59.333572       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedcd3dfd7e9, ext:241487161156, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:59.333608       1 update.go:396] Getting unavailable numbers
I0416 21:06:59.333686       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 1
I0416 21:06:59.333761       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:06:59.333766       1 update.go:68] Marking old pods for deletion
I0416 21:06:59.333770       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedcd3e4e752, ext:241487492668, loc:(*time.Location)(0x71c51c0)}}
I0416 21:06:59.333779       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:06:59.333803       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:06:59.333840       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:06:59.333933       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.417201ms)
I0416 21:06:59.333962       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:06:59.333981       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:06:59.333985       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:07:01.145921       1 controller.go:123] Found 0 jobs
I0416 21:07:01.149012       1 controller.go:139] Found 0 cronjobs
I0416 21:07:01.149023       1 controller.go:142] Found 0 groups
I0416 21:07:01.747426       1 service_controller.go:639] Detected change in list of current cluster nodes. New node set: map[e2e-test-peterhornyack-minion-group-06gd:{}]
I0416 21:07:01.747469       1 service_controller.go:647] Successfully updated 6 out of 6 load balancers to direct traffic to the updated set of nodes
I0416 21:07:01.883658       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:01.938497       1 gc_controller.go:144] GC'ing orphaned
I0416 21:07:01.943371       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:07:02.553474       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:07:02.972475       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:07:03.481326       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:04.378707       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:07:04.378735       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:04.378739       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:07:05.608474       1 wrap.go:47] GET /healthz: (152.105µs) 200 [kube-probe/1.15+ 127.0.0.1:37090]
I0416 21:07:07.217382       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:07.496164       1 replica_set.go:338] Pod kube-dns-autoscaler-97df449df-4ggmd updated, objectMeta {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:852 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc002bbc1f7 BlockOwnerDeletion:0xc002bbc1f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kube-dns-autoscaler-97df449df-4ggmd GenerateName:kube-dns-autoscaler-97df449df- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kube-dns-autoscaler-97df449df-4ggmd UID:50ee9110-be9e-4c36-8d01-00b5a25b69d9 ResourceVersion:886 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns-autoscaler pod-template-hash:97df449df] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kube-dns-autoscaler-97df449df UID:8f66681d-ed44-4c71-bafd-e0213837e6f4 Controller:0xc0020bc970 BlockOwnerDeletion:0xc0020bc971}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:07.496339       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:07.496464       1 replica_set_utils.go:58] Updating status for : kube-system/kube-dns-autoscaler-97df449df, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:07.496923       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:07:07.496940       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:07.496944       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:07:07.504701       1 deployment_controller.go:280] ReplicaSet kube-dns-autoscaler-97df449df updated.
I0416 21:07:07.504749       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:07:07.504743815 +0000 UTC m=+249.658467966)
I0416 21:07:07.507895       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (11.555344ms)
I0416 21:07:07.507955       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:07.508096       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (152.618µs)
I0416 21:07:07.518594       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (13.835611ms)
I0416 21:07:07.518923       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:07:07.518945       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:07:07.518936222 +0000 UTC m=+249.672660396)
I0416 21:07:07.519946       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (1.004008ms)
I0416 21:07:10.402335       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:11.152615       1 controller.go:123] Found 0 jobs
I0416 21:07:11.155392       1 controller.go:139] Found 0 cronjobs
I0416 21:07:11.155404       1 controller.go:142] Found 0 groups
I0416 21:07:11.739418       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:11.744515       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:12.034069       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:07:12.216650       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:13.136549       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:07:14.161006       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:07:14.161038       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:14.161026511 +0000 UTC m=+256.314750649)
I0416 21:07:14.161927       1 deployment_util.go:259] Updating replica set "metrics-server-v0.3.1-7d9cf58c5c" revision to 2
I0416 21:07:14.173073       1 controller_utils.go:202] Controller kube-system/metrics-server-v0.3.1-7d9cf58c5c either never recorded expectations, or the ttl expired.
I0416 21:07:14.173179       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:14.173217       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/metrics-server-v0.3.1-7d9cf58c5c, need 1, creating 1
I0416 21:07:14.173686       1 deployment_controller.go:214] ReplicaSet metrics-server-v0.3.1-7d9cf58c5c added.
I0416 21:07:14.176327       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"metrics-server-v0.3.1", UID:"c815ba23-a2bf-4fc3-b5fc-f8f3d4010eaa", APIVersion:"apps/v1", ResourceVersion:"903", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set metrics-server-v0.3.1-7d9cf58c5c to 1
I0416 21:07:14.188125       1 pvc_protection_controller.go:280] Got event on pod kube-system/metrics-server-v0.3.1-7d9cf58c5c-xrmt9
I0416 21:07:14.188255       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"metrics-server-v0.3.1-7d9cf58c5c-xrmt9"}
I0416 21:07:14.188289       1 replica_set.go:275] Pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9 created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metrics-server-v0.3.1-7d9cf58c5c-xrmt9", GenerateName:"metrics-server-v0.3.1-7d9cf58c5c-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-7d9cf58c5c-xrmt9", UID:"a3e1a1f1-ecf3-4864-a744-c84aed93ad6f", ResourceVersion:"905", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045634, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"metrics-server", "pod-template-hash":"7d9cf58c5c", "version":"v0.3.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"metrics-server-v0.3.1-7d9cf58c5c", UID:"703b501f-6896-4821-aaeb-ddc5eaac046d", Controller:(*bool)(0xc001d7cba7), BlockOwnerDeletion:(*bool)(0xc001d7cba8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"metrics-server-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002077000), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"metrics-server-token-q95tp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002077040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metrics-server", Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", Command:[]string{"/metrics-server", "--metric-resolution=30s", "--kubelet-port=10255", "--deprecated-kubelet-completely-insecure=true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"https", HostPort:0, ContainerPort:443, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:48, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"48m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:109051904, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:48, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"48m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:109051904, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"metrics-server-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=40m", "--extra-cpu=0.5m", "--memory=40Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=metrics-server-v0.3.1", "--container=metrics-server", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00168a820)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00168a860)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:314572800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"300Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:5, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"5m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001d7cce8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"metrics-server", DeprecatedServiceAccount:"metrics-server", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002267740), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d7cd40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d7cd60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc001d7cd68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001d7cd6c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:07:14.188625       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:14.188880       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (139.662µs)
I0416 21:07:14.188928       1 disruption.go:326] addPod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:14.188943       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:14.188963       1 disruption.go:329] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:14.192327       1 controller_utils.go:588] Controller metrics-server-v0.3.1-7d9cf58c5c created pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9
I0416 21:07:14.192419       1 replica_set_utils.go:58] Updating status for : kube-system/metrics-server-v0.3.1-7d9cf58c5c, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:07:14.193054       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"metrics-server-v0.3.1-7d9cf58c5c", UID:"703b501f-6896-4821-aaeb-ddc5eaac046d", APIVersion:"apps/v1", ResourceVersion:"904", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: metrics-server-v0.3.1-7d9cf58c5c-xrmt9
I0416 21:07:14.195935       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:07:14.197193       1 rolling.go:94] New replica set kube-system/metrics-server-v0.3.1-7d9cf58c5c has 0 available pods.
I0416 21:07:14.197212       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:07:14.175719475 +0000 UTC m=+256.329443610 - now: 2019-04-16 21:07:14.197206529 +0000 UTC m=+256.350930681]
I0416 21:07:14.207632       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"metrics-server-v0.3.1-7d9cf58c5c-xrmt9"}
I0416 21:07:14.207710       1 replica_set.go:338] Pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9 updated, objectMeta {Name:metrics-server-v0.3.1-7d9cf58c5c-xrmt9 GenerateName:metrics-server-v0.3.1-7d9cf58c5c- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-7d9cf58c5c-xrmt9 UID:a3e1a1f1-ecf3-4864-a744-c84aed93ad6f ResourceVersion:905 Generation:0 CreationTimestamp:2019-04-16 21:07:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:7d9cf58c5c version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-7d9cf58c5c UID:703b501f-6896-4821-aaeb-ddc5eaac046d Controller:0xc001d7cba7 BlockOwnerDeletion:0xc001d7cba8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:metrics-server-v0.3.1-7d9cf58c5c-xrmt9 GenerateName:metrics-server-v0.3.1-7d9cf58c5c- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-7d9cf58c5c-xrmt9 UID:a3e1a1f1-ecf3-4864-a744-c84aed93ad6f ResourceVersion:907 Generation:0 CreationTimestamp:2019-04-16 21:07:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:7d9cf58c5c version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-7d9cf58c5c UID:703b501f-6896-4821-aaeb-ddc5eaac046d Controller:0xc0013f16d7 BlockOwnerDeletion:0xc0013f16d8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:14.207976       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (122.491µs)
I0416 21:07:14.208014       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:14.208029       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:14.208032       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:14.212396       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-7d9cf58c5c updated.
I0416 21:07:14.215547       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (42.484053ms)
I0416 21:07:14.215608       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:14.215824       1 replica_set_utils.go:58] Updating status for : kube-system/metrics-server-v0.3.1-7d9cf58c5c, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:07:14.220385       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (59.345976ms)
I0416 21:07:14.220402       1 deployment_controller.go:484] Error syncing deployment kube-system/metrics-server-v0.3.1: Operation cannot be fulfilled on deployments.apps "metrics-server-v0.3.1": the object has been modified; please apply your changes to the latest version and try again
I0416 21:07:14.220430       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:14.220426678 +0000 UTC m=+256.374150828)
I0416 21:07:14.221380       1 rolling.go:94] New replica set kube-system/metrics-server-v0.3.1-7d9cf58c5c has 0 available pods.
I0416 21:07:14.221395       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:07:14 +0000 UTC - now: 2019-04-16 21:07:14.22139163 +0000 UTC m=+256.375115767]
I0416 21:07:14.229835       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-7d9cf58c5c updated.
I0416 21:07:14.238798       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (23.187743ms)
I0416 21:07:14.238845       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:14.239029       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (193.175µs)
I0416 21:07:14.239416       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:07:14.241975       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (21.536209ms)
I0416 21:07:14.242024       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:14.242019509 +0000 UTC m=+256.395743661)
I0416 21:07:14.243752       1 rolling.go:94] New replica set kube-system/metrics-server-v0.3.1-7d9cf58c5c has 0 available pods.
I0416 21:07:14.249961       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:07:14.252215       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (10.183686ms)
I0416 21:07:14.252297       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:14.252292325 +0000 UTC m=+256.406016476)
I0416 21:07:14.254449       1 rolling.go:94] New replica set kube-system/metrics-server-v0.3.1-7d9cf58c5c has 0 available pods.
I0416 21:07:14.254637       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:07:14 +0000 UTC - now: 2019-04-16 21:07:14.254630584 +0000 UTC m=+256.408354734]
I0416 21:07:14.254705       1 progress.go:193] Queueing up deployment "metrics-server-v0.3.1" for a progress check after 599s
I0416 21:07:14.254822       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (2.434898ms)
I0416 21:07:14.414499       1 replica_set.go:338] Pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9 updated, objectMeta {Name:metrics-server-v0.3.1-7d9cf58c5c-xrmt9 GenerateName:metrics-server-v0.3.1-7d9cf58c5c- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-7d9cf58c5c-xrmt9 UID:a3e1a1f1-ecf3-4864-a744-c84aed93ad6f ResourceVersion:907 Generation:0 CreationTimestamp:2019-04-16 21:07:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:7d9cf58c5c version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-7d9cf58c5c UID:703b501f-6896-4821-aaeb-ddc5eaac046d Controller:0xc0013f16d7 BlockOwnerDeletion:0xc0013f16d8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:metrics-server-v0.3.1-7d9cf58c5c-xrmt9 GenerateName:metrics-server-v0.3.1-7d9cf58c5c- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-7d9cf58c5c-xrmt9 UID:a3e1a1f1-ecf3-4864-a744-c84aed93ad6f ResourceVersion:912 Generation:0 CreationTimestamp:2019-04-16 21:07:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:7d9cf58c5c version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-7d9cf58c5c UID:703b501f-6896-4821-aaeb-ddc5eaac046d Controller:0xc0018e35f7 BlockOwnerDeletion:0xc0018e35f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:14.414617       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:14.414781       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (171.193µs)
I0416 21:07:14.415046       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:14.415083       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:14.415087       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
E0416 21:07:15.810534       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
E0416 21:07:15.810534       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:07:14.986578       1 replica_set.go:338] Pod coredns-5b969f4c88-zcdpb updated, objectMeta {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:856 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc002aef8bf BlockOwnerDeletion:0xc002aef8f0}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:913 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc00175b2df BlockOwnerDeletion:0xc00175b3d0}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:14.986694       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:14.986852       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (152.653µs)
I0416 21:07:14.987220       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 0 not ready: 3
I0416 21:07:14.987689       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:07:14.987708       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:14.987712       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:07:14.995589       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (8.633264ms)
I0416 21:07:15.457708       1 request.go:530] Throttling request took 90.485132ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:07:15.508267       1 request.go:530] Throttling request took 140.996253ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:07:15.558833       1 request.go:530] Throttling request took 191.575994ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:07:15.608044       1 request.go:530] Throttling request took 240.782426ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:07:15.608735       1 wrap.go:47] GET /healthz: (88.18µs) 200 [kube-probe/1.15+ 127.0.0.1:37126]
I0416 21:07:15.657739       1 request.go:530] Throttling request took 290.478987ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:07:15.707685       1 request.go:530] Throttling request took 338.042781ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:07:15.757930       1 request.go:530] Throttling request took 388.194257ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:07:15.807673       1 request.go:530] Throttling request took 437.922249ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
E0416 21:07:15.810534       1 resource_quota_controller.go:407] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request
I0416 21:07:15.810946       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:07:16.125586       1 replica_set.go:338] Pod heapster-v1.6.0-beta.1-5858bf5485-5td9x updated, objectMeta {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:860 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc002384897 BlockOwnerDeletion:0xc002384898}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:heapster-v1.6.0-beta.1-5858bf5485-5td9x GenerateName:heapster-v1.6.0-beta.1-5858bf5485- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x UID:49a1caec-a921-453f-8c62-7a6fa815c59f ResourceVersion:918 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:5858bf5485 version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-5858bf5485 UID:089fb806-c80c-46e9-aa5f-09c4c068e23a Controller:0xc00132855e BlockOwnerDeletion:0xc00132855f}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:16.125717       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:16.125903       1 replica_set_utils.go:58] Updating status for : kube-system/heapster-v1.6.0-beta.1-5858bf5485, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:16.130480       1 endpoints_controller.go:540] Update endpoints for kube-system/heapster, ready: 1 not ready: 0
I0416 21:07:16.130970       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:16.131014       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:16.131017       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:16.138058       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-5858bf5485 updated.
I0416 21:07:16.138092       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:16.138087287 +0000 UTC m=+258.291811425)
I0416 21:07:16.140479       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (14.772117ms)
I0416 21:07:16.140720       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:16.140902       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (194.313µs)
I0416 21:07:16.145241       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (17.018237ms)
I0416 21:07:16.148916       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:07:16.150492       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (12.394018ms)
I0416 21:07:16.150524       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:16.150519693 +0000 UTC m=+258.304243829)
I0416 21:07:16.151696       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.169722ms)
I0416 21:07:16.171049       1 replica_set.go:338] Pod metrics-server-v0.3.1-677c578bdf-xl48c updated, objectMeta {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:855 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc002b65e97 BlockOwnerDeletion:0xc002b65e98}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:metrics-server-v0.3.1-677c578bdf-xl48c GenerateName:metrics-server-v0.3.1-677c578bdf- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c UID:224fe499-97c1-4296-b944-d6862030a620 ResourceVersion:922 Generation:0 CreationTimestamp:2019-04-16 21:03:46 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:677c578bdf version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-677c578bdf UID:eb987e4f-a31f-4799-b1ca-cc8d0261c511 Controller:0xc000495177 BlockOwnerDeletion:0xc000495178}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:16.171183       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:16.171365       1 replica_set_utils.go:58] Updating status for : kube-system/metrics-server-v0.3.1-677c578bdf, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:16.172086       1 endpoints_controller.go:540] Update endpoints for kube-system/metrics-server, ready: 1 not ready: 0
I0416 21:07:16.173918       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:16.173952       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:16.173956       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:16.182755       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-677c578bdf updated.
I0416 21:07:16.182800       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:16.182793954 +0000 UTC m=+258.336518105)
I0416 21:07:16.184338       1 rolling.go:94] New replica set kube-system/metrics-server-v0.3.1-7d9cf58c5c has 0 available pods.
I0416 21:07:16.186438       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (15.257186ms)
I0416 21:07:16.186505       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:16.186660       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (189.659µs)
I0416 21:07:16.193153       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:07:16.196548       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (24.656216ms)
I0416 21:07:16.196714       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (13.91442ms)
I0416 21:07:16.196740       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:16.196736149 +0000 UTC m=+258.350460300)
I0416 21:07:16.198576       1 rolling.go:94] New replica set kube-system/metrics-server-v0.3.1-7d9cf58c5c has 0 available pods.
I0416 21:07:16.198599       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:07:16 +0000 UTC - now: 2019-04-16 21:07:16.198593805 +0000 UTC m=+258.352317941]
I0416 21:07:16.198658       1 progress.go:193] Queueing up deployment "metrics-server-v0.3.1" for a progress check after 599s
I0416 21:07:16.198674       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (1.935029ms)
I0416 21:07:17.149970       1 daemon_controller.go:554] Pod metadata-proxy-v0.1-m4h7x updated.
I0416 21:07:17.151338       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aedcd3e4e752, ext:241487492668, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.151646       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee14909e315, ext:259305367086, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.151662       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:07:17.151748       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:07:17.151755       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee14909e315, ext:259305367086, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.151807       1 update.go:396] Getting unavailable numbers
I0416 21:07:17.151891       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:07:17.151898       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:17.151902       1 update.go:68] Marking old pods for deletion
I0416 21:07:17.151906       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee1490de07f, ext:259305628600, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.151914       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:07:17.151939       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:07:17.151977       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:17.158536       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:07:17.158584       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:17.158589       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:07:17.182423       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:07:17.189580       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (39.57384ms)
I0416 21:07:17.191586       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee1490de07f, ext:259305628600, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.191904       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee14b7028dd, ext:259345624032, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.191931       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:07:17.191983       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:07:17.191989       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee14b7028dd, ext:259345624032, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.192042       1 update.go:396] Getting unavailable numbers
I0416 21:07:17.192146       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:07:17.192153       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:17.192157       1 update.go:68] Marking old pods for deletion
I0416 21:07:17.192160       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee14b741d58, ext:259345883320, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.192183       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:07:17.192210       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:07:17.195627       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:17.195893       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (6.263209ms)
I0416 21:07:17.204938       1 replica_set.go:338] Pod l7-default-backend-8f479dd9-wbtkw updated, objectMeta {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:864 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc0022b2b97 BlockOwnerDeletion:0xc0022b2b98}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:l7-default-backend-8f479dd9-wbtkw GenerateName:l7-default-backend-8f479dd9- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/l7-default-backend-8f479dd9-wbtkw UID:d2a16c9d-a630-4bdb-a762-209a1b23939f ResourceVersion:929 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:glbc name:glbc pod-template-hash:8f479dd9] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:l7-default-backend-8f479dd9 UID:eb2d558b-0e11-40f0-8ae2-266c97cd406f Controller:0xc000af60a7 BlockOwnerDeletion:0xc000af60a8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:17.205060       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.205217       1 replica_set_utils.go:58] Updating status for : kube-system/l7-default-backend-8f479dd9, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:17.206473       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:07:17.206517       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:17.206521       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:07:17.206799       1 endpoints_controller.go:540] Update endpoints for kube-system/default-http-backend, ready: 1 not ready: 0
I0416 21:07:17.216129       1 deployment_controller.go:280] ReplicaSet l7-default-backend-8f479dd9 updated.
I0416 21:07:17.216154       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:07:17.216148769 +0000 UTC m=+259.369872920)
I0416 21:07:17.220775       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (15.713053ms)
I0416 21:07:17.220839       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.221172       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (342.32µs)
I0416 21:07:17.227793       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (21.205474ms)
I0416 21:07:17.230939       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:07:17.234573       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (18.412659ms)
I0416 21:07:17.234625       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:07:17.234620645 +0000 UTC m=+259.388344795)
I0416 21:07:17.235258       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (635.211µs)
I0416 21:07:17.237415       1 replica_set.go:338] Pod event-exporter-v0.2.4-65d8d98768-n6vvr updated, objectMeta {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:862 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc0022b2697 BlockOwnerDeletion:0xc0022b2698}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:event-exporter-v0.2.4-65d8d98768-n6vvr GenerateName:event-exporter-v0.2.4-65d8d98768- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/event-exporter-v0.2.4-65d8d98768-n6vvr UID:32a8d941-90a9-4e4a-9748-a1acdd38a2e0 ResourceVersion:933 Generation:0 CreationTimestamp:2019-04-16 21:03:45 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:event-exporter pod-template-hash:65d8d98768 version:v0.2.4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:event-exporter-v0.2.4-65d8d98768 UID:a8ddd8df-17da-4437-afac-e1ee83ceb388 Controller:0xc000af7eb7 BlockOwnerDeletion:0xc000af7eb8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:17.237527       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.237670       1 replica_set_utils.go:58] Updating status for : kube-system/event-exporter-v0.2.4-65d8d98768, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:17.238088       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:07:17.238106       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:17.238110       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:07:17.246260       1 deployment_controller.go:280] ReplicaSet event-exporter-v0.2.4-65d8d98768 updated.
I0416 21:07:17.246286       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:07:17.246281552 +0000 UTC m=+259.400005703)
I0416 21:07:17.250557       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (13.02832ms)
I0416 21:07:17.250601       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.250762       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (171.368µs)
I0416 21:07:17.254627       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:07:17.255579       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (9.274714ms)
I0416 21:07:17.255609       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:07:17.255604863 +0000 UTC m=+259.409329015)
I0416 21:07:17.256288       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (678.069µs)
I0416 21:07:17.554844       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:07:17.554869       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:17.554864285 +0000 UTC m=+259.708588421)
I0416 21:07:17.555756       1 deployment_util.go:259] Updating replica set "heapster-v1.6.0-beta.1-77858557dc" revision to 2
I0416 21:07:17.564576       1 controller_utils.go:202] Controller kube-system/heapster-v1.6.0-beta.1-77858557dc either never recorded expectations, or the ttl expired.
I0416 21:07:17.564776       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.564803       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/heapster-v1.6.0-beta.1-77858557dc, need 1, creating 1
I0416 21:07:17.565306       1 deployment_controller.go:214] ReplicaSet heapster-v1.6.0-beta.1-77858557dc added.
I0416 21:07:17.569137       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1", UID:"92819fed-de33-48a3-a4b6-c4a67aa06a5a", APIVersion:"apps/v1", ResourceVersion:"937", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set heapster-v1.6.0-beta.1-77858557dc to 1
I0416 21:07:17.580804       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:07:17.582625       1 pvc_protection_controller.go:280] Got event on pod kube-system/heapster-v1.6.0-beta.1-77858557dc-gwsdj
I0416 21:07:17.582785       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1-77858557dc-gwsdj"}
I0416 21:07:17.582818       1 replica_set.go:275] Pod heapster-v1.6.0-beta.1-77858557dc-gwsdj created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"heapster-v1.6.0-beta.1-77858557dc-gwsdj", GenerateName:"heapster-v1.6.0-beta.1-77858557dc-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-77858557dc-gwsdj", UID:"c340e6d2-d96f-4e36-b8cb-fb9423b3b61e", ResourceVersion:"939", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045637, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"heapster", "pod-template-hash":"77858557dc", "version":"v1.6.0-beta.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"heapster-v1.6.0-beta.1-77858557dc", UID:"c0f336b4-1602-41aa-88da-129d22c15197", Controller:(*bool)(0xc000e62a67), BlockOwnerDeletion:(*bool)(0xc000e62a68)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"heapster-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc001dbe340), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"heapster-token-qrr2n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001dbe380), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"heapster", Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", Command:[]string{"/heapster", "--source=kubernetes.summary_api:''"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:88, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"88m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:213909504, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"204Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:88, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"88m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:213909504, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"204Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc0017543c0), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"heapster-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=80m", "--extra-cpu=0.5m", "--memory=140Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=heapster-v1.6.0-beta.1", "--container=heapster", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00072fc80)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00072fcc0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000e62bc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"heapster", DeprecatedServiceAccount:"heapster", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0014791a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000e62c20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000e62c50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc000e62c58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000e62c5c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Guaranteed"}}.
I0416 21:07:17.583174       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.583488       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (228.987µs)
I0416 21:07:17.583522       1 disruption.go:326] addPod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:17.583536       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:17.583540       1 disruption.go:329] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:17.585845       1 rolling.go:94] New replica set kube-system/heapster-v1.6.0-beta.1-77858557dc has 0 available pods.
I0416 21:07:17.585866       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:07:17.568555215 +0000 UTC m=+259.722279367 - now: 2019-04-16 21:07:17.585860535 +0000 UTC m=+259.739584672]
I0416 21:07:17.588762       1 controller_utils.go:588] Controller heapster-v1.6.0-beta.1-77858557dc created pod heapster-v1.6.0-beta.1-77858557dc-gwsdj
I0416 21:07:17.588859       1 replica_set_utils.go:58] Updating status for : kube-system/heapster-v1.6.0-beta.1-77858557dc, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:07:17.589211       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1-77858557dc", UID:"c0f336b4-1602-41aa-88da-129d22c15197", APIVersion:"apps/v1", ResourceVersion:"938", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: heapster-v1.6.0-beta.1-77858557dc-gwsdj
I0416 21:07:17.600729       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (45.849721ms)
I0416 21:07:17.600765       1 deployment_controller.go:484] Error syncing deployment kube-system/heapster-v1.6.0-beta.1: Operation cannot be fulfilled on deployments.apps "heapster-v1.6.0-beta.1": the object has been modified; please apply your changes to the latest version and try again
I0416 21:07:17.600800       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:17.600796738 +0000 UTC m=+259.754520877)
I0416 21:07:17.602007       1 rolling.go:94] New replica set kube-system/heapster-v1.6.0-beta.1-77858557dc has 0 available pods.
I0416 21:07:17.602025       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:07:17 +0000 UTC - now: 2019-04-16 21:07:17.602021379 +0000 UTC m=+259.755745517]
I0416 21:07:17.605411       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1-77858557dc-gwsdj"}
I0416 21:07:17.605499       1 replica_set.go:338] Pod heapster-v1.6.0-beta.1-77858557dc-gwsdj updated, objectMeta {Name:heapster-v1.6.0-beta.1-77858557dc-gwsdj GenerateName:heapster-v1.6.0-beta.1-77858557dc- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-77858557dc-gwsdj UID:c340e6d2-d96f-4e36-b8cb-fb9423b3b61e ResourceVersion:939 Generation:0 CreationTimestamp:2019-04-16 21:07:17 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:77858557dc version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-77858557dc UID:c0f336b4-1602-41aa-88da-129d22c15197 Controller:0xc000e62a67 BlockOwnerDeletion:0xc000e62a68}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:heapster-v1.6.0-beta.1-77858557dc-gwsdj GenerateName:heapster-v1.6.0-beta.1-77858557dc- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-77858557dc-gwsdj UID:c340e6d2-d96f-4e36-b8cb-fb9423b3b61e ResourceVersion:941 Generation:0 CreationTimestamp:2019-04-16 21:07:17 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:77858557dc version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-77858557dc UID:c0f336b4-1602-41aa-88da-129d22c15197 Controller:0xc0014cb5b7 BlockOwnerDeletion:0xc0014cb5b8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:17.605824       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (167.74µs)
I0416 21:07:17.605867       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:17.605893       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:17.605897       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:17.611996       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-77858557dc updated.
I0416 21:07:17.619593       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (55.025786ms)
I0416 21:07:17.619679       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.620279       1 replica_set_utils.go:58] Updating status for : kube-system/heapster-v1.6.0-beta.1-77858557dc, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:07:17.623511       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:07:17.631047       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (30.237419ms)
I0416 21:07:17.631102       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:17.631096676 +0000 UTC m=+259.784820827)
I0416 21:07:17.634012       1 rolling.go:94] New replica set kube-system/heapster-v1.6.0-beta.1-77858557dc has 0 available pods.
I0416 21:07:17.634033       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:07:17 +0000 UTC - now: 2019-04-16 21:07:17.634029006 +0000 UTC m=+259.787753158]
I0416 21:07:17.634088       1 progress.go:193] Queueing up deployment "heapster-v1.6.0-beta.1" for a progress check after 599s
I0416 21:07:17.634105       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (3.005004ms)
I0416 21:07:17.637917       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (18.276788ms)
I0416 21:07:17.638181       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.638359       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (182.331µs)
I0416 21:07:17.638453       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-77858557dc updated.
I0416 21:07:17.638484       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:17.638466826 +0000 UTC m=+259.792190966)
I0416 21:07:17.641182       1 rolling.go:94] New replica set kube-system/heapster-v1.6.0-beta.1-77858557dc has 0 available pods.
I0416 21:07:17.647383       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:07:17.649466       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (10.976878ms)
I0416 21:07:17.649499       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:17.649494936 +0000 UTC m=+259.803219075)
I0416 21:07:17.650797       1 rolling.go:94] New replica set kube-system/heapster-v1.6.0-beta.1-77858557dc has 0 available pods.
I0416 21:07:17.650813       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:07:17 +0000 UTC - now: 2019-04-16 21:07:17.650809434 +0000 UTC m=+259.804533573]
I0416 21:07:17.650846       1 progress.go:193] Queueing up deployment "heapster-v1.6.0-beta.1" for a progress check after 599s
I0416 21:07:17.650871       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.374244ms)
I0416 21:07:17.709663       1 replica_set.go:338] Pod heapster-v1.6.0-beta.1-77858557dc-gwsdj updated, objectMeta {Name:heapster-v1.6.0-beta.1-77858557dc-gwsdj GenerateName:heapster-v1.6.0-beta.1-77858557dc- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-77858557dc-gwsdj UID:c340e6d2-d96f-4e36-b8cb-fb9423b3b61e ResourceVersion:941 Generation:0 CreationTimestamp:2019-04-16 21:07:17 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:77858557dc version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-77858557dc UID:c0f336b4-1602-41aa-88da-129d22c15197 Controller:0xc0014cb5b7 BlockOwnerDeletion:0xc0014cb5b8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:heapster-v1.6.0-beta.1-77858557dc-gwsdj GenerateName:heapster-v1.6.0-beta.1-77858557dc- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-77858557dc-gwsdj UID:c340e6d2-d96f-4e36-b8cb-fb9423b3b61e ResourceVersion:947 Generation:0 CreationTimestamp:2019-04-16 21:07:17 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:77858557dc version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-77858557dc UID:c0f336b4-1602-41aa-88da-129d22c15197 Controller:0xc001772677 BlockOwnerDeletion:0xc001772678}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:17.709816       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:17.710170       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (359.872µs)
I0416 21:07:17.710271       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:17.710302       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:17.710305       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:18.642741       1 replica_set.go:338] Pod kubernetes-dashboard-85bcf5dbf8-t5nl6 updated, objectMeta {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:854 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc002b649be BlockOwnerDeletion:0xc002b649bf}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:kubernetes-dashboard-85bcf5dbf8-t5nl6 GenerateName:kubernetes-dashboard-85bcf5dbf8- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/kubernetes-dashboard-85bcf5dbf8-t5nl6 UID:8d9b0eb7-09ea-4ba2-8c06-4d0ee271c1bf ResourceVersion:950 Generation:0 CreationTimestamp:2019-04-16 21:03:50 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kubernetes-dashboard pod-template-hash:85bcf5dbf8] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:kubernetes-dashboard-85bcf5dbf8 UID:e9a8d0af-38ae-4c87-bb65-9510ad003870 Controller:0xc0017731a7 BlockOwnerDeletion:0xc0017731a8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:18.642853       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:18.643024       1 replica_set_utils.go:58] Updating status for : kube-system/kubernetes-dashboard-85bcf5dbf8, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:18.645323       1 endpoints_controller.go:540] Update endpoints for kube-system/kubernetes-dashboard, ready: 1 not ready: 0
I0416 21:07:18.645622       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:07:18.645674       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:18.645678       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:07:18.705029       1 deployment_controller.go:280] ReplicaSet kubernetes-dashboard-85bcf5dbf8 updated.
I0416 21:07:18.705071       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:07:18.705065703 +0000 UTC m=+260.858789841)
I0416 21:07:18.723623       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (80.766145ms)
I0416 21:07:18.723690       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:18.723836       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (157.502µs)
I0416 21:07:18.747662       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (102.531215ms)
I0416 21:07:18.764909       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:07:18.784754       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (79.660006ms)
I0416 21:07:18.784795       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:07:18.784790477 +0000 UTC m=+260.938514616)
I0416 21:07:18.787404       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (2.58915ms)
I0416 21:07:19.809190       1 replica_set.go:338] Pod fluentd-gcp-scaler-7db4984bf4-26sjq updated, objectMeta {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:858 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc0029f35ee BlockOwnerDeletion:0xc0029f35ef}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:fluentd-gcp-scaler-7db4984bf4-26sjq GenerateName:fluentd-gcp-scaler-7db4984bf4- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/fluentd-gcp-scaler-7db4984bf4-26sjq UID:646aa3ab-46d8-46d1-8b1b-13596b4d3371 ResourceVersion:956 Generation:0 CreationTimestamp:2019-04-16 21:03:48 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:fluentd-gcp-scaler pod-template-hash:7db4984bf4] Annotations:map[] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:fluentd-gcp-scaler-7db4984bf4 UID:9d4ec846-d076-4c91-9456-3f2fae399385 Controller:0xc0017db7ee BlockOwnerDeletion:0xc0017db7ef}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:19.809322       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:19.809463       1 replica_set_utils.go:58] Updating status for : kube-system/fluentd-gcp-scaler-7db4984bf4, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:19.809945       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:07:19.809977       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:19.809981       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:07:19.816427       1 deployment_controller.go:280] ReplicaSet fluentd-gcp-scaler-7db4984bf4 updated.
I0416 21:07:19.816454       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:07:19.816449645 +0000 UTC m=+261.970173796)
I0416 21:07:19.820172       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (10.867947ms)
I0416 21:07:19.820241       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:19.820383       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (162.74µs)
I0416 21:07:19.825796       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:07:19.826696       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (10.221456ms)
I0416 21:07:19.826724       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:07:19.826720667 +0000 UTC m=+261.980444818)
I0416 21:07:19.827180       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (456.83µs)
E0416 21:07:21.307801       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"971", Generation:2, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"2", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00189a840), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc00189a860), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc00189a880), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0029453c0), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a8a0)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:209715200, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc0026bc330), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a980)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a9c0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001184ca8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002888240), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc002b16de8)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc001184d20)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:2, NumberMisscheduled:0, DesiredNumberScheduled:2, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:2, NumberAvailable:1, NumberUnavailable:1, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
E0416 21:07:21.307801       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"971", Generation:2, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"2", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00189a840), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc00189a860), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc00189a880), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0029453c0), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a8a0)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:209715200, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc0026bc330), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a980)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a9c0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001184ca8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002888240), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc002b16de8)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc001184d20)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:2, NumberMisscheduled:0, DesiredNumberScheduled:2, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:2, NumberAvailable:1, NumberUnavailable:1, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
I0416 21:07:20.890428       1 replica_set.go:338] Pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9 updated, objectMeta {Name:metrics-server-v0.3.1-7d9cf58c5c-xrmt9 GenerateName:metrics-server-v0.3.1-7d9cf58c5c- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-7d9cf58c5c-xrmt9 UID:a3e1a1f1-ecf3-4864-a744-c84aed93ad6f ResourceVersion:912 Generation:0 CreationTimestamp:2019-04-16 21:07:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:7d9cf58c5c version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-7d9cf58c5c UID:703b501f-6896-4821-aaeb-ddc5eaac046d Controller:0xc0018e35f7 BlockOwnerDeletion:0xc0018e35f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:metrics-server-v0.3.1-7d9cf58c5c-xrmt9 GenerateName:metrics-server-v0.3.1-7d9cf58c5c- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-7d9cf58c5c-xrmt9 UID:a3e1a1f1-ecf3-4864-a744-c84aed93ad6f ResourceVersion:960 Generation:0 CreationTimestamp:2019-04-16 21:07:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:metrics-server pod-template-hash:7d9cf58c5c version:v0.3.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:metrics-server-v0.3.1-7d9cf58c5c UID:703b501f-6896-4821-aaeb-ddc5eaac046d Controller:0xc0017690b7 BlockOwnerDeletion:0xc0017690b8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:20.890580       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:20.890755       1 replica_set_utils.go:58] Updating status for : kube-system/metrics-server-v0.3.1-7d9cf58c5c, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:20.891502       1 endpoints_controller.go:540] Update endpoints for kube-system/metrics-server, ready: 2 not ready: 0
I0416 21:07:20.891759       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:20.891779       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:20.891783       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:20.900548       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-7d9cf58c5c updated.
I0416 21:07:20.900577       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:20.900572166 +0000 UTC m=+263.054296303)
I0416 21:07:20.902688       1 rolling.go:94] New replica set kube-system/metrics-server-v0.3.1-7d9cf58c5c has 1 available pods.
I0416 21:07:20.902703       1 rolling.go:169] Found 1 available pods in old RS kube-system/metrics-server-v0.3.1-677c578bdf
I0416 21:07:20.902707       1 rolling.go:140] Cleaned up unhealthy replicas from old RSes by 0
I0416 21:07:20.902742       1 rolling.go:203] Found 2 available pods in deployment metrics-server-v0.3.1, scaling down old RSes
I0416 21:07:20.907810       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (17.228752ms)
I0416 21:07:20.907893       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:20.908056       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (198.647µs)
I0416 21:07:20.909409       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (18.097311ms)
I0416 21:07:20.915588       1 replica_set.go:249] ReplicaSet metrics-server-v0.3.1-677c578bdf updated. Desired pod count change: 1->0
I0416 21:07:20.915624       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aeacab862122, ext:48883934755, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:20.915747       1 replica_set.go:516] Too many replicas for ReplicaSet kube-system/metrics-server-v0.3.1-677c578bdf, need 0, deleting 1
I0416 21:07:20.915759       1 controller_utils.go:350] Controller kube-system/metrics-server-v0.3.1-677c578bdf waiting on deletions for: [kube-system/metrics-server-v0.3.1-677c578bdf-xl48c]
I0416 21:07:20.915770       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:20.915800       1 controller_utils.go:599] Controller metrics-server-v0.3.1-677c578bdf deleting pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:07:20.916035       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-677c578bdf updated.
I0416 21:07:20.919820       1 rolling.go:148] Scaled down old RSes of deployment metrics-server-v0.3.1 by 1
I0416 21:07:20.920174       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"metrics-server-v0.3.1", UID:"c815ba23-a2bf-4fc3-b5fc-f8f3d4010eaa", APIVersion:"apps/v1", ResourceVersion:"925", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled down replica set metrics-server-v0.3.1-677c578bdf to 0
I0416 21:07:20.932265       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:07:20.934619       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (34.024892ms)
I0416 21:07:20.934658       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:20.934654246 +0000 UTC m=+263.088378385)
I0416 21:07:20.935815       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:07:20 +0000 UTC - now: 2019-04-16 21:07:20.935810121 +0000 UTC m=+263.089534260]
I0416 21:07:20.935848       1 progress.go:193] Queueing up deployment "metrics-server-v0.3.1" for a progress check after 599s
I0416 21:07:20.935867       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (1.210839ms)
I0416 21:07:20.938890       1 replica_set.go:405] Pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c deleted through k8s.io/kubernetes/pkg/controller/replicaset.(*ReplicaSetController).updatePod, timestamp 2019-04-16 21:07:50 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metrics-server-v0.3.1-677c578bdf-xl48c", GenerateName:"metrics-server-v0.3.1-677c578bdf-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c", UID:"224fe499-97c1-4296-b944-d6862030a620", ResourceVersion:"965", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045426, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc0016713e0), DeletionGracePeriodSeconds:(*int64)(0xc000c53748), Labels:map[string]string{"k8s-app":"metrics-server", "pod-template-hash":"677c578bdf", "version":"v0.3.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"metrics-server-v0.3.1-677c578bdf", UID:"eb987e4f-a31f-4799-b1ca-cc8d0261c511", Controller:(*bool)(0xc000c537b7), BlockOwnerDeletion:(*bool)(0xc000c537b8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"metrics-server-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0028fb5c0), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"metrics-server-token-q95tp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0028fb600), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metrics-server", Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", Command:[]string{"/metrics-server", "--metric-resolution=30s", "--kubelet-port=10255", "--deprecated-kubelet-completely-insecure=true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"https", HostPort:0, ContainerPort:443, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"metrics-server-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=40m", "--extra-cpu=0.5m", "--memory=40Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=metrics-server-v0.3.1", "--container=metrics-server", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001671460)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0016714a0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:314572800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"300Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:5, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"5m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000c538e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"metrics-server", DeprecatedServiceAccount:"metrics-server", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0026f0120), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000c53940)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000c53960)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc000c53968), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000c5396c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045636, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045636, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.2", StartTime:(*v1.Time)(0xc0016714e0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"metrics-server", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001671500), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", ImageID:"docker-pullable://k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b", ContainerID:"docker://ce7317f9318193fc3d113d8956ab0ca094cff76f4b9e11c7f3cbe03f7a641377"}, v1.ContainerStatus{Name:"metrics-server-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001671520), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://9e43ae4292e1acb306aceee2a9564baa3608e0be95695456c6d2da507e3424be"}}, QOSClass:"Burstable"}}.
I0416 21:07:20.939405       1 controller_utils.go:364] Controller kube-system/metrics-server-v0.3.1-677c578bdf received delete for pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:07:20.939415       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:20.939677       1 endpoints_controller.go:540] Update endpoints for kube-system/metrics-server, ready: 1 not ready: 0
I0416 21:07:20.941696       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:20.941739       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:20.941744       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:20.941975       1 replica_set_utils.go:58] Updating status for : kube-system/metrics-server-v0.3.1-677c578bdf, replicas 1->1 (need 0), fullyLabeledReplicas 1->1, readyReplicas 1->1, availableReplicas 1->1, sequence No: 1->2
I0416 21:07:20.942492       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"metrics-server-v0.3.1-677c578bdf", UID:"eb987e4f-a31f-4799-b1ca-cc8d0261c511", APIVersion:"apps/v1", ResourceVersion:"963", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:07:20.954947       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-677c578bdf updated.
I0416 21:07:20.954974       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:20.954969494 +0000 UTC m=+263.108693632)
I0416 21:07:20.957525       1 deployment_util.go:795] Deployment "metrics-server-v0.3.1" timed out (false) [last progress check: 2019-04-16 21:07:20 +0000 UTC - now: 2019-04-16 21:07:20.957495328 +0000 UTC m=+263.111219479]
I0416 21:07:20.957587       1 progress.go:193] Queueing up deployment "metrics-server-v0.3.1" for a progress check after 599s
I0416 21:07:20.957605       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (2.63289ms)
I0416 21:07:20.960307       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (20.791326ms)
I0416 21:07:20.960487       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (44.856865ms)
I0416 21:07:20.960534       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:20.960615       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:20.960709       1 replica_set_utils.go:58] Updating status for : kube-system/metrics-server-v0.3.1-677c578bdf, replicas 1->0 (need 0), fullyLabeledReplicas 1->0, readyReplicas 1->0, availableReplicas 1->0, sequence No: 2->2
I0416 21:07:20.970741       1 deployment_controller.go:280] ReplicaSet metrics-server-v0.3.1-677c578bdf updated.
I0416 21:07:20.970768       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:20.970762491 +0000 UTC m=+263.124486629)
I0416 21:07:20.975150       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (14.615378ms)
I0416 21:07:20.975208       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:20.975300       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:20.975958       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (751.812µs)
I0416 21:07:20.984714       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:07:20.987746       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (16.971273ms)
I0416 21:07:20.987796       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:20.987792298 +0000 UTC m=+263.141516436)
I0416 21:07:20.990300       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (2.496608ms)
I0416 21:07:21.159678       1 controller.go:123] Found 0 jobs
I0416 21:07:21.162455       1 controller.go:139] Found 0 cronjobs
I0416 21:07:21.162468       1 controller.go:142] Found 0 groups
I0416 21:07:21.249639       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:07:21.263243       1 daemon_controller.go:387] ControllerRevision fluentd-gcp-v3.2.0-7d69df4f7c added.
I0416 21:07:21.264449       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aedcb7bc7e28, ext:241088824081, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:21.264782       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fc82ee7, ext:263418501598, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:21.264797       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:21.264864       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:21.264870       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fc82ee7, ext:263418501598, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:21.264899       1 update.go:396] Getting unavailable numbers
I0416 21:07:21.264978       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:07:21.264985       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:21.264989       1 update.go:64] Marking pod fluentd-gcp-v3.2.0/fluentd-gcp-v3.2.0-4tl8c for deletion
I0416 21:07:21.264993       1 update.go:68] Marking old pods for deletion
I0416 21:07:21.264997       1 update.go:71] Number of unavailable DaemonSet pods: 1, is equal to or exceeds allowed maximum: 1
I0416 21:07:21.265014       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fcb947f, ext:263418724199, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:21.265023       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:21.265046       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [fluentd-gcp-v3.2.0-4tl8c], deleting 1
I0416 21:07:21.265073       1 controller_utils.go:599] Controller fluentd-gcp-v3.2.0 deleting pod kube-system/fluentd-gcp-v3.2.0-4tl8c
I0416 21:07:21.272078       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-4tl8c
I0416 21:07:21.272521       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-4tl8c updated.
I0416 21:07:21.272543       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:07:21.272594       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-4tl8c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:21.272598       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:07:21.274570       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:21.275134       1 event.go:258] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", APIVersion:"apps/v1", ResourceVersion:"971", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: fluentd-gcp-v3.2.0-4tl8c
I0416 21:07:21.286774       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (37.080177ms)
I0416 21:07:21.287997       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fcb947f, ext:263418724199, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:21.288023       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:21.290730       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:07:21.300987       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-4tl8c
I0416 21:07:21.301275       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-4tl8c updated.
I0416 21:07:21.301292       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:07:21.301333       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-4tl8c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:21.301339       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:07:21.307764       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (20.941696ms)
E0416 21:07:21.307801       1 daemon_controller.go:302] kube-system/fluentd-gcp-v3.2.0 failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"fluentd-gcp-v3.2.0", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", ResourceVersion:"971", Generation:2, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045425, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"addonmanager.kubernetes.io/mode":"Reconcile", "k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"2", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"},\"name\":\"fluentd-gcp-v3.2.0\",\"namespace\":\"kube-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"k8s-app\":\"fluentd-gcp\",\"version\":\"v3.2.0\"}},\"template\":{\"metadata\":{\"annotations\":{\"scheduler.alpha.kubernetes.io/critical-pod\":\"\"},\"labels\":{\"k8s-app\":\"fluentd-gcp\",\"kubernetes.io/cluster-service\":\"true\",\"version\":\"v3.2.0\"}},\"spec\":{\"containers\":[{\"env\":[{\"name\":\"NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"apiVersion\":\"v1\",\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"STACKDRIVER_METADATA_AGENT_URL\",\"value\":\"http://$(NODE_NAME):8799\"}],\"image\":\"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1\",\"livenessProbe\":{\"exec\":{\"command\":[\"/bin/sh\",\"-c\",\"LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300}; STUCK_THRESHOLD_SECONDS=${STUCK_THRESHOLD_SECONDS:-900}; if [ ! -e /var/log/fluentd-buffers ]; then\\n  exit 1;\\nfi; touch -d \\\"${STUCK_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-stuck; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-stuck -print -quit)\\\" ]; then\\n  rm -rf /var/log/fluentd-buffers;\\n  exit 1;\\nfi; touch -d \\\"${LIVENESS_THRESHOLD_SECONDS} seconds ago\\\" /tmp/marker-liveness; if [ -z \\\"$(find /var/log/fluentd-buffers -type d -newer /tmp/marker-liveness -print -quit)\\\" ]; then\\n  exit 1;\\nfi;\\n\"]},\"initialDelaySeconds\":600,\"periodSeconds\":60},\"name\":\"fluentd-gcp\",\"volumeMounts\":[{\"mountPath\":\"/var/log\",\"name\":\"varlog\"},{\"mountPath\":\"/var/lib/docker/containers\",\"name\":\"varlibdockercontainers\",\"readOnly\":true},{\"mountPath\":\"/etc/google-fluentd/config.d\",\"name\":\"config-volume\"}]},{\"command\":[\"/monitor\",\"--stackdriver-prefix=custom.googleapis.com/addons\",\"--api-override=https://monitoring.googleapis.com/\",\"--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count\",\"--pod-id=$(POD_NAME)\",\"--namespace-id=$(POD_NAMESPACE)\"],\"env\":[{\"name\":\"POD_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.name\"}}},{\"name\":\"POD_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}}],\"image\":\"k8s.gcr.io/prometheus-to-sd:v0.5.0\",\"name\":\"prometheus-to-sd-exporter\"}],\"dnsPolicy\":\"Default\",\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"priorityClassName\":\"system-node-critical\",\"serviceAccountName\":\"fluentd-gcp\",\"terminationGracePeriodSeconds\":60,\"tolerations\":[{\"effect\":\"NoExecute\",\"operator\":\"Exists\"},{\"effect\":\"NoSchedule\",\"operator\":\"Exists\"}],\"volumes\":[{\"hostPath\":{\"path\":\"/var/log\"},\"name\":\"varlog\"},{\"hostPath\":{\"path\":\"/var/lib/docker/containers\"},\"name\":\"varlibdockercontainers\"},{\"configMap\":{\"name\":\"fluentd-gcp-config-old-v1.2.5\"},\"name\":\"config-volume\"}]}},\"updateStrategy\":{\"type\":\"RollingUpdate\"}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00189a840), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"fluentd-gcp", "kubernetes.io/cluster-service":"true", "version":"v3.2.0"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":""}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"varlog", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc00189a860), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"varlibdockercontainers", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc00189a880), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0029453c0), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"fluentd-gcp", Image:"gcr.io/stackdriver-agents/stackdriver-logging-agent:0.6-1.6.0-1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a8a0)}, v1.EnvVar{Name:"STACKDRIVER_METADATA_AGENT_URL", Value:"http://$(NODE_NAME):8799", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:209715200, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"varlog", ReadOnly:false, MountPath:"/var/log", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"varlibdockercontainers", ReadOnly:true, MountPath:"/var/lib/docker/containers", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"config-volume", ReadOnly:false, MountPath:"/etc/google-fluentd/config.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc0026bc330), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"prometheus-to-sd-exporter", Image:"k8s.gcr.io/prometheus-to-sd:v0.5.0", Command:[]string{"/monitor", "--stackdriver-prefix=custom.googleapis.com/addons", "--api-override=https://monitoring.googleapis.com/", "--source=fluentd:http://localhost:24231?whitelisted=stackdriver_successful_requests_count,stackdriver_failed_requests_count,stackdriver_ingested_entries_count,stackdriver_dropped_entries_count", "--pod-id=$(POD_NAME)", "--namespace-id=$(POD_NAMESPACE)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a980)}, v1.EnvVar{Name:"POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00189a9c0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001184ca8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"fluentd-gcp", DeprecatedServiceAccount:"fluentd-gcp", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002888240), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc002b16de8)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc001184d20)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:2, NumberMisscheduled:0, DesiredNumberScheduled:2, NumberReady:1, ObservedGeneration:1, UpdatedNumberScheduled:2, NumberAvailable:1, NumberUnavailable:1, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "fluentd-gcp-v3.2.0": the object has been modified; please apply your changes to the latest version and try again
I0416 21:07:21.309842       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fcb947f, ext:263418724199, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:21.309876       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:21.310122       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.658855ms)
I0416 21:07:21.314835       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fcb947f, ext:263418724199, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:21.314857       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:21.315066       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.2751ms)
I0416 21:07:21.943679       1 gc_controller.go:144] GC'ing orphaned
I0416 21:07:21.948107       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:07:22.942629       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:07:23.069223       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:23.189216       1 pvc_protection_controller.go:280] Got event on pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:07:23.189406       1 replica_set.go:405] Pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c deleted through k8s.io/kubernetes/pkg/controller/replicaset.(*ReplicaSetController).updatePod, timestamp 2019-04-16 21:07:50 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metrics-server-v0.3.1-677c578bdf-xl48c", GenerateName:"metrics-server-v0.3.1-677c578bdf-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c", UID:"224fe499-97c1-4296-b944-d6862030a620", ResourceVersion:"981", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045426, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc00118e960), DeletionGracePeriodSeconds:(*int64)(0xc00265baa0), Labels:map[string]string{"k8s-app":"metrics-server", "pod-template-hash":"677c578bdf", "version":"v0.3.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"metrics-server-v0.3.1-677c578bdf", UID:"eb987e4f-a31f-4799-b1ca-cc8d0261c511", Controller:(*bool)(0xc00265bb07), BlockOwnerDeletion:(*bool)(0xc00265bb08)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"metrics-server-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc00285e840), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"metrics-server-token-q95tp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00285e880), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metrics-server", Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", Command:[]string{"/metrics-server", "--metric-resolution=30s", "--kubelet-port=10255", "--deprecated-kubelet-completely-insecure=true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"https", HostPort:0, ContainerPort:443, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"metrics-server-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=40m", "--extra-cpu=0.5m", "--memory=40Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=metrics-server-v0.3.1", "--container=metrics-server", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00118e9c0)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00118ea00)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:314572800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"300Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:5, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"5m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00265bc18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"metrics-server", DeprecatedServiceAccount:"metrics-server", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002b77f80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00265bc70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00265bc90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc00265bc98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00265bc9c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045643, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [metrics-server metrics-server-nanny]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045643, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [metrics-server metrics-server-nanny]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.2", StartTime:(*v1.Time)(0xc00118ea40), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"metrics-server", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0026fca10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", ImageID:"docker-pullable://k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b", ContainerID:"docker://ce7317f9318193fc3d113d8956ab0ca094cff76f4b9e11c7f3cbe03f7a641377"}, v1.ContainerStatus{Name:"metrics-server-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0026fca80)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://9e43ae4292e1acb306aceee2a9564baa3608e0be95695456c6d2da507e3424be"}}, QOSClass:"Burstable"}}.
I0416 21:07:23.189762       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:23.189831       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:23.189842       1 controller_utils.go:810] Ignoring inactive pod kube-system/fluentd-gcp-v3.2.0-4tl8c in state Pending, deletion time 2019-04-16 21:08:21 +0000 UTC
I0416 21:07:23.189909       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (152.131µs)
I0416 21:07:23.190087       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (101.873µs)
I0416 21:07:23.190128       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:23.190143       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:23.190147       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:24.214491       1 pvc_protection_controller.go:280] Got event on pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:07:24.214681       1 replica_set.go:405] Pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c deleted through k8s.io/kubernetes/pkg/controller/replicaset.(*ReplicaSetController).updatePod, timestamp 2019-04-16 21:07:50 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metrics-server-v0.3.1-677c578bdf-xl48c", GenerateName:"metrics-server-v0.3.1-677c578bdf-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c", UID:"224fe499-97c1-4296-b944-d6862030a620", ResourceVersion:"987", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045426, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc00117ed80), DeletionGracePeriodSeconds:(*int64)(0xc0027098f8), Labels:map[string]string{"k8s-app":"metrics-server", "pod-template-hash":"677c578bdf", "version":"v0.3.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"metrics-server-v0.3.1-677c578bdf", UID:"eb987e4f-a31f-4799-b1ca-cc8d0261c511", Controller:(*bool)(0xc002709957), BlockOwnerDeletion:(*bool)(0xc002709958)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"metrics-server-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc00285f640), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"metrics-server-token-q95tp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00285f680), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metrics-server", Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", Command:[]string{"/metrics-server", "--metric-resolution=30s", "--kubelet-port=10255", "--deprecated-kubelet-completely-insecure=true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"https", HostPort:0, ContainerPort:443, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"metrics-server-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=40m", "--extra-cpu=0.5m", "--memory=40Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=metrics-server-v0.3.1", "--container=metrics-server", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00117ede0)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00117ee20)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:314572800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"300Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:5, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"5m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002709a68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"metrics-server", DeprecatedServiceAccount:"metrics-server", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00254cea0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002709ac0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002709ae0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc002709ae8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002709aec)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045643, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [metrics-server metrics-server-nanny]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045643, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [metrics-server metrics-server-nanny]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.2", StartTime:(*v1.Time)(0xc00117ee60), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"metrics-server", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0026fd0a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", ImageID:"docker-pullable://k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b", ContainerID:"docker://ce7317f9318193fc3d113d8956ab0ca094cff76f4b9e11c7f3cbe03f7a641377"}, v1.ContainerStatus{Name:"metrics-server-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0026fd110)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://9e43ae4292e1acb306aceee2a9564baa3608e0be95695456c6d2da507e3424be"}}, QOSClass:"Burstable"}}.
I0416 21:07:24.215102       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.215183       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:24.215206       1 controller_utils.go:810] Ignoring inactive pod kube-system/fluentd-gcp-v3.2.0-4tl8c in state Pending, deletion time 2019-04-16 21:08:21 +0000 UTC
I0416 21:07:24.215387       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (288.186µs)
I0416 21:07:24.215630       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (138.803µs)
I0416 21:07:24.215712       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:24.215728       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:24.215732       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:24.255609       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-4tl8c
I0416 21:07:24.255754       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c, uid 1cb211f8-6725-4148-891a-23ab28faf75c, event type update
I0416 21:07:24.256128       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-4tl8c updated.
I0416 21:07:24.259871       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fcb947f, ext:263418724199, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.259909       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:24.260167       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (4.014943ms)
I0416 21:07:24.260221       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:07:24.260406       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-4tl8c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:24.260413       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:07:24.264885       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-4tl8c
I0416 21:07:24.264958       1 deployment_controller.go:356] Pod fluentd-gcp-v3.2.0-4tl8c deleted.
I0416 21:07:24.264983       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c, uid 1cb211f8-6725-4148-891a-23ab28faf75c, event type delete
I0416 21:07:24.265054       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-4tl8c"}
I0416 21:07:24.265166       1 daemon_controller.go:683] Pod fluentd-gcp-v3.2.0-4tl8c deleted.
I0416 21:07:24.265174       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fcb947f, ext:263418724199, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.267591       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee24fcb947f, ext:263418724199, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.267868       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee30ff74c13, ext:266421589288, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.267882       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [e2e-test-peterhornyack-minion-group-06gd], creating 1
I0416 21:07:24.269489       1 disruption.go:367] deletePod called on pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:07:24.269538       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-4tl8c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:24.269543       1 disruption.go:370] No matching pdb for pod "fluentd-gcp-v3.2.0-4tl8c"
I0416 21:07:24.297824       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-n97bf
I0416 21:07:24.297975       1 controller_utils.go:588] Controller fluentd-gcp-v3.2.0 created pod fluentd-gcp-v3.2.0-n97bf
I0416 21:07:24.298026       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:24.298041       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee30ff74c13, ext:266421589288, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.298170       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:24.298833       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-n97bf"}
I0416 21:07:24.298922       1 daemon_controller.go:506] Pod fluentd-gcp-v3.2.0-n97bf added.
I0416 21:07:24.298928       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee30ff74c13, ext:266421589288, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.298952       1 disruption.go:326] addPod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:24.298987       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:24.298991       1 disruption.go:329] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:24.299188       1 event.go:258] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", APIVersion:"apps/v1", ResourceVersion:"974", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: fluentd-gcp-v3.2.0-n97bf
I0416 21:07:24.317114       1 replica_set.go:338] Pod heapster-v1.6.0-beta.1-77858557dc-gwsdj updated, objectMeta {Name:heapster-v1.6.0-beta.1-77858557dc-gwsdj GenerateName:heapster-v1.6.0-beta.1-77858557dc- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-77858557dc-gwsdj UID:c340e6d2-d96f-4e36-b8cb-fb9423b3b61e ResourceVersion:947 Generation:0 CreationTimestamp:2019-04-16 21:07:17 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:77858557dc version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-77858557dc UID:c0f336b4-1602-41aa-88da-129d22c15197 Controller:0xc001772677 BlockOwnerDeletion:0xc001772678}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:heapster-v1.6.0-beta.1-77858557dc-gwsdj GenerateName:heapster-v1.6.0-beta.1-77858557dc- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-77858557dc-gwsdj UID:c340e6d2-d96f-4e36-b8cb-fb9423b3b61e ResourceVersion:991 Generation:0 CreationTimestamp:2019-04-16 21:07:17 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:heapster pod-template-hash:77858557dc version:v1.6.0-beta.1] Annotations:map[scheduler.alpha.kubernetes.io/critical-pod: seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:heapster-v1.6.0-beta.1-77858557dc UID:c0f336b4-1602-41aa-88da-129d22c15197 Controller:0xc002847cce BlockOwnerDeletion:0xc002847ccf}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:24.317245       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.317334       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:24.317444       1 replica_set_utils.go:58] Updating status for : kube-system/heapster-v1.6.0-beta.1-77858557dc, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:24.318029       1 endpoints_controller.go:540] Update endpoints for kube-system/heapster, ready: 2 not ready: 0
I0416 21:07:24.320132       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:24.320167       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:24.320171       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:24.320607       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-n97bf"}
I0416 21:07:24.320762       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-n97bf updated.
I0416 21:07:24.320775       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:24.320791       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:24.320808       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:24.325035       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:07:24.326083       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (60.867466ms)
I0416 21:07:24.328020       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee30ff74c13, ext:266421589288, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.328317       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee31391ac0d, ext:266482038059, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.328343       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:24.328399       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:24.328406       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee31391ac0d, ext:266482038059, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.328440       1 update.go:396] Getting unavailable numbers
I0416 21:07:24.328513       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:07:24.328519       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:24.328523       1 update.go:68] Marking old pods for deletion
I0416 21:07:24.328540       1 update.go:71] Number of unavailable DaemonSet pods: 1, is equal to or exceeds allowed maximum: 1
I0416 21:07:24.328544       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee313952a77, ext:266482266975, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.328552       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:24.328572       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:24.328592       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:24.328675       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.551856ms)
I0416 21:07:24.337867       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-77858557dc updated.
I0416 21:07:24.337895       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:24.337890153 +0000 UTC m=+266.491614290)
I0416 21:07:24.339084       1 rolling.go:94] New replica set kube-system/heapster-v1.6.0-beta.1-77858557dc has 1 available pods.
I0416 21:07:24.339094       1 rolling.go:169] Found 1 available pods in old RS kube-system/heapster-v1.6.0-beta.1-5858bf5485
I0416 21:07:24.339098       1 rolling.go:140] Cleaned up unhealthy replicas from old RSes by 0
I0416 21:07:24.339102       1 rolling.go:203] Found 2 available pods in deployment heapster-v1.6.0-beta.1, scaling down old RSes
I0416 21:07:24.344315       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (27.085405ms)
I0416 21:07:24.344374       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.344455       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:24.344539       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (176.064µs)
I0416 21:07:24.350565       1 replica_set.go:249] ReplicaSet heapster-v1.6.0-beta.1-5858bf5485 updated. Desired pod count change: 1->0
I0416 21:07:24.350597       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aeac30deea9b, ext:46973639580, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.350667       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:24.350722       1 replica_set.go:516] Too many replicas for ReplicaSet kube-system/heapster-v1.6.0-beta.1-5858bf5485, need 0, deleting 1
I0416 21:07:24.350731       1 controller_utils.go:350] Controller kube-system/heapster-v1.6.0-beta.1-5858bf5485 waiting on deletions for: [kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x]
I0416 21:07:24.350739       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.350771       1 controller_utils.go:599] Controller heapster-v1.6.0-beta.1-5858bf5485 deleting pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:07:24.350990       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-5858bf5485 updated.
I0416 21:07:24.352559       1 rolling.go:148] Scaled down old RSes of deployment heapster-v1.6.0-beta.1 by 1
I0416 21:07:24.352950       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (35.072108ms)
I0416 21:07:24.353157       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1", UID:"92819fed-de33-48a3-a4b6-c4a67aa06a5a", APIVersion:"apps/v1", ResourceVersion:"945", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled down replica set heapster-v1.6.0-beta.1-5858bf5485 to 0
I0416 21:07:24.366045       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:07:24.367146       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (29.247224ms)
I0416 21:07:24.367191       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:24.367186181 +0000 UTC m=+266.520910317)
I0416 21:07:24.368406       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:07:24 +0000 UTC - now: 2019-04-16 21:07:24.368399144 +0000 UTC m=+266.522123281]
I0416 21:07:24.368440       1 progress.go:193] Queueing up deployment "heapster-v1.6.0-beta.1" for a progress check after 599s
I0416 21:07:24.368466       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.265603ms)
I0416 21:07:24.372776       1 replica_set_utils.go:58] Updating status for : kube-system/heapster-v1.6.0-beta.1-5858bf5485, replicas 1->1 (need 0), fullyLabeledReplicas 1->1, readyReplicas 1->1, availableReplicas 1->1, sequence No: 1->2
I0416 21:07:24.373313       1 replica_set.go:405] Pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x deleted through k8s.io/kubernetes/pkg/controller/replicaset.(*ReplicaSetController).updatePod, timestamp 2019-04-16 21:07:54 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"heapster-v1.6.0-beta.1-5858bf5485-5td9x", GenerateName:"heapster-v1.6.0-beta.1-5858bf5485-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x", UID:"49a1caec-a921-453f-8c62-7a6fa815c59f", ResourceVersion:"998", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045424, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc001316920), DeletionGracePeriodSeconds:(*int64)(0xc0024a76c0), Labels:map[string]string{"k8s-app":"heapster", "pod-template-hash":"5858bf5485", "version":"v1.6.0-beta.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"heapster-v1.6.0-beta.1-5858bf5485", UID:"089fb806-c80c-46e9-aa5f-09c4c068e23a", Controller:(*bool)(0xc0024a7797), BlockOwnerDeletion:(*bool)(0xc0024a7798)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"heapster-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002acb300), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"heapster-token-qrr2n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002acb340), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"heapster", Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", Command:[]string{"/heapster", "--source=kubernetes.summary_api:''"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc001f339e0), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"heapster-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=80m", "--extra-cpu=0.5m", "--memory=140Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=heapster-v1.6.0-beta.1", "--container=heapster", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001316980)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0013169c0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024a7958), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"heapster", DeprecatedServiceAccount:"heapster", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002b68960), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024a79b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024a79d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc0024a79d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0024a79dc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045636, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045636, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.7", StartTime:(*v1.Time)(0xc001316a00), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"heapster", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001316a20), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", ImageID:"docker-pullable://k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521", ContainerID:"docker://c5d25e51980d51b3dbf19de076ba9d93e351d7cf1c8937aa49b7d98d527510e1"}, v1.ContainerStatus{Name:"heapster-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001316a40), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://8cac3ce8a693e035f6a425aaabc27f2fadd3446704c78eadd1377e1b692bb493"}}, QOSClass:"Burstable"}}.
I0416 21:07:24.373708       1 controller_utils.go:364] Controller kube-system/heapster-v1.6.0-beta.1-5858bf5485 received delete for pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:07:24.373718       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.373953       1 endpoints_controller.go:540] Update endpoints for kube-system/heapster, ready: 1 not ready: 0
I0416 21:07:24.374177       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:24.374208       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:24.374212       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:24.376602       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1-5858bf5485", UID:"089fb806-c80c-46e9-aa5f-09c4c068e23a", APIVersion:"apps/v1", ResourceVersion:"996", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:07:24.384940       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-5858bf5485 updated.
I0416 21:07:24.384966       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:24.384961962 +0000 UTC m=+266.538686099)
I0416 21:07:24.386011       1 deployment_util.go:795] Deployment "heapster-v1.6.0-beta.1" timed out (false) [last progress check: 2019-04-16 21:07:24 +0000 UTC - now: 2019-04-16 21:07:24.386004343 +0000 UTC m=+266.539728479]
I0416 21:07:24.386056       1 progress.go:193] Queueing up deployment "heapster-v1.6.0-beta.1" for a progress check after 599s
I0416 21:07:24.386068       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.103593ms)
I0416 21:07:24.389206       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (38.608245ms)
I0416 21:07:24.389425       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.389535       1 controller_utils.go:810] Ignoring inactive pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x in state Running, deletion time 2019-04-16 21:07:54 +0000 UTC
I0416 21:07:24.389551       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:24.389645       1 replica_set_utils.go:58] Updating status for : kube-system/heapster-v1.6.0-beta.1-5858bf5485, replicas 1->0 (need 0), fullyLabeledReplicas 1->0, readyReplicas 1->0, availableReplicas 1->0, sequence No: 2->2
I0416 21:07:24.390044       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (16.233257ms)
I0416 21:07:24.398192       1 deployment_controller.go:280] ReplicaSet heapster-v1.6.0-beta.1-5858bf5485 updated.
I0416 21:07:24.398241       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:24.398213768 +0000 UTC m=+266.551937907)
I0416 21:07:24.402363       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (12.956503ms)
I0416 21:07:24.402416       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:24.402500       1 controller_utils.go:810] Ignoring inactive pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x in state Running, deletion time 2019-04-16 21:07:54 +0000 UTC
I0416 21:07:24.402515       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:24.402582       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (176.624µs)
I0416 21:07:24.410761       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:07:24.412647       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (14.423045ms)
I0416 21:07:24.412681       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:24.412676728 +0000 UTC m=+266.566400869)
I0416 21:07:24.413906       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.212436ms)
I0416 21:07:24.550934       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:07:25.413295       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-n97bf updated.
I0416 21:07:25.415641       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee313952a77, ext:266482266975, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:25.415935       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee358ca9a4d, ext:267569655117, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:25.415963       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:25.415998       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:25.416003       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee358ca9a4d, ext:267569655117, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:25.416051       1 update.go:396] Getting unavailable numbers
I0416 21:07:25.416108       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:07:25.416128       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:25.416132       1 update.go:68] Marking old pods for deletion
I0416 21:07:25.416137       1 update.go:71] Number of unavailable DaemonSet pods: 1, is equal to or exceeds allowed maximum: 1
I0416 21:07:25.416141       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee358cdc7dd, ext:267569863429, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:25.416147       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:25.416165       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:25.416187       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:25.416330       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.994629ms)
I0416 21:07:25.416367       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:25.416385       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:25.416389       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:25.609455       1 wrap.go:47] GET /healthz: (105.749µs) 200 [kube-probe/1.15+ 127.0.0.1:37188]
I0416 21:07:25.810614       1 replica_set.go:338] Pod coredns-5b969f4c88-zcdpb updated, objectMeta {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:913 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc00175b2df BlockOwnerDeletion:0xc00175b3d0}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-zcdpb GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-zcdpb UID:cad6a7f7-9f47-4faf-b5a5-5dafffc6ca2d ResourceVersion:1007 Generation:0 CreationTimestamp:2019-04-16 21:03:44 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc002b18937 BlockOwnerDeletion:0xc002b18938}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:07:25.810799       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:25.810880       1 controller_utils.go:810] Ignoring inactive pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x in state Running, deletion time 2019-04-16 21:07:54 +0000 UTC
I0416 21:07:25.810892       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:25.811003       1 replica_set_utils.go:58] Updating status for : kube-system/coredns-5b969f4c88, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:07:25.811629       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 3 not ready: 0
I0416 21:07:25.812141       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:07:25.812163       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:25.812167       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:07:25.822042       1 deployment_controller.go:280] ReplicaSet coredns-5b969f4c88 updated.
I0416 21:07:25.822084       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:07:25.8220792 +0000 UTC m=+267.975803339)
I0416 21:07:25.826722       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (15.961978ms)
I0416 21:07:25.826782       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:25.826888       1 controller_utils.go:810] Ignoring inactive pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x in state Running, deletion time 2019-04-16 21:07:54 +0000 UTC
I0416 21:07:25.826904       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:25.826997       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (224.537µs)
I0416 21:07:25.827078       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (15.631572ms)
I0416 21:07:25.832654       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:07:25.833677       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (11.591051ms)
I0416 21:07:25.833717       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:07:25.833713666 +0000 UTC m=+267.987437806)
I0416 21:07:25.834667       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (948.203µs)
I0416 21:07:26.352830       1 pvc_protection_controller.go:280] Got event on pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:07:26.353045       1 replica_set.go:405] Pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x deleted through k8s.io/kubernetes/pkg/controller/replicaset.(*ReplicaSetController).updatePod, timestamp 2019-04-16 21:07:54 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"heapster-v1.6.0-beta.1-5858bf5485-5td9x", GenerateName:"heapster-v1.6.0-beta.1-5858bf5485-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x", UID:"49a1caec-a921-453f-8c62-7a6fa815c59f", ResourceVersion:"1012", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045424, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc002743000), DeletionGracePeriodSeconds:(*int64)(0xc0029261d8), Labels:map[string]string{"k8s-app":"heapster", "pod-template-hash":"5858bf5485", "version":"v1.6.0-beta.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"heapster-v1.6.0-beta.1-5858bf5485", UID:"089fb806-c80c-46e9-aa5f-09c4c068e23a", Controller:(*bool)(0xc00292620e), BlockOwnerDeletion:(*bool)(0xc00292620f)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"heapster-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002c5a380), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"heapster-token-qrr2n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002c5a3c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"heapster", Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", Command:[]string{"/heapster", "--source=kubernetes.summary_api:''"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc00250b740), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"heapster-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=80m", "--extra-cpu=0.5m", "--memory=140Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=heapster-v1.6.0-beta.1", "--container=heapster", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002743060)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0027430a0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002926378), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"heapster", DeprecatedServiceAccount:"heapster", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001f0f860), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0029263d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0029263f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc0029263f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0029263fc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045646, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [heapster heapster-nanny]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045646, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [heapster heapster-nanny]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.7", StartTime:(*v1.Time)(0xc0027430e0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"heapster", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f23960)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", ImageID:"docker-pullable://k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521", ContainerID:"docker://c5d25e51980d51b3dbf19de076ba9d93e351d7cf1c8937aa49b7d98d527510e1"}, v1.ContainerStatus{Name:"heapster-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f239d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://8cac3ce8a693e035f6a425aaabc27f2fadd3446704c78eadd1377e1b692bb493"}}, QOSClass:"Burstable"}}.
I0416 21:07:26.353548       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:26.353755       1 controller_utils.go:810] Ignoring inactive pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x in state Running, deletion time 2019-04-16 21:07:54 +0000 UTC
I0416 21:07:26.353765       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:26.353857       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (324.242µs)
I0416 21:07:26.354067       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (121.182µs)
I0416 21:07:26.354100       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:26.354129       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:26.354133       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:27.034405       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:07:27.120177       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:07:27.120278       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:07:27.216845       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:27.438468       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-n97bf updated.
I0416 21:07:27.440981       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee358cdc7dd, ext:267569863429, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:27.441354       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da4e7744, ext:269595074135, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:27.441384       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:27.441438       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:27.441444       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da4e7744, ext:269595074135, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:27.441485       1 update.go:396] Getting unavailable numbers
I0416 21:07:27.441559       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:07:27.441567       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:27.441571       1 update.go:68] Marking old pods for deletion
I0416 21:07:27.441575       1 update.go:74] Marking pod fluentd-gcp-v3.2.0/fluentd-gcp-v3.2.0-vqwbk for deletion
I0416 21:07:27.441579       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da51f28a, ext:269595302257, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:27.441586       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:27.441630       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [fluentd-gcp-v3.2.0-vqwbk], deleting 1
I0416 21:07:27.441661       1 controller_utils.go:599] Controller fluentd-gcp-v3.2.0 deleting pod kube-system/fluentd-gcp-v3.2.0-vqwbk
I0416 21:07:27.442091       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:27.442115       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:27.442119       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:27.459311       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:27.460171       1 event.go:258] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", APIVersion:"apps/v1", ResourceVersion:"993", FieldPath:""}): type: 'Normal' reason: 'SuccessfulDelete' Deleted pod: fluentd-gcp-v3.2.0-vqwbk
I0416 21:07:27.462704       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-vqwbk updated.
I0416 21:07:27.462731       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:07:27.462766       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-vqwbk, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:27.462769       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:07:27.538754       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:07:27.550763       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (112.255739ms)
I0416 21:07:27.605011       1 pvc_protection_controller.go:280] Got event on pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:07:27.614583       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da51f28a, ext:269595302257, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:27.614635       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:27.618048       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (67.199673ms)
I0416 21:07:27.621498       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x, uid 49a1caec-a921-453f-8c62-7a6fa815c59f, event type update
I0416 21:07:27.622360       1 replica_set.go:405] Pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x deleted through k8s.io/kubernetes/pkg/controller/replicaset.(*ReplicaSetController).updatePod, timestamp 2019-04-16 21:07:24 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"heapster-v1.6.0-beta.1-5858bf5485-5td9x", GenerateName:"heapster-v1.6.0-beta.1-5858bf5485-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x", UID:"49a1caec-a921-453f-8c62-7a6fa815c59f", ResourceVersion:"1016", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045424, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc002951ba0), DeletionGracePeriodSeconds:(*int64)(0xc002af2398), Labels:map[string]string{"k8s-app":"heapster", "pod-template-hash":"5858bf5485", "version":"v1.6.0-beta.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"heapster-v1.6.0-beta.1-5858bf5485", UID:"089fb806-c80c-46e9-aa5f-09c4c068e23a", Controller:(*bool)(0xc002af23ce), BlockOwnerDeletion:(*bool)(0xc002af23cf)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"heapster-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002ce1dc0), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"heapster-token-qrr2n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002ce1e00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"heapster", Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", Command:[]string{"/heapster", "--source=kubernetes.summary_api:''"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc002d4f1d0), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"heapster-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=80m", "--extra-cpu=0.5m", "--memory=140Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=heapster-v1.6.0-beta.1", "--container=heapster", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002951c20)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002951cc0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002af2538), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"heapster", DeprecatedServiceAccount:"heapster", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002d52960), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002af2590)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002af25b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc002af25b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002af25bc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045646, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [heapster heapster-nanny]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045646, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [heapster heapster-nanny]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.7", StartTime:(*v1.Time)(0xc002951d00), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"heapster", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cb49a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", ImageID:"docker-pullable://k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521", ContainerID:"docker://c5d25e51980d51b3dbf19de076ba9d93e351d7cf1c8937aa49b7d98d527510e1"}, v1.ContainerStatus{Name:"heapster-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cb4a10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://8cac3ce8a693e035f6a425aaabc27f2fadd3446704c78eadd1377e1b692bb493"}}, QOSClass:"Burstable"}}.
I0416 21:07:27.625774       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:27.625875       1 controller_utils.go:810] Ignoring inactive pod kube-system/fluentd-gcp-v3.2.0-vqwbk in state Running, deletion time 2019-04-16 21:08:27 +0000 UTC
I0416 21:07:27.625892       1 controller_utils.go:810] Ignoring inactive pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x in state Running, deletion time 2019-04-16 21:07:24 +0000 UTC
I0416 21:07:27.625898       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:27.626136       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (593.815µs)
I0416 21:07:27.627000       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (267.444µs)
I0416 21:07:27.628174       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:27.628205       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:27.628213       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:27.629964       1 pvc_protection_controller.go:280] Got event on pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x
I0416 21:07:27.645100       1 deployment_controller.go:356] Pod heapster-v1.6.0-beta.1-5858bf5485-5td9x deleted.
I0416 21:07:27.645160       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x, uid 49a1caec-a921-453f-8c62-7a6fa815c59f, event type delete
I0416 21:07:27.645440       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"kube-system", Name:"heapster-v1.6.0-beta.1-5858bf5485-5td9x"}
I0416 21:07:27.645515       1 replica_set.go:405] Pod kube-system/heapster-v1.6.0-beta.1-5858bf5485-5td9x deleted through k8s.io/kubernetes/vendor/k8s.io/client-go/tools/cache.ResourceEventHandlerFuncs.OnDelete, timestamp 2019-04-16 21:07:24 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"heapster-v1.6.0-beta.1-5858bf5485-5td9x", GenerateName:"heapster-v1.6.0-beta.1-5858bf5485-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/heapster-v1.6.0-beta.1-5858bf5485-5td9x", UID:"49a1caec-a921-453f-8c62-7a6fa815c59f", ResourceVersion:"1017", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045424, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc002d8c8c0), DeletionGracePeriodSeconds:(*int64)(0xc002af3fe0), Labels:map[string]string{"k8s-app":"heapster", "pod-template-hash":"5858bf5485", "version":"v1.6.0-beta.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"heapster-v1.6.0-beta.1-5858bf5485", UID:"089fb806-c80c-46e9-aa5f-09c4c068e23a", Controller:(*bool)(0xc0029a6047), BlockOwnerDeletion:(*bool)(0xc0029a6048)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"heapster-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc002d60f40), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"heapster-token-qrr2n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002d60f80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"heapster", Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", Command:[]string{"/heapster", "--source=kubernetes.summary_api:''"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc002d6dc80), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"heapster-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=80m", "--extra-cpu=0.5m", "--memory=140Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=heapster-v1.6.0-beta.1", "--container=heapster", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002d8c920)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002d8c960)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:50, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:94781440, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"heapster-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"heapster-token-qrr2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0029a61b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"heapster", DeprecatedServiceAccount:"heapster", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002da2240), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0029a6210)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0029a6250)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc0029a6258), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0029a625c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045646, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [heapster heapster-nanny]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045646, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [heapster heapster-nanny]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.7", StartTime:(*v1.Time)(0xc002d8c9a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"heapster", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cb5110)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/heapster-amd64:v1.6.0-beta.1", ImageID:"docker-pullable://k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521", ContainerID:"docker://c5d25e51980d51b3dbf19de076ba9d93e351d7cf1c8937aa49b7d98d527510e1"}, v1.ContainerStatus{Name:"heapster-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cb5180)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://8cac3ce8a693e035f6a425aaabc27f2fadd3446704c78eadd1377e1b692bb493"}}, QOSClass:"Burstable"}}.
I0416 21:07:27.645882       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:27.645945       1 controller_utils.go:810] Ignoring inactive pod kube-system/fluentd-gcp-v3.2.0-vqwbk in state Running, deletion time 2019-04-16 21:08:27 +0000 UTC
I0416 21:07:27.645956       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:50 +0000 UTC
I0416 21:07:27.646022       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (144.936µs)
I0416 21:07:27.646292       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (212.19µs)
I0416 21:07:27.646585       1 disruption.go:367] deletePod called on pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:27.646611       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-5858bf5485-5td9x, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:27.646615       1 disruption.go:370] No matching pdb for pod "heapster-v1.6.0-beta.1-5858bf5485-5td9x"
I0416 21:07:27.743079       1 request.go:530] Throttling request took 89.200238ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:07:27.796972       1 request.go:530] Throttling request took 143.053441ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:07:27.842870       1 request.go:530] Throttling request took 188.950094ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:07:27.893325       1 request.go:530] Throttling request took 239.401519ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:07:27.942931       1 request.go:530] Throttling request took 289.000697ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:07:27.992892       1 request.go:530] Throttling request took 338.953146ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:07:28.042914       1 request.go:530] Throttling request took 388.961285ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:07:28.242866       1 request.go:530] Throttling request took 97.632912ms, request: GET:https://localhost:443/api/v1?timeout=32s
I0416 21:07:28.292809       1 request.go:530] Throttling request took 147.567715ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1?timeout=32s
I0416 21:07:28.342808       1 request.go:530] Throttling request took 197.560835ms, request: GET:https://localhost:443/apis/apiregistration.k8s.io/v1beta1?timeout=32s
I0416 21:07:28.392846       1 request.go:530] Throttling request took 247.587905ms, request: GET:https://localhost:443/apis/extensions/v1beta1?timeout=32s
I0416 21:07:28.442867       1 request.go:530] Throttling request took 297.583748ms, request: GET:https://localhost:443/apis/apps/v1?timeout=32s
I0416 21:07:28.492910       1 request.go:530] Throttling request took 347.594067ms, request: GET:https://localhost:443/apis/apps/v1beta2?timeout=32s
I0416 21:07:28.542887       1 request.go:530] Throttling request took 397.573046ms, request: GET:https://localhost:443/apis/apps/v1beta1?timeout=32s
I0416 21:07:28.593145       1 request.go:530] Throttling request took 447.78194ms, request: GET:https://localhost:443/apis/events.k8s.io/v1beta1?timeout=32s
I0416 21:07:28.642930       1 request.go:530] Throttling request took 497.593456ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1?timeout=32s
I0416 21:07:28.692872       1 request.go:530] Throttling request took 547.547321ms, request: GET:https://localhost:443/apis/authentication.k8s.io/v1beta1?timeout=32s
I0416 21:07:28.742918       1 request.go:530] Throttling request took 597.581555ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1?timeout=32s
I0416 21:07:28.792790       1 request.go:530] Throttling request took 647.446798ms, request: GET:https://localhost:443/apis/authorization.k8s.io/v1beta1?timeout=32s
I0416 21:07:28.842878       1 request.go:530] Throttling request took 697.489821ms, request: GET:https://localhost:443/apis/autoscaling/v1?timeout=32s
I0416 21:07:28.892812       1 request.go:530] Throttling request took 747.435039ms, request: GET:https://localhost:443/apis/autoscaling/v2beta1?timeout=32s
I0416 21:07:28.942902       1 request.go:530] Throttling request took 797.519351ms, request: GET:https://localhost:443/apis/autoscaling/v2beta2?timeout=32s
I0416 21:07:28.992870       1 request.go:530] Throttling request took 847.48217ms, request: GET:https://localhost:443/apis/batch/v1?timeout=32s
I0416 21:07:29.042844       1 request.go:530] Throttling request took 897.445397ms, request: GET:https://localhost:443/apis/batch/v1beta1?timeout=32s
I0416 21:07:29.093132       1 request.go:530] Throttling request took 947.720408ms, request: GET:https://localhost:443/apis/batch/v2alpha1?timeout=32s
I0416 21:07:29.142842       1 request.go:530] Throttling request took 997.415272ms, request: GET:https://localhost:443/apis/certificates.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.192935       1 request.go:530] Throttling request took 1.047487042s, request: GET:https://localhost:443/apis/networking.k8s.io/v1?timeout=32s
I0416 21:07:29.242957       1 request.go:530] Throttling request took 1.097482872s, request: GET:https://localhost:443/apis/networking.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.292840       1 request.go:530] Throttling request took 1.147369409s, request: GET:https://localhost:443/apis/policy/v1beta1?timeout=32s
I0416 21:07:29.342837       1 request.go:530] Throttling request took 1.197360052s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1?timeout=32s
I0416 21:07:29.392845       1 request.go:530] Throttling request took 1.247358559s, request: GET:https://localhost:443/apis/rbac.authorization.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.442942       1 request.go:530] Throttling request took 1.297449704s, request: GET:https://localhost:443/apis/settings.k8s.io/v1alpha1?timeout=32s
I0416 21:07:29.492917       1 request.go:530] Throttling request took 1.347389103s, request: GET:https://localhost:443/apis/storage.k8s.io/v1?timeout=32s
I0416 21:07:29.542859       1 request.go:530] Throttling request took 1.397318944s, request: GET:https://localhost:443/apis/storage.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.592864       1 request.go:530] Throttling request took 1.447331018s, request: GET:https://localhost:443/apis/admissionregistration.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.642870       1 request.go:530] Throttling request took 1.49732649s, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.692873       1 request.go:530] Throttling request took 1.547319325s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:07:29.742886       1 request.go:530] Throttling request took 1.597322975s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.792859       1 request.go:530] Throttling request took 1.64729449s, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:07:29.842842       1 request.go:530] Throttling request took 1.69726502s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
W0416 21:07:29.995043       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:07:29.892817       1 request.go:530] Throttling request took 1.747235171s, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.942912       1 request.go:530] Throttling request took 1.797317369s, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:07:29.992862       1 request.go:530] Throttling request took 1.847254479s, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
W0416 21:07:29.995043       1 garbagecollector.go:644] failed to discover some groups: map[metrics.k8s.io/v1beta1:the server is currently unable to handle the request]
I0416 21:07:31.168330       1 controller.go:123] Found 0 jobs
I0416 21:07:31.171321       1 controller.go:139] Found 0 cronjobs
I0416 21:07:31.171334       1 controller.go:142] Found 0 groups
I0416 21:07:32.495576       1 pvc_protection_controller.go:280] Got event on pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:07:32.495695       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c, uid 224fe499-97c1-4296-b944-d6862030a620, event type update
I0416 21:07:32.495824       1 replica_set.go:405] Pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c deleted through k8s.io/kubernetes/pkg/controller/replicaset.(*ReplicaSetController).updatePod, timestamp 2019-04-16 21:07:20 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metrics-server-v0.3.1-677c578bdf-xl48c", GenerateName:"metrics-server-v0.3.1-677c578bdf-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c", UID:"224fe499-97c1-4296-b944-d6862030a620", ResourceVersion:"1028", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045426, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc002a0d440), DeletionGracePeriodSeconds:(*int64)(0xc002620f90), Labels:map[string]string{"k8s-app":"metrics-server", "pod-template-hash":"677c578bdf", "version":"v0.3.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"metrics-server-v0.3.1-677c578bdf", UID:"eb987e4f-a31f-4799-b1ca-cc8d0261c511", Controller:(*bool)(0xc002620ff7), BlockOwnerDeletion:(*bool)(0xc002620ff8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"metrics-server-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0028fb340), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"metrics-server-token-q95tp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0028fb380), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metrics-server", Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", Command:[]string{"/metrics-server", "--metric-resolution=30s", "--kubelet-port=10255", "--deprecated-kubelet-completely-insecure=true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"https", HostPort:0, ContainerPort:443, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"metrics-server-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=40m", "--extra-cpu=0.5m", "--memory=40Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=metrics-server-v0.3.1", "--container=metrics-server", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002a0d4a0)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc002a0d4e0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:314572800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"300Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:5, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"5m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002621108), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"metrics-server", DeprecatedServiceAccount:"metrics-server", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0028dc1e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002621160)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002621180)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc002621188), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00262118c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045643, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [metrics-server metrics-server-nanny]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045643, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [metrics-server metrics-server-nanny]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.2", StartTime:(*v1.Time)(0xc002a0d520), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"metrics-server", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cb5730)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", ImageID:"docker-pullable://k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b", ContainerID:"docker://ce7317f9318193fc3d113d8956ab0ca094cff76f4b9e11c7f3cbe03f7a641377"}, v1.ContainerStatus{Name:"metrics-server-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cb57a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://9e43ae4292e1acb306aceee2a9564baa3608e0be95695456c6d2da507e3424be"}}, QOSClass:"Burstable"}}.
I0416 21:07:32.496210       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:32.496461       1 controller_utils.go:810] Ignoring inactive pod kube-system/fluentd-gcp-v3.2.0-vqwbk in state Running, deletion time 2019-04-16 21:08:27 +0000 UTC
I0416 21:07:32.496487       1 controller_utils.go:810] Ignoring inactive pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c in state Running, deletion time 2019-04-16 21:07:20 +0000 UTC
I0416 21:07:32.496552       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (354.796µs)
I0416 21:07:32.496800       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (159.195µs)
I0416 21:07:32.496834       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:32.496849       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:32.496853       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:32.503808       1 pvc_protection_controller.go:280] Got event on pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c
I0416 21:07:32.503906       1 deployment_controller.go:356] Pod metrics-server-v0.3.1-677c578bdf-xl48c deleted.
I0416 21:07:32.503943       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c, uid 224fe499-97c1-4296-b944-d6862030a620, event type delete
I0416 21:07:32.504019       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"kube-system", Name:"metrics-server-v0.3.1-677c578bdf-xl48c"}
I0416 21:07:32.504104       1 replica_set.go:405] Pod kube-system/metrics-server-v0.3.1-677c578bdf-xl48c deleted through k8s.io/kubernetes/vendor/k8s.io/client-go/tools/cache.ResourceEventHandlerFuncs.OnDelete, timestamp 2019-04-16 21:07:20 +0000 UTC: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"metrics-server-v0.3.1-677c578bdf-xl48c", GenerateName:"metrics-server-v0.3.1-677c578bdf-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/metrics-server-v0.3.1-677c578bdf-xl48c", UID:"224fe499-97c1-4296-b944-d6862030a620", ResourceVersion:"1029", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045426, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(0xc0025b0440), DeletionGracePeriodSeconds:(*int64)(0xc0024a6158), Labels:map[string]string{"k8s-app":"metrics-server", "pod-template-hash":"677c578bdf", "version":"v0.3.1"}, Annotations:map[string]string{"scheduler.alpha.kubernetes.io/critical-pod":"", "seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"metrics-server-v0.3.1-677c578bdf", UID:"eb987e4f-a31f-4799-b1ca-cc8d0261c511", Controller:(*bool)(0xc0024a61b7), BlockOwnerDeletion:(*bool)(0xc0024a61b8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"metrics-server-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0028fbe80), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"metrics-server-token-q95tp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0028fbf00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"metrics-server", Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", Command:[]string{"/metrics-server", "--metric-resolution=30s", "--kubelet-port=10255", "--deprecated-kubelet-completely-insecure=true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"https", HostPort:0, ContainerPort:443, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"metrics-server-nanny", Image:"k8s.gcr.io/addon-resizer:1.8.4", Command:[]string{"/pod_nanny", "--config-dir=/etc/config", "--cpu=40m", "--extra-cpu=0.5m", "--memory=40Mi", "--extra-memory=4Mi", "--threshold=5", "--deployment=metrics-server-v0.3.1", "--container=metrics-server", "--poll-period=300000", "--estimator=exponential", "--minClusterSize=16"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"MY_POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0025b04a0)}, v1.EnvVar{Name:"MY_POD_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0025b04e0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:314572800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"300Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:5, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"5m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"metrics-server-config-volume", ReadOnly:false, MountPath:"/etc/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"metrics-server-token-q95tp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024a62c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"metrics-server", DeprecatedServiceAccount:"metrics-server", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-minion-group-06gd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0028dc8a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024a6320)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0024a6340)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc0024a6348), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0024a634c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045643, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [metrics-server metrics-server-nanny]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045643, loc:(*time.Location)(0x71c51c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [metrics-server metrics-server-nanny]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63691045612, loc:(*time.Location)(0x71c51c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.2.2", StartTime:(*v1.Time)(0xc0025b0560), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"metrics-server", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cb5ce0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/metrics-server-amd64:v0.3.1", ImageID:"docker-pullable://k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b", ContainerID:"docker://ce7317f9318193fc3d113d8956ab0ca094cff76f4b9e11c7f3cbe03f7a641377"}, v1.ContainerStatus{Name:"metrics-server-nanny", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002cb5d50)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/addon-resizer:1.8.4", ImageID:"docker-pullable://k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012", ContainerID:"docker://9e43ae4292e1acb306aceee2a9564baa3608e0be95695456c6d2da507e3424be"}}, QOSClass:"Burstable"}}.
I0416 21:07:32.504571       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:32.504649       1 controller_utils.go:810] Ignoring inactive pod kube-system/fluentd-gcp-v3.2.0-vqwbk in state Running, deletion time 2019-04-16 21:08:27 +0000 UTC
I0416 21:07:32.504744       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (178.103µs)
I0416 21:07:32.505026       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (197.543µs)
I0416 21:07:32.505061       1 disruption.go:367] deletePod called on pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:32.505077       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-677c578bdf-xl48c, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:32.505080       1 disruption.go:370] No matching pdb for pod "metrics-server-v0.3.1-677c578bdf-xl48c"
I0416 21:07:35.520977       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-vqwbk
I0416 21:07:35.521277       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-vqwbk updated.
I0416 21:07:35.522221       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da51f28a, ext:269595302257, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:35.523637       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:35.524489       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:07:35.524519       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-vqwbk, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:35.524523       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:07:35.535034       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:07:35.536770       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (15.453469ms)
I0416 21:07:35.537883       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da51f28a, ext:269595302257, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:35.537915       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:35.538104       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.301834ms)
I0416 21:07:35.608653       1 wrap.go:47] GET /healthz: (123.526µs) 200 [kube-probe/1.15+ 127.0.0.1:37224]
I0416 21:07:37.058472       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:41.125635       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-vqwbk
I0416 21:07:41.125722       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk, uid 057e795d-8687-45ce-97a0-66735522c9e6, event type update
I0416 21:07:41.125882       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-vqwbk updated.
I0416 21:07:41.126938       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:0, del:1, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da51f28a, ext:269595302257, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.126959       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:41.127150       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.251455ms)
I0416 21:07:41.127186       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:07:41.127203       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-vqwbk, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:41.127208       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:07:41.143270       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-vqwbk
I0416 21:07:41.143340       1 deployment_controller.go:356] Pod fluentd-gcp-v3.2.0-vqwbk deleted.
I0416 21:07:41.143362       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk, uid 057e795d-8687-45ce-97a0-66735522c9e6, event type delete
I0416 21:07:41.143446       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-vqwbk"}
I0416 21:07:41.143580       1 daemon_controller.go:683] Pod fluentd-gcp-v3.2.0-vqwbk deleted.
I0416 21:07:41.143588       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da51f28a, ext:269595302257, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.150807       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee3da51f28a, ext:269595302257, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.151084       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee749014c13, ext:283304804135, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.151163       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [e2e-test-peterhornyack-master], creating 1
I0416 21:07:41.151693       1 disruption.go:367] deletePod called on pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:07:41.151733       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-vqwbk, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:41.151737       1 disruption.go:370] No matching pdb for pod "fluentd-gcp-v3.2.0-vqwbk"
I0416 21:07:41.168811       1 pvc_protection_controller.go:280] Got event on pod kube-system/fluentd-gcp-v3.2.0-xtf58
I0416 21:07:41.169002       1 controller_utils.go:588] Controller fluentd-gcp-v3.2.0 created pod fluentd-gcp-v3.2.0-xtf58
I0416 21:07:41.169033       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:41.169046       1 controller_utils.go:191] Controller still waiting on expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee749014c13, ext:283304804135, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.169157       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:41.169796       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-xtf58"}
I0416 21:07:41.169876       1 daemon_controller.go:506] Pod fluentd-gcp-v3.2.0-xtf58 added.
I0416 21:07:41.169882       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee749014c13, ext:283304804135, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.169915       1 disruption.go:326] addPod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:41.169937       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:41.169940       1 disruption.go:329] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:41.170121       1 event.go:258] Event(v1.ObjectReference{Kind:"DaemonSet", Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0", UID:"4b6e545c-336f-4423-b6b1-36e6d618daf2", APIVersion:"apps/v1", ResourceVersion:"1036", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: fluentd-gcp-v3.2.0-xtf58
I0416 21:07:41.194909       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:07:41.200334       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (56.699441ms)
I0416 21:07:41.203589       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee749014c13, ext:283304804135, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.203846       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee74c26637e, ext:283357566584, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.203860       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:41.203903       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:41.203921       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee74c26637e, ext:283357566584, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.203949       1 update.go:396] Getting unavailable numbers
I0416 21:07:41.204022       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:07:41.204029       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:41.204033       1 update.go:68] Marking old pods for deletion
I0416 21:07:41.204037       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee74c29525f, ext:283357758794, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.204044       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:41.204066       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:41.204100       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:41.204177       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (3.804993ms)
I0416 21:07:41.216807       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"fluentd-gcp-v3.2.0-xtf58"}
I0416 21:07:41.217038       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-xtf58 updated.
I0416 21:07:41.218732       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee74c29525f, ext:283357758794, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.220623       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee74d264c72, ext:283374337932, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.220667       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:41.220730       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:41.220737       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee74d264c72, ext:283374337932, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.220776       1 update.go:396] Getting unavailable numbers
I0416 21:07:41.220856       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:07:41.220862       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:41.220866       1 update.go:68] Marking old pods for deletion
I0416 21:07:41.220881       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee74d2a2b86, ext:283374591599, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.220889       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:41.220917       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:41.220939       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:41.221026       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (3.972097ms)
I0416 21:07:41.223245       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:41.223281       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:41.223285       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:41.226838       1 controller.go:123] Found 0 jobs
I0416 21:07:41.237515       1 controller.go:139] Found 0 cronjobs
I0416 21:07:41.237529       1 controller.go:142] Found 0 groups
I0416 21:07:41.268413       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-xtf58 updated.
I0416 21:07:41.270607       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee74d2a2b86, ext:283374591599, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.270840       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee75024a4e4, ext:283424561126, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.270866       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:41.270905       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:41.270910       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee75024a4e4, ext:283424561126, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.270953       1 update.go:396] Getting unavailable numbers
I0416 21:07:41.271030       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 1
I0416 21:07:41.271036       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:41.271039       1 update.go:68] Marking old pods for deletion
I0416 21:07:41.271042       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee75027c2ff, ext:283424765415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:41.271049       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:41.271073       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:41.271105       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:41.271190       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.752633ms)
I0416 21:07:41.271221       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:41.273705       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:41.273715       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:41.739679       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:41.744967       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:41.948327       1 gc_controller.go:144] GC'ing orphaned
I0416 21:07:41.954742       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:07:42.034676       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:07:42.218720       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:43.029413       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:43.813934       1 daemon_controller.go:554] Pod fluentd-gcp-v3.2.0-xtf58 updated.
I0416 21:07:43.816266       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee75027c2ff, ext:283424765415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:43.820392       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee7f0e5c593, ext:285974088891, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:43.820428       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:43.820491       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:43.820499       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee7f0e5c593, ext:285974088891, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:43.820565       1 update.go:396] Getting unavailable numbers
I0416 21:07:43.820642       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:07:43.820649       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:43.820653       1 update.go:68] Marking old pods for deletion
I0416 21:07:43.820657       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee7f0ea3562, ext:285974379594, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:43.820688       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:43.820743       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:43.820770       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:43.824565       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:43.824608       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:43.824612       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:43.838506       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:07:43.838682       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (24.720487ms)
I0416 21:07:43.839841       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee7f0ea3562, ext:285974379594, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:43.840082       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee7f2129582, ext:285993802886, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:43.840110       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:43.840146       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:43.840151       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee7f2129582, ext:285993802886, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:43.841356       1 update.go:396] Getting unavailable numbers
I0416 21:07:43.841491       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:07:43.841498       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:43.841515       1 update.go:68] Marking old pods for deletion
I0416 21:07:43.841524       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee7f228925b, ext:285995243858, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:43.841539       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:43.841573       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:43.841613       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:43.841703       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.994082ms)
I0416 21:07:45.608537       1 wrap.go:47] GET /healthz: (92.438µs) 200 [kube-probe/1.15+ 127.0.0.1:37310]
I0416 21:07:45.914319       1 request.go:530] Throttling request took 83.681937ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:07:45.964328       1 request.go:530] Throttling request took 133.679031ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:07:46.013975       1 request.go:530] Throttling request took 183.302735ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:07:46.065146       1 request.go:530] Throttling request took 234.437107ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:07:46.113664       1 request.go:530] Throttling request took 282.962223ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:07:46.163531       1 request.go:530] Throttling request took 332.809579ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:07:46.213570       1 request.go:530] Throttling request took 382.810923ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:07:46.263576       1 request.go:530] Throttling request took 432.808762ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:07:46.266946       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:07:49.498370       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.498462       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:07:49.498477       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:07:49.498499       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:07:49.498494658 +0000 UTC m=+291.652218794)
I0416 21:07:49.499108       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (611.053µs)
I0416 21:07:49.499127       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:07:49.499124151 +0000 UTC m=+291.652848287)
I0416 21:07:49.499965       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (837.339µs)
I0416 21:07:49.500009       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.500031       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:07:49.500041       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:07:49.500038052 +0000 UTC m=+291.653762189)
I0416 21:07:49.500539       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (499.387µs)
I0416 21:07:49.500566       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:07:49.500571       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:07:49.500578       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:07:49.500575479 +0000 UTC m=+291.654299614)
I0416 21:07:49.500948       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (370.021µs)
I0416 21:07:49.500960       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:07:49.500958701 +0000 UTC m=+291.654682839)
I0416 21:07:49.501519       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (557.414µs)
I0416 21:07:49.501545       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:07:49.501552       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:07:49.501549792 +0000 UTC m=+291.655273930)
I0416 21:07:49.502449       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (895.413µs)
I0416 21:07:49.502489       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:07:49.502494       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:07:49.502501       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:07:49.5024983 +0000 UTC m=+291.656222439)
I0416 21:07:49.502811       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (310.847µs)
I0416 21:07:49.502819       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:07:49.502817082 +0000 UTC m=+291.656541220)
I0416 21:07:49.503409       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (568.7µs)
I0416 21:07:49.503453       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.507346       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.507539       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:07:49.507571       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.507587       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:07:49.507686       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:07:49.507699       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.507702       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:07:49.507778       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:07:49.507783       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.507786       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:07:49.507789       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:07:49.507802       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.507806       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:07:49.507849       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:07:49.507857       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.507859       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:07:49.507878       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:49.507886       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.507888       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:07:49.507931       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:07:49.507939       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.507942       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:07:49.507971       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:07:49.507980       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.507983       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:07:49.508049       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:07:49.508059       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508062       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:07:49.508109       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:07:49.508119       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508122       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:07:49.508125       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:07:49.508131       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508134       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:07:49.508183       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:49.508193       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508195       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:07:49.508266       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:49.508279       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508281       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:07:49.508309       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:07:49.508330       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508332       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:07:49.508369       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:07:49.508376       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508378       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:07:49.508417       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:07:49.508421       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508424       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:07:49.508427       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:07:49.508433       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508435       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:07:49.508458       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:49.508466       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508469       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:07:49.508520       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:07:49.508528       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508531       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:07:49.508568       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:07:49.508577       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508586       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:07:49.508606       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:07:49.508613       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:07:49.508615       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:07:49.513199       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.513293       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:07:49.514488       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee7f228925b, ext:285995243858, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.514708       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee95eadc69f, ext:291668429216, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.514734       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:49.514786       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:49.514791       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee95eadc69f, ext:291668429216, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.514833       1 update.go:396] Getting unavailable numbers
I0416 21:07:49.514927       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:07:49.514933       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:49.514937       1 update.go:68] Marking old pods for deletion
I0416 21:07:49.514940       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee95eb1581f, ext:291668663047, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.514947       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:07:49.514982       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:07:49.515003       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:49.515084       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.76939ms)
I0416 21:07:49.515144       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.515179       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:07:49.515634       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee14b741d58, ext:259345883320, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.515770       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee95ebdffae, ext:291669492388, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.515779       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:07:49.515804       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:07:49.515825       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee95ebdffae, ext:291669492388, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.515849       1 update.go:396] Getting unavailable numbers
I0416 21:07:49.515927       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:07:49.515932       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:07:49.515935       1 update.go:68] Marking old pods for deletion
I0416 21:07:49.515938       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee95ec09064, ext:291669660492, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.515945       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:07:49.515966       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:07:49.515997       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:07:49.516141       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (950.451µs)
I0416 21:07:49.517289       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.517386       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.517492       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (110.074µs)
I0416 21:07:49.517563       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.517619       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (63.952µs)
I0416 21:07:49.517629       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.517689       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (62.089µs)
I0416 21:07:49.517708       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.517775       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (69.07µs)
I0416 21:07:49.517794       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.517844       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (51.887µs)
I0416 21:07:49.517863       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.517899       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (38.16µs)
I0416 21:07:49.517926       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.517968       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (42.949µs)
I0416 21:07:49.517985       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.518038       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (54.805µs)
I0416 21:07:49.518054       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.518102       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (47.837µs)
I0416 21:07:49.518115       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:07:49.518148       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (34.139µs)
I0416 21:07:49.520420       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.698106       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:49.727384       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:50.069432       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:50.069519       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:07:50.069586       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.797µs)
I0416 21:07:50.069624       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:07:50.069644       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (449ns)
I0416 21:07:50.119870       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:07:51.241432       1 controller.go:123] Found 0 jobs
I0416 21:07:51.243863       1 controller.go:139] Found 0 cronjobs
I0416 21:07:51.243887       1 controller.go:142] Found 0 groups
I0416 21:07:53.018082       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:07:55.608902       1 wrap.go:47] GET /healthz: (84.339µs) 200 [kube-probe/1.15+ 127.0.0.1:37402]
I0416 21:07:57.034931       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:07:57.124760       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:07:57.219038       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:08:00.095719       1 request.go:530] Throttling request took 83.603741ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:08:00.145786       1 request.go:530] Throttling request took 133.658899ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:08:00.195674       1 request.go:530] Throttling request took 183.544051ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:08:00.245931       1 request.go:530] Throttling request took 233.77646ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:08:00.295747       1 request.go:530] Throttling request took 283.554582ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:08:00.345693       1 request.go:530] Throttling request took 333.51942ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:08:00.395616       1 request.go:530] Throttling request took 383.446106ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:08:00.445740       1 request.go:530] Throttling request took 433.553514ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:08:01.247683       1 controller.go:123] Found 0 jobs
I0416 21:08:01.250097       1 controller.go:139] Found 0 cronjobs
I0416 21:08:01.250109       1 controller.go:142] Found 0 groups
I0416 21:08:01.955062       1 gc_controller.go:144] GC'ing orphaned
I0416 21:08:01.959537       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:08:02.979521       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:08:05.608513       1 wrap.go:47] GET /healthz: (90.278µs) 200 [kube-probe/1.15+ 127.0.0.1:37436]
I0416 21:08:11.254190       1 controller.go:123] Found 0 jobs
I0416 21:08:11.256856       1 controller.go:139] Found 0 cronjobs
I0416 21:08:11.256867       1 controller.go:142] Found 0 groups
I0416 21:08:11.739989       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:08:11.740149       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (4.518µs)
I0416 21:08:11.740484       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 3 not ready: 0
I0416 21:08:11.740931       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (132.634µs)
I0416 21:08:11.741002       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (50.605µs)
I0416 21:08:11.741053       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (44.55µs)
I0416 21:08:11.741166       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (87.038µs)
I0416 21:08:11.747168       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (6.900221ms)
I0416 21:08:11.747615       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:08:12.035260       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:08:12.219354       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:08:15.608469       1 wrap.go:47] GET /healthz: (96.628µs) 200 [kube-probe/1.15+ 127.0.0.1:37468]
I0416 21:08:16.367384       1 request.go:530] Throttling request took 91.845387ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:08:16.417387       1 request.go:530] Throttling request took 141.855275ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:08:16.468775       1 request.go:530] Throttling request took 193.213618ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:08:16.517463       1 request.go:530] Throttling request took 241.909368ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:08:16.567442       1 request.go:530] Throttling request took 291.874982ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:08:16.617451       1 request.go:530] Throttling request took 341.860119ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:08:16.667495       1 request.go:530] Throttling request took 391.899878ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:08:16.717458       1 request.go:530] Throttling request took 441.852027ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:08:16.720034       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:08:21.261066       1 controller.go:123] Found 0 jobs
I0416 21:08:21.263751       1 controller.go:139] Found 0 cronjobs
I0416 21:08:21.263763       1 controller.go:142] Found 0 groups
I0416 21:08:21.959896       1 gc_controller.go:144] GC'ing orphaned
I0416 21:08:21.964218       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:08:24.651053       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:08:25.608570       1 wrap.go:47] GET /healthz: (90.053µs) 200 [kube-probe/1.15+ 127.0.0.1:37502]
I0416 21:08:27.035574       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:08:27.126684       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:08:27.219688       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:08:30.548498       1 request.go:530] Throttling request took 92.08567ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:08:30.598495       1 request.go:530] Throttling request took 142.078111ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:08:30.648450       1 request.go:530] Throttling request took 192.009681ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:08:30.698477       1 request.go:530] Throttling request took 242.023081ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:08:30.748509       1 request.go:530] Throttling request took 292.048247ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:08:30.798499       1 request.go:530] Throttling request took 342.02744ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:08:30.848537       1 request.go:530] Throttling request took 392.051656ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:08:30.898653       1 request.go:530] Throttling request took 442.162087ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:08:31.267642       1 controller.go:123] Found 0 jobs
I0416 21:08:31.269855       1 controller.go:139] Found 0 cronjobs
I0416 21:08:31.269867       1 controller.go:142] Found 0 groups
I0416 21:08:35.608555       1 wrap.go:47] GET /healthz: (78.664µs) 200 [kube-probe/1.15+ 127.0.0.1:37536]
I0416 21:08:41.273465       1 controller.go:123] Found 0 jobs
I0416 21:08:41.275860       1 controller.go:139] Found 0 cronjobs
I0416 21:08:41.275881       1 controller.go:142] Found 0 groups
I0416 21:08:41.740304       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:08:41.747883       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:08:41.964943       1 gc_controller.go:144] GC'ing orphaned
I0416 21:08:41.968889       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:08:42.036198       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:08:42.220019       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:08:42.557640       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:08:45.617044       1 wrap.go:47] GET /healthz: (92.835µs) 200 [kube-probe/1.15+ 127.0.0.1:37592]
I0416 21:08:45.768384       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:08:45.773896       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 21:08:46.820530       1 request.go:530] Throttling request took 92.860547ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:08:46.870492       1 request.go:530] Throttling request took 142.811975ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:08:46.920587       1 request.go:530] Throttling request took 192.887525ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:08:46.970526       1 request.go:530] Throttling request took 242.82005ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:08:47.020680       1 request.go:530] Throttling request took 292.974246ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:08:47.070502       1 request.go:530] Throttling request took 342.795755ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:08:47.120532       1 request.go:530] Throttling request took 392.811148ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:08:47.170565       1 request.go:530] Throttling request took 442.838546ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:08:47.172877       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:08:49.970729       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 21:08:51.280078       1 controller.go:123] Found 0 jobs
I0416 21:08:51.282497       1 controller.go:139] Found 0 cronjobs
I0416 21:08:51.282507       1 controller.go:142] Found 0 groups
I0416 21:08:53.135607       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:08:54.819868       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 54 items received
I0416 21:08:55.608748       1 wrap.go:47] GET /healthz: (72.484µs) 200 [kube-probe/1.15+ 127.0.0.1:37628]
I0416 21:08:57.036520       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:08:57.128672       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:08:57.220273       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:01.001286       1 request.go:530] Throttling request took 91.707675ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:09:01.051319       1 request.go:530] Throttling request took 141.723754ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:09:01.101215       1 request.go:530] Throttling request took 191.626524ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:09:01.151802       1 request.go:530] Throttling request took 242.189297ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:09:01.201240       1 request.go:530] Throttling request took 291.607863ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:09:01.251344       1 request.go:530] Throttling request took 341.707462ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:09:01.286468       1 controller.go:123] Found 0 jobs
I0416 21:09:01.288856       1 controller.go:139] Found 0 cronjobs
I0416 21:09:01.288891       1 controller.go:142] Found 0 groups
I0416 21:09:01.301331       1 request.go:530] Throttling request took 391.689005ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:09:01.351554       1 request.go:530] Throttling request took 441.906627ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:09:01.969172       1 gc_controller.go:144] GC'ing orphaned
I0416 21:09:01.973269       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:09:02.985287       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:09:05.608512       1 wrap.go:47] GET /healthz: (87.908µs) 200 [kube-probe/1.15+ 127.0.0.1:37662]
I0416 21:09:05.769974       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 21:09:06.671528       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:09:11.293026       1 controller.go:123] Found 0 jobs
I0416 21:09:11.295309       1 controller.go:139] Found 0 cronjobs
I0416 21:09:11.295320       1 controller.go:142] Found 0 groups
I0416 21:09:11.740655       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:11.748449       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:12.036832       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:09:12.220587       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:15.608524       1 wrap.go:47] GET /healthz: (93.784µs) 200 [kube-probe/1.15+ 127.0.0.1:37694]
I0416 21:09:17.273939       1 request.go:530] Throttling request took 95.702073ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:09:17.323399       1 request.go:530] Throttling request took 145.157395ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:09:17.373447       1 request.go:530] Throttling request took 195.179175ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:09:17.423479       1 request.go:530] Throttling request took 245.215924ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:09:17.473387       1 request.go:530] Throttling request took 292.303332ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:09:17.523407       1 request.go:530] Throttling request took 342.30621ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:09:17.573591       1 request.go:530] Throttling request took 392.418638ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:09:17.624656       1 request.go:530] Throttling request took 443.502977ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:09:17.627283       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:09:19.310553       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 3 items received
I0416 21:09:21.299222       1 controller.go:123] Found 0 jobs
I0416 21:09:21.301836       1 controller.go:139] Found 0 cronjobs
I0416 21:09:21.301849       1 controller.go:142] Found 0 groups
I0416 21:09:21.770942       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 115 items received
I0416 21:09:21.974024       1 gc_controller.go:144] GC'ing orphaned
I0416 21:09:21.979518       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:09:24.767086       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:09:25.608571       1 wrap.go:47] GET /healthz: (89.275µs) 200 [kube-probe/1.15+ 127.0.0.1:37728]
I0416 21:09:27.037140       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:09:27.130612       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:09:27.220898       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:28.815964       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 8 items received
I0416 21:09:31.305980       1 controller.go:123] Found 0 jobs
I0416 21:09:31.308817       1 controller.go:139] Found 0 cronjobs
I0416 21:09:31.308828       1 controller.go:142] Found 0 groups
I0416 21:09:31.454333       1 request.go:530] Throttling request took 92.105714ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:09:31.504346       1 request.go:530] Throttling request took 142.095495ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:09:31.554299       1 request.go:530] Throttling request took 192.021442ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:09:31.604309       1 request.go:530] Throttling request took 242.017699ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:09:31.654217       1 request.go:530] Throttling request took 291.922584ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:09:31.704293       1 request.go:530] Throttling request took 341.984355ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:09:31.754266       1 request.go:530] Throttling request took 391.930538ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:09:31.804255       1 request.go:530] Throttling request took 441.91459ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:09:32.761200       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 182 items received
I0416 21:09:34.021868       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 21:09:35.608529       1 wrap.go:47] GET /healthz: (85.646µs) 200 [kube-probe/1.15+ 127.0.0.1:37762]
I0416 21:09:35.784979       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 5 items received
I0416 21:09:41.087125       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 21:09:41.313701       1 controller.go:123] Found 0 jobs
I0416 21:09:41.316116       1 controller.go:139] Found 0 cronjobs
I0416 21:09:41.316127       1 controller.go:142] Found 0 groups
I0416 21:09:41.740973       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:41.748881       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:41.979830       1 gc_controller.go:144] GC'ing orphaned
I0416 21:09:41.984375       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:09:42.037807       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:09:42.221166       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:43.776881       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:09:45.608563       1 wrap.go:47] GET /healthz: (90.093µs) 200 [kube-probe/1.15+ 127.0.0.1:37814]
I0416 21:09:47.727679       1 request.go:530] Throttling request took 92.574131ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:09:47.777964       1 request.go:530] Throttling request took 142.858996ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:09:47.827684       1 request.go:530] Throttling request took 192.564822ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:09:47.877654       1 request.go:530] Throttling request took 242.514973ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:09:47.927732       1 request.go:530] Throttling request took 292.569434ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:09:47.978361       1 request.go:530] Throttling request took 343.194642ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:09:48.027688       1 request.go:530] Throttling request took 392.506804ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:09:48.077630       1 request.go:530] Throttling request took 442.45123ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:09:48.079991       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:09:51.319983       1 controller.go:123] Found 0 jobs
I0416 21:09:51.321936       1 controller.go:139] Found 0 cronjobs
I0416 21:09:51.321947       1 controller.go:142] Found 0 groups
W0416 21:09:54.551214       1 actual_state_of_world.go:503] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="e2e-test-peterhornyack-windows-node-group-31ht" does not exist
I0416 21:09:53.246018       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:09:54.090023       1 certificate_controller.go:77] Adding certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:09:54.090099       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (7.731µs)
I0416 21:09:54.090152       1 certificate_controller.go:77] Adding certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:09:54.099261       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:09:54.105027       1 log.go:172] [INFO] signed certificate with serial number 602428086936139915885919137051240194840987961119
I0416 21:09:54.105648       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:09:54.105761       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (15.594273ms)
I0416 21:09:54.105791       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (8.425µs)
I0416 21:09:54.111159       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (11.862138ms)
I0416 21:09:54.111390       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:09:54.111414       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (1.838µs)
I0416 21:09:54.111469       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:09:54.111482       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (450ns)
I0416 21:09:54.549471       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:54.549525       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:54.550747       1 taint_manager.go:441] Noticed node update: scheduler.nodeUpdateItem{nodeName:"e2e-test-peterhornyack-windows-node-group-31ht"}
I0416 21:09:54.550762       1 taint_manager.go:446] Updating known taints on node e2e-test-peterhornyack-windows-node-group-31ht: []
I0416 21:09:54.551200       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
W0416 21:09:54.551214       1 actual_state_of_world.go:503] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="e2e-test-peterhornyack-windows-node-group-31ht" does not exist
I0416 21:09:54.553493       1 cloud_cidr_allocator.go:237] Putting node e2e-test-peterhornyack-windows-node-group-31ht into the work queue
I0416 21:09:54.571173       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:54.571202       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:54.571246       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:54.571269       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:54.571382       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:09:54.571417       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-windows-node-group-31ht is already in a process of CIDR assignment.
I0416 21:09:54.576500       1 ttl_controller.go:271] Changed ttl annotation for node e2e-test-peterhornyack-windows-node-group-31ht to 0 seconds
I0416 21:09:54.581830       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:54.581859       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:54.581886       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:54.581923       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:54.582075       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:09:54.582192       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-windows-node-group-31ht is already in a process of CIDR assignment.
I0416 21:09:54.584274       1 controller_utils.go:200] Added [&Taint{Key:node.kubernetes.io/network-unavailable,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:09:54.551039445 +0000 UTC m=+416.704763722,}] Taint to Node e2e-test-peterhornyack-windows-node-group-31ht
I0416 21:09:54.584323       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-windows-node-group-31ht has no [] Taint
I0416 21:09:54.830038       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 22:09:54.553545058 +0000 UTC m=+4016.707269198 [59m59.723498004s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc0028a70a0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc0014469a0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0011766c0] Scheduling:0xc001446a80 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc002b0ad20] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc002b0acc0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:09:54 GMT] Etag:["PhgXEu4QpVYLYQG6-uT2Fww4ATg=/gf3u99yU-uz1x-W21K1tDcEoE9c="] Expires:[Tue, 16 Apr 2019 21:09:54 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
W0416 21:09:57.133187       1 node_lifecycle_controller.go:831] Missing timestamp for Node e2e-test-peterhornyack-windows-node-group-31ht. Assuming now as a timestamp.
I0416 21:09:55.081611       1 gen.go:9971] GCEBetaInstances.Get(context.Background.WithDeadline(2019-04-16 22:09:54.553537696 +0000 UTC m=+4016.707261870 [59m59.471915195s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{AllocationAffinity:<nil> CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc0028a7420] DisplayDevice:<nil> GuestAccelerators:[] Hostname: Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc001446af0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176780] Scheduling:0xc001446bd0 SelfLink:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc002b0b0e0] ShieldedVmConfig:<nil> ShieldedVmIntegrityPolicy:<nil> StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc002b0b080 Zone:https://www.googleapis.com/compute/beta/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 21:09:55 GMT] Etag:["JvDng9bLuaNjRoD8RuMEZEowqhY=/hTQQyPnFqoqPIAZkyJLYmrqSWCk="] Expires:[Tue, 16 Apr 2019 21:09:55 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 21:09:55.098578       1 cloud_cidr_allocator.go:282] Set node e2e-test-peterhornyack-windows-node-group-31ht PodCIDR to 10.64.1.0/24
I0416 21:09:55.099148       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:55.099177       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:55.099215       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:55.099261       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:55.099450       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:09:55.099479       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-windows-node-group-31ht is already in a process of CIDR assignment.
I0416 21:09:55.119697       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:55.119729       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:55.119760       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:55.119785       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:55.119991       1 controller_utils.go:200] Added [] Taint to Node e2e-test-peterhornyack-windows-node-group-31ht
I0416 21:09:55.126260       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:09:55.126354       1 cloud_cidr_allocator.go:233] Node e2e-test-peterhornyack-windows-node-group-31ht is already in a process of CIDR assignment.
I0416 21:09:55.126592       1 cloud_cidr_allocator.go:159] Updated CIDR for "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:09:55.154726       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-windows-node-group-31ht has no [&Taint{Key:node.kubernetes.io/network-unavailable,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 21:09:54 +0000 UTC,}] Taint
I0416 21:09:55.155082       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:55.155130       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:09:55.155157       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:55.155196       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:09:55.155387       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:09:55.609162       1 wrap.go:47] GET /healthz: (144.577µs) 200 [kube-probe/1.15+ 127.0.0.1:37852]
I0416 21:09:55.633262       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:09:55.633293       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:09:55.633287411 +0000 UTC m=+417.787011562)
I0416 21:09:55.641850       1 replica_set.go:249] ReplicaSet coredns-5b969f4c88 updated. Desired pod count change: 1->2
I0416 21:09:55.641897       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25aeac1b69a490, ext:46613632394, loc:(*time.Location)(0x71c51c0)}}
I0416 21:09:55.642060       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:09:55.642075       1 replica_set.go:477] Too few replicas for ReplicaSet kube-system/coredns-5b969f4c88, need 2, creating 1
I0416 21:09:55.642682       1 deployment_controller.go:280] ReplicaSet coredns-5b969f4c88 updated.
I0416 21:09:55.645887       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"kube-system", Name:"coredns", UID:"91d7e558-6fbf-44e2-84e7-9a55f0101e58", APIVersion:"apps/v1", ResourceVersion:"1317", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set coredns-5b969f4c88 to 2
I0416 21:09:55.654293       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:09:55.656863       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (23.564389ms)
I0416 21:09:55.656915       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:09:55.656911076 +0000 UTC m=+417.810635227)
I0416 21:09:55.667979       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:09:55.670649       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (13.724775ms)
I0416 21:09:55.670684       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:09:55.670679206 +0000 UTC m=+417.824403342)
I0416 21:09:55.671830       1 progress.go:193] Queueing up deployment "coredns" for a progress check after 449s
I0416 21:09:55.671851       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (1.168989ms)
I0416 21:09:55.674387       1 pvc_protection_controller.go:280] Got event on pod kube-system/coredns-5b969f4c88-6mpws
I0416 21:09:55.674529       1 controller_utils.go:588] Controller coredns-5b969f4c88 created pod coredns-5b969f4c88-6mpws
I0416 21:09:55.674610       1 replica_set_utils.go:58] Updating status for : kube-system/coredns-5b969f4c88, replicas 1->1 (need 2), fullyLabeledReplicas 1->1, readyReplicas 1->1, availableReplicas 1->1, sequence No: 1->2
I0416 21:09:55.674974       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"coredns-5b969f4c88-6mpws"}
I0416 21:09:55.675019       1 replica_set.go:275] Pod coredns-5b969f4c88-6mpws created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"coredns-5b969f4c88-6mpws", GenerateName:"coredns-5b969f4c88-", Namespace:"kube-system", SelfLink:"/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws", UID:"f98356f4-4e7b-4ce7-8a8f-f1971aa4e268", ResourceVersion:"1321", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691045795, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-dns", "pod-template-hash":"5b969f4c88"}, Annotations:map[string]string{"seccomp.security.alpha.kubernetes.io/pod":"docker/default"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"coredns-5b969f4c88", UID:"791055b4-f507-415a-8d87-24932eef483f", Controller:(*bool)(0xc001437a17), BlockOwnerDeletion:(*bool)(0xc001437a18)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc00170d080), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"coredns-token-8zsdf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00170d0c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"coredns", Image:"k8s.gcr.io/coredns:1.3.1", Command:[]string(nil), Args:[]string{"-conf", "/etc/coredns/Corefile"}, WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"dns", HostPort:0, ContainerPort:53, Protocol:"UDP", HostIP:""}, v1.ContainerPort{Name:"dns-tcp", HostPort:0, ContainerPort:53, Protocol:"TCP", HostIP:""}, v1.ContainerPort{Name:"metrics", HostPort:0, ContainerPort:9153, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:178257920, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"170Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:73400320, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"70Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"config-volume", ReadOnly:true, MountPath:"/etc/coredns", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"coredns-token-8zsdf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc000f55a70), ReadinessProbe:(*v1.Probe)(0xc000f55aa0), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc001450230), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001437d78), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"Default", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"coredns", DeprecatedServiceAccount:"coredns", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002b4d9e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001437dc0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001437de0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-cluster-critical", Priority:(*int32)(0xc001437de8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001437dec)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:09:55.675355       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:09:55.675722       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 3 not ready: 0
I0416 21:09:55.675939       1 disruption.go:326] addPod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:09:55.675975       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:09:55.675979       1 disruption.go:329] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:09:55.676181       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"kube-system", Name:"coredns-5b969f4c88", UID:"791055b4-f507-415a-8d87-24932eef483f", APIVersion:"apps/v1", ResourceVersion:"1318", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: coredns-5b969f4c88-6mpws
I0416 21:09:55.689624       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"kube-system", Name:"coredns-5b969f4c88-6mpws"}
I0416 21:09:55.689756       1 replica_set.go:338] Pod coredns-5b969f4c88-6mpws updated, objectMeta {Name:coredns-5b969f4c88-6mpws GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws UID:f98356f4-4e7b-4ce7-8a8f-f1971aa4e268 ResourceVersion:1321 Generation:0 CreationTimestamp:2019-04-16 21:09:55 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc001437a17 BlockOwnerDeletion:0xc001437a18}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-6mpws GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws UID:f98356f4-4e7b-4ce7-8a8f-f1971aa4e268 ResourceVersion:1322 Generation:0 CreationTimestamp:2019-04-16 21:09:55 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc00134793f BlockOwnerDeletion:0xc001347970}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:09:55.689991       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:09:55.690005       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:09:55.690009       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:09:55.696103       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (20.652141ms)
I0416 21:09:55.696433       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 3 not ready: 0
I0416 21:09:55.698954       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (57.059342ms)
I0416 21:09:55.699008       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:09:55.699161       1 replica_set_utils.go:58] Updating status for : kube-system/coredns-5b969f4c88, replicas 1->2 (need 2), fullyLabeledReplicas 1->2, readyReplicas 1->1, availableReplicas 1->1, sequence No: 2->2
I0416 21:09:55.699525       1 deployment_controller.go:280] ReplicaSet coredns-5b969f4c88 updated.
I0416 21:09:55.699546       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:09:55.69954077 +0000 UTC m=+417.853264920)
I0416 21:09:55.702919       1 progress.go:193] Queueing up deployment "coredns" for a progress check after 449s
I0416 21:09:55.702958       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (3.414136ms)
I0416 21:09:55.710988       1 deployment_controller.go:280] ReplicaSet coredns-5b969f4c88 updated.
I0416 21:09:55.711014       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:09:55.711008633 +0000 UTC m=+417.864732784)
I0416 21:09:55.716818       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (17.808929ms)
I0416 21:09:55.716866       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:09:55.716999       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (144.709µs)
I0416 21:09:55.720759       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (24.588911ms)
I0416 21:09:55.724762       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:09:55.729105       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (18.081931ms)
I0416 21:09:55.729144       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:09:55.72913975 +0000 UTC m=+417.882863901)
I0416 21:09:55.730035       1 progress.go:193] Queueing up deployment "coredns" for a progress check after 449s
I0416 21:09:55.730049       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (907.3µs)
I0416 21:09:55.733521       1 replica_set.go:338] Pod coredns-5b969f4c88-6mpws updated, objectMeta {Name:coredns-5b969f4c88-6mpws GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws UID:f98356f4-4e7b-4ce7-8a8f-f1971aa4e268 ResourceVersion:1322 Generation:0 CreationTimestamp:2019-04-16 21:09:55 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc00134793f BlockOwnerDeletion:0xc001347970}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-6mpws GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws UID:f98356f4-4e7b-4ce7-8a8f-f1971aa4e268 ResourceVersion:1326 Generation:0 CreationTimestamp:2019-04-16 21:09:55 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc000495a0f BlockOwnerDeletion:0xc000495a50}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:09:55.733648       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:09:55.733835       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (207.169µs)
I0416 21:09:55.733915       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:09:55.733929       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:09:55.733933       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:09:57.038170       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:09:57.133022       1 node_lifecycle_controller.go:642] Controller observed a new Node: "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:09:57.133043       1 controller_utils.go:164] Recording Registered Node e2e-test-peterhornyack-windows-node-group-31ht in Controller event message for node e2e-test-peterhornyack-windows-node-group-31ht
I0416 21:09:57.133160       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
W0416 21:09:57.133187       1 node_lifecycle_controller.go:831] Missing timestamp for Node e2e-test-peterhornyack-windows-node-group-31ht. Assuming now as a timestamp.
I0416 21:09:57.133624       1 event.go:258] Event(v1.ObjectReference{Kind:"Node", Namespace:"", Name:"e2e-test-peterhornyack-windows-node-group-31ht", UID:"325e885e-93b9-49cf-a8e7-93c860eaa6c3", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RegisteredNode' Node e2e-test-peterhornyack-windows-node-group-31ht event: Registered Node e2e-test-peterhornyack-windows-node-group-31ht in Controller
I0416 21:09:57.221446       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:09:57.694627       1 replica_set.go:338] Pod coredns-5b969f4c88-6mpws updated, objectMeta {Name:coredns-5b969f4c88-6mpws GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws UID:f98356f4-4e7b-4ce7-8a8f-f1971aa4e268 ResourceVersion:1326 Generation:0 CreationTimestamp:2019-04-16 21:09:55 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc000495a0f BlockOwnerDeletion:0xc000495a50}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-6mpws GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws UID:f98356f4-4e7b-4ce7-8a8f-f1971aa4e268 ResourceVersion:1330 Generation:0 CreationTimestamp:2019-04-16 21:09:55 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc000276b2f BlockOwnerDeletion:0xc000276b80}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:09:57.694764       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:09:57.694975       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (226.001µs)
I0416 21:09:57.695873       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 3 not ready: 3
I0416 21:09:57.696254       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:09:57.696276       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:09:57.696280       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:09:57.701746       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (6.678867ms)
I0416 21:10:01.326029       1 controller.go:123] Found 0 jobs
I0416 21:10:01.328434       1 controller.go:139] Found 0 cronjobs
I0416 21:10:01.328445       1 controller.go:142] Found 0 groups
I0416 21:10:01.841446       1 replica_set.go:338] Pod coredns-5b969f4c88-6mpws updated, objectMeta {Name:coredns-5b969f4c88-6mpws GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws UID:f98356f4-4e7b-4ce7-8a8f-f1971aa4e268 ResourceVersion:1330 Generation:0 CreationTimestamp:2019-04-16 21:09:55 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc000276b2f BlockOwnerDeletion:0xc000276b80}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:coredns-5b969f4c88-6mpws GenerateName:coredns-5b969f4c88- Namespace:kube-system SelfLink:/api/v1/namespaces/kube-system/pods/coredns-5b969f4c88-6mpws UID:f98356f4-4e7b-4ce7-8a8f-f1971aa4e268 ResourceVersion:1339 Generation:0 CreationTimestamp:2019-04-16 21:09:55 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[k8s-app:kube-dns pod-template-hash:5b969f4c88] Annotations:map[seccomp.security.alpha.kubernetes.io/pod:docker/default] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:coredns-5b969f4c88 UID:791055b4-f507-415a-8d87-24932eef483f Controller:0xc000b9693f BlockOwnerDeletion:0xc000b96970}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:10:01.841555       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:10:01.841774       1 replica_set_utils.go:58] Updating status for : kube-system/coredns-5b969f4c88, replicas 2->2 (need 2), fullyLabeledReplicas 2->2, readyReplicas 1->2, availableReplicas 1->2, sequence No: 2->2
I0416 21:10:01.844688       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:10:01.846687       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:10:01.846729       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:10:01.846747       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:10:01.854722       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (13.162861ms)
I0416 21:10:01.854924       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:10:01.855090       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (175.18µs)
I0416 21:10:01.855179       1 deployment_controller.go:280] ReplicaSet coredns-5b969f4c88 updated.
I0416 21:10:01.855218       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:10:01.855206093 +0000 UTC m=+424.008930231)
I0416 21:10:01.861018       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (17.825402ms)
I0416 21:10:01.870607       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:10:01.872154       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (16.926427ms)
I0416 21:10:01.872191       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:10:01.87218709 +0000 UTC m=+424.025911227)
I0416 21:10:01.873195       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (1.001946ms)
I0416 21:10:01.907463       1 request.go:530] Throttling request took 90.981799ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:10:01.957455       1 request.go:530] Throttling request took 140.969434ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:10:01.984925       1 gc_controller.go:144] GC'ing orphaned
I0416 21:10:01.990069       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:10:02.007835       1 request.go:530] Throttling request took 191.228398ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:10:02.058027       1 request.go:530] Throttling request took 241.506815ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:10:02.107432       1 request.go:530] Throttling request took 290.904891ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:10:02.157459       1 request.go:530] Throttling request took 340.905706ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:10:02.207698       1 request.go:530] Throttling request took 391.12098ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:10:02.257458       1 request.go:530] Throttling request took 440.870591ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:10:02.522161       1 wrap.go:47] GET /healthz: (112.908µs) 200 [kube-probe/1.15+ 127.0.0.1:37880]
I0416 21:10:02.778997       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:10:02.843548       1 wrap.go:47] GET /healthz: (118.857µs) 200 [kube-probe/1.15+ 127.0.0.1:37890]
I0416 21:10:03.988001       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:10:05.609030       1 wrap.go:47] GET /healthz: (128.867µs) 200 [kube-probe/1.15+ 127.0.0.1:37902]
I0416 21:10:05.791482       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 1 items received
I0416 21:10:07.763470       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 21:10:09.767366       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 21:10:11.332007       1 controller.go:123] Found 0 jobs
I0416 21:10:11.334117       1 controller.go:139] Found 0 cronjobs
I0416 21:10:11.334128       1 controller.go:142] Found 0 groups
I0416 21:10:11.741310       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:11.749303       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:12.038535       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:10:12.221846       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:13.277483       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:10:15.609981       1 wrap.go:47] GET /healthz: (85.402µs) 200 [kube-probe/1.15+ 127.0.0.1:37934]
I0416 21:10:16.790611       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 411 items received
I0416 21:10:18.180482       1 request.go:530] Throttling request took 92.833322ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:10:18.230611       1 request.go:530] Throttling request took 142.926568ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:10:18.280624       1 request.go:530] Throttling request took 192.954322ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:10:18.330829       1 request.go:530] Throttling request took 243.13292ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:10:18.380562       1 request.go:530] Throttling request took 292.894189ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:10:18.430514       1 request.go:530] Throttling request took 342.807554ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:10:18.480504       1 request.go:530] Throttling request took 392.794391ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:10:18.530494       1 request.go:530] Throttling request took 442.771151ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:10:18.533103       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:10:21.337633       1 controller.go:123] Found 0 jobs
I0416 21:10:21.339825       1 controller.go:139] Found 0 cronjobs
I0416 21:10:21.339836       1 controller.go:142] Found 0 groups
I0416 21:10:21.748253       1 service_controller.go:639] Detected change in list of current cluster nodes. New node set: map[e2e-test-peterhornyack-minion-group-06gd:{} e2e-test-peterhornyack-windows-node-group-31ht:{}]
I0416 21:10:21.748295       1 service_controller.go:647] Successfully updated 6 out of 6 load balancers to direct traffic to the updated set of nodes
I0416 21:10:21.990467       1 gc_controller.go:144] GC'ing orphaned
I0416 21:10:21.994350       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:10:22.026982       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:24.361417       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 21:10:24.867143       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:10:25.221441       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:25.608546       1 wrap.go:47] GET /healthz: (183.474µs) 200 [kube-probe/1.15+ 127.0.0.1:37968]
I0416 21:10:27.038878       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:10:27.135391       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:10:27.222086       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:31.343507       1 controller.go:123] Found 0 jobs
I0416 21:10:31.345909       1 controller.go:139] Found 0 cronjobs
I0416 21:10:31.345920       1 controller.go:142] Found 0 groups
I0416 21:10:32.262955       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 66 items received
I0416 21:10:32.361015       1 request.go:530] Throttling request took 92.193446ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:10:32.410824       1 request.go:530] Throttling request took 141.99391ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:10:32.461138       1 request.go:530] Throttling request took 191.991328ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:10:32.510881       1 request.go:530] Throttling request took 242.020996ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:10:32.561442       1 request.go:530] Throttling request took 292.193286ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:10:32.610850       1 request.go:530] Throttling request took 341.974018ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:10:32.660830       1 request.go:530] Throttling request took 391.947852ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:10:32.671313       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:32.710832       1 request.go:530] Throttling request took 441.937552ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:10:35.608346       1 wrap.go:47] GET /healthz: (113.369µs) 200 [kube-probe/1.15+ 127.0.0.1:38002]
I0416 21:10:39.043590       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:39.787997       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 1 items received
I0416 21:10:41.351071       1 controller.go:123] Found 0 jobs
I0416 21:10:41.354840       1 controller.go:139] Found 0 cronjobs
I0416 21:10:41.354854       1 controller.go:142] Found 0 groups
I0416 21:10:41.741643       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:41.749701       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:41.994634       1 gc_controller.go:144] GC'ing orphaned
I0416 21:10:41.999480       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:10:42.000003       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 21:10:42.039193       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:10:42.161680       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 21:10:42.222377       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:10:45.608838       1 wrap.go:47] GET /healthz: (84.803µs) 200 [kube-probe/1.15+ 127.0.0.1:38054]
I0416 21:10:48.633626       1 request.go:530] Throttling request took 90.655447ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:10:48.683617       1 request.go:530] Throttling request took 140.637737ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:10:48.733639       1 request.go:530] Throttling request took 190.648916ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:10:48.783634       1 request.go:530] Throttling request took 240.621593ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:10:48.833619       1 request.go:530] Throttling request took 290.613726ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:10:48.883699       1 request.go:530] Throttling request took 340.66591ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:10:48.933614       1 request.go:530] Throttling request took 390.575817ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:10:48.983646       1 request.go:530] Throttling request took 440.600775ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:10:48.986054       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:10:50.754556       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 21:10:51.361870       1 controller.go:123] Found 0 jobs
I0416 21:10:51.369944       1 controller.go:139] Found 0 cronjobs
I0416 21:10:51.369956       1 controller.go:142] Found 0 groups
I0416 21:10:53.339658       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:10:54.728147       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:10:55.608551       1 wrap.go:47] GET /healthz: (84.753µs) 200 [kube-probe/1.15+ 127.0.0.1:38090]
I0416 21:10:57.039616       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:10:57.138086       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:10:57.138122       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:10:57.223841       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:01.374109       1 controller.go:123] Found 0 jobs
I0416 21:11:01.376532       1 controller.go:139] Found 0 cronjobs
I0416 21:11:01.376544       1 controller.go:142] Found 0 groups
I0416 21:11:01.999837       1 gc_controller.go:144] GC'ing orphaned
I0416 21:11:02.004397       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:11:02.813688       1 request.go:530] Throttling request took 90.858383ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:11:02.863669       1 request.go:530] Throttling request took 140.79942ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:11:02.914339       1 request.go:530] Throttling request took 191.470326ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:11:02.963694       1 request.go:530] Throttling request took 240.824174ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:11:03.013699       1 request.go:530] Throttling request took 290.813384ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:11:03.064201       1 request.go:530] Throttling request took 341.306584ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:11:03.113702       1 request.go:530] Throttling request took 390.801332ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:11:03.163660       1 request.go:530] Throttling request took 440.753744ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:11:03.993537       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:11:04.401040       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:05.608577       1 wrap.go:47] GET /healthz: (96.781µs) 200 [kube-probe/1.15+ 127.0.0.1:38124]
I0416 21:11:11.380543       1 controller.go:123] Found 0 jobs
I0416 21:11:11.382932       1 controller.go:139] Found 0 cronjobs
I0416 21:11:11.382944       1 controller.go:142] Found 0 groups
I0416 21:11:11.741983       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:11.750097       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:12.039916       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:11:12.224132       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:14.786546       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 21:11:15.608608       1 wrap.go:47] GET /healthz: (99.609µs) 200 [kube-probe/1.15+ 127.0.0.1:38156]
I0416 21:11:19.086585       1 request.go:530] Throttling request took 91.726138ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:11:19.136722       1 request.go:530] Throttling request took 141.735146ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:11:19.186577       1 request.go:530] Throttling request took 191.685793ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:11:19.236624       1 request.go:530] Throttling request took 241.726105ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:11:19.286969       1 request.go:530] Throttling request took 292.038598ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:11:19.336602       1 request.go:530] Throttling request took 341.686829ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:11:19.386568       1 request.go:530] Throttling request took 391.622101ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:11:19.436689       1 request.go:530] Throttling request took 441.746075ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:11:19.438928       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:11:19.899454       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 270 items received
I0416 21:11:21.387711       1 controller.go:123] Found 0 jobs
I0416 21:11:21.390403       1 controller.go:139] Found 0 cronjobs
I0416 21:11:21.390414       1 controller.go:142] Found 0 groups
I0416 21:11:22.004780       1 gc_controller.go:144] GC'ing orphaned
I0416 21:11:22.009602       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:11:24.968190       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:11:25.608566       1 wrap.go:47] GET /healthz: (90.718µs) 200 [kube-probe/1.15+ 127.0.0.1:38190]
I0416 21:11:25.941890       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 14 items received
I0416 21:11:27.040218       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:11:27.140896       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:11:27.225115       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:27.780989       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 12 items received
I0416 21:11:28.447309       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:11:30.755883       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 5 items received
I0416 21:11:30.758872       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 52 items received
I0416 21:11:31.396771       1 controller.go:123] Found 0 jobs
I0416 21:11:31.398877       1 controller.go:139] Found 0 cronjobs
I0416 21:11:31.398889       1 controller.go:142] Found 0 groups
I0416 21:11:32.769984       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 21 items received
I0416 21:11:33.267321       1 request.go:530] Throttling request took 92.769168ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:11:33.316602       1 request.go:530] Throttling request took 142.02484ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:11:33.366610       1 request.go:530] Throttling request took 192.023665ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:11:33.416663       1 request.go:530] Throttling request took 242.064955ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:11:33.466672       1 request.go:530] Throttling request took 292.05526ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:11:33.516612       1 request.go:530] Throttling request took 341.984949ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:11:33.566558       1 request.go:530] Throttling request took 391.921999ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:11:33.616665       1 request.go:530] Throttling request took 442.017716ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:11:35.608541       1 wrap.go:47] GET /healthz: (100.885µs) 200 [kube-probe/1.15+ 127.0.0.1:38224]
I0416 21:11:39.761389       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 59 items received
I0416 21:11:40.302555       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 45 items received
I0416 21:11:41.403169       1 controller.go:123] Found 0 jobs
I0416 21:11:41.406118       1 controller.go:139] Found 0 cronjobs
I0416 21:11:41.406133       1 controller.go:142] Found 0 groups
I0416 21:11:41.742342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:41.750570       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:42.009861       1 gc_controller.go:144] GC'ing orphaned
I0416 21:11:42.017510       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:11:42.041042       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:11:42.225441       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:43.598335       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:44.818192       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:44.818524       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:44.819177       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:44.819609       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:11:44.819821       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:11:44.819947       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:11:45.608634       1 wrap.go:47] GET /healthz: (103.919µs) 200 [kube-probe/1.15+ 127.0.0.1:38276]
I0416 21:11:46.786981       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 21:11:49.539630       1 request.go:530] Throttling request took 91.829519ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:11:49.589510       1 request.go:530] Throttling request took 141.681146ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:11:49.639516       1 request.go:530] Throttling request took 191.671881ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:11:49.689413       1 request.go:530] Throttling request took 241.560153ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:11:49.739445       1 request.go:530] Throttling request took 291.584838ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:11:49.791096       1 request.go:530] Throttling request took 343.207469ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:11:49.839467       1 request.go:530] Throttling request took 391.572257ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:11:49.889495       1 request.go:530] Throttling request took 441.573982ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:11:49.892217       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:11:51.410193       1 controller.go:123] Found 0 jobs
I0416 21:11:51.415151       1 controller.go:139] Found 0 cronjobs
I0416 21:11:51.415164       1 controller.go:142] Found 0 groups
I0416 21:11:52.992361       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:11:53.435683       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:11:53.993171       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:11:54.815199       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:11:54.993380       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:11:55.608481       1 wrap.go:47] GET /healthz: (93.904µs) 200 [kube-probe/1.15+ 127.0.0.1:38312]
I0416 21:11:57.041352       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:11:57.143868       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:11:57.143908       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:11:57.225820       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.257475       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.258410       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.259548       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.259568       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.259652       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:11:57.259667       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:11:57.259689       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:11:57.259684227 +0000 UTC m=+539.413408378)
I0416 21:11:57.260586       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (895.458µs)
I0416 21:11:57.260618       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:11:57.260615565 +0000 UTC m=+539.414339703)
I0416 21:11:57.261739       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (1.11704ms)
I0416 21:11:57.261891       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:11:57.261904       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:11:57.261900288 +0000 UTC m=+539.415624425)
I0416 21:11:57.262442       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (539.07µs)
I0416 21:11:57.262471       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:11:57.262493       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:11:57.262490623 +0000 UTC m=+539.416214760)
I0416 21:11:57.263678       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.184ms)
I0416 21:11:57.263741       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:11:57.263747       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:11:57.263755       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:11:57.263752644 +0000 UTC m=+539.417476781)
I0416 21:11:57.264383       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (627.567µs)
I0416 21:11:57.264393       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:11:57.264390925 +0000 UTC m=+539.418115060)
I0416 21:11:57.264715       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (322.708µs)
I0416 21:11:57.264737       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:11:57.264746       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:11:57.26474313 +0000 UTC m=+539.418467268)
I0416 21:11:57.265159       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (413.836µs)
I0416 21:11:57.265174       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:11:57.265182       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:11:57.265178887 +0000 UTC m=+539.418903022)
I0416 21:11:57.265970       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (787.696µs)
I0416 21:11:57.266052       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.266066       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.267460       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.267721       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:11:57.267748       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.267752       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:11:57.267785       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:11:57.267795       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.267798       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:11:57.267833       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:11:57.267842       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.267845       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:11:57.267883       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:11:57.267890       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.267893       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:11:57.267897       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:11:57.267906       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.267908       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:11:57.267940       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:11:57.267956       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.267958       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:11:57.267984       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:11:57.267995       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.267997       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:11:57.268027       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:11:57.268035       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268037       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:11:57.268060       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:11:57.268067       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268069       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:11:57.268092       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:11:57.268103       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268105       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:11:57.268128       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:11:57.268138       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268149       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:11:57.268176       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:11:57.268183       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268185       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:11:57.268246       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:11:57.268254       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268256       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:11:57.268291       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:11:57.268301       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268304       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:11:57.268307       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:11:57.268314       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268316       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:11:57.268335       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:11:57.268342       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268344       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:11:57.268386       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:11:57.268393       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268396       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:11:57.268437       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:11:57.268444       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268447       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:11:57.268483       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:11:57.268487       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268491       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:11:57.268518       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:11:57.268525       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268528       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:11:57.268546       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:11:57.268554       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268556       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:11:57.268581       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:11:57.268589       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:11:57.268592       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:11:57.273175       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.273341       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:11:57.273357       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:11:57.274671       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25aee95eb1581f, ext:291668663047, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.275020       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:11:57.275046       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25af275064d30b, ext:539428767233, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.275099       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:11:57.275161       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:11:57.275166       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25af275064d30b, ext:539428767233, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.275217       1 update.go:396] Getting unavailable numbers
I0416 21:11:57.275352       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:11:57.275358       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:11:57.275364       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:11:57.275368       1 update.go:68] Marking old pods for deletion
I0416 21:11:57.275373       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25af275069d49a, ext:539429095313, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.275379       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:11:57.275420       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:11:57.275442       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:11:57.275543       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:11:57.275551       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.177398ms)
I0416 21:11:57.276020       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25aee95ec09064, ext:291669660492, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.276172       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:11:57.276179       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25af2750762197, ext:539429901454, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.276186       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:11:57.276315       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:11:57.276321       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25af2750762197, ext:539429901454, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.276360       1 update.go:396] Getting unavailable numbers
I0416 21:11:57.276482       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:11:57.276488       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:11:57.276492       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:11:57.276496       1 update.go:68] Marking old pods for deletion
I0416 21:11:57.276500       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25af27507b08a2, ext:539430222831, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.276506       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:11:57.276531       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:11:57.276565       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:11:57.276672       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:11:57.276677       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.089113ms)
I0416 21:11:57.277051       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.277198       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.277336       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.277470       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (139.572µs)
I0416 21:11:57.277553       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.277662       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (129.409µs)
I0416 21:11:57.277688       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.277835       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (148.157µs)
I0416 21:11:57.277846       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.277902       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (57.607µs)
I0416 21:11:57.277928       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.277984       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (58.976µs)
I0416 21:11:57.278002       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.278053       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (51.335µs)
I0416 21:11:57.278079       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.278148       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (68.337µs)
I0416 21:11:57.278157       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.278221       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (65.945µs)
I0416 21:11:57.278253       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.278342       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (91.153µs)
I0416 21:11:57.278359       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:11:57.278420       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (60.662µs)
I0416 21:11:57.279340       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.279363       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.279390       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.280282       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.336396       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.417009       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.458377       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.487467       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.606379       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.679725       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.780160       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.829412       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:57.829562       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:11:57.829591       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (2.594µs)
I0416 21:11:57.829633       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:11:57.829638       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (562ns)
I0416 21:11:57.829649       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:11:57.829656       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:11:57.829668       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (424ns)
I0416 21:11:57.829677       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (294ns)
I0416 21:11:57.880336       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:58.034920       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:11:58.755013       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:11:59.784592       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 52 items received
I0416 21:12:01.418903       1 controller.go:123] Found 0 jobs
I0416 21:12:01.421191       1 controller.go:139] Found 0 cronjobs
I0416 21:12:01.421203       1 controller.go:142] Found 0 groups
I0416 21:12:02.017905       1 gc_controller.go:144] GC'ing orphaned
I0416 21:12:02.021910       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:12:03.719575       1 request.go:530] Throttling request took 92.762804ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:12:03.769577       1 request.go:530] Throttling request took 142.742963ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:12:03.819621       1 request.go:530] Throttling request took 192.780537ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:12:03.869635       1 request.go:530] Throttling request took 242.787548ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:12:03.919619       1 request.go:530] Throttling request took 292.764455ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:12:03.969638       1 request.go:530] Throttling request took 342.776893ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:12:04.019656       1 request.go:530] Throttling request took 392.787511ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:12:04.069599       1 request.go:530] Throttling request took 442.720167ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:12:05.609351       1 wrap.go:47] GET /healthz: (124.121µs) 200 [kube-probe/1.15+ 127.0.0.1:38346]
I0416 21:12:10.787789       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 21:12:11.425523       1 controller.go:123] Found 0 jobs
I0416 21:12:11.428167       1 controller.go:139] Found 0 cronjobs
I0416 21:12:11.428177       1 controller.go:142] Found 0 groups
I0416 21:12:11.742630       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:12:11.751087       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:12:12.041685       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:12:12.226112       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:12:12.763892       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 96 items received
I0416 21:12:15.608622       1 wrap.go:47] GET /healthz: (87.819µs) 200 [kube-probe/1.15+ 127.0.0.1:38378]
I0416 21:12:16.511209       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 21:12:19.992784       1 request.go:530] Throttling request took 92.199084ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:12:20.042760       1 request.go:530] Throttling request took 142.16951ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:12:20.092732       1 request.go:530] Throttling request took 192.114216ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:12:20.142741       1 request.go:530] Throttling request took 242.11229ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:12:20.192748       1 request.go:530] Throttling request took 292.11302ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:12:20.242720       1 request.go:530] Throttling request took 342.076861ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:12:20.292584       1 request.go:530] Throttling request took 391.876696ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:12:20.342797       1 request.go:530] Throttling request took 442.082261ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:12:20.345178       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:12:21.431837       1 controller.go:123] Found 0 jobs
I0416 21:12:21.433919       1 controller.go:139] Found 0 cronjobs
I0416 21:12:21.433930       1 controller.go:142] Found 0 groups
I0416 21:12:22.022290       1 gc_controller.go:144] GC'ing orphaned
I0416 21:12:22.026180       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:12:22.216750       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 21:12:24.327485       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 275 items received
I0416 21:12:25.080637       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:12:25.610885       1 wrap.go:47] GET /healthz: (91.44µs) 200 [kube-probe/1.15+ 127.0.0.1:38410]
I0416 21:12:27.042092       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:12:27.146324       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:12:27.226905       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:12:31.437209       1 controller.go:123] Found 0 jobs
I0416 21:12:31.439381       1 controller.go:139] Found 0 cronjobs
I0416 21:12:31.439392       1 controller.go:142] Found 0 groups
I0416 21:12:31.783302       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 21:12:34.172195       1 request.go:530] Throttling request took 92.111949ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:12:34.222212       1 request.go:530] Throttling request took 142.133866ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:12:34.272364       1 request.go:530] Throttling request took 192.278735ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:12:34.322266       1 request.go:530] Throttling request took 242.155837ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:12:34.372196       1 request.go:530] Throttling request took 292.069977ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:12:34.422272       1 request.go:530] Throttling request took 342.124889ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:12:34.472329       1 request.go:530] Throttling request took 392.192638ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:12:34.522204       1 request.go:530] Throttling request took 442.056253ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:12:35.609371       1 wrap.go:47] GET /healthz: (95.244µs) 200 [kube-probe/1.15+ 127.0.0.1:38446]
I0416 21:12:37.767887       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 21:12:38.301824       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 42 items received
I0416 21:12:41.442741       1 controller.go:123] Found 0 jobs
I0416 21:12:41.445031       1 controller.go:139] Found 0 cronjobs
I0416 21:12:41.445043       1 controller.go:142] Found 0 groups
I0416 21:12:41.742972       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:12:41.743342       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (273.825µs)
I0416 21:12:41.743455       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (66.79µs)
I0416 21:12:41.743464       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.113µs)
I0416 21:12:41.743634       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:12:41.744010       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (100.106µs)
I0416 21:12:41.744071       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (43.685µs)
I0416 21:12:41.748485       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (4.996757ms)
I0416 21:12:41.752454       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:12:42.026522       1 gc_controller.go:144] GC'ing orphaned
I0416 21:12:42.030556       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:12:42.042716       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:12:42.112185       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 21:12:42.227283       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:12:43.301252       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 78 items received
I0416 21:12:45.608525       1 wrap.go:47] GET /healthz: (84.557µs) 200 [kube-probe/1.15+ 127.0.0.1:38498]
I0416 21:12:50.445649       1 request.go:530] Throttling request took 91.111743ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:12:50.495601       1 request.go:530] Throttling request took 141.067894ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:12:50.545653       1 request.go:530] Throttling request took 191.102922ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:12:50.595675       1 request.go:530] Throttling request took 241.123972ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:12:50.645699       1 request.go:530] Throttling request took 291.089276ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:12:50.695644       1 request.go:530] Throttling request took 341.065356ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:12:50.745638       1 request.go:530] Throttling request took 391.055299ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:12:50.795677       1 request.go:530] Throttling request took 441.0767ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:12:50.797836       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:12:51.449898       1 controller.go:123] Found 0 jobs
I0416 21:12:51.459444       1 controller.go:139] Found 0 cronjobs
I0416 21:12:51.459459       1 controller.go:142] Found 0 groups
I0416 21:12:53.527148       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:12:53.925950       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 21:12:54.923320       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:12:54.993432       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:12:55.608611       1 wrap.go:47] GET /healthz: (88.525µs) 200 [kube-probe/1.15+ 127.0.0.1:38534]
I0416 21:12:57.043044       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:12:57.148920       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:12:57.148968       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:12:57.227577       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:01.462875       1 controller.go:123] Found 0 jobs
I0416 21:13:01.465375       1 controller.go:139] Found 0 cronjobs
I0416 21:13:01.465387       1 controller.go:142] Found 0 groups
I0416 21:13:02.030898       1 gc_controller.go:144] GC'ing orphaned
I0416 21:13:02.035574       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:13:04.624991       1 request.go:530] Throttling request took 92.601655ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:13:04.674991       1 request.go:530] Throttling request took 142.59276ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:13:04.725025       1 request.go:530] Throttling request took 192.617975ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:13:04.775036       1 request.go:530] Throttling request took 242.607433ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:13:04.825013       1 request.go:530] Throttling request took 292.573899ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:13:04.875038       1 request.go:530] Throttling request took 342.591234ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:13:04.925026       1 request.go:530] Throttling request took 392.567471ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:13:04.975028       1 request.go:530] Throttling request took 442.562068ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:13:05.608628       1 wrap.go:47] GET /healthz: (93.52µs) 200 [kube-probe/1.15+ 127.0.0.1:38568]
I0416 21:13:08.793707       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 3 items received
I0416 21:13:11.469949       1 controller.go:123] Found 0 jobs
I0416 21:13:11.473784       1 controller.go:139] Found 0 cronjobs
I0416 21:13:11.473798       1 controller.go:142] Found 0 groups
I0416 21:13:11.743358       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:11.753114       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:12.043381       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:13:12.227898       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:12.780570       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 5 items received
I0416 21:13:13.418307       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:13:15.608612       1 wrap.go:47] GET /healthz: (84.336µs) 200 [kube-probe/1.15+ 127.0.0.1:38600]
I0416 21:13:18.763844       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:13:19.783923       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 21 items received
I0416 21:13:20.898337       1 request.go:530] Throttling request took 91.224675ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:13:20.948264       1 request.go:530] Throttling request took 141.133519ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:13:20.998355       1 request.go:530] Throttling request took 191.227895ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:13:21.048655       1 request.go:530] Throttling request took 241.523921ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:13:21.098889       1 request.go:530] Throttling request took 291.73046ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:13:21.148410       1 request.go:530] Throttling request took 341.219997ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:13:21.198324       1 request.go:530] Throttling request took 391.147122ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:13:21.248294       1 request.go:530] Throttling request took 441.10809ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:13:21.255213       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:13:21.478172       1 controller.go:123] Found 0 jobs
I0416 21:13:21.481940       1 controller.go:139] Found 0 cronjobs
I0416 21:13:21.481950       1 controller.go:142] Found 0 groups
I0416 21:13:22.035988       1 gc_controller.go:144] GC'ing orphaned
I0416 21:13:22.040838       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:13:25.221052       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:13:25.608623       1 wrap.go:47] GET /healthz: (94.895µs) 200 [kube-probe/1.15+ 127.0.0.1:38632]
I0416 21:13:27.043649       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:13:27.151241       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:13:27.228214       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:29.325064       1 reflector.go:249] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: forcing resync
I0416 21:13:31.410544       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 21:13:31.486007       1 controller.go:123] Found 0 jobs
I0416 21:13:31.495842       1 controller.go:139] Found 0 cronjobs
I0416 21:13:31.495854       1 controller.go:142] Found 0 groups
I0416 21:13:35.077743       1 request.go:530] Throttling request took 90.422076ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:13:35.127774       1 request.go:530] Throttling request took 140.43691ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:13:35.177781       1 request.go:530] Throttling request took 190.437264ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:13:35.228328       1 request.go:530] Throttling request took 240.967787ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:13:35.277796       1 request.go:530] Throttling request took 290.421872ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:13:35.327766       1 request.go:530] Throttling request took 340.378294ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:13:35.377780       1 request.go:530] Throttling request took 390.389518ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:13:35.427755       1 request.go:530] Throttling request took 440.34695ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:13:35.608835       1 wrap.go:47] GET /healthz: (113.507µs) 200 [kube-probe/1.15+ 127.0.0.1:38668]
I0416 21:13:40.462049       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 3 items received
I0416 21:13:41.500091       1 controller.go:123] Found 0 jobs
I0416 21:13:41.502816       1 controller.go:139] Found 0 cronjobs
I0416 21:13:41.502837       1 controller.go:142] Found 0 groups
I0416 21:13:41.744611       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:41.753396       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:42.040946       1 gc_controller.go:144] GC'ing orphaned
I0416 21:13:42.045137       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:13:42.045714       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:13:42.169809       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:42.228525       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:42.558353       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:13:45.000483       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:13:45.000464049 +0000 UTC m=+647.154188200)
I0416 21:13:45.001516       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (1.045099ms)
I0416 21:13:45.001551       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:13:45.001547995 +0000 UTC m=+647.155272131)
I0416 21:13:45.001923       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (373.09µs)
I0416 21:13:45.001933       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:13:45.001931109 +0000 UTC m=+647.155655246)
I0416 21:13:45.002805       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (856.165µs)
I0416 21:13:45.608113       1 wrap.go:47] GET /healthz: (82.051µs) 200 [kube-probe/1.15+ 127.0.0.1:38720]
I0416 21:13:46.000431       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:13:46.000410454 +0000 UTC m=+648.154134591)
I0416 21:13:46.001329       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (895.129µs)
I0416 21:13:46.001356       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:13:46.001353508 +0000 UTC m=+648.155077644)
I0416 21:13:46.001760       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (403.124µs)
I0416 21:13:46.961550       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:49.000360       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:13:49.000333172 +0000 UTC m=+651.154057309)
I0416 21:13:49.000886       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (542.714µs)
I0416 21:13:51.356484       1 request.go:530] Throttling request took 86.75326ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:13:51.406165       1 request.go:530] Throttling request took 136.451631ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:13:51.456055       1 request.go:530] Throttling request took 186.337153ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:13:51.506492       1 request.go:530] Throttling request took 236.764769ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:13:51.507687       1 controller.go:123] Found 0 jobs
I0416 21:13:51.510731       1 controller.go:139] Found 0 cronjobs
I0416 21:13:51.510753       1 controller.go:142] Found 0 groups
I0416 21:13:51.556086       1 request.go:530] Throttling request took 286.349118ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:13:51.606115       1 request.go:530] Throttling request took 336.362577ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:13:51.656372       1 request.go:530] Throttling request took 386.615145ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:13:51.706086       1 request.go:530] Throttling request took 436.30619ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:13:51.709546       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:13:53.618909       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:13:55.022781       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:13:55.608447       1 wrap.go:47] GET /healthz: (87.043µs) 200 [kube-probe/1.15+ 127.0.0.1:38756]
I0416 21:13:55.995722       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:13:57.045534       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:13:57.153517       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:13:57.153572       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:13:57.229023       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:13:58.125347       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:01.514175       1 controller.go:123] Found 0 jobs
I0416 21:14:01.516827       1 controller.go:139] Found 0 cronjobs
I0416 21:14:01.516842       1 controller.go:142] Found 0 groups
I0416 21:14:02.046098       1 gc_controller.go:144] GC'ing orphaned
I0416 21:14:02.050173       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:14:05.530906       1 request.go:530] Throttling request took 89.015651ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:14:05.581103       1 request.go:530] Throttling request took 139.104977ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:14:05.609208       1 wrap.go:47] GET /healthz: (86.11µs) 200 [kube-probe/1.15+ 127.0.0.1:38790]
I0416 21:14:05.630865       1 request.go:530] Throttling request took 188.943443ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:14:05.680877       1 request.go:530] Throttling request took 238.946446ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:14:05.730968       1 request.go:530] Throttling request took 288.995406ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:14:05.780960       1 request.go:530] Throttling request took 338.956419ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:14:05.830942       1 request.go:530] Throttling request took 388.930723ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:14:05.880973       1 request.go:530] Throttling request took 438.9683ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:14:07.684241       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:11.520434       1 controller.go:123] Found 0 jobs
I0416 21:14:11.522630       1 controller.go:139] Found 0 cronjobs
I0416 21:14:11.522641       1 controller.go:142] Found 0 groups
I0416 21:14:11.744968       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:11.754025       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:12.045861       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:14:12.229323       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:15.608431       1 wrap.go:47] GET /healthz: (78.29µs) 200 [kube-probe/1.15+ 127.0.0.1:38822]
I0416 21:14:17.770717       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:14:21.527331       1 controller.go:123] Found 0 jobs
I0416 21:14:21.529820       1 controller.go:139] Found 0 cronjobs
I0416 21:14:21.529847       1 controller.go:142] Found 0 groups
I0416 21:14:21.809999       1 request.go:530] Throttling request took 91.989168ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:14:21.860004       1 request.go:530] Throttling request took 141.987128ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:14:21.909997       1 request.go:530] Throttling request took 191.970609ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:14:21.960005       1 request.go:530] Throttling request took 241.968819ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:14:22.009986       1 request.go:530] Throttling request took 291.927485ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:14:22.050591       1 gc_controller.go:144] GC'ing orphaned
I0416 21:14:22.055305       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:14:22.059940       1 request.go:530] Throttling request took 341.880216ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:14:22.109987       1 request.go:530] Throttling request took 391.912788ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:14:22.159882       1 request.go:530] Throttling request took 441.802318ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:14:22.163314       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:14:25.319129       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:14:25.608621       1 wrap.go:47] GET /healthz: (85.597µs) 200 [kube-probe/1.15+ 127.0.0.1:38854]
I0416 21:14:27.046208       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:14:27.159332       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:14:27.229673       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:31.534110       1 controller.go:123] Found 0 jobs
I0416 21:14:31.538572       1 controller.go:139] Found 0 cronjobs
I0416 21:14:31.538601       1 controller.go:142] Found 0 groups
I0416 21:14:35.608431       1 wrap.go:47] GET /healthz: (101.466µs) 200 [kube-probe/1.15+ 127.0.0.1:38890]
I0416 21:14:35.983985       1 request.go:530] Throttling request took 91.907405ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:14:36.033967       1 request.go:530] Throttling request took 141.842478ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:14:36.083974       1 request.go:530] Throttling request took 191.795248ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:14:36.134014       1 request.go:530] Throttling request took 241.866583ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:14:36.183985       1 request.go:530] Throttling request took 291.827212ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:14:36.233948       1 request.go:530] Throttling request took 341.777763ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:14:36.283929       1 request.go:530] Throttling request took 391.748948ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:14:36.333872       1 request.go:530] Throttling request took 441.692761ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:14:41.554466       1 controller.go:123] Found 0 jobs
I0416 21:14:41.559822       1 controller.go:139] Found 0 cronjobs
I0416 21:14:41.559836       1 controller.go:142] Found 0 groups
I0416 21:14:41.745308       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:41.754457       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:42.046501       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:14:42.055809       1 gc_controller.go:144] GC'ing orphaned
I0416 21:14:42.059775       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:14:42.230343       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:45.608561       1 wrap.go:47] GET /healthz: (79.914µs) 200 [kube-probe/1.15+ 127.0.0.1:38942]
I0416 21:14:45.733010       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:51.573061       1 controller.go:123] Found 0 jobs
I0416 21:14:51.581434       1 controller.go:139] Found 0 cronjobs
I0416 21:14:51.581447       1 controller.go:142] Found 0 groups
I0416 21:14:52.263790       1 request.go:530] Throttling request took 91.893321ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:14:52.313776       1 request.go:530] Throttling request took 141.876619ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:14:52.363762       1 request.go:530] Throttling request took 191.85847ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:14:52.413764       1 request.go:530] Throttling request took 241.846249ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:14:52.463768       1 request.go:530] Throttling request took 291.843903ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:14:52.513756       1 request.go:530] Throttling request took 341.826355ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:14:52.563779       1 request.go:530] Throttling request took 391.829901ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:14:52.613769       1 request.go:530] Throttling request took 441.794819ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:14:52.616190       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:14:53.716545       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:14:55.127578       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:14:55.608492       1 wrap.go:47] GET /healthz: (100.439µs) 200 [kube-probe/1.15+ 127.0.0.1:38978]
I0416 21:14:55.996972       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:14:57.046789       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:14:57.162593       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:14:57.162630       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:14:57.230672       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:14:58.787037       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 21:15:01.585416       1 controller.go:123] Found 0 jobs
I0416 21:15:01.588497       1 controller.go:139] Found 0 cronjobs
I0416 21:15:01.588509       1 controller.go:142] Found 0 groups
I0416 21:15:02.060100       1 gc_controller.go:144] GC'ing orphaned
I0416 21:15:02.064548       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:15:05.608624       1 wrap.go:47] GET /healthz: (104.473µs) 200 [kube-probe/1.15+ 127.0.0.1:39012]
I0416 21:15:06.436445       1 request.go:530] Throttling request took 92.90916ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:15:06.486434       1 request.go:530] Throttling request took 142.904221ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:15:06.536402       1 request.go:530] Throttling request took 192.839922ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:15:06.586418       1 request.go:530] Throttling request took 242.852953ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:15:06.636394       1 request.go:530] Throttling request took 292.821716ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:15:06.686382       1 request.go:530] Throttling request took 342.805028ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:15:06.736440       1 request.go:530] Throttling request took 392.853774ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:15:06.786408       1 request.go:530] Throttling request took 442.788397ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:15:11.593075       1 controller.go:123] Found 0 jobs
I0416 21:15:11.595512       1 controller.go:139] Found 0 cronjobs
I0416 21:15:11.595523       1 controller.go:142] Found 0 groups
I0416 21:15:11.745701       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:11.755153       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:12.047075       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:15:12.230967       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:15.608412       1 wrap.go:47] GET /healthz: (96.016µs) 200 [kube-probe/1.15+ 127.0.0.1:39044]
I0416 21:15:17.772759       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 21:15:18.674799       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:15:21.599980       1 controller.go:123] Found 0 jobs
I0416 21:15:21.602423       1 controller.go:139] Found 0 cronjobs
I0416 21:15:21.602434       1 controller.go:142] Found 0 groups
I0416 21:15:22.064980       1 gc_controller.go:144] GC'ing orphaned
I0416 21:15:22.069468       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:15:22.716658       1 request.go:530] Throttling request took 92.132906ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:15:22.767045       1 request.go:530] Throttling request took 142.506019ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:15:22.816679       1 request.go:530] Throttling request took 192.137764ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:15:22.867329       1 request.go:530] Throttling request took 242.780054ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:15:22.916697       1 request.go:530] Throttling request took 292.140462ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:15:22.966733       1 request.go:530] Throttling request took 342.151992ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:15:23.016647       1 request.go:530] Throttling request took 392.075343ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:15:23.066656       1 request.go:530] Throttling request took 442.071095ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:15:23.069156       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:15:25.407539       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:15:25.608473       1 wrap.go:47] GET /healthz: (90.257µs) 200 [kube-probe/1.15+ 127.0.0.1:39076]
I0416 21:15:27.047435       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:15:27.165173       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:15:27.231308       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:31.615028       1 controller.go:123] Found 0 jobs
I0416 21:15:31.617758       1 controller.go:139] Found 0 cronjobs
I0416 21:15:31.617769       1 controller.go:142] Found 0 groups
I0416 21:15:35.608541       1 wrap.go:47] GET /healthz: (84.741µs) 200 [kube-probe/1.15+ 127.0.0.1:39112]
I0416 21:15:36.889356       1 request.go:530] Throttling request took 91.593506ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:15:36.939456       1 request.go:530] Throttling request took 141.693884ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:15:36.989375       1 request.go:530] Throttling request took 191.613059ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:15:37.039675       1 request.go:530] Throttling request took 241.863512ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:15:37.093310       1 request.go:530] Throttling request took 295.508466ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:15:37.139373       1 request.go:530] Throttling request took 341.55322ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:15:37.189325       1 request.go:530] Throttling request took 391.480794ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:15:37.239338       1 request.go:530] Throttling request took 441.491982ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:15:41.621928       1 controller.go:123] Found 0 jobs
I0416 21:15:41.624518       1 controller.go:139] Found 0 cronjobs
I0416 21:15:41.624532       1 controller.go:142] Found 0 groups
I0416 21:15:41.746044       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:41.755605       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:42.047814       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:15:42.070427       1 gc_controller.go:144] GC'ing orphaned
I0416 21:15:42.075433       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:15:42.232350       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:44.167060       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:45.608453       1 wrap.go:47] GET /healthz: (99.055µs) 200 [kube-probe/1.15+ 127.0.0.1:39164]
I0416 21:15:51.628722       1 controller.go:123] Found 0 jobs
I0416 21:15:51.631791       1 controller.go:139] Found 0 cronjobs
I0416 21:15:51.631803       1 controller.go:142] Found 0 groups
I0416 21:15:52.579094       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:15:52.579478       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:15:52.579586       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:15:52.579793       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:15:53.024329       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 21:15:53.169970       1 request.go:530] Throttling request took 92.786259ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:15:53.219693       1 request.go:530] Throttling request took 142.499555ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:15:53.269681       1 request.go:530] Throttling request took 192.458786ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:15:53.319690       1 request.go:530] Throttling request took 242.477713ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:15:53.369654       1 request.go:530] Throttling request took 292.440121ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:15:53.419801       1 request.go:530] Throttling request took 342.57408ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:15:53.469624       1 request.go:530] Throttling request took 392.348301ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:15:53.519603       1 request.go:530] Throttling request took 442.333209ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:15:53.521901       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:15:53.809908       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:15:55.231649       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:15:55.609044       1 wrap.go:47] GET /healthz: (87.981µs) 200 [kube-probe/1.15+ 127.0.0.1:39200]
I0416 21:15:55.999531       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:15:57.048085       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:15:57.167555       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:15:57.167589       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:15:57.232581       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:01.635640       1 controller.go:123] Found 0 jobs
I0416 21:16:01.638049       1 controller.go:139] Found 0 cronjobs
I0416 21:16:01.638061       1 controller.go:142] Found 0 groups
I0416 21:16:02.075701       1 gc_controller.go:144] GC'ing orphaned
I0416 21:16:02.079805       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:16:05.019628       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.019719       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:16:05.019735       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:16:05.019758       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:16:05.019752057 +0000 UTC m=+787.173476194)
I0416 21:16:05.021209       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (1.450576ms)
I0416 21:16:05.021264       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:16:05.021261776 +0000 UTC m=+787.174985915)
I0416 21:16:05.021649       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (385.194µs)
I0416 21:16:05.021693       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:16:05.021704       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:16:05.021700858 +0000 UTC m=+787.175424994)
I0416 21:16:05.022874       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.167353ms)
I0416 21:16:05.022944       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:16:05.022950       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:16:05.022959       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:16:05.022956129 +0000 UTC m=+787.176680265)
I0416 21:16:05.023669       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (709.514µs)
I0416 21:16:05.023685       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:16:05.023682619 +0000 UTC m=+787.177406759)
I0416 21:16:05.024014       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (329.858µs)
I0416 21:16:05.024052       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:16:05.024060       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:16:05.024057633 +0000 UTC m=+787.177781770)
I0416 21:16:05.024569       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (509.028µs)
I0416 21:16:05.024602       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:16:05.024606       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:16:05.024613       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:16:05.024611073 +0000 UTC m=+787.178335211)
I0416 21:16:05.025578       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (962.436µs)
I0416 21:16:05.025593       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:16:05.025590623 +0000 UTC m=+787.179314761)
I0416 21:16:05.025902       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (309.665µs)
I0416 21:16:05.029761       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.030035       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.030048       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.030306       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:16:05.030340       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030345       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:16:05.030408       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:16:05.030417       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030421       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:16:05.030443       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:16:05.030466       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030469       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:16:05.030513       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:16:05.030525       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030528       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:16:05.030571       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:16:05.030581       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030584       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:16:05.030654       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:16:05.030666       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030669       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:16:05.030673       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:16:05.030683       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030687       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:16:05.030726       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:16:05.030735       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030739       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:16:05.030771       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:16:05.030792       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030796       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:16:05.030827       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:16:05.030834       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030838       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:16:05.030869       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:16:05.030885       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030888       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:16:05.030925       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:16:05.030933       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030935       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:16:05.030974       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:16:05.030981       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.030983       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:16:05.031032       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:16:05.031041       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031044       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:16:05.031047       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:16:05.031051       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031053       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:16:05.031148       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:16:05.031160       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031162       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:16:05.031191       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:16:05.031199       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031216       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:16:05.031270       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:16:05.031278       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031280       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:16:05.031313       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:16:05.031322       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031325       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:16:05.031347       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:16:05.031357       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031359       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:16:05.031405       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:16:05.031414       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031417       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:16:05.031420       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:16:05.031427       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:16:05.031430       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:16:05.033189       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.033395       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:16:05.034982       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25af275069d49a, ext:539429095313, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.035340       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:16:05.035411       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25af65421c45e2, ext:787189131487, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.035485       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:16:05.035522       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:16:05.035542       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25af65421c45e2, ext:787189131487, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.035576       1 update.go:396] Getting unavailable numbers
I0416 21:16:05.035637       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:16:05.035667       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:16:05.035673       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:16:05.035678       1 update.go:68] Marking old pods for deletion
I0416 21:16:05.035681       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25af6542206d64, ext:787189403724, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.035705       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:16:05.035729       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:16:05.035750       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:16:05.035823       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:16:05.035868       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.42675ms)
I0416 21:16:05.035916       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:16:05.036448       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25af27507b08a2, ext:539430222831, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.036780       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:16:05.036789       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25af6542315134, ext:787190510621, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.036852       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:16:05.036885       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:16:05.036904       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25af6542315134, ext:787190510621, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.036933       1 update.go:396] Getting unavailable numbers
I0416 21:16:05.037027       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:16:05.037032       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:16:05.037037       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:16:05.037041       1 update.go:68] Marking old pods for deletion
I0416 21:16:05.037044       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25af6542353917, ext:787190766629, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.037064       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:16:05.037178       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:16:05.037204       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:16:05.037358       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:16:05.037365       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.435548ms)
I0416 21:16:05.037439       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.037524       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.037605       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (84.881µs)
I0416 21:16:05.037641       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.037697       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.037750       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (55.664µs)
I0416 21:16:05.037762       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.037802       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (41.558µs)
I0416 21:16:05.037830       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.037883       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (55.933µs)
I0416 21:16:05.037903       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.037936       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (35.396µs)
I0416 21:16:05.037947       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.037990       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (45.997µs)
I0416 21:16:05.038013       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.038060       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (48.409µs)
I0416 21:16:05.038138       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.038206       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (71.595µs)
I0416 21:16:05.038300       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.038345       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (48.521µs)
I0416 21:16:05.038354       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:16:05.038388       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (35.306µs)
I0416 21:16:05.040329       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.218524       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.247572       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.589523       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:05.589632       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:16:05.589663       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (2.713µs)
I0416 21:16:05.589689       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:16:05.589707       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (520ns)
I0416 21:16:05.589716       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:16:05.589724       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:16:05.589736       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (449ns)
I0416 21:16:05.589744       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (289ns)
I0416 21:16:05.608782       1 wrap.go:47] GET /healthz: (78.971µs) 200 [kube-probe/1.15+ 127.0.0.1:39234]
I0416 21:16:05.640177       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:07.342446       1 request.go:530] Throttling request took 89.648406ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:16:07.392654       1 request.go:530] Throttling request took 139.852847ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:16:07.442308       1 request.go:530] Throttling request took 189.492233ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:16:07.493217       1 request.go:530] Throttling request took 240.386617ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:16:07.542316       1 request.go:530] Throttling request took 289.45264ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:16:07.596056       1 request.go:530] Throttling request took 343.153082ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:16:07.642358       1 request.go:530] Throttling request took 389.470291ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:16:07.692347       1 request.go:530] Throttling request took 439.448876ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:16:10.976972       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 21:16:11.642060       1 controller.go:123] Found 0 jobs
I0416 21:16:11.644187       1 controller.go:139] Found 0 cronjobs
I0416 21:16:11.644199       1 controller.go:142] Found 0 groups
I0416 21:16:11.746413       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:11.758165       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:12.048380       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:16:12.232926       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:13.559216       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:16:15.608606       1 wrap.go:47] GET /healthz: (77.72µs) 200 [kube-probe/1.15+ 127.0.0.1:39268]
I0416 21:16:21.647688       1 controller.go:123] Found 0 jobs
I0416 21:16:21.650379       1 controller.go:139] Found 0 cronjobs
I0416 21:16:21.650391       1 controller.go:142] Found 0 groups
I0416 21:16:22.080181       1 gc_controller.go:144] GC'ing orphaned
I0416 21:16:22.084435       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:16:23.622575       1 request.go:530] Throttling request took 91.801705ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:16:23.672430       1 request.go:530] Throttling request took 141.651655ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:16:23.722526       1 request.go:530] Throttling request took 191.740004ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:16:23.772552       1 request.go:530] Throttling request took 241.744964ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:16:23.822525       1 request.go:530] Throttling request took 291.709694ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:16:23.872520       1 request.go:530] Throttling request took 341.700225ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:16:23.922505       1 request.go:530] Throttling request took 391.658874ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:16:23.972597       1 request.go:530] Throttling request took 441.703824ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:16:23.975441       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:16:25.502147       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:16:25.608414       1 wrap.go:47] GET /healthz: (96.621µs) 200 [kube-probe/1.15+ 127.0.0.1:39300]
I0416 21:16:27.048675       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:16:27.171354       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:16:27.233282       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:27.944485       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 21:16:28.781364       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:16:31.654672       1 controller.go:123] Found 0 jobs
I0416 21:16:31.657468       1 controller.go:139] Found 0 cronjobs
I0416 21:16:31.657481       1 controller.go:142] Found 0 groups
I0416 21:16:35.608625       1 wrap.go:47] GET /healthz: (89.314µs) 200 [kube-probe/1.15+ 127.0.0.1:39336]
I0416 21:16:37.795003       1 request.go:530] Throttling request took 90.976246ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:16:37.845070       1 request.go:530] Throttling request took 141.035605ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:16:37.895337       1 request.go:530] Throttling request took 191.290144ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:16:37.945026       1 request.go:530] Throttling request took 240.976339ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:16:37.994991       1 request.go:530] Throttling request took 290.934887ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:16:38.045340       1 request.go:530] Throttling request took 341.278046ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:16:38.095156       1 request.go:530] Throttling request took 391.086797ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:16:38.144985       1 request.go:530] Throttling request took 440.886853ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:16:38.778977       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:16:39.822038       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 5 items received
I0416 21:16:41.661605       1 controller.go:123] Found 0 jobs
I0416 21:16:41.664108       1 controller.go:139] Found 0 cronjobs
I0416 21:16:41.664118       1 controller.go:142] Found 0 groups
I0416 21:16:41.746752       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:41.759559       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:42.049096       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:16:42.084698       1 gc_controller.go:144] GC'ing orphaned
I0416 21:16:42.089808       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:16:42.233696       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:45.608095       1 wrap.go:47] GET /healthz: (87.119µs) 200 [kube-probe/1.15+ 127.0.0.1:39388]
I0416 21:16:51.668146       1 controller.go:123] Found 0 jobs
I0416 21:16:51.671079       1 controller.go:139] Found 0 cronjobs
I0416 21:16:51.671089       1 controller.go:142] Found 0 groups
I0416 21:16:51.789200       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 21:16:53.003078       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 21:16:53.902942       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:16:54.075879       1 request.go:530] Throttling request took 92.003305ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:16:54.125909       1 request.go:530] Throttling request took 142.029047ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:16:54.175868       1 request.go:530] Throttling request took 191.963934ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:16:54.225913       1 request.go:530] Throttling request took 241.991382ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:16:54.276024       1 request.go:530] Throttling request took 292.023472ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:16:54.326393       1 request.go:530] Throttling request took 342.460564ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:16:54.375930       1 request.go:530] Throttling request took 391.947296ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:16:54.425896       1 request.go:530] Throttling request took 441.940938ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:16:54.430782       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:16:55.335977       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:16:55.608553       1 wrap.go:47] GET /healthz: (92.971µs) 200 [kube-probe/1.15+ 127.0.0.1:39424]
I0416 21:16:56.002799       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:16:57.049403       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:16:57.175504       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:16:57.175556       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:16:57.234325       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:16:59.763773       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 222 items received
I0416 21:17:01.675346       1 controller.go:123] Found 0 jobs
I0416 21:17:01.678474       1 controller.go:139] Found 0 cronjobs
I0416 21:17:01.678485       1 controller.go:142] Found 0 groups
I0416 21:17:02.090088       1 gc_controller.go:144] GC'ing orphaned
I0416 21:17:02.095176       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:17:02.312637       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:05.089379       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 21:17:05.608431       1 wrap.go:47] GET /healthz: (94.579µs) 200 [kube-probe/1.15+ 127.0.0.1:39458]
I0416 21:17:08.248172       1 request.go:530] Throttling request took 93.242097ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:17:08.297727       1 request.go:530] Throttling request took 142.763966ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:17:08.347762       1 request.go:530] Throttling request took 192.816189ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:17:08.397757       1 request.go:530] Throttling request took 242.814987ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:17:08.447705       1 request.go:530] Throttling request took 292.753536ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:17:08.497715       1 request.go:530] Throttling request took 342.758133ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:17:08.548269       1 request.go:530] Throttling request took 393.266257ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:17:08.597666       1 request.go:530] Throttling request took 442.675277ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:17:08.701673       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:08.788749       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 21:17:11.682588       1 controller.go:123] Found 0 jobs
I0416 21:17:11.685478       1 controller.go:139] Found 0 cronjobs
I0416 21:17:11.685490       1 controller.go:142] Found 0 groups
I0416 21:17:11.747114       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:11.747676       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:17:11.748163       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (118.16µs)
I0416 21:17:11.750318       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (2.127725ms)
I0416 21:17:11.751001       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (325.139µs)
I0416 21:17:11.751181       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (141.466µs)
I0416 21:17:11.751201       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.85µs)
I0416 21:17:11.754028       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (6.747876ms)
I0416 21:17:11.764043       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:11.790417       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
I0416 21:17:12.049679       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:17:12.234632       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:15.000432       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:17:15.000415741 +0000 UTC m=+857.154139892)
I0416 21:17:15.001632       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (1.205669ms)
I0416 21:17:15.611035       1 wrap.go:47] GET /healthz: (117.983µs) 200 [kube-probe/1.15+ 127.0.0.1:39490]
I0416 21:17:18.000336       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:17:18.00031807 +0000 UTC m=+860.154042212)
I0416 21:17:18.001544       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.217703ms)
I0416 21:17:21.264938       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 123 items received
I0416 21:17:21.690403       1 controller.go:123] Found 0 jobs
I0416 21:17:21.699738       1 controller.go:139] Found 0 cronjobs
I0416 21:17:21.699774       1 controller.go:142] Found 0 groups
I0416 21:17:22.095496       1 gc_controller.go:144] GC'ing orphaned
I0416 21:17:22.100322       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:17:23.579403       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:24.531482       1 request.go:530] Throttling request took 91.207775ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:17:24.581471       1 request.go:530] Throttling request took 141.166307ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:17:24.632058       1 request.go:530] Throttling request took 191.751498ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:17:24.681360       1 request.go:530] Throttling request took 241.033807ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:17:24.731458       1 request.go:530] Throttling request took 291.142796ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:17:24.781358       1 request.go:530] Throttling request took 341.038738ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:17:24.783391       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 21:17:24.831375       1 request.go:530] Throttling request took 391.048491ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:17:24.881426       1 request.go:530] Throttling request took 441.088919ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:17:24.884144       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:17:25.596468       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:17:25.608533       1 wrap.go:47] GET /healthz: (127.129µs) 200 [kube-probe/1.15+ 127.0.0.1:39522]
I0416 21:17:27.050022       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:17:27.178282       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:17:27.235128       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:28.776388       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 21:17:31.704575       1 controller.go:123] Found 0 jobs
I0416 21:17:31.707503       1 controller.go:139] Found 0 cronjobs
I0416 21:17:31.707515       1 controller.go:142] Found 0 groups
I0416 21:17:35.613042       1 wrap.go:47] GET /healthz: (106.665µs) 200 [kube-probe/1.15+ 127.0.0.1:39556]
I0416 21:17:36.324897       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:38.700444       1 request.go:530] Throttling request took 90.934687ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:17:38.750390       1 request.go:530] Throttling request took 140.835913ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:17:38.800369       1 request.go:530] Throttling request took 190.806638ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:17:38.850400       1 request.go:530] Throttling request took 240.827987ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:17:38.900486       1 request.go:530] Throttling request took 290.930394ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:17:38.950552       1 request.go:530] Throttling request took 340.964325ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:17:39.000417       1 request.go:530] Throttling request took 390.844538ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:17:39.050395       1 request.go:530] Throttling request took 440.787556ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:17:41.711313       1 controller.go:123] Found 0 jobs
I0416 21:17:41.713950       1 controller.go:139] Found 0 cronjobs
I0416 21:17:41.713962       1 controller.go:142] Found 0 groups
I0416 21:17:41.747476       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:41.764475       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:41.772981       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 5 items received
I0416 21:17:42.050356       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:17:42.100622       1 gc_controller.go:144] GC'ing orphaned
I0416 21:17:42.105936       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:17:42.235483       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:42.765961       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 99 items received
I0416 21:17:45.607998       1 wrap.go:47] GET /healthz: (82.961µs) 200 [kube-probe/1.15+ 127.0.0.1:39610]
I0416 21:17:45.769955       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 21:17:51.723982       1 controller.go:123] Found 0 jobs
I0416 21:17:51.735666       1 controller.go:139] Found 0 cronjobs
I0416 21:17:51.735681       1 controller.go:142] Found 0 groups
I0416 21:17:53.990980       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:17:54.984797       1 request.go:530] Throttling request took 91.402494ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:17:55.034734       1 request.go:530] Throttling request took 141.306294ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:17:55.084631       1 request.go:530] Throttling request took 191.244763ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:17:55.134581       1 request.go:530] Throttling request took 241.1623ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:17:55.184613       1 request.go:530] Throttling request took 291.186799ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:17:55.234700       1 request.go:530] Throttling request took 341.266709ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:17:55.285393       1 request.go:530] Throttling request took 391.947603ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:17:55.334692       1 request.go:530] Throttling request took 441.188295ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:17:55.337277       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:17:55.423176       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:17:55.608628       1 wrap.go:47] GET /healthz: (103.069µs) 200 [kube-probe/1.15+ 127.0.0.1:39646]
I0416 21:17:56.008970       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:17:57.050646       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:17:57.182488       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:17:57.182591       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:17:57.235905       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:17:57.785968       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 21:17:58.793551       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 21:18:01.739773       1 controller.go:123] Found 0 jobs
I0416 21:18:01.742631       1 controller.go:139] Found 0 cronjobs
I0416 21:18:01.742644       1 controller.go:142] Found 0 groups
I0416 21:18:02.106250       1 gc_controller.go:144] GC'ing orphaned
I0416 21:18:02.110945       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:18:05.608499       1 wrap.go:47] GET /healthz: (97.583µs) 200 [kube-probe/1.15+ 127.0.0.1:39684]
I0416 21:18:09.153327       1 request.go:530] Throttling request took 87.234514ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:18:09.203315       1 request.go:530] Throttling request took 137.217156ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:18:09.253365       1 request.go:530] Throttling request took 187.238571ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:18:09.303344       1 request.go:530] Throttling request took 237.219451ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:18:09.353287       1 request.go:530] Throttling request took 287.101989ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:18:09.404391       1 request.go:530] Throttling request took 338.246555ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:18:09.456346       1 request.go:530] Throttling request took 390.179902ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:18:09.503525       1 request.go:530] Throttling request took 437.34918ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:18:11.746887       1 controller.go:123] Found 0 jobs
I0416 21:18:11.747914       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:18:11.749677       1 controller.go:139] Found 0 cronjobs
I0416 21:18:11.749686       1 controller.go:142] Found 0 groups
I0416 21:18:11.764772       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:18:11.793017       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 474 items received
I0416 21:18:12.050941       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:18:12.236214       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:18:15.608543       1 wrap.go:47] GET /healthz: (101.92µs) 200 [kube-probe/1.15+ 127.0.0.1:39716]
I0416 21:18:21.755060       1 controller.go:123] Found 0 jobs
I0416 21:18:21.761742       1 controller.go:139] Found 0 cronjobs
I0416 21:18:21.761754       1 controller.go:142] Found 0 groups
I0416 21:18:22.111246       1 gc_controller.go:144] GC'ing orphaned
I0416 21:18:22.116049       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:18:25.438131       1 request.go:530] Throttling request took 90.91786ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:18:25.488049       1 request.go:530] Throttling request took 140.840095ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:18:25.538079       1 request.go:530] Throttling request took 190.858071ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:18:25.588075       1 request.go:530] Throttling request took 240.844031ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:18:25.608707       1 wrap.go:47] GET /healthz: (142.126µs) 200 [kube-probe/1.15+ 127.0.0.1:39748]
I0416 21:18:25.638078       1 request.go:530] Throttling request took 290.834824ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:18:25.688151       1 request.go:530] Throttling request took 340.892583ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:18:25.693943       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:18:25.738087       1 request.go:530] Throttling request took 390.830046ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:18:25.788066       1 request.go:530] Throttling request took 440.780546ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:18:25.790344       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:18:26.163763       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 21:18:27.051676       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:18:27.064973       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:18:27.185040       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:18:27.236515       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:18:31.765589       1 controller.go:123] Found 0 jobs
I0416 21:18:31.768138       1 controller.go:139] Found 0 cronjobs
I0416 21:18:31.768149       1 controller.go:142] Found 0 groups
I0416 21:18:32.769538       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 21:18:35.608529       1 wrap.go:47] GET /healthz: (90.538µs) 200 [kube-probe/1.15+ 127.0.0.1:39782]
I0416 21:18:36.304940       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 30 items received
I0416 21:18:36.513990       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 21:18:39.606765       1 request.go:530] Throttling request took 89.962426ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:18:39.656743       1 request.go:530] Throttling request took 139.95181ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:18:39.706778       1 request.go:530] Throttling request took 189.976607ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:18:39.756761       1 request.go:530] Throttling request took 239.947362ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:18:39.806789       1 request.go:530] Throttling request took 289.969257ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:18:39.856763       1 request.go:530] Throttling request took 339.937689ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:18:39.906810       1 request.go:530] Throttling request took 389.961473ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:18:39.956795       1 request.go:530] Throttling request took 439.934443ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:18:41.748269       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:18:41.765064       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:18:41.772821       1 controller.go:123] Found 0 jobs
I0416 21:18:41.775597       1 controller.go:139] Found 0 cronjobs
I0416 21:18:41.775608       1 controller.go:142] Found 0 groups
I0416 21:18:42.052035       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:18:42.116416       1 gc_controller.go:144] GC'ing orphaned
I0416 21:18:42.122277       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:18:42.236825       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:18:42.558720       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:18:45.608409       1 wrap.go:47] GET /healthz: (167.898µs) 200 [kube-probe/1.15+ 127.0.0.1:39836]
I0416 21:18:46.765518       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 21:18:51.785915       1 controller.go:123] Found 0 jobs
I0416 21:18:51.793200       1 controller.go:139] Found 0 cronjobs
I0416 21:18:51.793214       1 controller.go:142] Found 0 groups
I0416 21:18:54.110634       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:18:55.516335       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:18:55.608983       1 wrap.go:47] GET /healthz: (88.329µs) 200 [kube-probe/1.15+ 127.0.0.1:39872]
I0416 21:18:55.890875       1 request.go:530] Throttling request took 91.681817ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:18:55.940944       1 request.go:530] Throttling request took 141.74117ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:18:55.990941       1 request.go:530] Throttling request took 191.728953ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:18:56.013303       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:18:56.040948       1 request.go:530] Throttling request took 241.726923ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:18:56.090839       1 request.go:530] Throttling request took 291.590797ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:18:56.140863       1 request.go:530] Throttling request took 341.607234ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:18:56.190918       1 request.go:530] Throttling request took 391.665291ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:18:56.240955       1 request.go:530] Throttling request took 441.694613ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:18:56.243392       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:18:57.052366       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:18:57.188191       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:18:57.188249       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:18:57.237162       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:00.464680       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 21:19:01.797773       1 controller.go:123] Found 0 jobs
I0416 21:19:01.800811       1 controller.go:139] Found 0 cronjobs
I0416 21:19:01.800825       1 controller.go:142] Found 0 groups
I0416 21:19:01.902345       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 5 items received
I0416 21:19:02.122570       1 gc_controller.go:144] GC'ing orphaned
I0416 21:19:02.127553       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:19:03.786332       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 21:19:05.608411       1 wrap.go:47] GET /healthz: (93.316µs) 200 [kube-probe/1.15+ 127.0.0.1:39906]
I0416 21:19:06.773497       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 0 items received
I0416 21:19:07.312904       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 3 items received
I0416 21:19:08.760777       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 0 items received
I0416 21:19:10.061020       1 request.go:530] Throttling request took 82.136791ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:19:10.110789       1 request.go:530] Throttling request took 131.878841ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:19:10.160786       1 request.go:530] Throttling request took 181.867427ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:19:10.210875       1 request.go:530] Throttling request took 231.939598ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:19:10.260789       1 request.go:530] Throttling request took 281.847994ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:19:10.310845       1 request.go:530] Throttling request took 331.896656ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:19:10.360815       1 request.go:530] Throttling request took 381.859393ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:19:10.411123       1 request.go:530] Throttling request took 432.157014ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:19:11.748697       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:11.765560       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:11.804450       1 controller.go:123] Found 0 jobs
I0416 21:19:11.807392       1 controller.go:139] Found 0 cronjobs
I0416 21:19:11.807413       1 controller.go:142] Found 0 groups
I0416 21:19:12.052662       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:19:12.237876       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:12.760477       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:19:12.782845       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 0 items received
I0416 21:19:13.700753       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:19:15.608513       1 wrap.go:47] GET /healthz: (97.493µs) 200 [kube-probe/1.15+ 127.0.0.1:39938]
I0416 21:19:18.818544       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:19:20.330294       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 207 items received
I0416 21:19:21.811325       1 controller.go:123] Found 0 jobs
I0416 21:19:21.814158       1 controller.go:139] Found 0 cronjobs
I0416 21:19:21.814171       1 controller.go:142] Found 0 groups
I0416 21:19:22.127851       1 gc_controller.go:144] GC'ing orphaned
I0416 21:19:22.132899       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:19:25.608402       1 wrap.go:47] GET /healthz: (181.137µs) 200 [kube-probe/1.15+ 127.0.0.1:39970]
I0416 21:19:25.798895       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:19:26.343882       1 request.go:530] Throttling request took 91.511715ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:19:26.393881       1 request.go:530] Throttling request took 141.491926ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:19:26.443881       1 request.go:530] Throttling request took 191.490345ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:19:26.494953       1 request.go:530] Throttling request took 242.536493ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:19:26.543882       1 request.go:530] Throttling request took 291.475836ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:19:26.593944       1 request.go:530] Throttling request took 341.529839ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:19:26.643918       1 request.go:530] Throttling request took 391.495527ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:19:26.693948       1 request.go:530] Throttling request took 441.503038ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:19:26.696164       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:19:27.052888       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:19:27.114316       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 21:19:27.191188       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:19:27.238295       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:31.818288       1 controller.go:123] Found 0 jobs
I0416 21:19:31.820592       1 controller.go:139] Found 0 cronjobs
I0416 21:19:31.820604       1 controller.go:142] Found 0 groups
I0416 21:19:35.608194       1 wrap.go:47] GET /healthz: (90.881µs) 200 [kube-probe/1.15+ 127.0.0.1:40004]
I0416 21:19:36.363634       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 21:19:38.304064       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 0 items received
I0416 21:19:40.515427       1 request.go:530] Throttling request took 92.420685ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:19:40.565338       1 request.go:530] Throttling request took 142.308555ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:19:40.615350       1 request.go:530] Throttling request took 192.308228ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:19:40.665397       1 request.go:530] Throttling request took 242.345578ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:19:40.715423       1 request.go:530] Throttling request took 292.353869ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:19:40.765532       1 request.go:530] Throttling request took 342.449051ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:19:40.815339       1 request.go:530] Throttling request took 392.256034ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:19:40.865400       1 request.go:530] Throttling request took 442.307234ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:19:41.749028       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:41.765854       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:41.824560       1 controller.go:123] Found 0 jobs
I0416 21:19:41.827308       1 controller.go:139] Found 0 cronjobs
I0416 21:19:41.827332       1 controller.go:142] Found 0 groups
I0416 21:19:42.053182       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:19:42.133258       1 gc_controller.go:144] GC'ing orphaned
I0416 21:19:42.137958       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:19:42.238582       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:42.762037       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 0 items received
I0416 21:19:44.735795       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:45.614102       1 wrap.go:47] GET /healthz: (91.866µs) 200 [kube-probe/1.15+ 127.0.0.1:40058]
I0416 21:19:51.763591       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 0 items received
I0416 21:19:51.831069       1 controller.go:123] Found 0 jobs
I0416 21:19:51.833307       1 controller.go:139] Found 0 cronjobs
I0416 21:19:51.833319       1 controller.go:142] Found 0 groups
I0416 21:19:54.201090       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:19:55.602564       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:19:55.608090       1 wrap.go:47] GET /healthz: (81.468µs) 200 [kube-probe/1.15+ 127.0.0.1:40094]
I0416 21:19:56.765911       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:19:56.796605       1 request.go:530] Throttling request took 91.904969ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:19:56.846604       1 request.go:530] Throttling request took 141.894807ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:19:56.896659       1 request.go:530] Throttling request took 191.937765ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:19:56.946642       1 request.go:530] Throttling request took 241.910805ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:19:56.996625       1 request.go:530] Throttling request took 291.884885ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:19:57.020323       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:19:57.046578       1 request.go:530] Throttling request took 341.821126ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:19:57.053399       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:19:57.096585       1 request.go:530] Throttling request took 391.807526ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:19:57.146649       1 request.go:530] Throttling request took 441.854036ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:19:57.149127       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:19:57.194179       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:19:57.194214       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:19:57.238984       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:19:58.788933       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 21:20:00.338278       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:00.338703       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:00.339283       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:00.339530       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:20:00.339635       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:20:00.339736       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:20:01.837381       1 controller.go:123] Found 0 jobs
I0416 21:20:01.840523       1 controller.go:139] Found 0 cronjobs
I0416 21:20:01.840536       1 controller.go:142] Found 0 groups
I0416 21:20:02.138211       1 gc_controller.go:144] GC'ing orphaned
I0416 21:20:02.142664       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:20:02.303947       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 0 items received
I0416 21:20:03.759181       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 21:20:05.608520       1 wrap.go:47] GET /healthz: (92.868µs) 200 [kube-probe/1.15+ 127.0.0.1:40128]
I0416 21:20:10.968284       1 request.go:530] Throttling request took 90.673311ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:20:11.018377       1 request.go:530] Throttling request took 140.756657ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:20:11.068305       1 request.go:530] Throttling request took 190.680015ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:20:11.118284       1 request.go:530] Throttling request took 240.650717ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:20:11.168341       1 request.go:530] Throttling request took 290.702693ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:20:11.218321       1 request.go:530] Throttling request took 340.671264ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:20:11.268346       1 request.go:530] Throttling request took 390.689659ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:20:11.318341       1 request.go:530] Throttling request took 440.67546ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:20:11.749302       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:11.766115       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:11.844566       1 controller.go:123] Found 0 jobs
I0416 21:20:11.847337       1 controller.go:139] Found 0 cronjobs
I0416 21:20:11.847359       1 controller.go:142] Found 0 groups
I0416 21:20:12.053661       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:20:12.239302       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.777633       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.779794       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.779884       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.780026       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:20:12.780042       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:20:12.780062       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:20:12.780057241 +0000 UTC m=+1034.933781392)
I0416 21:20:12.780730       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (667.888µs)
I0416 21:20:12.780757       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:20:12.780754371 +0000 UTC m=+1034.934478510)
I0416 21:20:12.781564       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (804.703µs)
I0416 21:20:12.781642       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:20:12.781654       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:20:12.781650375 +0000 UTC m=+1034.935374513)
I0416 21:20:12.782137       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (484.821µs)
I0416 21:20:12.782159       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:20:12.782167       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:20:12.782164829 +0000 UTC m=+1034.935888966)
I0416 21:20:12.783214       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.044296ms)
I0416 21:20:12.783270       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:20:12.783276       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:20:12.783284       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:20:12.783281 +0000 UTC m=+1034.937005138)
I0416 21:20:12.783889       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (604.051µs)
I0416 21:20:12.783926       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:20:12.78392339 +0000 UTC m=+1034.937647528)
I0416 21:20:12.785475       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (1.545936ms)
I0416 21:20:12.785512       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:20:12.785523       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:20:12.785519426 +0000 UTC m=+1034.939243564)
I0416 21:20:12.786025       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (503.208µs)
I0416 21:20:12.786044       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:20:12.788254       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:20:12.788247921 +0000 UTC m=+1034.941972078)
I0416 21:20:12.789118       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (867.207µs)
I0416 21:20:12.789155       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.789856       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.789978       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.789993       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.790185       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:20:12.790208       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790212       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:20:12.790259       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:20:12.790267       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790270       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:20:12.790298       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:20:12.790307       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790310       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:20:12.790340       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:20:12.790348       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790350       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:20:12.790377       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:20:12.790385       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790388       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:20:12.790408       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:20:12.790415       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790418       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:20:12.790464       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:20:12.790474       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790477       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:20:12.790516       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:20:12.790521       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790523       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:20:12.790527       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:20:12.790536       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790538       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:20:12.790578       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:20:12.790586       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790589       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:20:12.790624       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:20:12.790637       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790642       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:20:12.790678       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:20:12.790691       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790696       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:20:12.790727       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:20:12.790734       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790737       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:20:12.790740       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:20:12.790747       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790750       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:20:12.790785       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:20:12.790793       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790795       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:20:12.790858       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:20:12.790865       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790868       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:20:12.790895       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:20:12.790899       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790901       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:20:12.790941       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:20:12.790949       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.790952       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:20:12.790995       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:20:12.791004       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.791006       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:20:12.791026       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:20:12.791034       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.791036       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:20:12.791089       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:20:12.791102       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.791104       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:20:12.791107       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:20:12.791114       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:20:12.791117       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:20:12.793726       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.793801       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:20:12.793812       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:20:12.794509       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25af6542353917, ext:787190766629, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.794799       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:20:12.794813       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25afa32f5fcf03, ext:1034948532217, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.794891       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:20:12.794924       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:20:12.794928       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25afa32f5fcf03, ext:1034948532217, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.794978       1 update.go:396] Getting unavailable numbers
I0416 21:20:12.795072       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:20:12.795078       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:20:12.795085       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:20:12.795090       1 update.go:68] Marking old pods for deletion
I0416 21:20:12.795095       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25afa32f6428c5, ext:1034948817463, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.795101       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:20:12.795143       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:20:12.795164       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:20:12.795303       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:20:12.795329       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.483085ms)
I0416 21:20:12.796673       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25af6542206d64, ext:787189403724, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.796905       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:20:12.796916       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25afa32f7fee5b, ext:1034950637392, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.796925       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:20:12.796959       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:20:12.796963       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25afa32f7fee5b, ext:1034950637392, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.797007       1 update.go:396] Getting unavailable numbers
I0416 21:20:12.797101       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:20:12.797106       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:20:12.797111       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:20:12.797115       1 update.go:68] Marking old pods for deletion
I0416 21:20:12.797119       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25afa32f830bfa, ext:1034950841811, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.797125       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:20:12.797166       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:20:12.797188       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:20:12.797700       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:20:12.797709       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.356952ms)
I0416 21:20:12.799438       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.799553       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.799724       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (177.247µs)
I0416 21:20:12.799790       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.799928       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800006       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (80.732µs)
I0416 21:20:12.800048       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800130       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (84.893µs)
I0416 21:20:12.800140       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800196       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (57.451µs)
I0416 21:20:12.800212       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800300       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (90.529µs)
I0416 21:20:12.800333       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800388       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (55.712µs)
I0416 21:20:12.800429       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.800453       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.800462       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.800484       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.800578       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800631       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (55.399µs)
I0416 21:20:12.800649       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800731       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (83.83µs)
I0416 21:20:12.800741       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800812       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (72.707µs)
I0416 21:20:12.800831       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:20:12.800887       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (49.861µs)
I0416 21:20:12.857969       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.940055       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:12.978648       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:13.007558       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:13.126719       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:13.200699       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:13.300413       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:13.349923       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:13.350121       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:20:13.350154       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.875µs)
I0416 21:20:13.350223       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:20:13.350259       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:20:13.350269       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:20:13.350275       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (945ns)
I0416 21:20:13.350287       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (523ns)
I0416 21:20:13.350296       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (297ns)
I0416 21:20:13.400335       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:13.555100       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:15.609220       1 wrap.go:47] GET /healthz: (97.632µs) 200 [kube-probe/1.15+ 127.0.0.1:40160]
I0416 21:20:21.851360       1 controller.go:123] Found 0 jobs
I0416 21:20:21.854036       1 controller.go:139] Found 0 cronjobs
I0416 21:20:21.854047       1 controller.go:142] Found 0 groups
I0416 21:20:22.142964       1 gc_controller.go:144] GC'ing orphaned
I0416 21:20:22.147725       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:20:22.455420       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:25.608431       1 wrap.go:47] GET /healthz: (85.552µs) 200 [kube-probe/1.15+ 127.0.0.1:40192]
I0416 21:20:25.883659       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:20:27.053956       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:20:27.196955       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:20:27.239600       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:27.249857       1 request.go:530] Throttling request took 92.282373ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:20:27.299756       1 request.go:530] Throttling request took 142.178327ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:20:27.352919       1 request.go:530] Throttling request took 195.326545ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:20:27.399690       1 request.go:530] Throttling request took 242.099905ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:20:27.449745       1 request.go:530] Throttling request took 292.130551ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:20:27.499728       1 request.go:530] Throttling request took 342.104802ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:20:27.549730       1 request.go:530] Throttling request took 392.102779ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:20:27.599705       1 request.go:530] Throttling request took 442.065094ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:20:27.602079       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:20:30.441817       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:31.858041       1 controller.go:123] Found 0 jobs
I0416 21:20:31.860318       1 controller.go:139] Found 0 cronjobs
I0416 21:20:31.860327       1 controller.go:142] Found 0 groups
I0416 21:20:35.608548       1 wrap.go:47] GET /healthz: (86.944µs) 200 [kube-probe/1.15+ 127.0.0.1:40226]
I0416 21:20:40.450050       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:20:41.421062       1 request.go:530] Throttling request took 91.660771ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:20:41.471140       1 request.go:530] Throttling request took 141.690837ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:20:41.521077       1 request.go:530] Throttling request took 191.643114ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:20:41.571072       1 request.go:530] Throttling request took 241.608852ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:20:41.621105       1 request.go:530] Throttling request took 291.630192ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:20:41.671032       1 request.go:530] Throttling request took 341.551962ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:20:41.721178       1 request.go:530] Throttling request took 391.687265ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:20:41.749603       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:41.766359       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:41.771115       1 request.go:530] Throttling request took 441.583189ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:20:41.864748       1 controller.go:123] Found 0 jobs
I0416 21:20:41.867545       1 controller.go:139] Found 0 cronjobs
I0416 21:20:41.867557       1 controller.go:142] Found 0 groups
I0416 21:20:42.054267       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:20:42.147965       1 gc_controller.go:144] GC'ing orphaned
I0416 21:20:42.154908       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:20:42.239927       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:45.618964       1 wrap.go:47] GET /healthz: (88.86µs) 200 [kube-probe/1.15+ 127.0.0.1:40280]
I0416 21:20:46.790258       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 21:20:49.033641       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:51.872523       1 controller.go:123] Found 0 jobs
I0416 21:20:51.878546       1 controller.go:139] Found 0 cronjobs
I0416 21:20:51.878558       1 controller.go:142] Found 0 groups
I0416 21:20:54.289836       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:20:55.608603       1 wrap.go:47] GET /healthz: (85.678µs) 200 [kube-probe/1.15+ 127.0.0.1:40316]
I0416 21:20:55.734108       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:20:57.022799       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:20:57.054541       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:20:57.199397       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:20:57.199434       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:20:57.240300       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:20:57.702585       1 request.go:530] Throttling request took 91.143934ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:20:57.752682       1 request.go:530] Throttling request took 141.214976ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:20:57.802568       1 request.go:530] Throttling request took 191.098631ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:20:57.852595       1 request.go:530] Throttling request took 241.116325ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:20:57.902646       1 request.go:530] Throttling request took 291.161368ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:20:57.952534       1 request.go:530] Throttling request took 341.03962ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:20:58.002612       1 request.go:530] Throttling request took 391.099211ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:20:58.052673       1 request.go:530] Throttling request took 441.145399ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:20:58.055555       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:20:59.776400       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:21:01.882662       1 controller.go:123] Found 0 jobs
I0416 21:21:01.885063       1 controller.go:139] Found 0 cronjobs
I0416 21:21:01.885074       1 controller.go:142] Found 0 groups
I0416 21:21:02.155191       1 gc_controller.go:144] GC'ing orphaned
I0416 21:21:02.159631       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:21:04.965592       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:05.608701       1 wrap.go:47] GET /healthz: (85.325µs) 200 [kube-probe/1.15+ 127.0.0.1:40350]
I0416 21:21:08.795807       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:21:11.749958       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:11.766917       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:11.874252       1 request.go:530] Throttling request took 89.90492ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:21:11.889512       1 controller.go:123] Found 0 jobs
I0416 21:21:11.892616       1 controller.go:139] Found 0 cronjobs
I0416 21:21:11.892628       1 controller.go:142] Found 0 groups
I0416 21:21:11.924283       1 request.go:530] Throttling request took 139.925621ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:21:11.974172       1 request.go:530] Throttling request took 189.804636ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:21:12.024201       1 request.go:530] Throttling request took 239.787709ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:21:12.054838       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:21:12.074634       1 request.go:530] Throttling request took 290.239571ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:21:12.124281       1 request.go:530] Throttling request took 339.835889ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:21:12.174383       1 request.go:530] Throttling request took 389.948994ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:21:12.224318       1 request.go:530] Throttling request took 439.886492ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:21:12.241318       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:15.608594       1 wrap.go:47] GET /healthz: (84.368µs) 200 [kube-probe/1.15+ 127.0.0.1:40382]
I0416 21:21:21.896553       1 controller.go:123] Found 0 jobs
I0416 21:21:21.899031       1 controller.go:139] Found 0 cronjobs
I0416 21:21:21.899052       1 controller.go:142] Found 0 groups
I0416 21:21:22.160008       1 gc_controller.go:144] GC'ing orphaned
I0416 21:21:22.163971       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:21:25.608408       1 wrap.go:47] GET /healthz: (106.963µs) 200 [kube-probe/1.15+ 127.0.0.1:40414]
I0416 21:21:25.981992       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:21:27.055132       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:21:27.201972       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:21:27.241675       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:28.156204       1 request.go:530] Throttling request took 91.545357ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:21:28.206122       1 request.go:530] Throttling request took 141.461431ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:21:28.256293       1 request.go:530] Throttling request took 191.625144ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:21:28.306154       1 request.go:530] Throttling request took 241.452906ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:21:28.356157       1 request.go:530] Throttling request took 291.375561ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:21:28.406164       1 request.go:530] Throttling request took 341.450014ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:21:28.457250       1 request.go:530] Throttling request took 392.502061ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:21:28.506131       1 request.go:530] Throttling request took 441.4009ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:21:28.508511       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:21:31.903149       1 controller.go:123] Found 0 jobs
I0416 21:21:31.905924       1 controller.go:139] Found 0 cronjobs
I0416 21:21:31.905937       1 controller.go:142] Found 0 groups
I0416 21:21:35.608484       1 wrap.go:47] GET /healthz: (86.509µs) 200 [kube-probe/1.15+ 127.0.0.1:40448]
I0416 21:21:37.928010       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 21:21:38.786665       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 0 items received
I0416 21:21:41.751370       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:41.751529       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (5.636µs)
I0416 21:21:41.751957       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:21:41.752925       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (189.321µs)
I0416 21:21:41.753025       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (75.295µs)
I0416 21:21:41.753116       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (69.717µs)
I0416 21:21:41.753196       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (67.362µs)
I0416 21:21:41.761488       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (9.900157ms)
I0416 21:21:41.769033       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:41.909838       1 controller.go:123] Found 0 jobs
I0416 21:21:41.912106       1 controller.go:139] Found 0 cronjobs
I0416 21:21:41.912116       1 controller.go:142] Found 0 groups
I0416 21:21:42.055575       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:21:42.164241       1 gc_controller.go:144] GC'ing orphaned
I0416 21:21:42.168860       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:21:42.243325       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:42.327794       1 request.go:530] Throttling request took 90.92066ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:21:42.377813       1 request.go:530] Throttling request took 140.933737ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:21:42.427725       1 request.go:530] Throttling request took 190.831546ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:21:42.477735       1 request.go:530] Throttling request took 240.842609ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:21:42.527784       1 request.go:530] Throttling request took 290.859526ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:21:42.577781       1 request.go:530] Throttling request took 340.845309ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:21:42.627731       1 request.go:530] Throttling request took 390.788044ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:21:42.677800       1 request.go:530] Throttling request took 440.846326ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:21:45.412371       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 21:21:45.609530       1 wrap.go:47] GET /healthz: (129.476µs) 200 [kube-probe/1.15+ 127.0.0.1:40502]
I0416 21:21:48.219113       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 21:21:51.924609       1 controller.go:123] Found 0 jobs
I0416 21:21:51.931987       1 controller.go:139] Found 0 cronjobs
I0416 21:21:51.931999       1 controller.go:142] Found 0 groups
I0416 21:21:54.379666       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:21:55.608479       1 wrap.go:47] GET /healthz: (101.363µs) 200 [kube-probe/1.15+ 127.0.0.1:40538]
I0416 21:21:55.835098       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:21:57.026974       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:21:57.055964       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:21:57.204460       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:21:57.204497       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:21:57.243623       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:21:58.608992       1 request.go:530] Throttling request took 88.36563ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:21:58.658956       1 request.go:530] Throttling request took 138.316973ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:21:58.709096       1 request.go:530] Throttling request took 188.448012ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:21:58.759015       1 request.go:530] Throttling request took 238.349973ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:21:58.809022       1 request.go:530] Throttling request took 288.356224ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:21:58.859038       1 request.go:530] Throttling request took 338.361637ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:21:58.909104       1 request.go:530] Throttling request took 388.410188ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:21:58.959050       1 request.go:530] Throttling request took 438.34077ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:21:58.961620       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:22:01.935916       1 controller.go:123] Found 0 jobs
I0416 21:22:01.938512       1 controller.go:139] Found 0 cronjobs
I0416 21:22:01.938524       1 controller.go:142] Found 0 groups
I0416 21:22:02.169244       1 gc_controller.go:144] GC'ing orphaned
I0416 21:22:02.173650       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:22:02.946354       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 21:22:05.608498       1 wrap.go:47] GET /healthz: (116.137µs) 200 [kube-probe/1.15+ 127.0.0.1:40572]
I0416 21:22:08.396821       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:11.751747       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:11.769450       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:11.942050       1 controller.go:123] Found 0 jobs
I0416 21:22:11.944171       1 controller.go:139] Found 0 cronjobs
I0416 21:22:11.944182       1 controller.go:142] Found 0 groups
I0416 21:22:12.056355       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:22:12.243882       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:12.677517       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:22:12.781591       1 request.go:530] Throttling request took 93.39052ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:22:12.831175       1 request.go:530] Throttling request took 142.964144ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:22:12.881369       1 request.go:530] Throttling request took 193.150299ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:22:12.931372       1 request.go:530] Throttling request took 243.135826ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:22:12.981321       1 request.go:530] Throttling request took 293.073033ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:22:13.031721       1 request.go:530] Throttling request took 343.463626ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:22:13.081303       1 request.go:530] Throttling request took 393.007629ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:22:13.131172       1 request.go:530] Throttling request took 442.884363ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:22:13.841508       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:22:15.608492       1 wrap.go:47] GET /healthz: (71.386µs) 200 [kube-probe/1.15+ 127.0.0.1:40604]
I0416 21:22:16.978994       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 21:22:21.783509       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:22:21.948010       1 controller.go:123] Found 0 jobs
I0416 21:22:21.950599       1 controller.go:139] Found 0 cronjobs
I0416 21:22:21.950612       1 controller.go:142] Found 0 groups
I0416 21:22:22.173985       1 gc_controller.go:144] GC'ing orphaned
I0416 21:22:22.178664       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:22:25.608415       1 wrap.go:47] GET /healthz: (207.032µs) 200 [kube-probe/1.15+ 127.0.0.1:40636]
I0416 21:22:26.165298       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:22:27.056700       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:22:27.206801       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:22:27.244301       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:29.064031       1 request.go:530] Throttling request took 84.318449ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:22:29.113521       1 request.go:530] Throttling request took 133.817283ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:22:29.163496       1 request.go:530] Throttling request took 183.78911ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:22:29.213582       1 request.go:530] Throttling request took 233.864701ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:22:29.264091       1 request.go:530] Throttling request took 284.362857ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:22:29.313720       1 request.go:530] Throttling request took 333.964144ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:22:29.363529       1 request.go:530] Throttling request took 383.793118ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:22:29.413793       1 request.go:530] Throttling request took 434.042011ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:22:29.415864       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:22:31.954464       1 controller.go:123] Found 0 jobs
I0416 21:22:31.957050       1 controller.go:139] Found 0 cronjobs
I0416 21:22:31.957063       1 controller.go:142] Found 0 groups
I0416 21:22:35.608641       1 wrap.go:47] GET /healthz: (82.513µs) 200 [kube-probe/1.15+ 127.0.0.1:40670]
I0416 21:22:41.757085       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:41.775342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:41.961329       1 controller.go:123] Found 0 jobs
I0416 21:22:41.964181       1 controller.go:139] Found 0 cronjobs
I0416 21:22:41.964194       1 controller.go:142] Found 0 groups
I0416 21:22:42.057102       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:22:42.179034       1 gc_controller.go:144] GC'ing orphaned
I0416 21:22:42.184084       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:22:42.244582       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:43.237911       1 request.go:530] Throttling request took 80.26346ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:22:43.287755       1 request.go:530] Throttling request took 130.251477ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:22:43.341473       1 request.go:530] Throttling request took 183.975775ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:22:43.390398       1 request.go:530] Throttling request took 232.903769ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:22:43.438115       1 request.go:530] Throttling request took 280.570777ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:22:43.487346       1 request.go:530] Throttling request took 329.817759ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:22:43.537338       1 request.go:530] Throttling request took 379.805679ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:22:43.588343       1 request.go:530] Throttling request took 430.799852ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:22:45.608127       1 wrap.go:47] GET /healthz: (91.894µs) 200 [kube-probe/1.15+ 127.0.0.1:40722]
I0416 21:22:51.973007       1 controller.go:123] Found 0 jobs
I0416 21:22:51.979934       1 controller.go:139] Found 0 cronjobs
I0416 21:22:51.979948       1 controller.go:142] Found 0 groups
I0416 21:22:52.786297       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 21:22:54.466941       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:22:55.613294       1 wrap.go:47] GET /healthz: (121.322µs) 200 [kube-probe/1.15+ 127.0.0.1:40760]
I0416 21:22:55.946639       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:22:57.057381       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:22:57.209542       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:22:57.209581       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:22:57.244911       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:22:58.031886       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:22:59.517509       1 request.go:530] Throttling request took 90.42097ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:22:59.567559       1 request.go:530] Throttling request took 140.435356ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:22:59.617519       1 request.go:530] Throttling request took 190.404312ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:22:59.667473       1 request.go:530] Throttling request took 240.35091ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:22:59.717505       1 request.go:530] Throttling request took 290.373971ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:22:59.767596       1 request.go:530] Throttling request took 340.459317ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:22:59.817543       1 request.go:530] Throttling request took 390.398162ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:22:59.867940       1 request.go:530] Throttling request took 440.803049ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:22:59.869966       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:23:01.983822       1 controller.go:123] Found 0 jobs
I0416 21:23:01.986169       1 controller.go:139] Found 0 cronjobs
I0416 21:23:01.986181       1 controller.go:142] Found 0 groups
I0416 21:23:02.184345       1 gc_controller.go:144] GC'ing orphaned
I0416 21:23:02.190400       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:23:04.267131       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 103 items received
I0416 21:23:05.608457       1 wrap.go:47] GET /healthz: (96.572µs) 200 [kube-probe/1.15+ 127.0.0.1:40794]
I0416 21:23:09.799120       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 21:23:11.759753       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:11.775878       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:11.990002       1 controller.go:123] Found 0 jobs
I0416 21:23:11.992524       1 controller.go:139] Found 0 cronjobs
I0416 21:23:11.992536       1 controller.go:142] Found 0 groups
I0416 21:23:12.057682       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:23:12.245171       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:13.691931       1 request.go:530] Throttling request took 91.455754ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:23:13.741969       1 request.go:530] Throttling request took 141.48267ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:23:13.791832       1 request.go:530] Throttling request took 191.346959ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:23:13.794036       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
I0416 21:23:13.841852       1 request.go:530] Throttling request took 241.344974ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:23:13.891841       1 request.go:530] Throttling request took 291.317586ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:23:13.941894       1 request.go:530] Throttling request took 341.360931ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:23:13.991813       1 request.go:530] Throttling request took 391.257125ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:23:14.041889       1 request.go:530] Throttling request took 441.339761ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:23:15.608753       1 wrap.go:47] GET /healthz: (74.55µs) 200 [kube-probe/1.15+ 127.0.0.1:40826]
I0416 21:23:17.005307       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 21:23:17.775178       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 21:23:21.997017       1 controller.go:123] Found 0 jobs
I0416 21:23:21.999874       1 controller.go:139] Found 0 cronjobs
I0416 21:23:21.999905       1 controller.go:142] Found 0 groups
I0416 21:23:22.190733       1 gc_controller.go:144] GC'ing orphaned
I0416 21:23:22.195866       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:23:25.608537       1 wrap.go:47] GET /healthz: (139.639µs) 200 [kube-probe/1.15+ 127.0.0.1:40858]
I0416 21:23:25.824167       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 0 items received
I0416 21:23:26.372881       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:23:27.057988       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:23:27.211899       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:23:27.245481       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:29.325338       1 reflector.go:249] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: forcing resync
I0416 21:23:29.970430       1 request.go:530] Throttling request took 94.22407ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:23:30.020512       1 request.go:530] Throttling request took 144.254531ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:23:30.070449       1 request.go:530] Throttling request took 194.219304ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:23:30.092960       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 21:23:30.120554       1 request.go:530] Throttling request took 244.316601ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:23:30.170444       1 request.go:530] Throttling request took 294.199168ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:23:30.220426       1 request.go:530] Throttling request took 344.156329ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:23:30.270486       1 request.go:530] Throttling request took 391.092878ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:23:30.320416       1 request.go:530] Throttling request took 441.056668ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:23:30.322737       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:23:32.004524       1 controller.go:123] Found 0 jobs
I0416 21:23:32.008974       1 controller.go:139] Found 0 cronjobs
I0416 21:23:32.008985       1 controller.go:142] Found 0 groups
I0416 21:23:35.608614       1 wrap.go:47] GET /healthz: (89.201µs) 200 [kube-probe/1.15+ 127.0.0.1:40892]
I0416 21:23:39.781195       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:23:41.760088       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:41.776159       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:42.014113       1 controller.go:123] Found 0 jobs
I0416 21:23:42.016654       1 controller.go:139] Found 0 cronjobs
I0416 21:23:42.016665       1 controller.go:142] Found 0 groups
I0416 21:23:42.058651       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:23:42.196205       1 gc_controller.go:144] GC'ing orphaned
I0416 21:23:42.200863       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:23:42.245750       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:42.559041       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:23:42.598322       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:44.144678       1 request.go:530] Throttling request took 92.413308ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:23:44.194701       1 request.go:530] Throttling request took 140.189675ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:23:44.244928       1 request.go:530] Throttling request took 190.221039ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:23:44.294755       1 request.go:530] Throttling request took 240.195709ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:23:44.344732       1 request.go:530] Throttling request took 290.151239ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:23:44.394774       1 request.go:530] Throttling request took 340.131954ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:23:44.444727       1 request.go:530] Throttling request took 390.107822ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:23:44.494841       1 request.go:530] Throttling request took 440.216667ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:23:45.304543       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:45.608266       1 wrap.go:47] GET /healthz: (89.584µs) 200 [kube-probe/1.15+ 127.0.0.1:40940]
I0416 21:23:52.020650       1 controller.go:123] Found 0 jobs
I0416 21:23:52.023706       1 controller.go:139] Found 0 cronjobs
I0416 21:23:52.023718       1 controller.go:142] Found 0 groups
I0416 21:23:52.181989       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:54.555037       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:23:55.609896       1 wrap.go:47] GET /healthz: (99.875µs) 200 [kube-probe/1.15+ 127.0.0.1:40982]
I0416 21:23:56.039311       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:23:57.058954       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:23:57.214368       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:23:57.214405       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:23:57.246183       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:23:59.033592       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:24:00.423254       1 request.go:530] Throttling request took 92.002868ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:24:00.473298       1 request.go:530] Throttling request took 142.049874ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:24:00.523308       1 request.go:530] Throttling request took 192.051244ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:24:00.573360       1 request.go:530] Throttling request took 242.098672ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:24:00.623282       1 request.go:530] Throttling request took 291.998969ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:24:00.673292       1 request.go:530] Throttling request took 341.994733ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:24:00.723265       1 request.go:530] Throttling request took 391.942517ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:24:00.773319       1 request.go:530] Throttling request took 442.006137ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:24:00.775517       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:24:02.027984       1 controller.go:123] Found 0 jobs
I0416 21:24:02.030867       1 controller.go:139] Found 0 cronjobs
I0416 21:24:02.030880       1 controller.go:142] Found 0 groups
I0416 21:24:02.201060       1 gc_controller.go:144] GC'ing orphaned
I0416 21:24:02.205830       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:24:05.516114       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 21:24:05.609170       1 wrap.go:47] GET /healthz: (84.537µs) 200 [kube-probe/1.15+ 127.0.0.1:41016]
I0416 21:24:05.768265       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 21:24:08.099252       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:08.099583       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:24:08.099687       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:24:08.099776       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:24:11.760400       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:11.776482       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:12.034603       1 controller.go:123] Found 0 jobs
I0416 21:24:12.036985       1 controller.go:139] Found 0 cronjobs
I0416 21:24:12.036996       1 controller.go:142] Found 0 groups
I0416 21:24:12.059561       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:24:12.246850       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:14.487742       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:14.597839       1 request.go:530] Throttling request took 91.964582ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:24:14.647838       1 request.go:530] Throttling request took 141.934261ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:24:14.697803       1 request.go:530] Throttling request took 191.897101ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:24:14.748363       1 request.go:530] Throttling request took 242.433587ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:24:14.797853       1 request.go:530] Throttling request took 291.921932ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:24:14.847847       1 request.go:530] Throttling request took 341.912946ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:24:14.897846       1 request.go:530] Throttling request took 391.898051ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:24:14.947871       1 request.go:530] Throttling request took 441.916474ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:24:15.608465       1 wrap.go:47] GET /healthz: (102.414µs) 200 [kube-probe/1.15+ 127.0.0.1:41048]
I0416 21:24:18.795223       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 365 items received
I0416 21:24:20.539816       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.539935       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:24:20.539951       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:24:20.539973       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:24:20.539967903 +0000 UTC m=+1282.693692041)
I0416 21:24:20.540810       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (838.577µs)
I0416 21:24:20.540837       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:24:20.540835153 +0000 UTC m=+1282.694559292)
I0416 21:24:20.542073       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.232347ms)
I0416 21:24:20.542123       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:24:20.542133       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:24:20.542142       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:24:20.54213921 +0000 UTC m=+1282.695863347)
I0416 21:24:20.542818       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (676.71µs)
I0416 21:24:20.542830       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:24:20.542827801 +0000 UTC m=+1282.696551939)
I0416 21:24:20.543289       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (458.514µs)
I0416 21:24:20.543311       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:24:20.543333       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:24:20.543340       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:24:20.543338332 +0000 UTC m=+1282.697062471)
I0416 21:24:20.543789       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (448.867µs)
I0416 21:24:20.543798       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:24:20.54379631 +0000 UTC m=+1282.697520447)
I0416 21:24:20.544988       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (1.188052ms)
I0416 21:24:20.545010       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:24:20.545016       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:24:20.545040       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:24:20.545037094 +0000 UTC m=+1282.698761232)
I0416 21:24:20.545372       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (333.135µs)
I0416 21:24:20.545383       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:24:20.545380866 +0000 UTC m=+1282.699105003)
I0416 21:24:20.545996       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (612.117µs)
I0416 21:24:20.552551       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.552640       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.552803       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.553006       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:24:20.553039       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.553044       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:24:20.553096       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:24:20.553107       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.553110       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:24:20.553140       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:24:20.553149       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.553152       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:24:20.553190       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:24:20.553199       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.553202       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:24:20.554396       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:24:20.554436       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.554440       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:24:20.554443       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:24:20.554452       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.554455       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:24:20.554480       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:24:20.554515       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.554518       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:24:20.554569       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:24:20.554574       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.554577       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:24:20.554618       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.554668       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:24:20.555937       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25afa32f830bfa, ext:1034950841811, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.556152       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:24:20.556163       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25afe1212654aa, ext:1282709884319, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.556346       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:24:20.556411       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:24:20.556416       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25afe1212654aa, ext:1282709884319, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.556472       1 update.go:396] Getting unavailable numbers
I0416 21:24:20.556570       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:24:20.556576       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:24:20.556582       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:24:20.556587       1 update.go:68] Marking old pods for deletion
I0416 21:24:20.556591       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25afe1212ce147, ext:1282710313524, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.556612       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:24:20.556637       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:24:20.556660       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:24:20.556772       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:24:20.556779       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.086125ms)
I0416 21:24:20.556825       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:24:20.556854       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.556858       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:24:20.556984       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:24:20.557528       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25afa32f6428c5, ext:1034948817463, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.557723       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:24:20.557746       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25afe1213e7d2c, ext:1282711467601, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.557782       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:24:20.557826       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:24:20.557830       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25afe1213e7d2c, ext:1282711467601, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.557859       1 update.go:396] Getting unavailable numbers
I0416 21:24:20.557955       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:24:20.557960       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:24:20.557965       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:24:20.557969       1 update.go:68] Marking old pods for deletion
I0416 21:24:20.557985       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25afe121422682, ext:1282711707556, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.557991       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:24:20.558014       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:24:20.558033       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:24:20.558166       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:24:20.558171       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.174368ms)
I0416 21:24:20.558203       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:24:20.558249       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558252       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:24:20.558256       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:24:20.558264       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558267       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:24:20.558334       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:24:20.558343       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558345       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:24:20.558407       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:24:20.558414       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558417       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:24:20.558459       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:24:20.558470       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558485       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:24:20.558504       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:24:20.558511       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558514       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:24:20.558539       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:24:20.558547       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558549       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:24:20.558566       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:24:20.558573       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558576       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:24:20.558605       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:24:20.558613       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.558615       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:24:20.558990       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:24:20.559004       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.559025       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:24:20.559049       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:24:20.559056       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.559059       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:24:20.559078       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:24:20.559085       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.559087       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:24:20.559138       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:24:20.559142       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:24:20.559145       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:24:20.562850       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.563006       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.563193       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (197.082µs)
I0416 21:24:20.563313       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.563331       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.563408       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.563483       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (77.55µs)
I0416 21:24:20.563494       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.563547       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (55.159µs)
I0416 21:24:20.563573       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.563644       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (73.261µs)
I0416 21:24:20.563653       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.563705       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (53.542µs)
I0416 21:24:20.563721       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.563779       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (59.642µs)
I0416 21:24:20.563800       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.563880       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (83.935µs)
I0416 21:24:20.563888       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.563940       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (52.566µs)
I0416 21:24:20.563962       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.564025       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (68.446µs)
I0416 21:24:20.564043       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:24:20.564118       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (77.601µs)
I0416 21:24:20.738897       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:20.767526       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:21.109897       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:21.109986       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:24:21.110017       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.856µs)
I0416 21:24:21.110056       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:24:21.110061       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (457ns)
I0416 21:24:21.110070       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:24:21.110079       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:24:21.110090       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (396ns)
I0416 21:24:21.110099       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (277ns)
I0416 21:24:21.160334       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:22.040754       1 controller.go:123] Found 0 jobs
I0416 21:24:22.043396       1 controller.go:139] Found 0 cronjobs
I0416 21:24:22.043410       1 controller.go:142] Found 0 groups
I0416 21:24:22.205979       1 gc_controller.go:144] GC'ing orphaned
I0416 21:24:22.210281       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:24:25.608549       1 wrap.go:47] GET /healthz: (78.873µs) 200 [kube-probe/1.15+ 127.0.0.1:41080]
I0416 21:24:26.559565       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:24:26.788530       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 21:24:27.059921       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:24:27.217283       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:24:27.247220       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:30.876099       1 request.go:530] Throttling request took 93.042504ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:24:30.926071       1 request.go:530] Throttling request took 143.007018ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:24:30.976030       1 request.go:530] Throttling request took 192.946576ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:24:31.026304       1 request.go:530] Throttling request took 243.224815ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:24:31.076068       1 request.go:530] Throttling request took 292.986572ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:24:31.126168       1 request.go:530] Throttling request took 343.00016ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:24:31.176049       1 request.go:530] Throttling request took 392.951831ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:24:31.226131       1 request.go:530] Throttling request took 442.946038ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:24:31.228088       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:24:32.047263       1 controller.go:123] Found 0 jobs
I0416 21:24:32.049420       1 controller.go:139] Found 0 cronjobs
I0416 21:24:32.049432       1 controller.go:142] Found 0 groups
I0416 21:24:33.606390       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:35.608650       1 wrap.go:47] GET /healthz: (79.809µs) 200 [kube-probe/1.15+ 127.0.0.1:41114]
I0416 21:24:41.761607       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:41.776756       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:42.053147       1 controller.go:123] Found 0 jobs
I0416 21:24:42.055570       1 controller.go:139] Found 0 cronjobs
I0416 21:24:42.055581       1 controller.go:142] Found 0 groups
I0416 21:24:42.060562       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:24:42.211036       1 gc_controller.go:144] GC'ing orphaned
I0416 21:24:42.217189       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:24:42.247740       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:45.050825       1 request.go:530] Throttling request took 91.479696ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:24:45.100818       1 request.go:530] Throttling request took 140.081133ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:24:45.150951       1 request.go:530] Throttling request took 190.198579ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:24:45.201418       1 request.go:530] Throttling request took 240.650459ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:24:45.250948       1 request.go:530] Throttling request took 290.029824ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:24:45.300947       1 request.go:530] Throttling request took 340.139184ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:24:45.350908       1 request.go:530] Throttling request took 390.08677ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:24:45.401133       1 request.go:530] Throttling request took 440.29752ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:24:45.609136       1 wrap.go:47] GET /healthz: (100.781µs) 200 [kube-probe/1.15+ 127.0.0.1:41168]
I0416 21:24:47.778751       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 21:24:51.766316       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 0 items received
I0416 21:24:52.061450       1 controller.go:123] Found 0 jobs
I0416 21:24:52.067488       1 controller.go:139] Found 0 cronjobs
I0416 21:24:52.067500       1 controller.go:142] Found 0 groups
I0416 21:24:52.307447       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 24 items received
I0416 21:24:54.643584       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:24:55.608756       1 wrap.go:47] GET /healthz: (87.88µs) 200 [kube-probe/1.15+ 127.0.0.1:41210]
I0416 21:24:56.124253       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:24:57.060866       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:24:57.219776       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:24:57.219824       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:24:57.248053       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:24:59.037854       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:24:59.771933       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 21:25:01.026575       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 21:25:01.328661       1 request.go:530] Throttling request took 90.020648ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:25:01.381341       1 request.go:530] Throttling request took 142.680179ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:25:01.429334       1 request.go:530] Throttling request took 190.662659ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:25:01.478733       1 request.go:530] Throttling request took 240.048936ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:25:01.528705       1 request.go:530] Throttling request took 290.013655ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:25:01.578761       1 request.go:530] Throttling request took 340.062159ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:25:01.628713       1 request.go:530] Throttling request took 389.993153ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:25:01.678798       1 request.go:530] Throttling request took 440.049207ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:25:01.681382       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:25:02.071549       1 controller.go:123] Found 0 jobs
I0416 21:25:02.073738       1 controller.go:139] Found 0 cronjobs
I0416 21:25:02.073749       1 controller.go:142] Found 0 groups
I0416 21:25:02.217435       1 gc_controller.go:144] GC'ing orphaned
I0416 21:25:02.222400       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:25:05.608830       1 wrap.go:47] GET /healthz: (101.207µs) 200 [kube-probe/1.15+ 127.0.0.1:41244]
I0416 21:25:11.762217       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:11.777216       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:12.061220       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:25:12.077747       1 controller.go:123] Found 0 jobs
I0416 21:25:12.080280       1 controller.go:139] Found 0 cronjobs
I0416 21:25:12.080299       1 controller.go:142] Found 0 groups
I0416 21:25:12.248553       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:13.982354       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:25:14.791511       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 21:25:15.503871       1 request.go:530] Throttling request took 92.059826ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:25:15.554993       1 request.go:530] Throttling request took 143.16897ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:25:15.603625       1 request.go:530] Throttling request took 191.796444ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:25:15.612844       1 wrap.go:47] GET /healthz: (122.7µs) 200 [kube-probe/1.15+ 127.0.0.1:41276]
I0416 21:25:15.653601       1 request.go:530] Throttling request took 241.75873ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:25:15.703643       1 request.go:530] Throttling request took 291.776343ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:25:15.753651       1 request.go:530] Throttling request took 341.791083ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:25:15.803693       1 request.go:530] Throttling request took 391.804716ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:25:15.853613       1 request.go:530] Throttling request took 441.693335ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:25:20.785115       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 0 items received
I0416 21:25:22.085062       1 controller.go:123] Found 0 jobs
I0416 21:25:22.087898       1 controller.go:139] Found 0 cronjobs
I0416 21:25:22.087928       1 controller.go:142] Found 0 groups
I0416 21:25:22.222856       1 gc_controller.go:144] GC'ing orphaned
I0416 21:25:22.227331       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:25:25.608688       1 wrap.go:47] GET /healthz: (98.682µs) 200 [kube-probe/1.15+ 127.0.0.1:41308]
I0416 21:25:26.783681       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:25:27.061590       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:25:27.222676       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:25:27.248995       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:31.781973       1 request.go:530] Throttling request took 91.867024ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:25:31.831819       1 request.go:530] Throttling request took 141.694169ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:25:31.882004       1 request.go:530] Throttling request took 191.875255ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:25:31.931936       1 request.go:530] Throttling request took 241.737741ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:25:31.981916       1 request.go:530] Throttling request took 291.753127ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:25:32.031817       1 request.go:530] Throttling request took 341.657977ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:25:32.081784       1 request.go:530] Throttling request took 391.61342ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:25:32.092120       1 controller.go:123] Found 0 jobs
I0416 21:25:32.094701       1 controller.go:139] Found 0 cronjobs
I0416 21:25:32.094716       1 controller.go:142] Found 0 groups
I0416 21:25:32.131974       1 request.go:530] Throttling request took 441.800967ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:25:32.135295       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:25:32.769197       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 141 items received
I0416 21:25:35.608578       1 wrap.go:47] GET /healthz: (92.346µs) 200 [kube-probe/1.15+ 127.0.0.1:41342]
I0416 21:25:41.762501       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:41.777662       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:42.061922       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:25:42.099525       1 controller.go:123] Found 0 jobs
I0416 21:25:42.102273       1 controller.go:139] Found 0 cronjobs
I0416 21:25:42.102287       1 controller.go:142] Found 0 groups
I0416 21:25:42.227798       1 gc_controller.go:144] GC'ing orphaned
I0416 21:25:42.232704       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:25:42.249644       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:45.608284       1 wrap.go:47] GET /healthz: (88.169µs) 200 [kube-probe/1.15+ 127.0.0.1:41394]
I0416 21:25:45.956678       1 request.go:530] Throttling request took 91.709686ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:25:46.006559       1 request.go:530] Throttling request took 141.594775ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:25:46.056508       1 request.go:530] Throttling request took 191.53196ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:25:46.106563       1 request.go:530] Throttling request took 241.58072ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:25:46.156500       1 request.go:530] Throttling request took 291.510061ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:25:46.206523       1 request.go:530] Throttling request took 341.523365ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:25:46.256631       1 request.go:530] Throttling request took 391.600639ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:25:46.307342       1 request.go:530] Throttling request took 442.309652ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:25:49.728604       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:52.106178       1 controller.go:123] Found 0 jobs
I0416 21:25:52.109013       1 controller.go:139] Found 0 cronjobs
I0416 21:25:52.109026       1 controller.go:142] Found 0 groups
I0416 21:25:53.791332       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 21:25:54.726136       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:25:55.608338       1 wrap.go:47] GET /healthz: (121.525µs) 200 [kube-probe/1.15+ 127.0.0.1:41432]
I0416 21:25:56.242504       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:25:57.062184       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:25:57.225477       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:25:57.225512       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:25:57.250244       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:25:58.775489       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 0 items received
I0416 21:25:59.040395       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:26:02.114007       1 controller.go:123] Found 0 jobs
I0416 21:26:02.116579       1 controller.go:139] Found 0 cronjobs
I0416 21:26:02.116593       1 controller.go:142] Found 0 groups
I0416 21:26:02.233055       1 gc_controller.go:144] GC'ing orphaned
I0416 21:26:02.236326       1 request.go:530] Throttling request took 93.444289ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:26:02.237498       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:26:02.285940       1 request.go:530] Throttling request took 143.04306ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:26:02.335882       1 request.go:530] Throttling request took 192.962792ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:26:02.385934       1 request.go:530] Throttling request took 242.997579ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:26:02.435935       1 request.go:530] Throttling request took 293.008699ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:26:02.485906       1 request.go:530] Throttling request took 342.968051ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:26:02.535850       1 request.go:530] Throttling request took 392.902854ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:26:02.585900       1 request.go:530] Throttling request took 442.953304ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:26:02.587939       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:26:03.466800       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 21:26:03.765821       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 271 items received
I0416 21:26:05.608641       1 wrap.go:47] GET /healthz: (88.394µs) 200 [kube-probe/1.15+ 127.0.0.1:41466]
I0416 21:26:11.762839       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:26:11.763397       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (440.477µs)
I0416 21:26:11.763566       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (107.13µs)
I0416 21:26:11.763576       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.189µs)
I0416 21:26:11.763796       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:26:11.766284       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (2.128149ms)
I0416 21:26:11.766433       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (90.945µs)
I0416 21:26:11.768059       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (4.458772ms)
I0416 21:26:11.781591       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:26:12.062478       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:26:12.120514       1 controller.go:123] Found 0 jobs
I0416 21:26:12.123144       1 controller.go:139] Found 0 cronjobs
I0416 21:26:12.123156       1 controller.go:142] Found 0 groups
I0416 21:26:12.250801       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:26:15.608436       1 wrap.go:47] GET /healthz: (92.953µs) 200 [kube-probe/1.15+ 127.0.0.1:41498]
I0416 21:26:16.411528       1 request.go:530] Throttling request took 92.422836ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:26:16.461575       1 request.go:530] Throttling request took 142.463712ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:26:16.511660       1 request.go:530] Throttling request took 192.529233ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:26:16.561533       1 request.go:530] Throttling request took 242.391297ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:26:16.611542       1 request.go:530] Throttling request took 292.394895ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:26:16.661525       1 request.go:530] Throttling request took 342.369513ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:26:16.711644       1 request.go:530] Throttling request took 392.466135ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:26:16.761596       1 request.go:530] Throttling request took 442.4174ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:26:16.766308       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 0 items received
I0416 21:26:17.116469       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 21:26:22.127480       1 controller.go:123] Found 0 jobs
I0416 21:26:22.130306       1 controller.go:139] Found 0 cronjobs
I0416 21:26:22.130319       1 controller.go:142] Found 0 groups
I0416 21:26:22.238018       1 gc_controller.go:144] GC'ing orphaned
I0416 21:26:22.243206       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:26:25.608482       1 wrap.go:47] GET /healthz: (102.834µs) 200 [kube-probe/1.15+ 127.0.0.1:41530]
I0416 21:26:27.018536       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:26:27.062812       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:26:27.227782       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:26:27.251400       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:26:32.134068       1 controller.go:123] Found 0 jobs
I0416 21:26:32.136263       1 controller.go:139] Found 0 cronjobs
I0416 21:26:32.136275       1 controller.go:142] Found 0 groups
I0416 21:26:32.688544       1 request.go:530] Throttling request took 91.187901ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:26:32.738599       1 request.go:530] Throttling request took 141.234318ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:26:32.788503       1 request.go:530] Throttling request took 191.139827ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:26:32.838589       1 request.go:530] Throttling request took 241.205639ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:26:32.888546       1 request.go:530] Throttling request took 291.158647ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:26:32.938530       1 request.go:530] Throttling request took 341.134106ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:26:32.988497       1 request.go:530] Throttling request took 391.071184ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:26:33.038576       1 request.go:530] Throttling request took 441.143454ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:26:33.040961       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:26:35.608603       1 wrap.go:47] GET /healthz: (85.097µs) 200 [kube-probe/1.15+ 127.0.0.1:41564]
I0416 21:26:36.788147       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 21:26:38.151172       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:26:38.151205       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:26:38.151245       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:26:38.151265       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:26:38.151393       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:26:39.001278       1 deployment_controller.go:168] Adding deployment linux-nginx
I0416 21:26:39.001309       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:26:39.001304614 +0000 UTC m=+1421.155028752)
I0416 21:26:39.001594       1 deployment_util.go:259] Updating replica set "linux-nginx-7c4f9bd84f" revision to 1
I0416 21:26:39.007964       1 controller_utils.go:202] Controller default/linux-nginx-7c4f9bd84f either never recorded expectations, or the ttl expired.
I0416 21:26:39.008016       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b003c07a4658, ext:1421161737551, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:39.008092       1 replica_set.go:477] Too few replicas for ReplicaSet default/linux-nginx-7c4f9bd84f, need 1, creating 1
I0416 21:26:39.009131       1 deployment_controller.go:214] ReplicaSet linux-nginx-7c4f9bd84f added.
I0416 21:26:39.012736       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"default", Name:"linux-nginx", UID:"4d8827e5-cf46-4305-8af9-67a01c838f26", APIVersion:"apps/v1", ResourceVersion:"3305", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set linux-nginx-7c4f9bd84f to 1
I0416 21:26:39.018153       1 pvc_protection_controller.go:280] Got event on pod default/linux-nginx-7c4f9bd84f-vsbts
I0416 21:26:39.018299       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"linux-nginx-7c4f9bd84f-vsbts"}
I0416 21:26:39.018346       1 replica_set.go:275] Pod linux-nginx-7c4f9bd84f-vsbts created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"linux-nginx-7c4f9bd84f-vsbts", GenerateName:"linux-nginx-7c4f9bd84f-", Namespace:"default", SelfLink:"/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-vsbts", UID:"f5280e49-36a5-4b0f-80b6-20ae60dde311", ResourceVersion:"3307", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691046799, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"nginx", "pod-template-hash":"7c4f9bd84f"}, Annotations:map[string]string{"kubernetes.io/limit-ranger":"LimitRanger plugin set: cpu request for container nginx"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"linux-nginx-7c4f9bd84f", UID:"cfcfe1ee-ed72-4fe3-9893-feafcf03d806", Controller:(*bool)(0xc001110077), BlockOwnerDeletion:(*bool)(0xc001110078)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fq4g7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0020af080), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"nginx:1.7.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fq4g7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0011100d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002128ae0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001110120)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001110140)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001110148), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00111014c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:26:39.018627       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b003c07a4658, ext:1421161737551, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:39.018688       1 disruption.go:326] addPod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:26:39.018703       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:26:39.018707       1 disruption.go:329] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:26:39.021434       1 controller_utils.go:588] Controller linux-nginx-7c4f9bd84f created pod linux-nginx-7c4f9bd84f-vsbts
I0416 21:26:39.021512       1 replica_set_utils.go:58] Updating status for : default/linux-nginx-7c4f9bd84f, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:26:39.021979       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"default", Name:"linux-nginx-7c4f9bd84f", UID:"cfcfe1ee-ed72-4fe3-9893-feafcf03d806", APIVersion:"apps/v1", ResourceVersion:"3306", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: linux-nginx-7c4f9bd84f-vsbts
I0416 21:26:39.024600       1 deployment_controller.go:175] Updating deployment linux-nginx
I0416 21:26:39.030089       1 deployment_util.go:795] Deployment "linux-nginx" timed out (false) [last progress check: 2019-04-16 21:26:39.012261694 +0000 UTC m=+1421.165985845 - now: 2019-04-16 21:26:39.030050978 +0000 UTC m=+1421.183775130]
I0416 21:26:39.034692       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"linux-nginx-7c4f9bd84f-vsbts"}
I0416 21:26:39.034817       1 replica_set.go:338] Pod linux-nginx-7c4f9bd84f-vsbts updated, objectMeta {Name:linux-nginx-7c4f9bd84f-vsbts GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-vsbts UID:f5280e49-36a5-4b0f-80b6-20ae60dde311 ResourceVersion:3307 Generation:0 CreationTimestamp:2019-04-16 21:26:39 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:cfcfe1ee-ed72-4fe3-9893-feafcf03d806 Controller:0xc001110077 BlockOwnerDeletion:0xc001110078}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-nginx-7c4f9bd84f-vsbts GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-vsbts UID:f5280e49-36a5-4b0f-80b6-20ae60dde311 ResourceVersion:3309 Generation:0 CreationTimestamp:2019-04-16 21:26:39 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:cfcfe1ee-ed72-4fe3-9893-feafcf03d806 Controller:0xc001a08107 BlockOwnerDeletion:0xc001a08108}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:26:39.035001       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:26:39.035017       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:26:39.035020       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:26:39.037684       1 deployment_controller.go:280] ReplicaSet linux-nginx-7c4f9bd84f updated.
I0416 21:26:39.041678       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (33.719969ms)
I0416 21:26:39.041740       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b003c07a4658, ext:1421161737551, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:39.041831       1 replica_set_utils.go:58] Updating status for : default/linux-nginx-7c4f9bd84f, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:26:39.051752       1 deployment_controller.go:280] ReplicaSet linux-nginx-7c4f9bd84f updated.
I0416 21:26:39.054598       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (53.283438ms)
I0416 21:26:39.054632       1 deployment_controller.go:484] Error syncing deployment default/linux-nginx: Operation cannot be fulfilled on deployments.apps "linux-nginx": the object has been modified; please apply your changes to the latest version and try again
I0416 21:26:39.054663       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:26:39.054658703 +0000 UTC m=+1421.208382845)
I0416 21:26:39.056091       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (14.367814ms)
I0416 21:26:39.056266       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b003c07a4658, ext:1421161737551, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:39.056329       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (71.543µs)
I0416 21:26:39.062615       1 deployment_controller.go:175] Updating deployment linux-nginx
I0416 21:26:39.065793       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (11.122363ms)
I0416 21:26:39.065832       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:26:39.065828038 +0000 UTC m=+1421.219552175)
I0416 21:26:39.066177       1 deployment_util.go:795] Deployment "linux-nginx" timed out (false) [last progress check: 2019-04-16 21:26:39 +0000 UTC - now: 2019-04-16 21:26:39.06617212 +0000 UTC m=+1421.219896256]
I0416 21:26:39.066207       1 progress.go:193] Queueing up deployment "linux-nginx" for a progress check after 599s
I0416 21:26:39.066218       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (388.639µs)
I0416 21:26:39.069154       1 replica_set.go:338] Pod linux-nginx-7c4f9bd84f-vsbts updated, objectMeta {Name:linux-nginx-7c4f9bd84f-vsbts GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-vsbts UID:f5280e49-36a5-4b0f-80b6-20ae60dde311 ResourceVersion:3309 Generation:0 CreationTimestamp:2019-04-16 21:26:39 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:cfcfe1ee-ed72-4fe3-9893-feafcf03d806 Controller:0xc001a08107 BlockOwnerDeletion:0xc001a08108}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-nginx-7c4f9bd84f-vsbts GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-vsbts UID:f5280e49-36a5-4b0f-80b6-20ae60dde311 ResourceVersion:3313 Generation:0 CreationTimestamp:2019-04-16 21:26:39 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:cfcfe1ee-ed72-4fe3-9893-feafcf03d806 Controller:0xc001a09b4f BlockOwnerDeletion:0xc001a09b70}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:26:39.069272       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b003c07a4658, ext:1421161737551, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:39.069376       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (110.311µs)
I0416 21:26:39.069446       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:26:39.069460       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:26:39.069464       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:26:39.790747       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 21:26:41.763355       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:26:41.785689       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:26:42.063303       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:26:42.139870       1 controller.go:123] Found 0 jobs
I0416 21:26:42.142500       1 controller.go:139] Found 0 cronjobs
I0416 21:26:42.142514       1 controller.go:142] Found 0 groups
I0416 21:26:42.243579       1 gc_controller.go:144] GC'ing orphaned
I0416 21:26:42.248381       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:26:42.252158       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:26:45.608525       1 wrap.go:47] GET /healthz: (86.001µs) 200 [kube-probe/1.15+ 127.0.0.1:41616]
I0416 21:26:46.864143       1 request.go:530] Throttling request took 90.469011ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:26:46.914157       1 request.go:530] Throttling request took 140.500496ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:26:46.964134       1 request.go:530] Throttling request took 190.470205ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:26:47.014289       1 request.go:530] Throttling request took 240.567912ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:26:47.064163       1 request.go:530] Throttling request took 290.467147ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:26:47.114095       1 request.go:530] Throttling request took 340.392699ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:26:47.164134       1 request.go:530] Throttling request took 390.425532ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:26:47.214170       1 request.go:530] Throttling request took 440.443926ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:26:48.516928       1 replica_set.go:338] Pod linux-nginx-7c4f9bd84f-vsbts updated, objectMeta {Name:linux-nginx-7c4f9bd84f-vsbts GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-vsbts UID:f5280e49-36a5-4b0f-80b6-20ae60dde311 ResourceVersion:3313 Generation:0 CreationTimestamp:2019-04-16 21:26:39 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:cfcfe1ee-ed72-4fe3-9893-feafcf03d806 Controller:0xc001a09b4f BlockOwnerDeletion:0xc001a09b70}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-nginx-7c4f9bd84f-vsbts GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-vsbts UID:f5280e49-36a5-4b0f-80b6-20ae60dde311 ResourceVersion:3332 Generation:0 CreationTimestamp:2019-04-16 21:26:39 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:cfcfe1ee-ed72-4fe3-9893-feafcf03d806 Controller:0xc0027ad697 BlockOwnerDeletion:0xc0027ad698}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:26:48.517029       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b003c07a4658, ext:1421161737551, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:48.517204       1 replica_set_utils.go:58] Updating status for : default/linux-nginx-7c4f9bd84f, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:26:48.517877       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:26:48.517896       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:26:48.517899       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:26:48.525116       1 deployment_controller.go:280] ReplicaSet linux-nginx-7c4f9bd84f updated.
I0416 21:26:48.525142       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:26:48.525136754 +0000 UTC m=+1430.678860904)
I0416 21:26:48.527782       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (10.752232ms)
I0416 21:26:48.527851       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b003c07a4658, ext:1421161737551, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:48.527927       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (86.037µs)
I0416 21:26:48.532442       1 deployment_controller.go:175] Updating deployment linux-nginx
I0416 21:26:48.534170       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (9.023961ms)
I0416 21:26:48.534203       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:26:48.534199059 +0000 UTC m=+1430.687923210)
I0416 21:26:48.534619       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (417.67µs)
I0416 21:26:49.914579       1 deployment_controller.go:168] Adding deployment linux-ubuntu
I0416 21:26:49.914605       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:26:49.914599743 +0000 UTC m=+1432.068323880)
I0416 21:26:49.914911       1 deployment_util.go:259] Updating replica set "linux-ubuntu-5dbcdfff9d" revision to 1
I0416 21:26:49.923751       1 controller_utils.go:202] Controller default/linux-ubuntu-5dbcdfff9d either never recorded expectations, or the ttl expired.
I0416 21:26:49.923820       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b006771053da, ext:1432077541076, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:49.923844       1 replica_set.go:477] Too few replicas for ReplicaSet default/linux-ubuntu-5dbcdfff9d, need 1, creating 1
I0416 21:26:49.924260       1 deployment_controller.go:214] ReplicaSet linux-ubuntu-5dbcdfff9d added.
I0416 21:26:49.925944       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"default", Name:"linux-ubuntu", UID:"abf9507f-5489-4b2b-a4f8-808dd69ba50d", APIVersion:"apps/v1", ResourceVersion:"3338", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set linux-ubuntu-5dbcdfff9d to 1
I0416 21:26:49.935949       1 controller_utils.go:588] Controller linux-ubuntu-5dbcdfff9d created pod linux-ubuntu-5dbcdfff9d-xmpzc
I0416 21:26:49.936030       1 replica_set_utils.go:58] Updating status for : default/linux-ubuntu-5dbcdfff9d, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:26:49.936575       1 pvc_protection_controller.go:280] Got event on pod default/linux-ubuntu-5dbcdfff9d-xmpzc
I0416 21:26:49.936603       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"default", Name:"linux-ubuntu-5dbcdfff9d", UID:"7d8aa653-d67a-4d6b-8a1b-0e2344c09030", APIVersion:"apps/v1", ResourceVersion:"3339", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: linux-ubuntu-5dbcdfff9d-xmpzc
I0416 21:26:49.936725       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"linux-ubuntu-5dbcdfff9d-xmpzc"}
I0416 21:26:49.936753       1 replica_set.go:275] Pod linux-ubuntu-5dbcdfff9d-xmpzc created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"linux-ubuntu-5dbcdfff9d-xmpzc", GenerateName:"linux-ubuntu-5dbcdfff9d-", Namespace:"default", SelfLink:"/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-xmpzc", UID:"1148e799-d519-4ff7-a7a8-e41e13bfa7cb", ResourceVersion:"3340", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691046809, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"ubuntu", "pod-template-hash":"5dbcdfff9d"}, Annotations:map[string]string{"kubernetes.io/limit-ranger":"LimitRanger plugin set: cpu request for container ubuntu"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"linux-ubuntu-5dbcdfff9d", UID:"7d8aa653-d67a-4d6b-8a1b-0e2344c09030", Controller:(*bool)(0xc0028b87a7), BlockOwnerDeletion:(*bool)(0xc0028b87a8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fq4g7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001d9de00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"ubuntu", Image:"ubuntu", Command:[]string{"sleep", "123456"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fq4g7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0028b87e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001692fc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0028b8830)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0028b8850)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0028b8858), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0028b885c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:26:49.937026       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b006771053da, ext:1432077541076, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:49.937078       1 disruption.go:326] addPod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:26:49.937107       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:26:49.937111       1 disruption.go:329] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:26:49.940506       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:26:49.941548       1 deployment_util.go:795] Deployment "linux-ubuntu" timed out (false) [last progress check: 2019-04-16 21:26:49.925556274 +0000 UTC m=+1432.079280428 - now: 2019-04-16 21:26:49.941538251 +0000 UTC m=+1432.095262388]
I0416 21:26:49.951204       1 deployment_controller.go:280] ReplicaSet linux-ubuntu-5dbcdfff9d updated.
I0416 21:26:49.957912       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (34.158824ms)
I0416 21:26:49.957959       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b006771053da, ext:1432077541076, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:49.958070       1 replica_set_utils.go:58] Updating status for : default/linux-ubuntu-5dbcdfff9d, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:26:49.958686       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"linux-ubuntu-5dbcdfff9d-xmpzc"}
I0416 21:26:49.958758       1 replica_set.go:338] Pod linux-ubuntu-5dbcdfff9d-xmpzc updated, objectMeta {Name:linux-ubuntu-5dbcdfff9d-xmpzc GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-xmpzc UID:1148e799-d519-4ff7-a7a8-e41e13bfa7cb ResourceVersion:3340 Generation:0 CreationTimestamp:2019-04-16 21:26:49 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:7d8aa653-d67a-4d6b-8a1b-0e2344c09030 Controller:0xc0028b87a7 BlockOwnerDeletion:0xc0028b87a8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-ubuntu-5dbcdfff9d-xmpzc GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-xmpzc UID:1148e799-d519-4ff7-a7a8-e41e13bfa7cb ResourceVersion:3342 Generation:0 CreationTimestamp:2019-04-16 21:26:49 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:7d8aa653-d67a-4d6b-8a1b-0e2344c09030 Controller:0xc0028b9997 BlockOwnerDeletion:0xc0028b9998}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:26:49.958922       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:26:49.958936       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:26:49.958953       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:26:49.961943       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (47.334298ms)
I0416 21:26:49.961959       1 deployment_controller.go:484] Error syncing deployment default/linux-ubuntu: Operation cannot be fulfilled on deployments.apps "linux-ubuntu": the object has been modified; please apply your changes to the latest version and try again
I0416 21:26:49.962003       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:26:49.961998855 +0000 UTC m=+1432.115722994)
I0416 21:26:49.962406       1 deployment_util.go:795] Deployment "linux-ubuntu" timed out (false) [last progress check: 2019-04-16 21:26:49 +0000 UTC - now: 2019-04-16 21:26:49.962401611 +0000 UTC m=+1432.116125748]
I0416 21:26:49.969514       1 deployment_controller.go:280] ReplicaSet linux-ubuntu-5dbcdfff9d updated.
I0416 21:26:49.972760       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (14.801754ms)
I0416 21:26:49.972818       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b006771053da, ext:1432077541076, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:49.972907       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (100.919µs)
I0416 21:26:49.974888       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:26:49.976871       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (14.861184ms)
I0416 21:26:49.976905       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:26:49.976900777 +0000 UTC m=+1432.130624915)
I0416 21:26:49.983868       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:26:49.984969       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (8.046373ms)
I0416 21:26:49.985001       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:26:49.984997 +0000 UTC m=+1432.138721141)
I0416 21:26:49.985436       1 deployment_util.go:795] Deployment "linux-ubuntu" timed out (false) [last progress check: 2019-04-16 21:26:49 +0000 UTC - now: 2019-04-16 21:26:49.985431408 +0000 UTC m=+1432.139155560]
I0416 21:26:49.985468       1 progress.go:193] Queueing up deployment "linux-ubuntu" for a progress check after 599s
I0416 21:26:49.985491       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (492.982µs)
I0416 21:26:49.994329       1 replica_set.go:338] Pod linux-ubuntu-5dbcdfff9d-xmpzc updated, objectMeta {Name:linux-ubuntu-5dbcdfff9d-xmpzc GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-xmpzc UID:1148e799-d519-4ff7-a7a8-e41e13bfa7cb ResourceVersion:3342 Generation:0 CreationTimestamp:2019-04-16 21:26:49 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:7d8aa653-d67a-4d6b-8a1b-0e2344c09030 Controller:0xc0028b9997 BlockOwnerDeletion:0xc0028b9998}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-ubuntu-5dbcdfff9d-xmpzc GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-xmpzc UID:1148e799-d519-4ff7-a7a8-e41e13bfa7cb ResourceVersion:3347 Generation:0 CreationTimestamp:2019-04-16 21:26:49 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:7d8aa653-d67a-4d6b-8a1b-0e2344c09030 Controller:0xc001f776d7 BlockOwnerDeletion:0xc001f776d8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:26:49.994441       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b006771053da, ext:1432077541076, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:49.994525       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (92.055µs)
I0416 21:26:49.994606       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:26:49.994633       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:26:49.994637       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:26:52.146514       1 controller.go:123] Found 0 jobs
I0416 21:26:52.152529       1 controller.go:139] Found 0 cronjobs
I0416 21:26:52.152542       1 controller.go:142] Found 0 groups
I0416 21:26:54.837969       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:26:55.608444       1 wrap.go:47] GET /healthz: (83.657µs) 200 [kube-probe/1.15+ 127.0.0.1:41654]
I0416 21:26:56.342370       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:26:57.063511       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:26:57.165926       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 21:26:57.230551       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:26:57.230587       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:26:57.253167       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:26:57.281941       1 replica_set.go:338] Pod linux-ubuntu-5dbcdfff9d-xmpzc updated, objectMeta {Name:linux-ubuntu-5dbcdfff9d-xmpzc GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-xmpzc UID:1148e799-d519-4ff7-a7a8-e41e13bfa7cb ResourceVersion:3347 Generation:0 CreationTimestamp:2019-04-16 21:26:49 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:7d8aa653-d67a-4d6b-8a1b-0e2344c09030 Controller:0xc001f776d7 BlockOwnerDeletion:0xc001f776d8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-ubuntu-5dbcdfff9d-xmpzc GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-xmpzc UID:1148e799-d519-4ff7-a7a8-e41e13bfa7cb ResourceVersion:3363 Generation:0 CreationTimestamp:2019-04-16 21:26:49 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:7d8aa653-d67a-4d6b-8a1b-0e2344c09030 Controller:0xc0024a7c27 BlockOwnerDeletion:0xc0024a7c28}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:26:57.282047       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b006771053da, ext:1432077541076, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:57.282166       1 replica_set_utils.go:58] Updating status for : default/linux-ubuntu-5dbcdfff9d, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:26:57.282849       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:26:57.282870       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:26:57.282874       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:26:57.291222       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (9.171462ms)
I0416 21:26:57.291409       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b006771053da, ext:1432077541076, loc:(*time.Location)(0x71c51c0)}}
I0416 21:26:57.291536       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (148.555µs)
I0416 21:26:57.291624       1 deployment_controller.go:280] ReplicaSet linux-ubuntu-5dbcdfff9d updated.
I0416 21:26:57.291657       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:26:57.291652696 +0000 UTC m=+1439.445376834)
I0416 21:26:57.297877       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:26:57.299490       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (7.825725ms)
I0416 21:26:57.299533       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:26:57.299528475 +0000 UTC m=+1439.453252615)
I0416 21:26:57.299960       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (429.17µs)
I0416 21:27:00.042325       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:27:00.806585       1 deployment_controller.go:168] Adding deployment windows-nettest
I0416 21:27:00.806612       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:27:00.806607378 +0000 UTC m=+1442.960331517)
I0416 21:27:00.806926       1 deployment_util.go:259] Updating replica set "windows-nettest-944bd6d8d" revision to 1
I0416 21:27:00.812852       1 controller_utils.go:202] Controller default/windows-nettest-944bd6d8d either never recorded expectations, or the ttl expired.
I0416 21:27:00.812917       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b009307414ad, ext:1442966637988, loc:(*time.Location)(0x71c51c0)}}
I0416 21:27:00.812941       1 replica_set.go:477] Too few replicas for ReplicaSet default/windows-nettest-944bd6d8d, need 1, creating 1
I0416 21:27:00.813526       1 deployment_controller.go:214] ReplicaSet windows-nettest-944bd6d8d added.
I0416 21:27:00.816370       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"default", Name:"windows-nettest", UID:"ae1fb189-b088-4687-b78a-6d3a98e2bb7b", APIVersion:"apps/v1", ResourceVersion:"3373", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set windows-nettest-944bd6d8d to 1
I0416 21:27:00.828705       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-rfhxl
I0416 21:27:00.828811       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"windows-nettest-944bd6d8d-rfhxl"}
I0416 21:27:00.828865       1 replica_set.go:275] Pod windows-nettest-944bd6d8d-rfhxl created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"windows-nettest-944bd6d8d-rfhxl", GenerateName:"windows-nettest-944bd6d8d-", Namespace:"default", SelfLink:"/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-rfhxl", UID:"db88e65c-9310-4d07-b676-6399d59d69a0", ResourceVersion:"3375", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691046820, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"nettest", "pod-template-hash":"944bd6d8d"}, Annotations:map[string]string{"kubernetes.io/limit-ranger":"LimitRanger plugin set: cpu request for container nettest"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"windows-nettest-944bd6d8d", UID:"8b5de186-44bd-4108-b022-df873336c192", Controller:(*bool)(0xc00287afa0), BlockOwnerDeletion:(*bool)(0xc00287afa1)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fq4g7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00203f680), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nettest", Image:"e2eteam/nettest:1.0", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fq4g7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00287afd8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"windows"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00131f020), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/os", Operator:"Equal", Value:"windows", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00287b040)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00287b060)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00287b068), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00287b06c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:27:00.829127       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b009307414ad, ext:1442966637988, loc:(*time.Location)(0x71c51c0)}}
I0416 21:27:00.829188       1 disruption.go:326] addPod called on pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:27:00.829203       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-rfhxl, PodDisruptionBudget controller will avoid syncing.
I0416 21:27:00.829207       1 disruption.go:329] No matching pdb for pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:27:00.831343       1 controller_utils.go:588] Controller windows-nettest-944bd6d8d created pod windows-nettest-944bd6d8d-rfhxl
I0416 21:27:00.831419       1 replica_set_utils.go:58] Updating status for : default/windows-nettest-944bd6d8d, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:27:00.832012       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"default", Name:"windows-nettest-944bd6d8d", UID:"8b5de186-44bd-4108-b022-df873336c192", APIVersion:"apps/v1", ResourceVersion:"3374", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: windows-nettest-944bd6d8d-rfhxl
I0416 21:27:00.833546       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:27:00.835693       1 deployment_util.go:795] Deployment "windows-nettest" timed out (false) [last progress check: 2019-04-16 21:27:00.815932317 +0000 UTC m=+1442.969656453 - now: 2019-04-16 21:27:00.835683982 +0000 UTC m=+1442.989408134]
I0416 21:27:00.844251       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"windows-nettest-944bd6d8d-rfhxl"}
I0416 21:27:00.844340       1 replica_set.go:338] Pod windows-nettest-944bd6d8d-rfhxl updated, objectMeta {Name:windows-nettest-944bd6d8d-rfhxl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-rfhxl UID:db88e65c-9310-4d07-b676-6399d59d69a0 ResourceVersion:3375 Generation:0 CreationTimestamp:2019-04-16 21:27:00 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:8b5de186-44bd-4108-b022-df873336c192 Controller:0xc00287afa0 BlockOwnerDeletion:0xc00287afa1}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:windows-nettest-944bd6d8d-rfhxl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-rfhxl UID:db88e65c-9310-4d07-b676-6399d59d69a0 ResourceVersion:3377 Generation:0 CreationTimestamp:2019-04-16 21:27:00 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:8b5de186-44bd-4108-b022-df873336c192 Controller:0xc0028c04f7 BlockOwnerDeletion:0xc0028c04f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:27:00.844496       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:27:00.844527       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-rfhxl, PodDisruptionBudget controller will avoid syncing.
I0416 21:27:00.844531       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:27:00.855725       1 deployment_controller.go:280] ReplicaSet windows-nettest-944bd6d8d updated.
I0416 21:27:00.860552       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (53.931121ms)
I0416 21:27:00.860586       1 deployment_controller.go:484] Error syncing deployment default/windows-nettest: Operation cannot be fulfilled on deployments.apps "windows-nettest": the object has been modified; please apply your changes to the latest version and try again
I0416 21:27:00.860616       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:27:00.860612618 +0000 UTC m=+1443.014336757)
I0416 21:27:00.861057       1 deployment_util.go:795] Deployment "windows-nettest" timed out (false) [last progress check: 2019-04-16 21:27:00 +0000 UTC - now: 2019-04-16 21:27:00.861051446 +0000 UTC m=+1443.014775597]
I0416 21:27:00.862951       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (50.130093ms)
I0416 21:27:00.862992       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b009307414ad, ext:1442966637988, loc:(*time.Location)(0x71c51c0)}}
I0416 21:27:00.863070       1 replica_set_utils.go:58] Updating status for : default/windows-nettest-944bd6d8d, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:27:00.875000       1 deployment_controller.go:280] ReplicaSet windows-nettest-944bd6d8d updated.
I0416 21:27:00.877790       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:27:00.880033       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (17.026982ms)
I0416 21:27:00.880078       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b009307414ad, ext:1442966637988, loc:(*time.Location)(0x71c51c0)}}
I0416 21:27:00.880170       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (103.526µs)
I0416 21:27:00.881668       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (21.047422ms)
I0416 21:27:00.881715       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:27:00.881710444 +0000 UTC m=+1443.035434582)
I0416 21:27:00.888160       1 replica_set.go:338] Pod windows-nettest-944bd6d8d-rfhxl updated, objectMeta {Name:windows-nettest-944bd6d8d-rfhxl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-rfhxl UID:db88e65c-9310-4d07-b676-6399d59d69a0 ResourceVersion:3377 Generation:0 CreationTimestamp:2019-04-16 21:27:00 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:8b5de186-44bd-4108-b022-df873336c192 Controller:0xc0028c04f7 BlockOwnerDeletion:0xc0028c04f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:windows-nettest-944bd6d8d-rfhxl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-rfhxl UID:db88e65c-9310-4d07-b676-6399d59d69a0 ResourceVersion:3381 Generation:0 CreationTimestamp:2019-04-16 21:27:00 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:8b5de186-44bd-4108-b022-df873336c192 Controller:0xc0028c1bb7 BlockOwnerDeletion:0xc0028c1bb8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:27:00.888281       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b009307414ad, ext:1442966637988, loc:(*time.Location)(0x71c51c0)}}
I0416 21:27:00.888363       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (89.339µs)
I0416 21:27:00.888461       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:27:00.888489       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-rfhxl, PodDisruptionBudget controller will avoid syncing.
I0416 21:27:00.888493       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:27:00.893538       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (11.815804ms)
I0416 21:27:00.893723       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:27:00.893750       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:27:00.89374609 +0000 UTC m=+1443.047470228)
I0416 21:27:00.894156       1 deployment_util.go:795] Deployment "windows-nettest" timed out (false) [last progress check: 2019-04-16 21:27:00 +0000 UTC - now: 2019-04-16 21:27:00.894150902 +0000 UTC m=+1443.047875040]
I0416 21:27:00.894186       1 progress.go:193] Queueing up deployment "windows-nettest" for a progress check after 599s
I0416 21:27:00.894194       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (446.768µs)
I0416 21:27:02.156734       1 controller.go:123] Found 0 jobs
I0416 21:27:02.159695       1 controller.go:139] Found 0 cronjobs
I0416 21:27:02.159707       1 controller.go:142] Found 0 groups
I0416 21:27:02.248666       1 gc_controller.go:144] GC'ing orphaned
I0416 21:27:02.253437       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:27:02.741271       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:03.141534       1 request.go:530] Throttling request took 86.931811ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:27:03.191533       1 request.go:530] Throttling request took 136.915367ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:27:03.242490       1 request.go:530] Throttling request took 187.739301ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:27:03.291939       1 request.go:530] Throttling request took 237.304568ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:27:03.341414       1 request.go:530] Throttling request took 286.772922ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:27:03.391490       1 request.go:530] Throttling request took 336.821918ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:27:03.441423       1 request.go:530] Throttling request took 386.770722ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:27:03.491477       1 request.go:530] Throttling request took 436.80208ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:27:03.493916       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:27:05.608476       1 wrap.go:47] GET /healthz: (100.03µs) 200 [kube-probe/1.15+ 127.0.0.1:41688]
I0416 21:27:11.763890       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:11.786155       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:12.063839       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:27:12.163677       1 controller.go:123] Found 0 jobs
I0416 21:27:12.165986       1 controller.go:139] Found 0 cronjobs
I0416 21:27:12.165999       1 controller.go:142] Found 0 groups
I0416 21:27:12.253472       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:13.922176       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:14.772122       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 21:27:15.608700       1 wrap.go:47] GET /healthz: (93.902µs) 200 [kube-probe/1.15+ 127.0.0.1:41722]
I0416 21:27:17.317207       1 request.go:530] Throttling request took 90.868606ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:27:17.367198       1 request.go:530] Throttling request took 140.851065ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:27:17.417038       1 request.go:530] Throttling request took 190.668086ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:27:17.467178       1 request.go:530] Throttling request took 240.77177ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:27:17.517150       1 request.go:530] Throttling request took 290.764622ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:27:17.567185       1 request.go:530] Throttling request took 340.793574ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:27:17.617166       1 request.go:530] Throttling request took 390.766132ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:27:17.667150       1 request.go:530] Throttling request took 440.742102ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:27:22.170142       1 controller.go:123] Found 0 jobs
I0416 21:27:22.172891       1 controller.go:139] Found 0 cronjobs
I0416 21:27:22.172903       1 controller.go:142] Found 0 groups
I0416 21:27:22.253841       1 gc_controller.go:144] GC'ing orphaned
I0416 21:27:22.258699       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:27:24.883485       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:27:25.608583       1 wrap.go:47] GET /healthz: (99.756µs) 200 [kube-probe/1.15+ 127.0.0.1:41754]
I0416 21:27:27.064583       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:27:27.208538       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:27:27.233395       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:27:27.233467       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:27:27.254022       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:32.177203       1 controller.go:123] Found 0 jobs
I0416 21:27:32.179710       1 controller.go:139] Found 0 cronjobs
I0416 21:27:32.179724       1 controller.go:142] Found 0 groups
I0416 21:27:33.315062       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 0 items received
I0416 21:27:33.594446       1 request.go:530] Throttling request took 81.9452ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:27:33.644432       1 request.go:530] Throttling request took 131.928049ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:27:33.694438       1 request.go:530] Throttling request took 181.927177ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:27:33.744512       1 request.go:530] Throttling request took 231.992664ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:27:33.794575       1 request.go:530] Throttling request took 282.014599ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:27:33.844490       1 request.go:530] Throttling request took 331.928844ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:27:33.894375       1 request.go:530] Throttling request took 381.807922ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:27:33.944463       1 request.go:530] Throttling request took 431.881278ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:27:33.946746       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:27:35.608631       1 wrap.go:47] GET /healthz: (108.172µs) 200 [kube-probe/1.15+ 127.0.0.1:41788]
I0416 21:27:35.949905       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 21:27:39.941981       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:40.778987       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:27:41.764167       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:41.786473       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:42.065010       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:27:42.183721       1 controller.go:123] Found 0 jobs
I0416 21:27:42.186175       1 controller.go:139] Found 0 cronjobs
I0416 21:27:42.186187       1 controller.go:142] Found 0 groups
I0416 21:27:42.254544       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:42.259061       1 gc_controller.go:144] GC'ing orphaned
I0416 21:27:42.264079       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:27:45.608453       1 wrap.go:47] GET /healthz: (84.221µs) 200 [kube-probe/1.15+ 127.0.0.1:41840]
I0416 21:27:45.873214       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:47.770155       1 request.go:530] Throttling request took 90.921423ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:27:47.820121       1 request.go:530] Throttling request took 140.874833ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:27:47.870049       1 request.go:530] Throttling request took 190.799194ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:27:47.920084       1 request.go:530] Throttling request took 240.826693ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:27:47.970216       1 request.go:530] Throttling request took 289.816437ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:27:48.020135       1 request.go:530] Throttling request took 339.688412ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:27:48.070177       1 request.go:530] Throttling request took 389.721439ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:27:48.120155       1 request.go:530] Throttling request took 439.678969ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:27:48.762054       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 21:27:52.190710       1 controller.go:123] Found 0 jobs
I0416 21:27:52.194474       1 controller.go:139] Found 0 cronjobs
I0416 21:27:52.194490       1 controller.go:142] Found 0 groups
I0416 21:27:54.785401       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:27:55.608653       1 wrap.go:47] GET /healthz: (85.123µs) 200 [kube-probe/1.15+ 127.0.0.1:41876]
I0416 21:27:56.458628       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:27:57.065361       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:27:57.221610       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 21:27:57.236587       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:27:57.255175       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:27:57.905201       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 17 items received
I0416 21:28:00.036004       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:28:02.198617       1 controller.go:123] Found 0 jobs
I0416 21:28:02.201125       1 controller.go:139] Found 0 cronjobs
I0416 21:28:02.201135       1 controller.go:142] Found 0 groups
I0416 21:28:02.247188       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:02.264598       1 gc_controller.go:144] GC'ing orphaned
I0416 21:28:02.269458       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:28:04.047294       1 request.go:530] Throttling request took 93.280955ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:28:04.097097       1 request.go:530] Throttling request took 143.077004ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:28:04.147125       1 request.go:530] Throttling request took 193.096881ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:28:04.197155       1 request.go:530] Throttling request took 243.116384ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:28:04.247222       1 request.go:530] Throttling request took 293.173496ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:28:04.297560       1 request.go:530] Throttling request took 343.506557ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:28:04.347149       1 request.go:530] Throttling request took 393.084744ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:28:04.397245       1 request.go:530] Throttling request took 443.138753ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:28:04.399333       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:28:05.608958       1 wrap.go:47] GET /healthz: (95.107µs) 200 [kube-probe/1.15+ 127.0.0.1:41912]
I0416 21:28:11.333431       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 264 items received
I0416 21:28:11.764772       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:11.786944       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:12.065573       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:28:12.205366       1 controller.go:123] Found 0 jobs
I0416 21:28:12.208147       1 controller.go:139] Found 0 cronjobs
I0416 21:28:12.208160       1 controller.go:142] Found 0 groups
I0416 21:28:12.255684       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:14.123411       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:28:15.609330       1 wrap.go:47] GET /healthz: (119.385µs) 200 [kube-probe/1.15+ 127.0.0.1:41944]
I0416 21:28:15.858336       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:15.859015       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:15.859548       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:15.859874       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:28:15.860004       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:28:15.860133       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:28:18.223386       1 request.go:530] Throttling request took 91.200486ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:28:18.273472       1 request.go:530] Throttling request took 141.273039ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:28:18.323486       1 request.go:530] Throttling request took 191.274394ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:28:18.373587       1 request.go:530] Throttling request took 241.372934ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:28:18.423416       1 request.go:530] Throttling request took 291.191496ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:28:18.473502       1 request.go:530] Throttling request took 341.24861ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:28:18.523905       1 request.go:530] Throttling request took 391.661437ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:28:18.573520       1 request.go:530] Throttling request took 441.238791ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:28:18.981344       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 21:28:20.820556       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:28:22.212297       1 controller.go:123] Found 0 jobs
I0416 21:28:22.214911       1 controller.go:139] Found 0 cronjobs
I0416 21:28:22.214931       1 controller.go:142] Found 0 groups
I0416 21:28:22.269930       1 gc_controller.go:144] GC'ing orphaned
I0416 21:28:22.274531       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:28:22.775588       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 0 items received
I0416 21:28:24.954753       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:28:25.608954       1 wrap.go:47] GET /healthz: (164.352µs) 200 [kube-probe/1.15+ 127.0.0.1:41976]
I0416 21:28:27.065790       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:28:27.239323       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:28:27.256210       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:27.388580       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:28:28.297618       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.299851       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.299957       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.300035       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:28:28.300049       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:28:28.300072       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:28:28.300067082 +0000 UTC m=+1530.453791233)
I0416 21:28:28.300957       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (885.871µs)
I0416 21:28:28.300985       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:28:28.300982302 +0000 UTC m=+1530.454706437)
I0416 21:28:28.301334       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (346.436µs)
I0416 21:28:28.301386       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:28:28.301396       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:28:28.301393926 +0000 UTC m=+1530.455118062)
I0416 21:28:28.301771       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (375.208µs)
I0416 21:28:28.301790       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:28:28.301802       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:28:28.301796619 +0000 UTC m=+1530.455520755)
I0416 21:28:28.303143       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (1.343529ms)
I0416 21:28:28.303206       1 deployment_controller.go:175] Updating deployment linux-nginx
I0416 21:28:28.303212       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:28:28.303219       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:28:28.303216239 +0000 UTC m=+1530.456940375)
I0416 21:28:28.303591       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (371.227µs)
I0416 21:28:28.303617       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:28:28.303614215 +0000 UTC m=+1530.457338352)
I0416 21:28:28.303883       1 deployment_util.go:795] Deployment "windows-nettest" timed out (false) [last progress check: 2019-04-16 21:27:00 +0000 UTC - now: 2019-04-16 21:28:28.303878038 +0000 UTC m=+1530.457602189]
I0416 21:28:28.303906       1 progress.go:193] Queueing up deployment "windows-nettest" for a progress check after 511s
I0416 21:28:28.303917       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (301.083µs)
I0416 21:28:28.303960       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:28:28.303964       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:28:28.303971       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:28:28.303968524 +0000 UTC m=+1530.457692661)
I0416 21:28:28.304600       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (628.866µs)
I0416 21:28:28.304611       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:28:28.304608594 +0000 UTC m=+1530.458332730)
I0416 21:28:28.305219       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (607.491µs)
I0416 21:28:28.305270       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:28:28.305278       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:28:28.305275604 +0000 UTC m=+1530.458999741)
I0416 21:28:28.305589       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (311.369µs)
I0416 21:28:28.305603       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:28:28.305610       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:28:28.305607691 +0000 UTC m=+1530.459331827)
I0416 21:28:28.305856       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (246.208µs)
I0416 21:28:28.305893       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:28:28.305900       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:28:28.305897956 +0000 UTC m=+1530.459622092)
I0416 21:28:28.306742       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (840.919µs)
I0416 21:28:28.315767       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.315878       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:28:28.315891       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:28:28.316050       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.316064       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.316099       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.316337       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.316887       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25afe121422682, ext:1282711707556, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.317097       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:28:28.317198       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b01f12e80043, ext:1530470918468, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.317274       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:28:28.317307       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:28:28.317324       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b01f12e80043, ext:1530470918468, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.317352       1 update.go:396] Getting unavailable numbers
I0416 21:28:28.317422       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:28:28.317454       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:28:28.317460       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:28:28.317464       1 update.go:68] Marking old pods for deletion
I0416 21:28:28.317468       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b01f12ec2872, ext:1530471190874, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.317489       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:28:28.317512       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:28:28.317536       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:28:28.317614       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:28:28.317662       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.312442ms)
I0416 21:28:28.318684       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25afe1212ce147, ext:1282710313524, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.318854       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:28:28.318862       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b01f13016956, ext:1530472583760, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.318909       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:28:28.318939       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:28:28.318943       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b01f13016956, ext:1530472583760, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.318981       1 update.go:396] Getting unavailable numbers
I0416 21:28:28.319057       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:28:28.319063       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:28:28.319067       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:28:28.319070       1 update.go:68] Marking old pods for deletion
I0416 21:28:28.319073       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b01f1304a772, ext:1530472796265, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.319079       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:28:28.319103       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:28:28.319137       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:28:28.319268       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:28:28.319274       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (3.364415ms)
I0416 21:28:28.319422       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:28:28.319442       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319446       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:28:28.319519       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:28:28.319527       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319529       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:28:28.319571       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:28:28.319579       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319581       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:28:28.319607       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:28:28.319613       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319615       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:28:28.319654       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:28:28.319661       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319664       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:28:28.319702       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:28:28.319712       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319715       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:28:28.319718       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:28:28.319725       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319727       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:28:28.319785       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:28:28.319792       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319795       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:28:28.319819       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:28:28.319823       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319826       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:28:28.319844       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:28:28.319850       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319852       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:28:28.319925       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:28:28.319933       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319935       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:28:28.319938       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:28:28.319943       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319945       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:28:28.319967       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:28:28.319974       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.319976       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:28:28.319997       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:28:28.320004       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320007       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:28:28.320034       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:28:28.320042       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320045       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:28:28.320066       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:28:28.320072       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320075       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:28:28.320093       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:28:28.320099       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320113       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:28:28.320159       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:28:28.320167       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320169       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:28:28.320172       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:28:28.320182       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320185       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:28:28.320221       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:28:28.320238       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320240       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:28:28.320262       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:28:28.320272       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320274       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:28:28.320294       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:28:28.320302       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320306       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:28:28.320461       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:28:28.320534       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-rfhxl, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320539       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:28:28.320597       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:28:28.320607       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320611       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:28:28.320630       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:28:28.320638       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:28:28.320641       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:28:28.322713       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.322867       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323023       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (162.326µs)
I0416 21:28:28.323050       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.323327       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323394       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (71.198µs)
I0416 21:28:28.323406       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323461       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (56.091µs)
I0416 21:28:28.323488       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b003c07a4658, ext:1421161737551, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323540       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (54.125µs)
I0416 21:28:28.323565       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b009307414ad, ext:1442966637988, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323592       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (28.189µs)
I0416 21:28:28.323634       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b006771053da, ext:1432077541076, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323662       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (28.935µs)
I0416 21:28:28.323670       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323727       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (58.474µs)
I0416 21:28:28.323745       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323813       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (68.997µs)
I0416 21:28:28.323856       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.323873       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.323914       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (42.48µs)
I0416 21:28:28.323943       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.323988       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.324002       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.324046       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.324090       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (39.436µs)
I0416 21:28:28.324098       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.324131       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (33.691µs)
I0416 21:28:28.324159       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.324198       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (40.465µs)
I0416 21:28:28.324213       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:28:28.324350       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (137.827µs)
I0416 21:28:28.378006       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.460835       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.499079       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.529114       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.647269       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.720778       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.820352       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.869949       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:28.870039       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:28:28.870071       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.757µs)
I0416 21:28:28.870152       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:28:28.870159       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (640ns)
I0416 21:28:28.870168       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:28:28.870176       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:28:28.870201       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (559ns)
I0416 21:28:28.870210       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (266ns)
I0416 21:28:28.920368       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:29.075120       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:32.221160       1 controller.go:123] Found 0 jobs
I0416 21:28:32.223159       1 controller.go:139] Found 0 cronjobs
I0416 21:28:32.223171       1 controller.go:142] Found 0 groups
I0416 21:28:32.239721       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:28:34.499923       1 request.go:530] Throttling request took 91.718348ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:28:34.549961       1 request.go:530] Throttling request took 141.739983ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:28:34.600039       1 request.go:530] Throttling request took 191.818431ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:28:34.649828       1 request.go:530] Throttling request took 241.599204ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:28:34.699957       1 request.go:530] Throttling request took 291.70897ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:28:34.750007       1 request.go:530] Throttling request took 341.727807ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:28:34.799897       1 request.go:530] Throttling request took 391.607248ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:28:34.850351       1 request.go:530] Throttling request took 442.052155ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:28:34.860462       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:28:35.608595       1 wrap.go:47] GET /healthz: (97.943µs) 200 [kube-probe/1.15+ 127.0.0.1:42010]
I0416 21:28:37.764194       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 11 items received
I0416 21:28:41.765153       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:41.787383       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:42.066120       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:28:42.227119       1 controller.go:123] Found 0 jobs
I0416 21:28:42.229625       1 controller.go:139] Found 0 cronjobs
I0416 21:28:42.229643       1 controller.go:142] Found 0 groups
I0416 21:28:42.256639       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:28:42.274871       1 gc_controller.go:144] GC'ing orphaned
I0416 21:28:42.278944       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:28:42.559369       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:28:45.269048       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 102 items received
I0416 21:28:45.609365       1 wrap.go:47] GET /healthz: (133.954µs) 200 [kube-probe/1.15+ 127.0.0.1:42062]
I0416 21:28:48.676554       1 request.go:530] Throttling request took 90.425316ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:28:48.726625       1 request.go:530] Throttling request took 140.470658ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:28:48.777133       1 request.go:530] Throttling request took 190.972911ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:28:48.826587       1 request.go:530] Throttling request took 240.40987ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:28:48.876659       1 request.go:530] Throttling request took 290.457836ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:28:48.926647       1 request.go:530] Throttling request took 340.451044ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:28:48.976626       1 request.go:530] Throttling request took 390.397138ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:28:49.027124       1 request.go:530] Throttling request took 440.910903ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:28:51.763406       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:28:52.233685       1 controller.go:123] Found 0 jobs
I0416 21:28:52.236051       1 controller.go:139] Found 0 cronjobs
I0416 21:28:52.236062       1 controller.go:142] Found 0 groups
I0416 21:28:54.826789       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 13 items received
I0416 21:28:55.608816       1 wrap.go:47] GET /healthz: (105.405µs) 200 [kube-probe/1.15+ 127.0.0.1:42098]
I0416 21:28:55.796207       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
I0416 21:28:56.305817       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 0 items received
I0416 21:28:56.935914       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:28:57.066361       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:28:57.242917       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:28:57.257200       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:00.768110       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:29:01.029017       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:29:02.240222       1 controller.go:123] Found 0 jobs
I0416 21:29:02.242678       1 controller.go:139] Found 0 cronjobs
I0416 21:29:02.242690       1 controller.go:142] Found 0 groups
I0416 21:29:02.279995       1 gc_controller.go:144] GC'ing orphaned
I0416 21:29:02.284711       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:29:04.007577       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 21:29:04.961032       1 request.go:530] Throttling request took 92.057581ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:29:05.011018       1 request.go:530] Throttling request took 142.038888ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:29:05.061076       1 request.go:530] Throttling request took 192.08586ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:29:05.110904       1 request.go:530] Throttling request took 241.907767ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:29:05.160935       1 request.go:530] Throttling request took 291.923428ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:29:05.210906       1 request.go:530] Throttling request took 341.865952ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:29:05.260989       1 request.go:530] Throttling request took 391.947932ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:29:05.311012       1 request.go:530] Throttling request took 441.970621ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:29:05.313323       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:29:05.608430       1 wrap.go:47] GET /healthz: (104.011µs) 200 [kube-probe/1.15+ 127.0.0.1:42134]
I0416 21:29:11.765520       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:11.787808       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:12.066869       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:29:12.246705       1 controller.go:123] Found 0 jobs
I0416 21:29:12.249139       1 controller.go:139] Found 0 cronjobs
I0416 21:29:12.249162       1 controller.go:142] Found 0 groups
I0416 21:29:12.257639       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:15.608702       1 wrap.go:47] GET /healthz: (94.212µs) 200 [kube-probe/1.15+ 127.0.0.1:42166]
I0416 21:29:16.306556       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 0 items received
I0416 21:29:19.130045       1 request.go:530] Throttling request took 92.014797ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:29:19.180106       1 request.go:530] Throttling request took 142.070181ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:29:19.230137       1 request.go:530] Throttling request took 192.049432ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:29:19.280199       1 request.go:530] Throttling request took 242.144849ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:29:19.330412       1 request.go:530] Throttling request took 292.316012ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:29:19.380187       1 request.go:530] Throttling request took 342.076966ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:29:19.430122       1 request.go:530] Throttling request took 391.997707ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:29:19.480081       1 request.go:530] Throttling request took 441.973417ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:29:22.253743       1 controller.go:123] Found 0 jobs
I0416 21:29:22.256720       1 controller.go:139] Found 0 cronjobs
I0416 21:29:22.256732       1 controller.go:142] Found 0 groups
I0416 21:29:22.285198       1 gc_controller.go:144] GC'ing orphaned
I0416 21:29:22.290835       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:29:23.792443       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 21:29:25.030400       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:29:25.608686       1 wrap.go:47] GET /healthz: (90.381µs) 200 [kube-probe/1.15+ 127.0.0.1:42198]
I0416 21:29:25.788668       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 11 items received
I0416 21:29:26.783326       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:29:27.067133       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:29:27.246977       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:29:27.258280       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:27.637713       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:29:31.060479       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:32.247421       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:29:32.261751       1 controller.go:123] Found 0 jobs
I0416 21:29:32.264683       1 controller.go:139] Found 0 cronjobs
I0416 21:29:32.264697       1 controller.go:142] Found 0 groups
I0416 21:29:34.366083       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 21:29:35.418516       1 request.go:530] Throttling request took 95.970308ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:29:35.465003       1 request.go:530] Throttling request took 142.434205ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:29:35.514275       1 request.go:530] Throttling request took 191.693584ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:29:35.564684       1 request.go:530] Throttling request took 242.112847ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:29:35.608670       1 wrap.go:47] GET /healthz: (106.395µs) 200 [kube-probe/1.15+ 127.0.0.1:42232]
I0416 21:29:35.614182       1 request.go:530] Throttling request took 291.600079ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:29:35.664181       1 request.go:530] Throttling request took 341.579403ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:29:35.714279       1 request.go:530] Throttling request took 391.656347ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:29:35.764237       1 request.go:530] Throttling request took 441.607408ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:29:35.766506       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:29:41.765921       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:41.788256       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:42.069199       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:29:42.258824       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:29:42.268696       1 controller.go:123] Found 0 jobs
I0416 21:29:42.271189       1 controller.go:139] Found 0 cronjobs
I0416 21:29:42.271201       1 controller.go:142] Found 0 groups
I0416 21:29:42.291431       1 gc_controller.go:144] GC'ing orphaned
I0416 21:29:42.296661       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:29:45.610470       1 wrap.go:47] GET /healthz: (102.981µs) 200 [kube-probe/1.15+ 127.0.0.1:42296]
I0416 21:29:49.586338       1 request.go:530] Throttling request took 95.420747ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:29:49.632835       1 request.go:530] Throttling request took 141.901503ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:29:49.682850       1 request.go:530] Throttling request took 191.907658ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:29:49.732893       1 request.go:530] Throttling request took 241.901662ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:29:49.783337       1 request.go:530] Throttling request took 292.35044ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:29:49.833408       1 request.go:530] Throttling request took 342.401273ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:29:49.882928       1 request.go:530] Throttling request took 391.888497ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:29:49.932925       1 request.go:530] Throttling request took 441.863978ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:29:52.276533       1 controller.go:123] Found 0 jobs
I0416 21:29:52.278703       1 controller.go:139] Found 0 cronjobs
I0416 21:29:52.278716       1 controller.go:142] Found 0 groups
I0416 21:29:54.801031       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 21:29:55.608554       1 wrap.go:47] GET /healthz: (83.765µs) 200 [kube-probe/1.15+ 127.0.0.1:42332]
I0416 21:29:57.035098       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:29:57.069469       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:29:57.249943       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:29:57.259316       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:02.024837       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:30:02.282755       1 controller.go:123] Found 0 jobs
I0416 21:30:02.285095       1 controller.go:139] Found 0 cronjobs
I0416 21:30:02.285105       1 controller.go:142] Found 0 groups
I0416 21:30:02.296975       1 gc_controller.go:144] GC'ing orphaned
I0416 21:30:02.301698       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:30:05.608442       1 wrap.go:47] GET /healthz: (103.207µs) 200 [kube-probe/1.15+ 127.0.0.1:42368]
I0416 21:30:05.890215       1 request.go:530] Throttling request took 56.035382ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:30:05.936914       1 request.go:530] Throttling request took 102.705884ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:30:05.986998       1 request.go:530] Throttling request took 152.538725ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:30:06.036957       1 request.go:530] Throttling request took 202.491064ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:30:06.086968       1 request.go:530] Throttling request took 252.492016ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:30:06.136969       1 request.go:530] Throttling request took 302.479626ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:30:06.170682       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=deployments, namespace default, name linux-nginx, uid 4d8827e5-cf46-4305-8af9-67a01c838f26, event type delete
I0416 21:30:06.170848       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=deployments, namespace default, name linux-nginx, uid 4d8827e5-cf46-4305-8af9-67a01c838f26, event type delete
I0416 21:30:06.170960       1 garbagecollector.go:405] processing item [extensions/v1beta1/ReplicaSet, namespace: default, name: linux-nginx-7c4f9bd84f, uid: cfcfe1ee-ed72-4fe3-9893-feafcf03d806]
I0416 21:30:06.171292       1 deployment_controller.go:193] Deleting deployment linux-nginx
I0416 21:30:06.171316       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:30:06.17130899 +0000 UTC m=+1628.325033141)
I0416 21:30:06.171360       1 deployment_controller.go:573] Deployment default/linux-nginx has been deleted
I0416 21:30:06.171364       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (52.654µs)
I0416 21:30:06.186882       1 request.go:530] Throttling request took 352.394726ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:30:06.236918       1 request.go:530] Throttling request took 402.41171ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:30:06.239423       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:30:06.452907       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:30:06.479558       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=deployments, namespace default, name linux-ubuntu, uid abf9507f-5489-4b2b-a4f8-808dd69ba50d, event type delete
I0416 21:30:06.479656       1 garbagecollector.go:405] processing item [extensions/v1beta1/ReplicaSet, namespace: default, name: linux-ubuntu-5dbcdfff9d, uid: 7d8aa653-d67a-4d6b-8a1b-0e2344c09030]
I0416 21:30:06.479705       1 deployment_controller.go:193] Deleting deployment linux-ubuntu
I0416 21:30:06.479724       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:30:06.479718984 +0000 UTC m=+1628.633443120)
I0416 21:30:06.479747       1 deployment_controller.go:573] Deployment default/linux-ubuntu has been deleted
I0416 21:30:06.479752       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (30.113µs)
I0416 21:30:06.480480       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=deployments, namespace default, name linux-ubuntu, uid abf9507f-5489-4b2b-a4f8-808dd69ba50d, event type delete
I0416 21:30:06.701505       1 garbagecollector.go:518] delete object [extensions/v1beta1/ReplicaSet, namespace: default, name: linux-nginx-7c4f9bd84f, uid: cfcfe1ee-ed72-4fe3-9893-feafcf03d806] with propagation policy Background
I0416 21:30:06.702159       1 garbagecollector.go:518] delete object [extensions/v1beta1/ReplicaSet, namespace: default, name: linux-ubuntu-5dbcdfff9d, uid: 7d8aa653-d67a-4d6b-8a1b-0e2344c09030] with propagation policy Background
I0416 21:30:06.709291       1 replica_set.go:575] ReplicaSet default/linux-ubuntu-5dbcdfff9d has been deleted
I0416 21:30:06.709329       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (61.855µs)
I0416 21:30:06.709429       1 garbagecollector.go:405] processing item [v1/Pod, namespace: default, name: linux-ubuntu-5dbcdfff9d-xmpzc, uid: 1148e799-d519-4ff7-a7a8-e41e13bfa7cb]
I0416 21:30:06.709801       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=replicasets, namespace default, name linux-ubuntu-5dbcdfff9d, uid 7d8aa653-d67a-4d6b-8a1b-0e2344c09030, event type delete
I0416 21:30:06.711473       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=replicasets, namespace default, name linux-ubuntu-5dbcdfff9d, uid 7d8aa653-d67a-4d6b-8a1b-0e2344c09030, event type delete
I0416 21:30:06.716162       1 replica_set.go:575] ReplicaSet default/linux-nginx-7c4f9bd84f has been deleted
I0416 21:30:06.716175       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (36.116µs)
I0416 21:30:06.716314       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=replicasets, namespace default, name linux-nginx-7c4f9bd84f, uid cfcfe1ee-ed72-4fe3-9893-feafcf03d806, event type delete
I0416 21:30:06.716416       1 garbagecollector.go:405] processing item [v1/Pod, namespace: default, name: linux-nginx-7c4f9bd84f-vsbts, uid: f5280e49-36a5-4b0f-80b6-20ae60dde311]
I0416 21:30:06.716778       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=replicasets, namespace default, name linux-nginx-7c4f9bd84f, uid cfcfe1ee-ed72-4fe3-9893-feafcf03d806, event type delete
I0416 21:30:06.719160       1 garbagecollector.go:518] delete object [v1/Pod, namespace: default, name: linux-ubuntu-5dbcdfff9d-xmpzc, uid: 1148e799-d519-4ff7-a7a8-e41e13bfa7cb] with propagation policy Background
I0416 21:30:06.722837       1 garbagecollector.go:518] delete object [v1/Pod, namespace: default, name: linux-nginx-7c4f9bd84f-vsbts, uid: f5280e49-36a5-4b0f-80b6-20ae60dde311] with propagation policy Background
I0416 21:30:06.729353       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:30:06.729378       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:06.729382       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:30:06.741551       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:30:06.741588       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:06.741592       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:30:06.777639       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=deployments, namespace default, name windows-nettest, uid ae1fb189-b088-4687-b78a-6d3a98e2bb7b, event type delete
I0416 21:30:06.781889       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=deployments, namespace default, name windows-nettest, uid ae1fb189-b088-4687-b78a-6d3a98e2bb7b, event type delete
I0416 21:30:06.777797       1 garbagecollector.go:405] processing item [apps/v1/ReplicaSet, namespace: default, name: windows-nettest-944bd6d8d, uid: 8b5de186-44bd-4108-b022-df873336c192]
I0416 21:30:06.777884       1 deployment_controller.go:193] Deleting deployment windows-nettest
I0416 21:30:06.782371       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:30:06.782357993 +0000 UTC m=+1628.936082144)
I0416 21:30:06.782402       1 deployment_controller.go:573] Deployment default/windows-nettest has been deleted
I0416 21:30:06.782407       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (46.066µs)
I0416 21:30:06.786162       1 garbagecollector.go:518] delete object [apps/v1/ReplicaSet, namespace: default, name: windows-nettest-944bd6d8d, uid: 8b5de186-44bd-4108-b022-df873336c192] with propagation policy Background
I0416 21:30:06.792817       1 replica_set.go:575] ReplicaSet default/windows-nettest-944bd6d8d has been deleted
I0416 21:30:06.792835       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (63.623µs)
I0416 21:30:06.792970       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=replicasets, namespace default, name windows-nettest-944bd6d8d, uid 8b5de186-44bd-4108-b022-df873336c192, event type delete
I0416 21:30:06.793053       1 garbagecollector.go:405] processing item [v1/Pod, namespace: default, name: windows-nettest-944bd6d8d-rfhxl, uid: db88e65c-9310-4d07-b676-6399d59d69a0]
I0416 21:30:06.793533       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=replicasets, namespace default, name windows-nettest-944bd6d8d, uid 8b5de186-44bd-4108-b022-df873336c192, event type delete
I0416 21:30:06.799072       1 garbagecollector.go:518] delete object [v1/Pod, namespace: default, name: windows-nettest-944bd6d8d-rfhxl, uid: db88e65c-9310-4d07-b676-6399d59d69a0] with propagation policy Background
I0416 21:30:06.807212       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-rfhxl
I0416 21:30:06.807487       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:30:06.807509       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-rfhxl, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:06.807512       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:30:06.819357       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-rfhxl
I0416 21:30:06.819672       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:30:06.819694       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-rfhxl, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:06.819697       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:30:08.038133       1 pvc_protection_controller.go:280] Got event on pod default/linux-nginx-7c4f9bd84f-vsbts
I0416 21:30:08.038420       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:30:08.038440       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:08.038446       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:30:09.055813       1 pvc_protection_controller.go:280] Got event on pod default/linux-nginx-7c4f9bd84f-vsbts
I0416 21:30:09.055902       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name linux-nginx-7c4f9bd84f-vsbts, uid f5280e49-36a5-4b0f-80b6-20ae60dde311, event type update
I0416 21:30:09.056038       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:30:09.056055       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:09.056059       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:30:09.062086       1 pvc_protection_controller.go:280] Got event on pod default/linux-nginx-7c4f9bd84f-vsbts
I0416 21:30:09.062154       1 deployment_controller.go:356] Pod linux-nginx-7c4f9bd84f-vsbts deleted.
I0416 21:30:09.062167       1 deployment_controller.go:424] Cannot get replicaset "linux-nginx-7c4f9bd84f" for pod "linux-nginx-7c4f9bd84f-vsbts": replicaset.apps "linux-nginx-7c4f9bd84f" not found
I0416 21:30:09.062207       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name linux-nginx-7c4f9bd84f-vsbts, uid f5280e49-36a5-4b0f-80b6-20ae60dde311, event type delete
I0416 21:30:09.062291       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"default", Name:"linux-nginx-7c4f9bd84f-vsbts"}
I0416 21:30:09.062394       1 disruption.go:367] deletePod called on pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:30:09.062425       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-vsbts, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:09.062429       1 disruption.go:370] No matching pdb for pod "linux-nginx-7c4f9bd84f-vsbts"
I0416 21:30:11.766271       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:11.788611       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:11.798704       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:30:12.069806       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:30:12.259856       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:12.289530       1 controller.go:123] Found 0 jobs
I0416 21:30:12.292456       1 controller.go:139] Found 0 cronjobs
I0416 21:30:12.292467       1 controller.go:142] Found 0 groups
I0416 21:30:12.794074       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-rfhxl
I0416 21:30:12.794182       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name windows-nettest-944bd6d8d-rfhxl, uid db88e65c-9310-4d07-b676-6399d59d69a0, event type update
I0416 21:30:12.794807       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:30:12.794848       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-rfhxl, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:12.794852       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:30:12.800765       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-rfhxl
I0416 21:30:12.800823       1 deployment_controller.go:356] Pod windows-nettest-944bd6d8d-rfhxl deleted.
I0416 21:30:12.800837       1 deployment_controller.go:424] Cannot get replicaset "windows-nettest-944bd6d8d" for pod "windows-nettest-944bd6d8d-rfhxl": replicaset.apps "windows-nettest-944bd6d8d" not found
I0416 21:30:12.800884       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name windows-nettest-944bd6d8d-rfhxl, uid db88e65c-9310-4d07-b676-6399d59d69a0, event type delete
I0416 21:30:12.800939       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"default", Name:"windows-nettest-944bd6d8d-rfhxl"}
I0416 21:30:12.801026       1 disruption.go:367] deletePod called on pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:30:12.801044       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-rfhxl, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:12.801048       1 disruption.go:370] No matching pdb for pod "windows-nettest-944bd6d8d-rfhxl"
I0416 21:30:12.930292       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 21:30:15.608564       1 wrap.go:47] GET /healthz: (102.475µs) 200 [kube-probe/1.15+ 127.0.0.1:42400]
I0416 21:30:15.788353       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 21:30:20.035940       1 request.go:530] Throttling request took 91.331292ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:30:20.085860       1 request.go:530] Throttling request took 141.269048ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:30:20.135846       1 request.go:530] Throttling request took 191.245419ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:30:20.185952       1 request.go:530] Throttling request took 241.318678ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:30:20.236029       1 request.go:530] Throttling request took 291.403161ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:30:20.285929       1 request.go:530] Throttling request took 341.273873ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:30:20.335894       1 request.go:530] Throttling request took 391.242284ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:30:20.385876       1 request.go:530] Throttling request took 441.208164ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:30:22.296862       1 controller.go:123] Found 0 jobs
I0416 21:30:22.299502       1 controller.go:139] Found 0 cronjobs
I0416 21:30:22.299515       1 controller.go:142] Found 0 groups
I0416 21:30:22.302130       1 gc_controller.go:144] GC'ing orphaned
I0416 21:30:22.306563       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:30:22.884214       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:25.124523       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:30:25.608547       1 wrap.go:47] GET /healthz: (86.938µs) 200 [kube-probe/1.15+ 127.0.0.1:42432]
I0416 21:30:26.790775       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 21:30:27.070662       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:30:27.103720       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:30:27.103759       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:30:27.103787       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:30:27.103809       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:30:27.103950       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:30:27.252509       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:30:27.252548       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:30:27.260429       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:27.830751       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:30:32.253003       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:30:32.303904       1 controller.go:123] Found 0 jobs
I0416 21:30:32.306265       1 controller.go:139] Found 0 cronjobs
I0416 21:30:32.306277       1 controller.go:142] Found 0 groups
I0416 21:30:35.608755       1 wrap.go:47] GET /healthz: (88.673µs) 200 [kube-probe/1.15+ 127.0.0.1:42466]
I0416 21:30:35.662298       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:36.340163       1 request.go:530] Throttling request took 91.513094ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:30:36.389953       1 request.go:530] Throttling request took 141.274744ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:30:36.439965       1 request.go:530] Throttling request took 191.277469ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:30:36.490003       1 request.go:530] Throttling request took 241.301037ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:30:36.540328       1 request.go:530] Throttling request took 291.618666ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:30:36.590021       1 request.go:530] Throttling request took 341.301325ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:30:36.640024       1 request.go:530] Throttling request took 391.276179ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:30:36.690037       1 request.go:530] Throttling request took 441.276158ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:30:36.692311       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:30:38.670656       1 pvc_protection_controller.go:280] Got event on pod default/linux-ubuntu-5dbcdfff9d-xmpzc
I0416 21:30:38.670864       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:30:38.670883       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:38.670888       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:30:41.766603       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:41.767024       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (292.998µs)
I0416 21:30:41.767090       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.997µs)
I0416 21:30:41.767310       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:30:41.767874       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (139.599µs)
I0416 21:30:41.767930       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (43.895µs)
I0416 21:30:41.768003       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (46.094µs)
I0416 21:30:41.771923       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (4.817703ms)
I0416 21:30:41.796854       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:42.071501       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:30:42.260968       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:30:42.306805       1 gc_controller.go:144] GC'ing orphaned
I0416 21:30:42.312965       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:30:42.313472       1 controller.go:123] Found 0 jobs
I0416 21:30:42.315429       1 controller.go:139] Found 0 cronjobs
I0416 21:30:42.315437       1 controller.go:142] Found 0 groups
I0416 21:30:42.528587       1 pvc_protection_controller.go:280] Got event on pod default/linux-ubuntu-5dbcdfff9d-xmpzc
I0416 21:30:42.528677       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name linux-ubuntu-5dbcdfff9d-xmpzc, uid 1148e799-d519-4ff7-a7a8-e41e13bfa7cb, event type update
I0416 21:30:42.528823       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:30:42.528841       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:42.528845       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:30:42.535131       1 pvc_protection_controller.go:280] Got event on pod default/linux-ubuntu-5dbcdfff9d-xmpzc
I0416 21:30:42.535186       1 deployment_controller.go:356] Pod linux-ubuntu-5dbcdfff9d-xmpzc deleted.
I0416 21:30:42.535212       1 deployment_controller.go:424] Cannot get replicaset "linux-ubuntu-5dbcdfff9d" for pod "linux-ubuntu-5dbcdfff9d-xmpzc": replicaset.apps "linux-ubuntu-5dbcdfff9d" not found
I0416 21:30:42.535265       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name linux-ubuntu-5dbcdfff9d-xmpzc, uid 1148e799-d519-4ff7-a7a8-e41e13bfa7cb, event type delete
I0416 21:30:42.535350       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"default", Name:"linux-ubuntu-5dbcdfff9d-xmpzc"}
I0416 21:30:42.535458       1 disruption.go:367] deletePod called on pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:30:42.535580       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-xmpzc, PodDisruptionBudget controller will avoid syncing.
I0416 21:30:42.535585       1 disruption.go:370] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-xmpzc"
I0416 21:30:45.608076       1 wrap.go:47] GET /healthz: (86.762µs) 200 [kube-probe/1.15+ 127.0.0.1:42518]
I0416 21:30:50.490139       1 request.go:530] Throttling request took 94.643038ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:30:50.538890       1 request.go:530] Throttling request took 143.391856ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:30:50.588882       1 request.go:530] Throttling request took 193.372029ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:30:50.638798       1 request.go:530] Throttling request took 243.28062ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:30:50.688841       1 request.go:530] Throttling request took 293.311925ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:30:50.739113       1 request.go:530] Throttling request took 343.559612ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:30:50.789341       1 request.go:530] Throttling request took 393.805003ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:30:50.838877       1 request.go:530] Throttling request took 443.295895ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:30:51.680740       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:30:52.319705       1 controller.go:123] Found 0 jobs
I0416 21:30:52.321954       1 controller.go:139] Found 0 cronjobs
I0416 21:30:52.321965       1 controller.go:142] Found 0 groups
I0416 21:30:55.608621       1 wrap.go:47] GET /healthz: (79.967µs) 200 [kube-probe/1.15+ 127.0.0.1:42554]
I0416 21:30:56.029033       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 21:30:56.770424       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 21:30:57.072272       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:30:57.261474       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:02.020304       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:31:02.313266       1 gc_controller.go:144] GC'ing orphaned
I0416 21:31:02.317904       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:31:02.326617       1 controller.go:123] Found 0 jobs
I0416 21:31:02.329215       1 controller.go:139] Found 0 cronjobs
I0416 21:31:02.329249       1 controller.go:142] Found 0 groups
I0416 21:31:04.782067       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 21:31:05.395985       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:05.608697       1 wrap.go:47] GET /healthz: (84.566µs) 200 [kube-probe/1.15+ 127.0.0.1:42590]
I0416 21:31:06.792818       1 request.go:530] Throttling request took 92.453739ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:31:06.842764       1 request.go:530] Throttling request took 142.459816ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:31:06.892762       1 request.go:530] Throttling request took 192.442908ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:31:06.942874       1 request.go:530] Throttling request took 242.534877ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:31:06.992772       1 request.go:530] Throttling request took 292.438912ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:31:07.042811       1 request.go:530] Throttling request took 342.47215ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:31:07.093052       1 request.go:530] Throttling request took 392.705268ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:31:07.142803       1 request.go:530] Throttling request took 442.434602ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:31:07.145146       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:31:11.767006       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:11.797202       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:12.072590       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:31:12.261934       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:12.333367       1 controller.go:123] Found 0 jobs
I0416 21:31:12.336355       1 controller.go:139] Found 0 cronjobs
I0416 21:31:12.336369       1 controller.go:142] Found 0 groups
I0416 21:31:13.771323       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 102 items received
I0416 21:31:14.264658       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:31:15.608589       1 wrap.go:47] GET /healthz: (86.439µs) 200 [kube-probe/1.15+ 127.0.0.1:42622]
I0416 21:31:20.941801       1 request.go:530] Throttling request took 93.433413ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:31:20.991777       1 request.go:530] Throttling request took 143.389185ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:31:21.041862       1 request.go:530] Throttling request took 193.459589ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:31:21.092874       1 request.go:530] Throttling request took 244.461954ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:31:21.141767       1 request.go:530] Throttling request took 293.34808ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:31:21.191799       1 request.go:530] Throttling request took 343.363898ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:31:21.241820       1 request.go:530] Throttling request took 393.379814ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:31:21.291774       1 request.go:530] Throttling request took 443.319506ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:31:22.318321       1 gc_controller.go:144] GC'ing orphaned
I0416 21:31:22.322501       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:31:22.339957       1 controller.go:123] Found 0 jobs
I0416 21:31:22.342373       1 controller.go:139] Found 0 cronjobs
I0416 21:31:22.342384       1 controller.go:142] Found 0 groups
I0416 21:31:22.414628       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 21:31:25.196846       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:31:25.608569       1 wrap.go:47] GET /healthz: (80.073µs) 200 [kube-probe/1.15+ 127.0.0.1:42654]
I0416 21:31:25.780860       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 21:31:27.074384       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:31:27.194134       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:31:27.258442       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:31:27.258477       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:31:27.262461       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:27.985051       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:31:30.887909       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:32.258899       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:31:32.346539       1 controller.go:123] Found 0 jobs
I0416 21:31:32.351040       1 controller.go:139] Found 0 cronjobs
I0416 21:31:32.351067       1 controller.go:142] Found 0 groups
I0416 21:31:35.608619       1 wrap.go:47] GET /healthz: (85.771µs) 200 [kube-probe/1.15+ 127.0.0.1:42688]
I0416 21:31:37.248270       1 request.go:530] Throttling request took 80.699871ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:31:37.298267       1 request.go:530] Throttling request took 130.685204ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:31:37.348725       1 request.go:530] Throttling request took 181.167471ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:31:37.398314       1 request.go:530] Throttling request took 230.743782ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:31:37.448393       1 request.go:530] Throttling request took 280.787933ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:31:37.498402       1 request.go:530] Throttling request took 330.776204ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:31:37.548272       1 request.go:530] Throttling request took 380.625734ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:31:37.598167       1 request.go:530] Throttling request took 430.521712ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:31:37.600588       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:31:41.767358       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:41.797484       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:42.079736       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:31:42.263025       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:42.322769       1 gc_controller.go:144] GC'ing orphaned
I0416 21:31:42.329872       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:31:42.356119       1 controller.go:123] Found 0 jobs
I0416 21:31:42.360890       1 controller.go:139] Found 0 cronjobs
I0416 21:31:42.360904       1 controller.go:142] Found 0 groups
I0416 21:31:45.608065       1 wrap.go:47] GET /healthz: (90.157µs) 200 [kube-probe/1.15+ 127.0.0.1:42740]
I0416 21:31:46.441989       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:51.395393       1 request.go:530] Throttling request took 91.801996ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:31:51.446698       1 request.go:530] Throttling request took 143.099399ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:31:51.495210       1 request.go:530] Throttling request took 191.597522ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:31:51.547028       1 request.go:530] Throttling request took 243.3959ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:31:51.595197       1 request.go:530] Throttling request took 291.55575ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:31:51.645353       1 request.go:530] Throttling request took 341.621046ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:31:51.695401       1 request.go:530] Throttling request took 391.753486ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:31:51.745468       1 request.go:530] Throttling request took 441.809663ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:31:52.365490       1 controller.go:123] Found 0 jobs
I0416 21:31:52.369158       1 controller.go:139] Found 0 cronjobs
I0416 21:31:52.369171       1 controller.go:142] Found 0 groups
I0416 21:31:55.608518       1 wrap.go:47] GET /healthz: (91.385µs) 200 [kube-probe/1.15+ 127.0.0.1:42776]
I0416 21:31:57.080011       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:31:57.263536       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:31:57.767855       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 176 items received
I0416 21:32:02.330218       1 gc_controller.go:144] GC'ing orphaned
I0416 21:32:02.334199       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:32:02.372653       1 controller.go:123] Found 0 jobs
I0416 21:32:02.375011       1 controller.go:139] Found 0 cronjobs
I0416 21:32:02.375024       1 controller.go:142] Found 0 groups
I0416 21:32:03.010365       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:32:05.608453       1 wrap.go:47] GET /healthz: (77.064µs) 200 [kube-probe/1.15+ 127.0.0.1:42812]
I0416 21:32:07.700999       1 request.go:530] Throttling request took 91.0109ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:32:07.751118       1 request.go:530] Throttling request took 141.121458ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:32:07.801193       1 request.go:530] Throttling request took 191.195214ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:32:07.851097       1 request.go:530] Throttling request took 241.078251ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:32:07.901240       1 request.go:530] Throttling request took 291.106206ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:32:07.951009       1 request.go:530] Throttling request took 340.974507ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:32:08.002826       1 request.go:530] Throttling request took 392.780937ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:32:08.051097       1 request.go:530] Throttling request took 441.026302ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:32:08.055790       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:32:10.518317       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 21:32:11.767791       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:11.797812       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:12.080327       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:32:12.263987       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:12.379303       1 controller.go:123] Found 0 jobs
I0416 21:32:12.382065       1 controller.go:139] Found 0 cronjobs
I0416 21:32:12.382078       1 controller.go:142] Found 0 groups
I0416 21:32:15.608386       1 wrap.go:47] GET /healthz: (86.511µs) 200 [kube-probe/1.15+ 127.0.0.1:42844]
I0416 21:32:19.793841       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 21:32:21.849625       1 request.go:530] Throttling request took 90.319587ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:32:21.898097       1 request.go:530] Throttling request took 138.745283ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:32:21.948009       1 request.go:530] Throttling request took 188.677448ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:32:21.998095       1 request.go:530] Throttling request took 238.752655ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:32:22.048444       1 request.go:530] Throttling request took 289.095022ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:32:22.095120       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 21:32:22.097939       1 request.go:530] Throttling request took 338.592467ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:32:22.148043       1 request.go:530] Throttling request took 388.656789ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:32:22.198606       1 request.go:530] Throttling request took 439.193758ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:32:22.334535       1 gc_controller.go:144] GC'ing orphaned
I0416 21:32:22.338932       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:32:22.386050       1 controller.go:123] Found 0 jobs
I0416 21:32:22.389727       1 controller.go:139] Found 0 cronjobs
I0416 21:32:22.389741       1 controller.go:142] Found 0 groups
I0416 21:32:23.619453       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:23.619731       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:32:23.619831       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:32:23.619949       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:32:25.279792       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:32:25.608586       1 wrap.go:47] GET /healthz: (93.303µs) 200 [kube-probe/1.15+ 127.0.0.1:42876]
I0416 21:32:27.081884       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:32:27.263901       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:32:27.264418       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:27.310583       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:32:28.114689       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:32:32.264381       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:32:32.264464       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:32:32.393975       1 controller.go:123] Found 0 jobs
I0416 21:32:32.397215       1 controller.go:139] Found 0 cronjobs
I0416 21:32:32.397242       1 controller.go:142] Found 0 groups
I0416 21:32:35.608455       1 wrap.go:47] GET /healthz: (80.789µs) 200 [kube-probe/1.15+ 127.0.0.1:42910]
I0416 21:32:35.797785       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 495 items received
I0416 21:32:36.059940       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.060035       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:32:36.060052       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:32:36.060075       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:32:36.06006961 +0000 UTC m=+1778.213793747)
I0416 21:32:36.061052       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (976.967µs)
I0416 21:32:36.061083       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:32:36.061080475 +0000 UTC m=+1778.214804611)
I0416 21:32:36.061481       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (398.148µs)
I0416 21:32:36.061516       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:32:36.061526       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:32:36.06152298 +0000 UTC m=+1778.215247117)
I0416 21:32:36.061855       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (330.329µs)
I0416 21:32:36.061892       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:32:36.061897       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:32:36.061905       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:32:36.061902437 +0000 UTC m=+1778.215626574)
I0416 21:32:36.062360       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (455.68µs)
I0416 21:32:36.062371       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:32:36.062368984 +0000 UTC m=+1778.216093120)
I0416 21:32:36.063290       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (917.476µs)
I0416 21:32:36.063326       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:32:36.063331       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:32:36.063341       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:32:36.063336953 +0000 UTC m=+1778.217061090)
I0416 21:32:36.064376       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.035571ms)
I0416 21:32:36.064404       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:32:36.06440115 +0000 UTC m=+1778.218125300)
I0416 21:32:36.064974       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (570.741µs)
I0416 21:32:36.064990       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:32:36.064999       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:32:36.064996846 +0000 UTC m=+1778.218720983)
I0416 21:32:36.065322       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (310.528µs)
I0416 21:32:36.075697       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.075807       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:32:36.077176       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b01f1304a772, ext:1530472796265, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.077527       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:32:36.077537       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b05d049f1458, ext:1778231258432, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.077612       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:32:36.077661       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:32:36.077667       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b05d049f1458, ext:1778231258432, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.077715       1 update.go:396] Getting unavailable numbers
I0416 21:32:36.077837       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:32:36.077844       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:32:36.077850       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:32:36.077854       1 update.go:68] Marking old pods for deletion
I0416 21:32:36.077858       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b05d04a3fed6, ext:1778231580607, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.077865       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:32:36.077906       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:32:36.077930       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:32:36.078047       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:32:36.078054       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.200707ms)
I0416 21:32:36.078120       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:32:36.078658       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b01f12ec2872, ext:1530471190874, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.078861       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:32:36.078869       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b05d04b36d8a, ext:1778232592004, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.078919       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:32:36.078959       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:32:36.078977       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b05d04b36d8a, ext:1778232592004, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.079007       1 update.go:396] Getting unavailable numbers
I0416 21:32:36.079108       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:32:36.079114       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:32:36.079118       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:32:36.079122       1 update.go:68] Marking old pods for deletion
I0416 21:32:36.079137       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b05d04b784dc, ext:1778232860114, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.079144       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:32:36.079166       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:32:36.079187       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:32:36.079329       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:32:36.079335       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.20249ms)
I0416 21:32:36.079413       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.079460       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.079561       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.079706       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:32:36.079715       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.079718       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:32:36.079754       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:32:36.079785       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.079787       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:32:36.079817       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:32:36.079825       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.079827       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:32:36.079850       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:32:36.079859       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.079862       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:32:36.079885       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:32:36.079893       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.079895       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:32:36.079931       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:32:36.079940       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.079942       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:32:36.079945       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:32:36.079953       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.079955       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:32:36.080004       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:32:36.080011       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080013       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:32:36.080039       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:32:36.080047       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080049       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:32:36.080077       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:32:36.080084       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080086       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:32:36.080112       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:32:36.080119       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080121       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:32:36.080139       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:32:36.080148       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080150       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:32:36.080152       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:32:36.080159       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080161       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:32:36.080198       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:32:36.080202       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080204       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:32:36.080278       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:32:36.080285       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080288       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:32:36.080313       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:32:36.080323       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080325       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:32:36.080355       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:32:36.080365       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080367       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:32:36.080392       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:32:36.080401       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080403       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:32:36.080425       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:32:36.080434       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080437       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:32:36.080455       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:32:36.080461       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080464       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:32:36.080485       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:32:36.080491       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080494       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:32:36.080509       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:32:36.080520       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:32:36.080522       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:32:36.085529       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.085691       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.085942       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (264.419µs)
I0416 21:32:36.086017       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.086035       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.086092       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086180       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (82.638µs)
I0416 21:32:36.086192       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086271       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (81.106µs)
I0416 21:32:36.086295       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086376       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (83.355µs)
I0416 21:32:36.086397       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086465       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (70.882µs)
I0416 21:32:36.086507       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086559       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (53.291µs)
I0416 21:32:36.086582       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086633       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (51.954µs)
I0416 21:32:36.086667       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086715       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (49.948µs)
I0416 21:32:36.086723       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086835       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (110.941µs)
I0416 21:32:36.086858       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:32:36.086920       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (63.828µs)
I0416 21:32:36.259385       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.290557       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.629936       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:36.630034       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:32:36.630078       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (3.362µs)
I0416 21:32:36.630105       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:32:36.630111       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (527ns)
I0416 21:32:36.630120       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:32:36.630143       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:32:36.630247       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (610ns)
I0416 21:32:36.630256       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (297ns)
I0416 21:32:36.680506       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:38.156261       1 request.go:530] Throttling request took 94.005654ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:32:38.206256       1 request.go:530] Throttling request took 143.989774ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:32:38.256439       1 request.go:530] Throttling request took 194.187478ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:32:38.306427       1 request.go:530] Throttling request took 240.832833ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:32:38.356248       1 request.go:530] Throttling request took 290.588313ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:32:38.406325       1 request.go:530] Throttling request took 340.641441ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:32:38.456384       1 request.go:530] Throttling request took 390.713831ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:32:38.506763       1 request.go:530] Throttling request took 441.062569ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:32:38.509432       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:32:41.768198       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:41.798241       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:42.082270       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:32:42.264758       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:32:42.339329       1 gc_controller.go:144] GC'ing orphaned
I0416 21:32:42.344152       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:32:42.401316       1 controller.go:123] Found 0 jobs
I0416 21:32:42.403840       1 controller.go:139] Found 0 cronjobs
I0416 21:32:42.403861       1 controller.go:142] Found 0 groups
I0416 21:32:45.609351       1 wrap.go:47] GET /healthz: (151.452µs) 200 [kube-probe/1.15+ 127.0.0.1:42962]
I0416 21:32:52.301352       1 request.go:530] Throttling request took 82.552249ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:32:52.351620       1 request.go:530] Throttling request took 132.784571ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:32:52.401325       1 request.go:530] Throttling request took 182.483348ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:32:52.408153       1 controller.go:123] Found 0 jobs
I0416 21:32:52.411049       1 controller.go:139] Found 0 cronjobs
I0416 21:32:52.411061       1 controller.go:142] Found 0 groups
I0416 21:32:52.451675       1 request.go:530] Throttling request took 232.831342ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:32:52.501295       1 request.go:530] Throttling request took 282.437625ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:32:52.552368       1 request.go:530] Throttling request took 333.503936ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:32:52.602371       1 request.go:530] Throttling request took 383.479995ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:32:52.651330       1 request.go:530] Throttling request took 432.430433ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:32:55.608597       1 wrap.go:47] GET /healthz: (88.075µs) 200 [kube-probe/1.15+ 127.0.0.1:42998]
I0416 21:32:57.082645       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:32:57.265082       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:02.344494       1 gc_controller.go:144] GC'ing orphaned
I0416 21:33:02.349377       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:33:02.414837       1 controller.go:123] Found 0 jobs
I0416 21:33:02.417729       1 controller.go:139] Found 0 cronjobs
I0416 21:33:02.417743       1 controller.go:142] Found 0 groups
I0416 21:33:03.008694       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:33:05.608766       1 wrap.go:47] GET /healthz: (97.909µs) 200 [kube-probe/1.15+ 127.0.0.1:43032]
I0416 21:33:08.610067       1 request.go:530] Throttling request took 94.042205ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:33:08.660092       1 request.go:530] Throttling request took 144.062887ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:33:08.710054       1 request.go:530] Throttling request took 194.020181ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:33:08.760288       1 request.go:530] Throttling request took 244.240954ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:33:08.810055       1 request.go:530] Throttling request took 294.000563ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:33:08.860188       1 request.go:530] Throttling request took 344.119904ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:33:08.910098       1 request.go:530] Throttling request took 394.030736ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:33:08.960135       1 request.go:530] Throttling request took 444.0276ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:33:08.962339       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:33:09.319612       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 36 items received
I0416 21:33:11.768978       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:11.798689       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:12.083064       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:33:12.265346       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:12.393011       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:12.421470       1 controller.go:123] Found 0 jobs
I0416 21:33:12.424149       1 controller.go:139] Found 0 cronjobs
I0416 21:33:12.424161       1 controller.go:142] Found 0 groups
I0416 21:33:14.952349       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 21:33:15.608725       1 wrap.go:47] GET /healthz: (89.781µs) 200 [kube-probe/1.15+ 127.0.0.1:43066]
I0416 21:33:21.468927       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 21:33:22.350097       1 gc_controller.go:144] GC'ing orphaned
I0416 21:33:22.355119       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:33:22.429155       1 controller.go:123] Found 0 jobs
I0416 21:33:22.432636       1 controller.go:139] Found 0 cronjobs
I0416 21:33:22.432651       1 controller.go:142] Found 0 groups
I0416 21:33:22.754493       1 request.go:530] Throttling request took 89.743616ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:33:22.804492       1 request.go:530] Throttling request took 139.721268ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:33:22.854516       1 request.go:530] Throttling request took 189.71763ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:33:22.904549       1 request.go:530] Throttling request took 239.739906ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:33:22.954508       1 request.go:530] Throttling request took 289.696844ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:33:23.004883       1 request.go:530] Throttling request took 340.052479ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:33:23.054452       1 request.go:530] Throttling request took 389.623437ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:33:23.104363       1 request.go:530] Throttling request took 439.522142ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:33:25.356832       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:33:25.608625       1 wrap.go:47] GET /healthz: (97.437µs) 200 [kube-probe/1.15+ 127.0.0.1:43098]
I0416 21:33:25.787797       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:33:27.083367       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:33:27.265649       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:27.271981       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:33:27.429921       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:33:28.356502       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:33:29.325707       1 reflector.go:249] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: forcing resync
I0416 21:33:32.272665       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:33:32.272742       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:33:32.436833       1 controller.go:123] Found 0 jobs
I0416 21:33:32.439833       1 controller.go:139] Found 0 cronjobs
I0416 21:33:32.439845       1 controller.go:142] Found 0 groups
I0416 21:33:35.609646       1 wrap.go:47] GET /healthz: (85.141µs) 200 [kube-probe/1.15+ 127.0.0.1:43132]
I0416 21:33:38.909029       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 4 items received
I0416 21:33:39.062975       1 request.go:530] Throttling request took 91.511012ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:33:39.112841       1 request.go:530] Throttling request took 141.35861ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:33:39.162993       1 request.go:530] Throttling request took 191.50773ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:33:39.212972       1 request.go:530] Throttling request took 241.457006ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:33:39.262930       1 request.go:530] Throttling request took 291.425441ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:33:39.312921       1 request.go:530] Throttling request took 341.387184ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:33:39.363352       1 request.go:530] Throttling request took 391.815898ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:33:39.412967       1 request.go:530] Throttling request took 441.417226ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:33:39.415142       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:33:41.769396       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:41.799001       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:42.084065       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:33:42.265943       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:42.355445       1 gc_controller.go:144] GC'ing orphaned
I0416 21:33:42.361770       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:33:42.444383       1 controller.go:123] Found 0 jobs
I0416 21:33:42.447587       1 controller.go:139] Found 0 cronjobs
I0416 21:33:42.447601       1 controller.go:142] Found 0 groups
I0416 21:33:42.559641       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:33:43.028958       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:43.770199       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 0 items received
I0416 21:33:43.822709       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:33:45.608811       1 wrap.go:47] GET /healthz: (107.731µs) 200 [kube-probe/1.15+ 127.0.0.1:43184]
I0416 21:33:49.793856       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 21:33:52.452048       1 controller.go:123] Found 0 jobs
I0416 21:33:52.456306       1 controller.go:139] Found 0 cronjobs
I0416 21:33:52.456321       1 controller.go:142] Found 0 groups
I0416 21:33:53.208646       1 request.go:530] Throttling request took 81.751528ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:33:53.258583       1 request.go:530] Throttling request took 131.682838ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:33:53.308583       1 request.go:530] Throttling request took 181.677377ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:33:53.358947       1 request.go:530] Throttling request took 232.032072ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:33:53.408639       1 request.go:530] Throttling request took 281.714218ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:33:53.458552       1 request.go:530] Throttling request took 331.603977ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:33:53.508607       1 request.go:530] Throttling request took 381.652042ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:33:53.558635       1 request.go:530] Throttling request took 431.667668ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:33:54.120118       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 21:33:55.608483       1 wrap.go:47] GET /healthz: (92.641µs) 200 [kube-probe/1.15+ 127.0.0.1:43220]
I0416 21:33:57.084444       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:33:57.268018       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:57.402377       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:33:59.800165       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
I0416 21:34:02.362062       1 gc_controller.go:144] GC'ing orphaned
I0416 21:34:02.372637       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:34:02.462020       1 controller.go:123] Found 0 jobs
I0416 21:34:02.465271       1 controller.go:139] Found 0 cronjobs
I0416 21:34:02.465285       1 controller.go:142] Found 0 groups
I0416 21:34:03.008554       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:34:05.609438       1 wrap.go:47] GET /healthz: (85.446µs) 200 [kube-probe/1.15+ 127.0.0.1:43254]
I0416 21:34:09.515718       1 request.go:530] Throttling request took 91.597547ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:34:09.565637       1 request.go:530] Throttling request took 141.512549ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:34:09.615725       1 request.go:530] Throttling request took 191.554224ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:34:09.665676       1 request.go:530] Throttling request took 241.500836ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:34:09.715729       1 request.go:530] Throttling request took 291.539483ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:34:09.766354       1 request.go:530] Throttling request took 342.158152ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:34:09.815705       1 request.go:530] Throttling request took 391.504286ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:34:09.865718       1 request.go:530] Throttling request took 441.504272ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:34:09.868493       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:34:11.769735       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:11.799308       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:12.085200       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:34:12.268363       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:12.469643       1 controller.go:123] Found 0 jobs
I0416 21:34:12.472715       1 controller.go:139] Found 0 cronjobs
I0416 21:34:12.472727       1 controller.go:142] Found 0 groups
I0416 21:34:14.405543       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:34:14.773879       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 21:34:14.780863       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 23 items received
I0416 21:34:15.609850       1 wrap.go:47] GET /healthz: (86.362µs) 200 [kube-probe/1.15+ 127.0.0.1:43288]
I0416 21:34:22.372961       1 gc_controller.go:144] GC'ing orphaned
I0416 21:34:22.377789       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:34:22.477061       1 controller.go:123] Found 0 jobs
I0416 21:34:22.480026       1 controller.go:139] Found 0 cronjobs
I0416 21:34:22.480039       1 controller.go:142] Found 0 groups
I0416 21:34:23.661608       1 request.go:530] Throttling request took 89.49639ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:34:23.711580       1 request.go:530] Throttling request took 139.458791ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:34:23.761573       1 request.go:530] Throttling request took 189.4377ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:34:23.811581       1 request.go:530] Throttling request took 239.435298ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:34:23.861581       1 request.go:530] Throttling request took 289.431044ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:34:23.911582       1 request.go:530] Throttling request took 339.41396ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:34:23.961535       1 request.go:530] Throttling request took 389.358357ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:34:24.011596       1 request.go:530] Throttling request took 439.397507ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:34:25.442560       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:34:25.608684       1 wrap.go:47] GET /healthz: (104.406µs) 200 [kube-probe/1.15+ 127.0.0.1:43320]
I0416 21:34:27.085518       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:34:27.268752       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:27.287380       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:34:27.561173       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:34:28.309153       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 0 items received
I0416 21:34:28.527679       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:34:30.850018       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:32.287817       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:34:32.287906       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:34:32.484037       1 controller.go:123] Found 0 jobs
I0416 21:34:32.486717       1 controller.go:139] Found 0 cronjobs
I0416 21:34:32.486730       1 controller.go:142] Found 0 groups
I0416 21:34:33.336560       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 190 items received
I0416 21:34:35.608630       1 wrap.go:47] GET /healthz: (86.997µs) 200 [kube-probe/1.15+ 127.0.0.1:43354]
I0416 21:34:38.790326       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 21:34:39.968934       1 request.go:530] Throttling request took 91.966345ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:34:40.018984       1 request.go:530] Throttling request took 142.006979ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:34:40.069340       1 request.go:530] Throttling request took 192.356261ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:34:40.119059       1 request.go:530] Throttling request took 242.067597ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:34:40.169007       1 request.go:530] Throttling request took 292.004808ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:34:40.219087       1 request.go:530] Throttling request took 342.070544ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:34:40.268994       1 request.go:530] Throttling request took 391.956505ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:34:40.319196       1 request.go:530] Throttling request took 442.162398ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:34:40.321579       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:34:41.317337       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 0 items received
I0416 21:34:41.770077       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:41.799606       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:42.085892       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:34:42.269136       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:42.378374       1 gc_controller.go:144] GC'ing orphaned
I0416 21:34:42.382341       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:34:42.490741       1 controller.go:123] Found 0 jobs
I0416 21:34:42.493127       1 controller.go:139] Found 0 cronjobs
I0416 21:34:42.493139       1 controller.go:142] Found 0 groups
I0416 21:34:45.608527       1 wrap.go:47] GET /healthz: (76.244µs) 200 [kube-probe/1.15+ 127.0.0.1:43406]
I0416 21:34:49.168388       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 21:34:51.787610       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 0 items received
I0416 21:34:52.498091       1 controller.go:123] Found 0 jobs
I0416 21:34:52.501773       1 controller.go:139] Found 0 cronjobs
I0416 21:34:52.501787       1 controller.go:142] Found 0 groups
I0416 21:34:54.114737       1 request.go:530] Throttling request took 91.090161ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:34:54.164677       1 request.go:530] Throttling request took 141.024995ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:34:54.214721       1 request.go:530] Throttling request took 191.057189ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:34:54.264611       1 request.go:530] Throttling request took 240.937829ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:34:54.314769       1 request.go:530] Throttling request took 291.068056ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:34:54.364701       1 request.go:530] Throttling request took 341.000926ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:34:54.414770       1 request.go:530] Throttling request took 391.062887ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:34:54.464708       1 request.go:530] Throttling request took 440.987944ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:34:54.769068       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 16 items received
I0416 21:34:55.608702       1 wrap.go:47] GET /healthz: (96.569µs) 200 [kube-probe/1.15+ 127.0.0.1:43442]
I0416 21:34:57.086333       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:34:57.269810       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:34:58.774249       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 21:34:59.528557       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:02.382650       1 gc_controller.go:144] GC'ing orphaned
I0416 21:35:02.388540       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:35:02.505912       1 controller.go:123] Found 0 jobs
I0416 21:35:02.508903       1 controller.go:139] Found 0 cronjobs
I0416 21:35:02.508915       1 controller.go:142] Found 0 groups
I0416 21:35:04.008445       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:35:05.608737       1 wrap.go:47] GET /healthz: (95.074µs) 200 [kube-probe/1.15+ 127.0.0.1:43476]
I0416 21:35:10.422127       1 request.go:530] Throttling request took 89.506838ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:35:10.472174       1 request.go:530] Throttling request took 139.53447ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:35:10.522184       1 request.go:530] Throttling request took 189.551998ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:35:10.572125       1 request.go:530] Throttling request took 239.446786ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:35:10.622207       1 request.go:530] Throttling request took 289.513582ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:35:10.673083       1 request.go:530] Throttling request took 340.378649ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:35:10.722265       1 request.go:530] Throttling request took 389.530736ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:35:10.772112       1 request.go:530] Throttling request took 439.374812ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:35:10.774363       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:35:11.770401       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:11.770965       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (409.882µs)
I0416 21:35:11.771179       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (127.31µs)
I0416 21:35:11.771189       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.213µs)
I0416 21:35:11.771403       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:35:11.771893       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (134.607µs)
I0416 21:35:11.771980       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (47.54µs)
I0416 21:35:11.776394       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (5.159954ms)
I0416 21:35:11.799922       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:12.087160       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:35:12.270072       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:12.513211       1 controller.go:123] Found 0 jobs
I0416 21:35:12.516632       1 controller.go:139] Found 0 cronjobs
I0416 21:35:12.516646       1 controller.go:142] Found 0 groups
I0416 21:35:13.791774       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 3 items received
I0416 21:35:15.608811       1 wrap.go:47] GET /healthz: (86.706µs) 200 [kube-probe/1.15+ 127.0.0.1:43510]
I0416 21:35:22.388840       1 gc_controller.go:144] GC'ing orphaned
I0416 21:35:22.393483       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:35:22.520870       1 controller.go:123] Found 0 jobs
I0416 21:35:22.523322       1 controller.go:139] Found 0 cronjobs
I0416 21:35:22.523336       1 controller.go:142] Found 0 groups
I0416 21:35:24.569079       1 request.go:530] Throttling request took 93.957475ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:35:24.617778       1 request.go:530] Throttling request took 142.667094ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:35:24.667758       1 request.go:530] Throttling request took 192.640824ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:35:24.717743       1 request.go:530] Throttling request took 242.608674ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:35:24.768662       1 request.go:530] Throttling request took 293.525958ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:35:24.817784       1 request.go:530] Throttling request took 342.631675ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:35:24.867859       1 request.go:530] Throttling request took 392.70572ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:35:24.917751       1 request.go:530] Throttling request took 442.561704ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:35:25.569420       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:35:25.608687       1 wrap.go:47] GET /healthz: (119.905µs) 200 [kube-probe/1.15+ 127.0.0.1:43542]
I0416 21:35:26.368982       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 21:35:27.087525       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:35:27.270429       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:27.292950       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:35:27.652548       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:35:28.802882       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:35:32.293337       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:35:32.293416       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:35:32.527521       1 controller.go:123] Found 0 jobs
I0416 21:35:32.530218       1 controller.go:139] Found 0 cronjobs
I0416 21:35:32.530244       1 controller.go:142] Found 0 groups
I0416 21:35:35.609511       1 wrap.go:47] GET /healthz: (105.661µs) 200 [kube-probe/1.15+ 127.0.0.1:43576]
I0416 21:35:37.766463       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 3 items received
I0416 21:35:40.874958       1 request.go:530] Throttling request took 90.388021ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:35:40.924960       1 request.go:530] Throttling request took 140.375676ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:35:40.974973       1 request.go:530] Throttling request took 190.380747ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:35:41.024937       1 request.go:530] Throttling request took 240.31961ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:35:41.074938       1 request.go:530] Throttling request took 290.305993ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:35:41.124976       1 request.go:530] Throttling request took 340.330057ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:35:41.174978       1 request.go:530] Throttling request took 390.326016ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:35:41.225023       1 request.go:530] Throttling request took 440.353989ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:35:41.227708       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:35:41.770784       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:41.800202       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:42.087888       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:35:42.270688       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:42.394372       1 gc_controller.go:144] GC'ing orphaned
I0416 21:35:42.398692       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:35:42.535006       1 controller.go:123] Found 0 jobs
I0416 21:35:42.537837       1 controller.go:139] Found 0 cronjobs
I0416 21:35:42.537850       1 controller.go:142] Found 0 groups
I0416 21:35:45.608461       1 wrap.go:47] GET /healthz: (106.1µs) 200 [kube-probe/1.15+ 127.0.0.1:43628]
I0416 21:35:46.271398       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 126 items received
I0416 21:35:47.010741       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:52.542165       1 controller.go:123] Found 0 jobs
I0416 21:35:52.545297       1 controller.go:139] Found 0 cronjobs
I0416 21:35:52.545311       1 controller.go:142] Found 0 groups
I0416 21:35:52.789253       1 deployment_controller.go:168] Adding deployment linux-nginx
I0416 21:35:52.789287       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:35:52.789282297 +0000 UTC m=+1974.943006448)
I0416 21:35:52.789627       1 deployment_util.go:259] Updating replica set "linux-nginx-7c4f9bd84f" revision to 1
I0416 21:35:52.795820       1 controller_utils.go:202] Controller default/linux-nginx-7c4f9bd84f either never recorded expectations, or the ttl expired.
I0416 21:35:52.795864       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b08e2f6fde2e, ext:1974949584683, loc:(*time.Location)(0x71c51c0)}}
I0416 21:35:52.795939       1 replica_set.go:477] Too few replicas for ReplicaSet default/linux-nginx-7c4f9bd84f, need 1, creating 1
I0416 21:35:52.796357       1 deployment_controller.go:214] ReplicaSet linux-nginx-7c4f9bd84f added.
I0416 21:35:52.798873       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"default", Name:"linux-nginx", UID:"1d60203f-1c97-4187-a13c-7bcf2c3b1c58", APIVersion:"apps/v1", ResourceVersion:"4445", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set linux-nginx-7c4f9bd84f to 1
I0416 21:35:52.805635       1 controller_utils.go:588] Controller linux-nginx-7c4f9bd84f created pod linux-nginx-7c4f9bd84f-bp2kn
I0416 21:35:52.805717       1 replica_set_utils.go:58] Updating status for : default/linux-nginx-7c4f9bd84f, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:35:52.806131       1 pvc_protection_controller.go:280] Got event on pod default/linux-nginx-7c4f9bd84f-bp2kn
I0416 21:35:52.806162       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"default", Name:"linux-nginx-7c4f9bd84f", UID:"476dbaf0-3eb7-4e09-b792-594398a3570a", APIVersion:"apps/v1", ResourceVersion:"4446", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: linux-nginx-7c4f9bd84f-bp2kn
I0416 21:35:52.806756       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"linux-nginx-7c4f9bd84f-bp2kn"}
I0416 21:35:52.806799       1 replica_set.go:275] Pod linux-nginx-7c4f9bd84f-bp2kn created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"linux-nginx-7c4f9bd84f-bp2kn", GenerateName:"linux-nginx-7c4f9bd84f-", Namespace:"default", SelfLink:"/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-bp2kn", UID:"a29adc4f-8de9-475e-81d6-d02bcecddab5", ResourceVersion:"4447", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691047352, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"nginx", "pod-template-hash":"7c4f9bd84f"}, Annotations:map[string]string{"kubernetes.io/limit-ranger":"LimitRanger plugin set: cpu request for container nginx"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"linux-nginx-7c4f9bd84f", UID:"476dbaf0-3eb7-4e09-b792-594398a3570a", Controller:(*bool)(0xc0026213d7), BlockOwnerDeletion:(*bool)(0xc0026213d8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fq4g7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001e68e80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"nginx:1.7.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fq4g7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002621418), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001692000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002621460)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002621480)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002621488), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00262148c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:35:52.807119       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b08e2f6fde2e, ext:1974949584683, loc:(*time.Location)(0x71c51c0)}}
I0416 21:35:52.807209       1 disruption.go:326] addPod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:35:52.807251       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:35:52.807255       1 disruption.go:329] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:35:52.819449       1 deployment_controller.go:175] Updating deployment linux-nginx
I0416 21:35:52.823321       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"linux-nginx-7c4f9bd84f-bp2kn"}
I0416 21:35:52.823908       1 replica_set.go:338] Pod linux-nginx-7c4f9bd84f-bp2kn updated, objectMeta {Name:linux-nginx-7c4f9bd84f-bp2kn GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-bp2kn UID:a29adc4f-8de9-475e-81d6-d02bcecddab5 ResourceVersion:4447 Generation:0 CreationTimestamp:2019-04-16 21:35:52 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:476dbaf0-3eb7-4e09-b792-594398a3570a Controller:0xc0026213d7 BlockOwnerDeletion:0xc0026213d8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-nginx-7c4f9bd84f-bp2kn GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-bp2kn UID:a29adc4f-8de9-475e-81d6-d02bcecddab5 ResourceVersion:4448 Generation:0 CreationTimestamp:2019-04-16 21:35:52 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:476dbaf0-3eb7-4e09-b792-594398a3570a Controller:0xc002621d07 BlockOwnerDeletion:0xc002621d08}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:35:52.824179       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:35:52.824196       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:35:52.824211       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:35:52.828263       1 deployment_util.go:795] Deployment "linux-nginx" timed out (false) [last progress check: 2019-04-16 21:35:52.798414396 +0000 UTC m=+1974.952138557 - now: 2019-04-16 21:35:52.828247298 +0000 UTC m=+1974.981971449]
I0416 21:35:52.832822       1 deployment_controller.go:280] ReplicaSet linux-nginx-7c4f9bd84f updated.
I0416 21:35:52.835822       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (40.022154ms)
I0416 21:35:52.835884       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b08e2f6fde2e, ext:1974949584683, loc:(*time.Location)(0x71c51c0)}}
I0416 21:35:52.835983       1 replica_set_utils.go:58] Updating status for : default/linux-nginx-7c4f9bd84f, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:35:52.846276       1 deployment_controller.go:280] ReplicaSet linux-nginx-7c4f9bd84f updated.
I0416 21:35:52.847550       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (11.648072ms)
I0416 21:35:52.847592       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b08e2f6fde2e, ext:1974949584683, loc:(*time.Location)(0x71c51c0)}}
I0416 21:35:52.847682       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (100.378µs)
I0416 21:35:52.851252       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (61.940597ms)
I0416 21:35:52.851271       1 deployment_controller.go:484] Error syncing deployment default/linux-nginx: Operation cannot be fulfilled on deployments.apps "linux-nginx": the object has been modified; please apply your changes to the latest version and try again
I0416 21:35:52.851321       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:35:52.851304556 +0000 UTC m=+1975.005028695)
I0416 21:35:52.859304       1 deployment_controller.go:175] Updating deployment linux-nginx
I0416 21:35:52.864454       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (13.13593ms)
I0416 21:35:52.869187       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:35:52.869172125 +0000 UTC m=+1975.022896263)
I0416 21:35:52.869642       1 deployment_util.go:795] Deployment "linux-nginx" timed out (false) [last progress check: 2019-04-16 21:35:52 +0000 UTC - now: 2019-04-16 21:35:52.869635349 +0000 UTC m=+1975.023359501]
I0416 21:35:52.869683       1 progress.go:193] Queueing up deployment "linux-nginx" for a progress check after 599s
I0416 21:35:52.869695       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (520.951µs)
I0416 21:35:52.866264       1 replica_set.go:338] Pod linux-nginx-7c4f9bd84f-bp2kn updated, objectMeta {Name:linux-nginx-7c4f9bd84f-bp2kn GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-bp2kn UID:a29adc4f-8de9-475e-81d6-d02bcecddab5 ResourceVersion:4448 Generation:0 CreationTimestamp:2019-04-16 21:35:52 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:476dbaf0-3eb7-4e09-b792-594398a3570a Controller:0xc002621d07 BlockOwnerDeletion:0xc002621d08}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-nginx-7c4f9bd84f-bp2kn GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-bp2kn UID:a29adc4f-8de9-475e-81d6-d02bcecddab5 ResourceVersion:4453 Generation:0 CreationTimestamp:2019-04-16 21:35:52 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:476dbaf0-3eb7-4e09-b792-594398a3570a Controller:0xc0024a742f BlockOwnerDeletion:0xc0024a7450}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:35:52.869748       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b08e2f6fde2e, ext:1974949584683, loc:(*time.Location)(0x71c51c0)}}
I0416 21:35:52.869820       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (80.366µs)
I0416 21:35:52.866381       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:35:52.869850       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:35:52.869854       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:35:55.020682       1 request.go:530] Throttling request took 90.605411ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:35:55.070615       1 request.go:530] Throttling request took 140.515295ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:35:55.120671       1 request.go:530] Throttling request took 190.565852ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:35:55.170529       1 request.go:530] Throttling request took 240.416002ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:35:55.220709       1 request.go:530] Throttling request took 290.583366ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:35:55.270714       1 request.go:530] Throttling request took 340.578464ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:35:55.320689       1 request.go:530] Throttling request took 390.545323ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:35:55.370639       1 request.go:530] Throttling request took 440.479932ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:35:55.608626       1 wrap.go:47] GET /healthz: (109.127µs) 200 [kube-probe/1.15+ 127.0.0.1:43676]
I0416 21:35:56.014264       1 replica_set.go:338] Pod linux-nginx-7c4f9bd84f-bp2kn updated, objectMeta {Name:linux-nginx-7c4f9bd84f-bp2kn GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-bp2kn UID:a29adc4f-8de9-475e-81d6-d02bcecddab5 ResourceVersion:4453 Generation:0 CreationTimestamp:2019-04-16 21:35:52 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:476dbaf0-3eb7-4e09-b792-594398a3570a Controller:0xc0024a742f BlockOwnerDeletion:0xc0024a7450}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-nginx-7c4f9bd84f-bp2kn GenerateName:linux-nginx-7c4f9bd84f- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-nginx-7c4f9bd84f-bp2kn UID:a29adc4f-8de9-475e-81d6-d02bcecddab5 ResourceVersion:4459 Generation:0 CreationTimestamp:2019-04-16 21:35:52 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nginx pod-template-hash:7c4f9bd84f] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nginx] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-nginx-7c4f9bd84f UID:476dbaf0-3eb7-4e09-b792-594398a3570a Controller:0xc0027adb9f BlockOwnerDeletion:0xc0027adbc0}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:35:56.014382       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b08e2f6fde2e, ext:1974949584683, loc:(*time.Location)(0x71c51c0)}}
I0416 21:35:56.014530       1 replica_set_utils.go:58] Updating status for : default/linux-nginx-7c4f9bd84f, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:35:56.015328       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:35:56.015352       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:35:56.015356       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:35:56.020909       1 deployment_controller.go:280] ReplicaSet linux-nginx-7c4f9bd84f updated.
I0416 21:35:56.020936       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:35:56.020931033 +0000 UTC m=+1978.174655168)
I0416 21:35:56.024573       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (10.177483ms)
I0416 21:35:56.024635       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b08e2f6fde2e, ext:1974949584683, loc:(*time.Location)(0x71c51c0)}}
I0416 21:35:56.024736       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (111.947µs)
I0416 21:35:56.029577       1 deployment_controller.go:175] Updating deployment linux-nginx
I0416 21:35:56.030962       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (10.020842ms)
I0416 21:35:56.030995       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:35:56.03099105 +0000 UTC m=+1978.184715201)
I0416 21:35:56.031410       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (416.997µs)
I0416 21:35:57.090691       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:35:57.271026       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:35:57.829272       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 7 items received
I0416 21:36:00.765487       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 21:36:02.399018       1 gc_controller.go:144] GC'ing orphaned
I0416 21:36:02.403825       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:36:02.549645       1 controller.go:123] Found 0 jobs
I0416 21:36:02.552435       1 controller.go:139] Found 0 cronjobs
I0416 21:36:02.552449       1 controller.go:142] Found 0 groups
I0416 21:36:02.800869       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:36:03.692719       1 deployment_controller.go:168] Adding deployment linux-ubuntu
I0416 21:36:03.692747       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:36:03.692741269 +0000 UTC m=+1985.846465408)
I0416 21:36:03.693127       1 deployment_util.go:259] Updating replica set "linux-ubuntu-5dbcdfff9d" revision to 1
I0416 21:36:03.699249       1 controller_utils.go:202] Controller default/linux-ubuntu-5dbcdfff9d either never recorded expectations, or the ttl expired.
I0416 21:36:03.699305       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b090e9ae8151, ext:1985853026362, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:03.699343       1 replica_set.go:477] Too few replicas for ReplicaSet default/linux-ubuntu-5dbcdfff9d, need 1, creating 1
I0416 21:36:03.699754       1 deployment_controller.go:214] ReplicaSet linux-ubuntu-5dbcdfff9d added.
I0416 21:36:03.703390       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"default", Name:"linux-ubuntu", UID:"7d8eaf52-c99f-49fc-b9a4-a7adc217dfb2", APIVersion:"apps/v1", ResourceVersion:"4477", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set linux-ubuntu-5dbcdfff9d to 1
I0416 21:36:03.709774       1 pvc_protection_controller.go:280] Got event on pod default/linux-ubuntu-5dbcdfff9d-zl2vx
I0416 21:36:03.709927       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"linux-ubuntu-5dbcdfff9d-zl2vx"}
I0416 21:36:03.709961       1 replica_set.go:275] Pod linux-ubuntu-5dbcdfff9d-zl2vx created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"linux-ubuntu-5dbcdfff9d-zl2vx", GenerateName:"linux-ubuntu-5dbcdfff9d-", Namespace:"default", SelfLink:"/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-zl2vx", UID:"3404d7c2-f049-4cba-ae4c-f1e066b9aa65", ResourceVersion:"4479", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691047363, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"ubuntu", "pod-template-hash":"5dbcdfff9d"}, Annotations:map[string]string{"kubernetes.io/limit-ranger":"LimitRanger plugin set: cpu request for container ubuntu"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"linux-ubuntu-5dbcdfff9d", UID:"a07a968a-16de-4711-9ab0-bb3ab9abdfdb", Controller:(*bool)(0xc00260ccb7), BlockOwnerDeletion:(*bool)(0xc00260ccb8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fq4g7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001801e00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"ubuntu", Image:"ubuntu", Command:[]string{"sleep", "123456"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fq4g7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00260ccf8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002128fc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00260cd90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00260cdc0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00260cdc8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00260cdcc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:36:03.710206       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b090e9ae8151, ext:1985853026362, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:03.710284       1 disruption.go:326] addPod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:03.710300       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:03.710303       1 disruption.go:329] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:03.712667       1 controller_utils.go:588] Controller linux-ubuntu-5dbcdfff9d created pod linux-ubuntu-5dbcdfff9d-zl2vx
I0416 21:36:03.712750       1 replica_set_utils.go:58] Updating status for : default/linux-ubuntu-5dbcdfff9d, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:36:03.713057       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"default", Name:"linux-ubuntu-5dbcdfff9d", UID:"a07a968a-16de-4711-9ab0-bb3ab9abdfdb", APIVersion:"apps/v1", ResourceVersion:"4478", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: linux-ubuntu-5dbcdfff9d-zl2vx
I0416 21:36:03.722949       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:36:03.727883       1 deployment_util.go:795] Deployment "linux-ubuntu" timed out (false) [last progress check: 2019-04-16 21:36:03.702952741 +0000 UTC m=+1985.856676892 - now: 2019-04-16 21:36:03.727868292 +0000 UTC m=+1985.881592433]
I0416 21:36:03.731625       1 deployment_controller.go:280] ReplicaSet linux-ubuntu-5dbcdfff9d updated.
I0416 21:36:03.736275       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"linux-ubuntu-5dbcdfff9d-zl2vx"}
I0416 21:36:03.736371       1 replica_set.go:338] Pod linux-ubuntu-5dbcdfff9d-zl2vx updated, objectMeta {Name:linux-ubuntu-5dbcdfff9d-zl2vx GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-zl2vx UID:3404d7c2-f049-4cba-ae4c-f1e066b9aa65 ResourceVersion:4479 Generation:0 CreationTimestamp:2019-04-16 21:36:03 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:a07a968a-16de-4711-9ab0-bb3ab9abdfdb Controller:0xc00260ccb7 BlockOwnerDeletion:0xc00260ccb8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-ubuntu-5dbcdfff9d-zl2vx GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-zl2vx UID:3404d7c2-f049-4cba-ae4c-f1e066b9aa65 ResourceVersion:4482 Generation:0 CreationTimestamp:2019-04-16 21:36:03 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:a07a968a-16de-4711-9ab0-bb3ab9abdfdb Controller:0xc0024993a7 BlockOwnerDeletion:0xc0024993a8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:03.736520       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:03.736535       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:03.736539       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:03.738129       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (38.898481ms)
I0416 21:36:03.738171       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b090e9ae8151, ext:1985853026362, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:03.738287       1 replica_set_utils.go:58] Updating status for : default/linux-ubuntu-5dbcdfff9d, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:36:03.747761       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (55.004684ms)
I0416 21:36:03.747788       1 deployment_controller.go:484] Error syncing deployment default/linux-ubuntu: Operation cannot be fulfilled on deployments.apps "linux-ubuntu": the object has been modified; please apply your changes to the latest version and try again
I0416 21:36:03.747845       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:36:03.747840944 +0000 UTC m=+1985.901565094)
I0416 21:36:03.748266       1 deployment_util.go:795] Deployment "linux-ubuntu" timed out (false) [last progress check: 2019-04-16 21:36:03 +0000 UTC - now: 2019-04-16 21:36:03.748261427 +0000 UTC m=+1985.901985564]
I0416 21:36:03.749830       1 deployment_controller.go:280] ReplicaSet linux-ubuntu-5dbcdfff9d updated.
I0416 21:36:03.753300       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (15.129994ms)
I0416 21:36:03.753356       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b090e9ae8151, ext:1985853026362, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:03.753441       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (94.819µs)
I0416 21:36:03.762000       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:36:03.765172       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (17.318786ms)
I0416 21:36:03.765242       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:36:03.765220365 +0000 UTC m=+1985.918944517)
I0416 21:36:03.773790       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:36:03.777680       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (12.446101ms)
I0416 21:36:03.777734       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:36:03.777716171 +0000 UTC m=+1985.931440322)
I0416 21:36:03.778159       1 deployment_util.go:795] Deployment "linux-ubuntu" timed out (false) [last progress check: 2019-04-16 21:36:03 +0000 UTC - now: 2019-04-16 21:36:03.778152048 +0000 UTC m=+1985.931876183]
I0416 21:36:03.778199       1 progress.go:193] Queueing up deployment "linux-ubuntu" for a progress check after 599s
I0416 21:36:03.778209       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (491.967µs)
I0416 21:36:03.780618       1 replica_set.go:338] Pod linux-ubuntu-5dbcdfff9d-zl2vx updated, objectMeta {Name:linux-ubuntu-5dbcdfff9d-zl2vx GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-zl2vx UID:3404d7c2-f049-4cba-ae4c-f1e066b9aa65 ResourceVersion:4482 Generation:0 CreationTimestamp:2019-04-16 21:36:03 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:a07a968a-16de-4711-9ab0-bb3ab9abdfdb Controller:0xc0024993a7 BlockOwnerDeletion:0xc0024993a8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-ubuntu-5dbcdfff9d-zl2vx GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-zl2vx UID:3404d7c2-f049-4cba-ae4c-f1e066b9aa65 ResourceVersion:4486 Generation:0 CreationTimestamp:2019-04-16 21:36:03 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:a07a968a-16de-4711-9ab0-bb3ab9abdfdb Controller:0xc001efd5f7 BlockOwnerDeletion:0xc001efd5f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:03.780718       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b090e9ae8151, ext:1985853026362, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:03.780826       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (114.104µs)
I0416 21:36:03.780905       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:03.780920       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:03.780924       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:04.008786       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:36:05.610272       1 wrap.go:47] GET /healthz: (118.859µs) 200 [kube-probe/1.15+ 127.0.0.1:43710]
I0416 21:36:06.189300       1 replica_set.go:338] Pod linux-ubuntu-5dbcdfff9d-zl2vx updated, objectMeta {Name:linux-ubuntu-5dbcdfff9d-zl2vx GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-zl2vx UID:3404d7c2-f049-4cba-ae4c-f1e066b9aa65 ResourceVersion:4486 Generation:0 CreationTimestamp:2019-04-16 21:36:03 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:a07a968a-16de-4711-9ab0-bb3ab9abdfdb Controller:0xc001efd5f7 BlockOwnerDeletion:0xc001efd5f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:linux-ubuntu-5dbcdfff9d-zl2vx GenerateName:linux-ubuntu-5dbcdfff9d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/linux-ubuntu-5dbcdfff9d-zl2vx UID:3404d7c2-f049-4cba-ae4c-f1e066b9aa65 ResourceVersion:4492 Generation:0 CreationTimestamp:2019-04-16 21:36:03 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:ubuntu pod-template-hash:5dbcdfff9d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container ubuntu] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:linux-ubuntu-5dbcdfff9d UID:a07a968a-16de-4711-9ab0-bb3ab9abdfdb Controller:0xc001a08817 BlockOwnerDeletion:0xc001a08818}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:06.189414       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b090e9ae8151, ext:1985853026362, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:06.189642       1 replica_set_utils.go:58] Updating status for : default/linux-ubuntu-5dbcdfff9d, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:36:06.190069       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:06.190088       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:06.190091       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:06.200709       1 deployment_controller.go:280] ReplicaSet linux-ubuntu-5dbcdfff9d updated.
I0416 21:36:06.200737       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:36:06.200731758 +0000 UTC m=+1988.354455909)
I0416 21:36:06.203543       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (14.124104ms)
I0416 21:36:06.203606       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b090e9ae8151, ext:1985853026362, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:06.203704       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (110.599µs)
I0416 21:36:06.208283       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (7.536967ms)
I0416 21:36:06.208463       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:36:06.208488       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:36:06.208483615 +0000 UTC m=+1988.362207767)
I0416 21:36:06.208935       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (448.421µs)
I0416 21:36:09.781476       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 0 items received
I0416 21:36:11.328245       1 request.go:530] Throttling request took 91.615596ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:36:11.378298       1 request.go:530] Throttling request took 141.618989ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:36:11.428295       1 request.go:530] Throttling request took 191.653875ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:36:11.478254       1 request.go:530] Throttling request took 241.598566ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:36:11.528245       1 request.go:530] Throttling request took 291.585885ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:36:11.578907       1 request.go:530] Throttling request took 342.249298ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:36:11.628165       1 request.go:530] Throttling request took 391.491603ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:36:11.678136       1 request.go:530] Throttling request took 441.449382ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:36:11.680386       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:36:11.771072       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:11.800525       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:12.091895       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:36:12.271359       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:12.557208       1 controller.go:123] Found 0 jobs
I0416 21:36:12.561061       1 controller.go:139] Found 0 cronjobs
I0416 21:36:12.561087       1 controller.go:142] Found 0 groups
I0416 21:36:14.587208       1 deployment_controller.go:168] Adding deployment windows-nettest
I0416 21:36:14.587253       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:36:14.587247129 +0000 UTC m=+1996.740971267)
I0416 21:36:14.587582       1 deployment_util.go:259] Updating replica set "windows-nettest-944bd6d8d" revision to 1
I0416 21:36:14.595908       1 controller_utils.go:202] Controller default/windows-nettest-944bd6d8d either never recorded expectations, or the ttl expired.
I0416 21:36:14.595979       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b093a385dcf3, ext:1996749699568, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:14.596002       1 replica_set.go:477] Too few replicas for ReplicaSet default/windows-nettest-944bd6d8d, need 1, creating 1
I0416 21:36:14.596474       1 deployment_controller.go:214] ReplicaSet windows-nettest-944bd6d8d added.
I0416 21:36:14.597459       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"default", Name:"windows-nettest", UID:"dff73f55-3f0f-49c0-b20d-876bff0d4505", APIVersion:"apps/v1", ResourceVersion:"4511", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set windows-nettest-944bd6d8d to 1
I0416 21:36:14.610632       1 controller_utils.go:588] Controller windows-nettest-944bd6d8d created pod windows-nettest-944bd6d8d-x7mcl
I0416 21:36:14.610702       1 replica_set_utils.go:58] Updating status for : default/windows-nettest-944bd6d8d, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:36:14.611181       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-x7mcl
I0416 21:36:14.612283       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"windows-nettest-944bd6d8d-x7mcl"}
I0416 21:36:14.612331       1 replica_set.go:275] Pod windows-nettest-944bd6d8d-x7mcl created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"windows-nettest-944bd6d8d-x7mcl", GenerateName:"windows-nettest-944bd6d8d-", Namespace:"default", SelfLink:"/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-x7mcl", UID:"422bcff4-8412-4194-b3b1-f07b5f2977a6", ResourceVersion:"4513", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691047374, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"nettest", "pod-template-hash":"944bd6d8d"}, Annotations:map[string]string{"kubernetes.io/limit-ranger":"LimitRanger plugin set: cpu request for container nettest"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"windows-nettest-944bd6d8d", UID:"94d05e34-2475-4181-a923-8e2d837a32d0", Controller:(*bool)(0xc0017da6c7), BlockOwnerDeletion:(*bool)(0xc0017da6c8)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fq4g7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0013f6480), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nettest", Image:"e2eteam/nettest:1.0", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fq4g7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0017da758), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"windows"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0024ee540), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/os", Operator:"Equal", Value:"windows", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0017da7c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0017da7f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0017da7f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0017da7fc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:36:14.612602       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b093a385dcf3, ext:1996749699568, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:14.612686       1 disruption.go:326] addPod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:14.612702       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:14.612705       1 disruption.go:329] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:14.612715       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"default", Name:"windows-nettest-944bd6d8d", UID:"94d05e34-2475-4181-a923-8e2d837a32d0", APIVersion:"apps/v1", ResourceVersion:"4512", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: windows-nettest-944bd6d8d-x7mcl
I0416 21:36:14.616944       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:36:14.624597       1 deployment_util.go:795] Deployment "windows-nettest" timed out (false) [last progress check: 2019-04-16 21:36:14.597210827 +0000 UTC m=+1996.750934978 - now: 2019-04-16 21:36:14.624581312 +0000 UTC m=+1996.778305451]
I0416 21:36:14.629737       1 deployment_controller.go:280] ReplicaSet windows-nettest-944bd6d8d updated.
I0416 21:36:14.633986       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (38.084014ms)
I0416 21:36:14.634070       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b093a385dcf3, ext:1996749699568, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:14.634185       1 replica_set_utils.go:58] Updating status for : default/windows-nettest-944bd6d8d, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:36:14.636355       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"windows-nettest-944bd6d8d-x7mcl"}
I0416 21:36:14.636443       1 replica_set.go:338] Pod windows-nettest-944bd6d8d-x7mcl updated, objectMeta {Name:windows-nettest-944bd6d8d-x7mcl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-x7mcl UID:422bcff4-8412-4194-b3b1-f07b5f2977a6 ResourceVersion:4513 Generation:0 CreationTimestamp:2019-04-16 21:36:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:94d05e34-2475-4181-a923-8e2d837a32d0 Controller:0xc0017da6c7 BlockOwnerDeletion:0xc0017da6c8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:windows-nettest-944bd6d8d-x7mcl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-x7mcl UID:422bcff4-8412-4194-b3b1-f07b5f2977a6 ResourceVersion:4515 Generation:0 CreationTimestamp:2019-04-16 21:36:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:94d05e34-2475-4181-a923-8e2d837a32d0 Controller:0xc001772137 BlockOwnerDeletion:0xc001772138}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:14.636597       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:14.636614       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:14.636618       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:14.640933       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (53.672005ms)
I0416 21:36:14.640965       1 deployment_controller.go:484] Error syncing deployment default/windows-nettest: Operation cannot be fulfilled on deployments.apps "windows-nettest": the object has been modified; please apply your changes to the latest version and try again
I0416 21:36:14.641002       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:36:14.640998071 +0000 UTC m=+1996.794722223)
I0416 21:36:14.641502       1 deployment_util.go:795] Deployment "windows-nettest" timed out (false) [last progress check: 2019-04-16 21:36:14 +0000 UTC - now: 2019-04-16 21:36:14.641497541 +0000 UTC m=+1996.795221679]
I0416 21:36:14.651757       1 deployment_controller.go:280] ReplicaSet windows-nettest-944bd6d8d updated.
I0416 21:36:14.655265       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (21.207842ms)
I0416 21:36:14.655316       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b093a385dcf3, ext:1996749699568, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:14.655403       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (98.881µs)
I0416 21:36:14.658533       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:36:14.661370       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (20.357957ms)
I0416 21:36:14.661421       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:36:14.66141701 +0000 UTC m=+1996.815141162)
I0416 21:36:14.668794       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:36:14.670567       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (9.124689ms)
I0416 21:36:14.670604       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:36:14.670599868 +0000 UTC m=+1996.824324020)
I0416 21:36:14.671078       1 deployment_util.go:795] Deployment "windows-nettest" timed out (false) [last progress check: 2019-04-16 21:36:14 +0000 UTC - now: 2019-04-16 21:36:14.671072916 +0000 UTC m=+1996.824797052]
I0416 21:36:14.671111       1 progress.go:193] Queueing up deployment "windows-nettest" for a progress check after 599s
I0416 21:36:14.671135       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (534.247µs)
I0416 21:36:14.677321       1 replica_set.go:338] Pod windows-nettest-944bd6d8d-x7mcl updated, objectMeta {Name:windows-nettest-944bd6d8d-x7mcl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-x7mcl UID:422bcff4-8412-4194-b3b1-f07b5f2977a6 ResourceVersion:4515 Generation:0 CreationTimestamp:2019-04-16 21:36:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:94d05e34-2475-4181-a923-8e2d837a32d0 Controller:0xc001772137 BlockOwnerDeletion:0xc001772138}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:windows-nettest-944bd6d8d-x7mcl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-x7mcl UID:422bcff4-8412-4194-b3b1-f07b5f2977a6 ResourceVersion:4520 Generation:0 CreationTimestamp:2019-04-16 21:36:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:94d05e34-2475-4181-a923-8e2d837a32d0 Controller:0xc0016aa697 BlockOwnerDeletion:0xc0016aa698}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:14.677429       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b093a385dcf3, ext:1996749699568, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:14.677528       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (104.012µs)
I0416 21:36:14.677629       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:14.677657       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:14.677661       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:15.608503       1 wrap.go:47] GET /healthz: (109.369µs) 200 [kube-probe/1.15+ 127.0.0.1:43744]
I0416 21:36:22.404146       1 gc_controller.go:144] GC'ing orphaned
I0416 21:36:22.408648       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:36:22.571093       1 controller.go:123] Found 0 jobs
I0416 21:36:22.574203       1 controller.go:139] Found 0 cronjobs
I0416 21:36:22.574215       1 controller.go:142] Found 0 groups
I0416 21:36:23.357716       1 replica_set.go:338] Pod windows-nettest-944bd6d8d-x7mcl updated, objectMeta {Name:windows-nettest-944bd6d8d-x7mcl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-x7mcl UID:422bcff4-8412-4194-b3b1-f07b5f2977a6 ResourceVersion:4520 Generation:0 CreationTimestamp:2019-04-16 21:36:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:94d05e34-2475-4181-a923-8e2d837a32d0 Controller:0xc0016aa697 BlockOwnerDeletion:0xc0016aa698}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:windows-nettest-944bd6d8d-x7mcl GenerateName:windows-nettest-944bd6d8d- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-nettest-944bd6d8d-x7mcl UID:422bcff4-8412-4194-b3b1-f07b5f2977a6 ResourceVersion:4538 Generation:0 CreationTimestamp:2019-04-16 21:36:14 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:nettest pod-template-hash:944bd6d8d] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-nettest-944bd6d8d UID:94d05e34-2475-4181-a923-8e2d837a32d0 Controller:0xc00156d917 BlockOwnerDeletion:0xc00156d918}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:23.357811       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b093a385dcf3, ext:1996749699568, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:23.357931       1 replica_set_utils.go:58] Updating status for : default/windows-nettest-944bd6d8d, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:36:23.359495       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:23.359538       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:23.359542       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:23.366032       1 deployment_controller.go:280] ReplicaSet windows-nettest-944bd6d8d updated.
I0416 21:36:23.366073       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:36:23.366068496 +0000 UTC m=+2005.519792645)
I0416 21:36:23.370641       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (12.830298ms)
I0416 21:36:23.370703       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b093a385dcf3, ext:1996749699568, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:23.370795       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (103.023µs)
I0416 21:36:23.377932       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:36:23.381274       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (15.191658ms)
I0416 21:36:23.381328       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:36:23.381322848 +0000 UTC m=+2005.535046999)
I0416 21:36:23.381880       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (554.815µs)
I0416 21:36:25.474197       1 request.go:530] Throttling request took 91.826373ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:36:25.524211       1 request.go:530] Throttling request took 141.826112ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:36:25.536055       1 deployment_controller.go:168] Adding deployment windows-powershell
I0416 21:36:25.536095       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:36:25.536075743 +0000 UTC m=+2007.689799883)
I0416 21:36:25.536406       1 deployment_util.go:259] Updating replica set "windows-powershell-7c9878bbfd" revision to 1
I0416 21:36:25.542634       1 controller_utils.go:202] Controller default/windows-powershell-7c9878bbfd either never recorded expectations, or the ttl expired.
I0416 21:36:25.542709       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:1, del:0, key:"default/windows-powershell-7c9878bbfd", timestamp:time.Time{wall:0xbf25b096605905f6, ext:2007696429299, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:25.542737       1 replica_set.go:477] Too few replicas for ReplicaSet default/windows-powershell-7c9878bbfd, need 1, creating 1
I0416 21:36:25.543270       1 deployment_controller.go:214] ReplicaSet windows-powershell-7c9878bbfd added.
I0416 21:36:25.545533       1 event.go:258] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"default", Name:"windows-powershell", UID:"e549d1bf-971b-4fd7-a24e-4aedce29d2d8", APIVersion:"apps/v1", ResourceVersion:"4545", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set windows-powershell-7c9878bbfd to 1
I0416 21:36:25.559201       1 pvc_protection_controller.go:280] Got event on pod default/windows-powershell-7c9878bbfd-fwlj7
I0416 21:36:25.559348       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"windows-powershell-7c9878bbfd-fwlj7"}
I0416 21:36:25.559383       1 replica_set.go:275] Pod windows-powershell-7c9878bbfd-fwlj7 created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"windows-powershell-7c9878bbfd-fwlj7", GenerateName:"windows-powershell-7c9878bbfd-", Namespace:"default", SelfLink:"/api/v1/namespaces/default/pods/windows-powershell-7c9878bbfd-fwlj7", UID:"a6e6c5da-2f67-4819-92a0-13f0a95c23e4", ResourceVersion:"4547", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63691047385, loc:(*time.Location)(0x71c51c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"powershell", "pod-template-hash":"7c9878bbfd"}, Annotations:map[string]string{"kubernetes.io/limit-ranger":"LimitRanger plugin set: cpu request for container nettest"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"apps/v1", Kind:"ReplicaSet", Name:"windows-powershell-7c9878bbfd", UID:"30a8a0c0-e291-4c05-bfe4-f109a5a1afe9", Controller:(*bool)(0xc000af7047), BlockOwnerDeletion:(*bool)(0xc000af7048)}}, Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fq4g7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001ce2000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nettest", Image:"e2eteam/nettest:1.0", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fq4g7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000af7088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"windows"}, ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0023e0fc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/os", Operator:"Equal", Value:"windows", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000af7100)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000af7120)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000af7128), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000af712c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition(nil), Message:"", Reason:"", NominatedNodeName:"", HostIP:"", PodIP:"", StartTime:(*v1.Time)(nil), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus(nil), QOSClass:"Burstable"}}.
I0416 21:36:25.559674       1 controller_utils.go:236] Lowered expectations &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-powershell-7c9878bbfd", timestamp:time.Time{wall:0xbf25b096605905f6, ext:2007696429299, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:25.559748       1 disruption.go:326] addPod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:25.559766       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:25.559770       1 disruption.go:329] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:25.569116       1 deployment_controller.go:175] Updating deployment windows-powershell
I0416 21:36:25.574207       1 deployment_util.go:795] Deployment "windows-powershell" timed out (false) [last progress check: 2019-04-16 21:36:25.54512217 +0000 UTC m=+2007.698846322 - now: 2019-04-16 21:36:25.574192729 +0000 UTC m=+2007.727916866]
I0416 21:36:25.574686       1 controller_utils.go:588] Controller windows-powershell-7c9878bbfd created pod windows-powershell-7c9878bbfd-fwlj7
I0416 21:36:25.574762       1 replica_set_utils.go:58] Updating status for : default/windows-powershell-7c9878bbfd, replicas 0->0 (need 1), fullyLabeledReplicas 0->0, readyReplicas 0->0, availableReplicas 0->0, sequence No: 0->1
I0416 21:36:25.575079       1 event.go:258] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"default", Name:"windows-powershell-7c9878bbfd", UID:"30a8a0c0-e291-4c05-bfe4-f109a5a1afe9", APIVersion:"apps/v1", ResourceVersion:"4546", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: windows-powershell-7c9878bbfd-fwlj7
I0416 21:36:25.575132       1 request.go:530] Throttling request took 192.757831ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:36:25.579085       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"windows-powershell-7c9878bbfd-fwlj7"}
I0416 21:36:25.579155       1 replica_set.go:338] Pod windows-powershell-7c9878bbfd-fwlj7 updated, objectMeta {Name:windows-powershell-7c9878bbfd-fwlj7 GenerateName:windows-powershell-7c9878bbfd- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-powershell-7c9878bbfd-fwlj7 UID:a6e6c5da-2f67-4819-92a0-13f0a95c23e4 ResourceVersion:4547 Generation:0 CreationTimestamp:2019-04-16 21:36:25 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:powershell pod-template-hash:7c9878bbfd] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-powershell-7c9878bbfd UID:30a8a0c0-e291-4c05-bfe4-f109a5a1afe9 Controller:0xc000af7047 BlockOwnerDeletion:0xc000af7048}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:windows-powershell-7c9878bbfd-fwlj7 GenerateName:windows-powershell-7c9878bbfd- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-powershell-7c9878bbfd-fwlj7 UID:a6e6c5da-2f67-4819-92a0-13f0a95c23e4 ResourceVersion:4549 Generation:0 CreationTimestamp:2019-04-16 21:36:25 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:powershell pod-template-hash:7c9878bbfd] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-powershell-7c9878bbfd UID:30a8a0c0-e291-4c05-bfe4-f109a5a1afe9 Controller:0xc0005bdc87 BlockOwnerDeletion:0xc0005bdc88}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:25.580569       1 disruption.go:338] updatePod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:25.580595       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:25.580599       1 disruption.go:341] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:25.594940       1 deployment_controller.go:280] ReplicaSet windows-powershell-7c9878bbfd updated.
I0416 21:36:25.597164       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-powershell-7c9878bbfd" (54.526634ms)
I0416 21:36:25.597274       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-powershell-7c9878bbfd", timestamp:time.Time{wall:0xbf25b096605905f6, ext:2007696429299, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:25.597398       1 replica_set_utils.go:58] Updating status for : default/windows-powershell-7c9878bbfd, replicas 0->1 (need 1), fullyLabeledReplicas 0->1, readyReplicas 0->0, availableReplicas 0->0, sequence No: 1->1
I0416 21:36:25.605526       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (69.436034ms)
I0416 21:36:25.605557       1 deployment_controller.go:484] Error syncing deployment default/windows-powershell: Operation cannot be fulfilled on deployments.apps "windows-powershell": the object has been modified; please apply your changes to the latest version and try again
I0416 21:36:25.605587       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:36:25.60558299 +0000 UTC m=+2007.759307129)
I0416 21:36:25.606051       1 deployment_util.go:795] Deployment "windows-powershell" timed out (false) [last progress check: 2019-04-16 21:36:25 +0000 UTC - now: 2019-04-16 21:36:25.606047274 +0000 UTC m=+2007.759771412]
I0416 21:36:25.609119       1 wrap.go:47] GET /healthz: (92.631µs) 200 [kube-probe/1.15+ 127.0.0.1:43776]
I0416 21:36:25.622363       1 deployment_controller.go:280] ReplicaSet windows-powershell-7c9878bbfd updated.
I0416 21:36:25.622412       1 deployment_controller.go:175] Updating deployment windows-powershell
I0416 21:36:25.624631       1 request.go:530] Throttling request took 242.238036ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:36:25.626984       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (21.39027ms)
I0416 21:36:25.627038       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:36:25.627033431 +0000 UTC m=+2007.780757569)
I0416 21:36:25.629621       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-powershell-7c9878bbfd" (32.407617ms)
I0416 21:36:25.629663       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-powershell-7c9878bbfd", timestamp:time.Time{wall:0xbf25b096605905f6, ext:2007696429299, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:25.629774       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-powershell-7c9878bbfd" (121.32µs)
I0416 21:36:25.630049       1 replica_set.go:338] Pod windows-powershell-7c9878bbfd-fwlj7 updated, objectMeta {Name:windows-powershell-7c9878bbfd-fwlj7 GenerateName:windows-powershell-7c9878bbfd- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-powershell-7c9878bbfd-fwlj7 UID:a6e6c5da-2f67-4819-92a0-13f0a95c23e4 ResourceVersion:4549 Generation:0 CreationTimestamp:2019-04-16 21:36:25 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:powershell pod-template-hash:7c9878bbfd] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-powershell-7c9878bbfd UID:30a8a0c0-e291-4c05-bfe4-f109a5a1afe9 Controller:0xc0005bdc87 BlockOwnerDeletion:0xc0005bdc88}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:windows-powershell-7c9878bbfd-fwlj7 GenerateName:windows-powershell-7c9878bbfd- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-powershell-7c9878bbfd-fwlj7 UID:a6e6c5da-2f67-4819-92a0-13f0a95c23e4 ResourceVersion:4553 Generation:0 CreationTimestamp:2019-04-16 21:36:25 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:powershell pod-template-hash:7c9878bbfd] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-powershell-7c9878bbfd UID:30a8a0c0-e291-4c05-bfe4-f109a5a1afe9 Controller:0xc0005804f7 BlockOwnerDeletion:0xc0005804f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:25.630138       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-powershell-7c9878bbfd", timestamp:time.Time{wall:0xbf25b096605905f6, ext:2007696429299, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:25.630190       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-powershell-7c9878bbfd" (61.452µs)
I0416 21:36:25.630268       1 disruption.go:338] updatePod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:25.630282       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:25.630286       1 disruption.go:341] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:25.639763       1 deployment_controller.go:175] Updating deployment windows-powershell
I0416 21:36:25.641590       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (14.546766ms)
I0416 21:36:25.641622       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:36:25.641617512 +0000 UTC m=+2007.795341652)
I0416 21:36:25.642064       1 deployment_util.go:795] Deployment "windows-powershell" timed out (false) [last progress check: 2019-04-16 21:36:25 +0000 UTC - now: 2019-04-16 21:36:25.64205925 +0000 UTC m=+2007.795783386]
I0416 21:36:25.642093       1 progress.go:193] Queueing up deployment "windows-powershell" for a progress check after 599s
I0416 21:36:25.642105       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (485.858µs)
I0416 21:36:25.652786       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:36:25.676603       1 request.go:530] Throttling request took 294.186503ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:36:25.724323       1 request.go:530] Throttling request took 341.812316ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:36:25.774252       1 request.go:530] Throttling request took 391.775567ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:36:25.824354       1 request.go:530] Throttling request took 441.895204ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:36:27.093344       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:36:27.271686       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:27.299987       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:36:27.767502       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:36:29.041880       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:36:31.378510       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:31.379334       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:31.379489       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:31.379916       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:36:31.380049       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:36:31.380150       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:36:31.792957       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 21:36:32.224000       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 21:36:32.300459       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:36:32.300544       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:36:32.577957       1 controller.go:123] Found 0 jobs
I0416 21:36:32.580415       1 controller.go:139] Found 0 cronjobs
I0416 21:36:32.580429       1 controller.go:142] Found 0 groups
I0416 21:36:35.608717       1 wrap.go:47] GET /healthz: (104.37µs) 200 [kube-probe/1.15+ 127.0.0.1:43810]
I0416 21:36:36.803209       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 21:36:39.781207       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:36:41.771846       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:41.780978       1 request.go:530] Throttling request took 91.059158ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:36:41.800769       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:41.831015       1 request.go:530] Throttling request took 141.030986ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:36:41.880952       1 request.go:530] Throttling request took 191.002693ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:36:41.930989       1 request.go:530] Throttling request took 241.033112ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:36:41.980982       1 request.go:530] Throttling request took 291.013158ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:36:42.030945       1 request.go:530] Throttling request took 340.965353ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:36:42.081295       1 request.go:530] Throttling request took 391.325989ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:36:42.093618       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:36:42.131326       1 request.go:530] Throttling request took 439.990231ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:36:42.135315       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:36:42.272005       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:42.409374       1 gc_controller.go:144] GC'ing orphaned
I0416 21:36:42.414420       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:36:42.586178       1 controller.go:123] Found 0 jobs
I0416 21:36:42.588774       1 controller.go:139] Found 0 cronjobs
I0416 21:36:42.588786       1 controller.go:142] Found 0 groups
I0416 21:36:43.818036       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.820028       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.820163       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.820223       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:36:43.820253       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:36:43.820269       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:36:43.820263935 +0000 UTC m=+2025.973988072)
I0416 21:36:43.821214       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (941.29µs)
I0416 21:36:43.821264       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:36:43.821260572 +0000 UTC m=+2025.974984709)
I0416 21:36:43.821679       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (416.357µs)
I0416 21:36:43.821799       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:36:43.821809       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:36:43.821806641 +0000 UTC m=+2025.975530777)
I0416 21:36:43.822154       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (345.496µs)
I0416 21:36:43.822179       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:36:43.822190       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:36:43.822187191 +0000 UTC m=+2025.975911330)
I0416 21:36:43.822842       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (639.333µs)
I0416 21:36:43.822900       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:36:43.822905       1 deployment_controller.go:175] Updating deployment linux-nginx
I0416 21:36:43.822926       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:36:43.8229233 +0000 UTC m=+2025.976647437)
I0416 21:36:43.824095       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (1.167712ms)
I0416 21:36:43.824118       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:36:43.824115473 +0000 UTC m=+2025.977839610)
I0416 21:36:43.824421       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (304.244µs)
I0416 21:36:43.824449       1 deployment_controller.go:175] Updating deployment windows-nettest
I0416 21:36:43.824458       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:36:43.824456078 +0000 UTC m=+2025.978180213)
I0416 21:36:43.824803       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (344.725µs)
I0416 21:36:43.824823       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:36:43.824845       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:36:43.824842322 +0000 UTC m=+2025.978566458)
I0416 21:36:43.825922       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.076734ms)
I0416 21:36:43.825956       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:36:43.825960       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:36:43.825969       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:36:43.825965976 +0000 UTC m=+2025.979690113)
I0416 21:36:43.826504       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (535.255µs)
I0416 21:36:43.826514       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:36:43.82651253 +0000 UTC m=+2025.980236665)
I0416 21:36:43.826863       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (347.652µs)
I0416 21:36:43.826889       1 deployment_controller.go:175] Updating deployment linux-ubuntu
I0416 21:36:43.826897       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:36:43.826894559 +0000 UTC m=+2025.980618695)
I0416 21:36:43.827140       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (244.535µs)
I0416 21:36:43.827153       1 deployment_controller.go:175] Updating deployment windows-powershell
I0416 21:36:43.827180       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:36:43.827177741 +0000 UTC m=+2025.980901876)
I0416 21:36:43.827397       1 deployment_util.go:795] Deployment "windows-powershell" timed out (false) [last progress check: 2019-04-16 21:36:25 +0000 UTC - now: 2019-04-16 21:36:43.827392315 +0000 UTC m=+2025.981116466]
I0416 21:36:43.827417       1 progress.go:193] Queueing up deployment "windows-powershell" for a progress check after 581s
I0416 21:36:43.827427       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (247.75µs)
I0416 21:36:43.835926       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.836049       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:36:43.836067       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:36:43.837939       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b05d04a3fed6, ext:1778231580607, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.838296       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:36:43.838323       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b09af1f78b63, ext:2025992030812, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.838376       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:36:43.838439       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:36:43.838444       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b09af1f78b63, ext:2025992030812, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.838493       1 update.go:396] Getting unavailable numbers
I0416 21:36:43.838599       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:36:43.838607       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:36:43.838614       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:36:43.838618       1 update.go:68] Marking old pods for deletion
I0416 21:36:43.838622       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b09af1fc567e, ext:2025992345022, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.838629       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:36:43.838670       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:36:43.838784       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:36:43.838928       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:36:43.838939       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.853537ms)
I0416 21:36:43.839483       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b05d04b784dc, ext:1778232860114, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.839672       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:36:43.839680       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b09af20c7aaa, ext:2025993402788, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.839783       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:36:43.839825       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:36:43.839829       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b09af20c7aaa, ext:2025993402788, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.839887       1 update.go:396] Getting unavailable numbers
I0416 21:36:43.839995       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:36:43.840017       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:36:43.840023       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:36:43.840027       1 update.go:68] Marking old pods for deletion
I0416 21:36:43.840031       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b09af211d691, ext:2025993754026, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.840039       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:36:43.840063       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:36:43.840083       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:36:43.840191       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:36:43.840197       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.223938ms)
I0416 21:36:43.840313       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.840330       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.840341       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.840362       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.840584       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:36:43.840591       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.840595       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:36:43.840620       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:36:43.840635       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.840638       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:36:43.840775       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:36:43.840793       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.840798       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:36:43.840846       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:36:43.840862       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.840873       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:36:43.840878       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:36:43.840890       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.840895       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:36:43.840931       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:36:43.840942       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.840947       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:36:43.841029       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:36:43.841038       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841040       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:36:43.841069       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:36:43.841077       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841079       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:36:43.841104       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:36:43.841113       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841116       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:36:43.841144       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:36:43.841154       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841156       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:36:43.841158       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:36:43.841166       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841169       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:36:43.841195       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:43.841203       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841205       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:36:43.841390       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:36:43.841402       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841404       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:36:43.841429       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:36:43.841445       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841448       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:36:43.841475       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:36:43.841480       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841482       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:36:43.841502       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:36:43.841511       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841513       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:36:43.841541       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:36:43.841549       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841552       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:36:43.841573       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:36:43.841580       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841583       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:36:43.841609       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:36:43.841619       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841621       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:36:43.841649       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:36:43.841658       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841660       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:36:43.841663       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:36:43.841669       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841671       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:36:43.841767       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:36:43.841778       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841780       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:36:43.841831       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:43.841839       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841842       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:36:43.841865       1 disruption.go:338] updatePod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:43.841873       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841875       1 disruption.go:341] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:43.841925       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:36:43.841933       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841937       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:36:43.841952       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:36:43.841959       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:43.841962       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:36:43.845439       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.845599       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.845838       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (246.921µs)
I0416 21:36:43.845869       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.845941       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846014       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (76.825µs)
I0416 21:36:43.846024       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846082       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (59.229µs)
I0416 21:36:43.846326       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846411       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (89.029µs)
I0416 21:36:43.846423       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846497       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (75.987µs)
I0416 21:36:43.846518       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-ubuntu-5dbcdfff9d", timestamp:time.Time{wall:0xbf25b090e9ae8151, ext:1985853026362, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846571       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (54.928µs)
I0416 21:36:43.846580       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846642       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (63.44µs)
I0416 21:36:43.846664       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846768       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (105.231µs)
I0416 21:36:43.846796       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846867       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (73.532µs)
I0416 21:36:43.846912       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-powershell-7c9878bbfd", timestamp:time.Time{wall:0xbf25b096605905f6, ext:2007696429299, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.846945       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-powershell-7c9878bbfd" (34.056µs)
I0416 21:36:43.846961       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.847025       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (65.129µs)
I0416 21:36:43.847034       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/linux-nginx-7c4f9bd84f", timestamp:time.Time{wall:0xbf25b08e2f6fde2e, ext:1974949584683, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.847085       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (49.578µs)
I0416 21:36:43.847104       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-nettest-944bd6d8d", timestamp:time.Time{wall:0xbf25b093a385dcf3, ext:1996749699568, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.847146       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (42.579µs)
I0416 21:36:43.847162       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:43.847222       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (61.463µs)
I0416 21:36:43.847681       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.847831       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.847860       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.847939       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.898058       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:43.981498       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:44.019536       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:44.050671       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:44.167394       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:44.240813       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:44.340380       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:44.389898       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:44.390032       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:36:44.390074       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (3.487µs)
I0416 21:36:44.390131       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:36:44.390141       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:36:44.390150       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:36:44.390156       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (892ns)
I0416 21:36:44.390182       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (676ns)
I0416 21:36:44.390191       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (295ns)
I0416 21:36:44.440526       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:44.595590       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:45.608567       1 wrap.go:47] GET /healthz: (90.739µs) 200 [kube-probe/1.15+ 127.0.0.1:43862]
I0416 21:36:46.794971       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 21:36:51.774654       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 21:36:52.592807       1 controller.go:123] Found 0 jobs
I0416 21:36:52.595388       1 controller.go:139] Found 0 cronjobs
I0416 21:36:52.595401       1 controller.go:142] Found 0 groups
I0416 21:36:53.724899       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:55.608545       1 wrap.go:47] GET /healthz: (80.577µs) 200 [kube-probe/1.15+ 127.0.0.1:43898]
I0416 21:36:55.933432       1 request.go:530] Throttling request took 91.728372ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:36:55.983545       1 request.go:530] Throttling request took 141.824778ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:36:56.033495       1 request.go:530] Throttling request took 191.762929ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:36:56.083573       1 request.go:530] Throttling request took 241.84237ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:36:56.133496       1 request.go:530] Throttling request took 291.755119ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:36:56.183609       1 request.go:530] Throttling request took 341.857446ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:36:56.233523       1 request.go:530] Throttling request took 391.738203ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:36:56.283505       1 request.go:530] Throttling request took 441.708568ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:36:56.401890       1 replica_set.go:338] Pod windows-powershell-7c9878bbfd-fwlj7 updated, objectMeta {Name:windows-powershell-7c9878bbfd-fwlj7 GenerateName:windows-powershell-7c9878bbfd- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-powershell-7c9878bbfd-fwlj7 UID:a6e6c5da-2f67-4819-92a0-13f0a95c23e4 ResourceVersion:4553 Generation:0 CreationTimestamp:2019-04-16 21:36:25 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:powershell pod-template-hash:7c9878bbfd] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-powershell-7c9878bbfd UID:30a8a0c0-e291-4c05-bfe4-f109a5a1afe9 Controller:0xc0005804f7 BlockOwnerDeletion:0xc0005804f8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]} -> {Name:windows-powershell-7c9878bbfd-fwlj7 GenerateName:windows-powershell-7c9878bbfd- Namespace:default SelfLink:/api/v1/namespaces/default/pods/windows-powershell-7c9878bbfd-fwlj7 UID:a6e6c5da-2f67-4819-92a0-13f0a95c23e4 ResourceVersion:4616 Generation:0 CreationTimestamp:2019-04-16 21:36:25 +0000 UTC DeletionTimestamp:<nil> DeletionGracePeriodSeconds:<nil> Labels:map[app:powershell pod-template-hash:7c9878bbfd] Annotations:map[kubernetes.io/limit-ranger:LimitRanger plugin set: cpu request for container nettest] OwnerReferences:[{APIVersion:apps/v1 Kind:ReplicaSet Name:windows-powershell-7c9878bbfd UID:30a8a0c0-e291-4c05-bfe4-f109a5a1afe9 Controller:0xc0022338e7 BlockOwnerDeletion:0xc0022338e8}] Initializers:nil Finalizers:[] ClusterName: ManagedFields:[]}.
I0416 21:36:56.402127       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-powershell-7c9878bbfd", timestamp:time.Time{wall:0xbf25b096605905f6, ext:2007696429299, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:56.402301       1 replica_set_utils.go:58] Updating status for : default/windows-powershell-7c9878bbfd, replicas 1->1 (need 1), fullyLabeledReplicas 1->1, readyReplicas 0->1, availableReplicas 0->1, sequence No: 1->1
I0416 21:36:56.402865       1 disruption.go:338] updatePod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:56.402883       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:36:56.402886       1 disruption.go:341] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:36:56.411336       1 deployment_controller.go:280] ReplicaSet windows-powershell-7c9878bbfd updated.
I0416 21:36:56.411363       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:36:56.411357569 +0000 UTC m=+2038.565081707)
I0416 21:36:56.414095       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-powershell-7c9878bbfd" (12.055655ms)
I0416 21:36:56.414139       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"default/windows-powershell-7c9878bbfd", timestamp:time.Time{wall:0xbf25b096605905f6, ext:2007696429299, loc:(*time.Location)(0x71c51c0)}}
I0416 21:36:56.414222       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-powershell-7c9878bbfd" (94.036µs)
I0416 21:36:56.420382       1 deployment_controller.go:175] Updating deployment windows-powershell
I0416 21:36:56.421527       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (10.161348ms)
I0416 21:36:56.421577       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:36:56.421573323 +0000 UTC m=+2038.575297459)
I0416 21:36:56.422005       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (429.394µs)
I0416 21:36:57.094559       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:36:57.272448       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:36:57.794791       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 21:37:02.414730       1 gc_controller.go:144] GC'ing orphaned
I0416 21:37:02.419135       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:37:02.599325       1 controller.go:123] Found 0 jobs
I0416 21:37:02.601761       1 controller.go:139] Found 0 cronjobs
I0416 21:37:02.601773       1 controller.go:142] Found 0 groups
I0416 21:37:02.784148       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 21:37:03.171759       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:05.004881       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:37:05.608647       1 wrap.go:47] GET /healthz: (88.085µs) 200 [kube-probe/1.15+ 127.0.0.1:43936]
I0416 21:37:09.933098       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 21:37:11.772192       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:11.801988       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:12.094826       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:37:12.235909       1 request.go:530] Throttling request took 91.389922ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:37:12.272728       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:12.285910       1 request.go:530] Throttling request took 141.369269ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:37:12.335918       1 request.go:530] Throttling request took 191.369118ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:37:12.386077       1 request.go:530] Throttling request took 241.509531ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:37:12.435939       1 request.go:530] Throttling request took 291.361113ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:37:12.485996       1 request.go:530] Throttling request took 341.414266ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:37:12.535884       1 request.go:530] Throttling request took 391.294383ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:37:12.585986       1 request.go:530] Throttling request took 441.38892ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:37:12.588603       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:37:12.606034       1 controller.go:123] Found 0 jobs
I0416 21:37:12.608909       1 controller.go:139] Found 0 cronjobs
I0416 21:37:12.608927       1 controller.go:142] Found 0 groups
I0416 21:37:14.546409       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:37:15.609396       1 wrap.go:47] GET /healthz: (120.626µs) 200 [kube-probe/1.15+ 127.0.0.1:43972]
I0416 21:37:19.142516       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:22.419427       1 gc_controller.go:144] GC'ing orphaned
I0416 21:37:22.424037       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:37:22.613126       1 controller.go:123] Found 0 jobs
I0416 21:37:22.615508       1 controller.go:139] Found 0 cronjobs
I0416 21:37:22.615519       1 controller.go:142] Found 0 groups
I0416 21:37:25.608565       1 wrap.go:47] GET /healthz: (121.939µs) 200 [kube-probe/1.15+ 127.0.0.1:44010]
I0416 21:37:25.736593       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:37:26.388408       1 request.go:530] Throttling request took 92.429041ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:37:26.436440       1 request.go:530] Throttling request took 140.450874ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:37:26.486431       1 request.go:530] Throttling request took 190.436111ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:37:26.536420       1 request.go:530] Throttling request took 240.397987ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:37:26.586615       1 request.go:530] Throttling request took 290.581607ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:37:26.636360       1 request.go:530] Throttling request took 340.318761ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:37:26.686439       1 request.go:530] Throttling request took 390.390231ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:37:26.736387       1 request.go:530] Throttling request took 440.305224ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:37:27.095050       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:37:27.273020       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:27.305638       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:37:27.894079       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:37:29.319092       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:37:32.306127       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:37:32.306194       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:37:32.310845       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 0 items received
I0416 21:37:32.619547       1 controller.go:123] Found 0 jobs
I0416 21:37:32.622087       1 controller.go:139] Found 0 cronjobs
I0416 21:37:32.622099       1 controller.go:142] Found 0 groups
I0416 21:37:35.609315       1 wrap.go:47] GET /healthz: (127.54µs) 200 [kube-probe/1.15+ 127.0.0.1:44048]
I0416 21:37:41.772549       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:41.802325       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:42.095341       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:37:42.273368       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:42.424417       1 gc_controller.go:144] GC'ing orphaned
I0416 21:37:42.428852       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:37:42.631753       1 controller.go:123] Found 0 jobs
I0416 21:37:42.634538       1 controller.go:139] Found 0 cronjobs
I0416 21:37:42.634552       1 controller.go:142] Found 0 groups
I0416 21:37:42.689273       1 request.go:530] Throttling request took 91.889725ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:37:42.739399       1 request.go:530] Throttling request took 142.018204ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:37:42.789341       1 request.go:530] Throttling request took 191.953415ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:37:42.839332       1 request.go:530] Throttling request took 241.934328ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:37:42.889408       1 request.go:530] Throttling request took 291.991409ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:37:42.940052       1 request.go:530] Throttling request took 342.622314ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:37:42.989351       1 request.go:530] Throttling request took 391.926057ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:37:43.040344       1 request.go:530] Throttling request took 442.899112ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:37:43.042864       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:37:45.608443       1 wrap.go:47] GET /healthz: (83.982µs) 200 [kube-probe/1.15+ 127.0.0.1:44104]
I0416 21:37:51.836860       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=deployments, namespace default, name linux-nginx, uid 1d60203f-1c97-4187-a13c-7bcf2c3b1c58, event type delete
I0416 21:37:51.836982       1 garbagecollector.go:405] processing item [apps/v1/ReplicaSet, namespace: default, name: linux-nginx-7c4f9bd84f, uid: 476dbaf0-3eb7-4e09-b792-594398a3570a]
I0416 21:37:51.841949       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=deployments, namespace default, name linux-nginx, uid 1d60203f-1c97-4187-a13c-7bcf2c3b1c58, event type delete
I0416 21:37:51.842039       1 deployment_controller.go:193] Deleting deployment linux-nginx
I0416 21:37:51.842068       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:37:51.842061505 +0000 UTC m=+2093.995785699)
I0416 21:37:51.842118       1 deployment_controller.go:573] Deployment default/linux-nginx has been deleted
I0416 21:37:51.842125       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (59.627µs)
I0416 21:37:52.147218       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=deployments, namespace default, name linux-ubuntu, uid 7d8eaf52-c99f-49fc-b9a4-a7adc217dfb2, event type delete
I0416 21:37:52.147338       1 garbagecollector.go:405] processing item [extensions/v1beta1/ReplicaSet, namespace: default, name: linux-ubuntu-5dbcdfff9d, uid: a07a968a-16de-4711-9ab0-bb3ab9abdfdb]
I0416 21:37:52.147413       1 deployment_controller.go:193] Deleting deployment linux-ubuntu
I0416 21:37:52.147434       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:37:52.147429198 +0000 UTC m=+2094.301153337)
I0416 21:37:52.147457       1 deployment_controller.go:573] Deployment default/linux-ubuntu has been deleted
I0416 21:37:52.147462       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (29.932µs)
I0416 21:37:52.148540       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=deployments, namespace default, name linux-ubuntu, uid 7d8eaf52-c99f-49fc-b9a4-a7adc217dfb2, event type delete
I0416 21:37:52.384165       1 garbagecollector.go:518] delete object [extensions/v1beta1/ReplicaSet, namespace: default, name: linux-ubuntu-5dbcdfff9d, uid: a07a968a-16de-4711-9ab0-bb3ab9abdfdb] with propagation policy Background
I0416 21:37:52.386446       1 garbagecollector.go:518] delete object [apps/v1/ReplicaSet, namespace: default, name: linux-nginx-7c4f9bd84f, uid: 476dbaf0-3eb7-4e09-b792-594398a3570a] with propagation policy Background
I0416 21:37:52.398854       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=replicasets, namespace default, name linux-nginx-7c4f9bd84f, uid 476dbaf0-3eb7-4e09-b792-594398a3570a, event type delete
I0416 21:37:52.399036       1 replica_set.go:575] ReplicaSet default/linux-nginx-7c4f9bd84f has been deleted
I0416 21:37:52.399061       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-nginx-7c4f9bd84f" (24.485µs)
I0416 21:37:52.399152       1 garbagecollector.go:405] processing item [v1/Pod, namespace: default, name: linux-nginx-7c4f9bd84f-bp2kn, uid: a29adc4f-8de9-475e-81d6-d02bcecddab5]
I0416 21:37:52.399930       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=replicasets, namespace default, name linux-nginx-7c4f9bd84f, uid 476dbaf0-3eb7-4e09-b792-594398a3570a, event type delete
I0416 21:37:52.409868       1 replica_set.go:575] ReplicaSet default/linux-ubuntu-5dbcdfff9d has been deleted
I0416 21:37:52.409896       1 replica_set.go:566] Finished syncing ReplicaSet "default/linux-ubuntu-5dbcdfff9d" (56.932µs)
I0416 21:37:52.409998       1 garbagecollector.go:405] processing item [v1/Pod, namespace: default, name: linux-ubuntu-5dbcdfff9d-zl2vx, uid: 3404d7c2-f049-4cba-ae4c-f1e066b9aa65]
I0416 21:37:52.410567       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=replicasets, namespace default, name linux-ubuntu-5dbcdfff9d, uid a07a968a-16de-4711-9ab0-bb3ab9abdfdb, event type delete
I0416 21:37:52.413363       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=replicasets, namespace default, name linux-ubuntu-5dbcdfff9d, uid a07a968a-16de-4711-9ab0-bb3ab9abdfdb, event type delete
I0416 21:37:52.417905       1 garbagecollector.go:518] delete object [v1/Pod, namespace: default, name: linux-nginx-7c4f9bd84f-bp2kn, uid: a29adc4f-8de9-475e-81d6-d02bcecddab5] with propagation policy Background
I0416 21:37:52.423165       1 garbagecollector.go:518] delete object [v1/Pod, namespace: default, name: linux-ubuntu-5dbcdfff9d-zl2vx, uid: 3404d7c2-f049-4cba-ae4c-f1e066b9aa65] with propagation policy Background
I0416 21:37:52.428737       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:37:52.428763       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:52.428768       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:37:52.443701       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:37:52.443731       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:52.443735       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:37:52.466535       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=deployments, namespace default, name windows-nettest, uid dff73f55-3f0f-49c0-b20d-876bff0d4505, event type delete
I0416 21:37:52.466637       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=deployments, namespace default, name windows-nettest, uid dff73f55-3f0f-49c0-b20d-876bff0d4505, event type delete
I0416 21:37:52.466691       1 garbagecollector.go:405] processing item [extensions/v1beta1/ReplicaSet, namespace: default, name: windows-nettest-944bd6d8d, uid: 94d05e34-2475-4181-a923-8e2d837a32d0]
I0416 21:37:52.467052       1 deployment_controller.go:193] Deleting deployment windows-nettest
I0416 21:37:52.467072       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:37:52.467066939 +0000 UTC m=+2094.620791090)
I0416 21:37:52.467095       1 deployment_controller.go:573] Deployment default/windows-nettest has been deleted
I0416 21:37:52.467100       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (30.24µs)
I0416 21:37:52.475869       1 garbagecollector.go:518] delete object [extensions/v1beta1/ReplicaSet, namespace: default, name: windows-nettest-944bd6d8d, uid: 94d05e34-2475-4181-a923-8e2d837a32d0] with propagation policy Background
I0416 21:37:52.482743       1 replica_set.go:575] ReplicaSet default/windows-nettest-944bd6d8d has been deleted
I0416 21:37:52.482760       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-nettest-944bd6d8d" (55.836µs)
I0416 21:37:52.482865       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=replicasets, namespace default, name windows-nettest-944bd6d8d, uid 94d05e34-2475-4181-a923-8e2d837a32d0, event type delete
I0416 21:37:52.482960       1 garbagecollector.go:405] processing item [v1/Pod, namespace: default, name: windows-nettest-944bd6d8d-x7mcl, uid: 422bcff4-8412-4194-b3b1-f07b5f2977a6]
I0416 21:37:52.484412       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=replicasets, namespace default, name windows-nettest-944bd6d8d, uid 94d05e34-2475-4181-a923-8e2d837a32d0, event type delete
I0416 21:37:52.488734       1 garbagecollector.go:518] delete object [v1/Pod, namespace: default, name: windows-nettest-944bd6d8d-x7mcl, uid: 422bcff4-8412-4194-b3b1-f07b5f2977a6] with propagation policy Background
I0416 21:37:52.497428       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:37:52.497452       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:52.497457       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:37:52.639899       1 controller.go:123] Found 0 jobs
I0416 21:37:52.643278       1 controller.go:139] Found 0 cronjobs
I0416 21:37:52.643291       1 controller.go:142] Found 0 groups
I0416 21:37:52.766001       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=deployments, namespace default, name windows-powershell, uid e549d1bf-971b-4fd7-a24e-4aedce29d2d8, event type delete
I0416 21:37:52.766114       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=deployments, namespace default, name windows-powershell, uid e549d1bf-971b-4fd7-a24e-4aedce29d2d8, event type delete
I0416 21:37:52.766177       1 garbagecollector.go:405] processing item [apps/v1/ReplicaSet, namespace: default, name: windows-powershell-7c9878bbfd, uid: 30a8a0c0-e291-4c05-bfe4-f109a5a1afe9]
I0416 21:37:52.766570       1 deployment_controller.go:193] Deleting deployment windows-powershell
I0416 21:37:52.766590       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:37:52.766585393 +0000 UTC m=+2094.920309531)
I0416 21:37:52.766614       1 deployment_controller.go:573] Deployment default/windows-powershell has been deleted
I0416 21:37:52.766620       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (31.003µs)
I0416 21:37:52.770167       1 garbagecollector.go:518] delete object [apps/v1/ReplicaSet, namespace: default, name: windows-powershell-7c9878bbfd, uid: 30a8a0c0-e291-4c05-bfe4-f109a5a1afe9] with propagation policy Background
I0416 21:37:52.775334       1 resource_quota_monitor.go:354] QuotaMonitor process object: extensions/v1beta1, Resource=replicasets, namespace default, name windows-powershell-7c9878bbfd, uid 30a8a0c0-e291-4c05-bfe4-f109a5a1afe9, event type delete
I0416 21:37:52.775482       1 replica_set.go:575] ReplicaSet default/windows-powershell-7c9878bbfd has been deleted
I0416 21:37:52.775493       1 replica_set.go:566] Finished syncing ReplicaSet "default/windows-powershell-7c9878bbfd" (37.017µs)
I0416 21:37:52.775570       1 garbagecollector.go:405] processing item [v1/Pod, namespace: default, name: windows-powershell-7c9878bbfd-fwlj7, uid: a6e6c5da-2f67-4819-92a0-13f0a95c23e4]
I0416 21:37:52.775942       1 resource_quota_monitor.go:354] QuotaMonitor process object: apps/v1, Resource=replicasets, namespace default, name windows-powershell-7c9878bbfd, uid 30a8a0c0-e291-4c05-bfe4-f109a5a1afe9, event type delete
I0416 21:37:52.778992       1 garbagecollector.go:518] delete object [v1/Pod, namespace: default, name: windows-powershell-7c9878bbfd-fwlj7, uid: a6e6c5da-2f67-4819-92a0-13f0a95c23e4] with propagation policy Background
I0416 21:37:52.786356       1 disruption.go:338] updatePod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:37:52.786392       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:52.786397       1 disruption.go:341] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:37:54.103060       1 pvc_protection_controller.go:280] Got event on pod default/linux-nginx-7c4f9bd84f-bp2kn
I0416 21:37:54.103277       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:37:54.103298       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:54.103302       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:37:55.121830       1 pvc_protection_controller.go:280] Got event on pod default/linux-nginx-7c4f9bd84f-bp2kn
I0416 21:37:55.121950       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name linux-nginx-7c4f9bd84f-bp2kn, uid a29adc4f-8de9-475e-81d6-d02bcecddab5, event type update
I0416 21:37:55.122096       1 disruption.go:338] updatePod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:37:55.122114       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:55.122118       1 disruption.go:341] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:37:55.126274       1 pvc_protection_controller.go:280] Got event on pod default/linux-nginx-7c4f9bd84f-bp2kn
I0416 21:37:55.126334       1 deployment_controller.go:356] Pod linux-nginx-7c4f9bd84f-bp2kn deleted.
I0416 21:37:55.126348       1 deployment_controller.go:424] Cannot get replicaset "linux-nginx-7c4f9bd84f" for pod "linux-nginx-7c4f9bd84f-bp2kn": replicaset.apps "linux-nginx-7c4f9bd84f" not found
I0416 21:37:55.126385       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name linux-nginx-7c4f9bd84f-bp2kn, uid a29adc4f-8de9-475e-81d6-d02bcecddab5, event type delete
I0416 21:37:55.126449       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"default", Name:"linux-nginx-7c4f9bd84f-bp2kn"}
I0416 21:37:55.126540       1 disruption.go:367] deletePod called on pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:37:55.126558       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-nginx-7c4f9bd84f-bp2kn, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:55.126562       1 disruption.go:370] No matching pdb for pod "linux-nginx-7c4f9bd84f-bp2kn"
I0416 21:37:55.608636       1 wrap.go:47] GET /healthz: (86.562µs) 200 [kube-probe/1.15+ 127.0.0.1:44142]
I0416 21:37:56.304095       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:56.839175       1 request.go:530] Throttling request took 92.217829ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:37:56.889202       1 request.go:530] Throttling request took 142.233635ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:37:56.939207       1 request.go:530] Throttling request took 192.209301ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:37:56.989268       1 request.go:530] Throttling request took 242.24361ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:37:57.039306       1 request.go:530] Throttling request took 292.208888ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:37:57.093507       1 request.go:530] Throttling request took 346.479966ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:37:57.096179       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:37:57.139090       1 request.go:530] Throttling request took 392.048602ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:37:57.160415       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-x7mcl
I0416 21:37:57.160691       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:37:57.160712       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:57.160716       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:37:57.173305       1 pvc_protection_controller.go:280] Got event on pod default/windows-powershell-7c9878bbfd-fwlj7
I0416 21:37:57.173568       1 disruption.go:338] updatePod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:37:57.173588       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:57.173592       1 disruption.go:341] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:37:57.189188       1 request.go:530] Throttling request took 442.136389ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:37:57.273667       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:37:58.168662       1 pvc_protection_controller.go:280] Got event on pod default/windows-powershell-7c9878bbfd-fwlj7
I0416 21:37:58.168768       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name windows-powershell-7c9878bbfd-fwlj7, uid a6e6c5da-2f67-4819-92a0-13f0a95c23e4, event type update
I0416 21:37:58.168943       1 disruption.go:338] updatePod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:37:58.168990       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:58.168993       1 disruption.go:341] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:37:58.174972       1 pvc_protection_controller.go:280] Got event on pod default/windows-powershell-7c9878bbfd-fwlj7
I0416 21:37:58.175045       1 deployment_controller.go:356] Pod windows-powershell-7c9878bbfd-fwlj7 deleted.
I0416 21:37:58.175060       1 deployment_controller.go:424] Cannot get replicaset "windows-powershell-7c9878bbfd" for pod "windows-powershell-7c9878bbfd-fwlj7": replicaset.apps "windows-powershell-7c9878bbfd" not found
I0416 21:37:58.175102       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name windows-powershell-7c9878bbfd-fwlj7, uid a6e6c5da-2f67-4819-92a0-13f0a95c23e4, event type delete
I0416 21:37:58.175170       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"default", Name:"windows-powershell-7c9878bbfd-fwlj7"}
I0416 21:37:58.175294       1 disruption.go:367] deletePod called on pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:37:58.175312       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-powershell-7c9878bbfd-fwlj7, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:58.175332       1 disruption.go:370] No matching pdb for pod "windows-powershell-7c9878bbfd-fwlj7"
I0416 21:37:58.194356       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-x7mcl
I0416 21:37:58.194455       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name windows-nettest-944bd6d8d-x7mcl, uid 422bcff4-8412-4194-b3b1-f07b5f2977a6, event type update
I0416 21:37:58.194594       1 disruption.go:338] updatePod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:37:58.194618       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:58.194622       1 disruption.go:341] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:37:58.202190       1 pvc_protection_controller.go:280] Got event on pod default/windows-nettest-944bd6d8d-x7mcl
I0416 21:37:58.202268       1 deployment_controller.go:356] Pod windows-nettest-944bd6d8d-x7mcl deleted.
I0416 21:37:58.202283       1 deployment_controller.go:424] Cannot get replicaset "windows-nettest-944bd6d8d" for pod "windows-nettest-944bd6d8d-x7mcl": replicaset.apps "windows-nettest-944bd6d8d" not found
I0416 21:37:58.202325       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name windows-nettest-944bd6d8d-x7mcl, uid 422bcff4-8412-4194-b3b1-f07b5f2977a6, event type delete
I0416 21:37:58.202411       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"default", Name:"windows-nettest-944bd6d8d-x7mcl"}
I0416 21:37:58.202524       1 disruption.go:367] deletePod called on pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:37:58.202542       1 disruption.go:401] No PodDisruptionBudgets found for pod windows-nettest-944bd6d8d-x7mcl, PodDisruptionBudget controller will avoid syncing.
I0416 21:37:58.202546       1 disruption.go:370] No matching pdb for pod "windows-nettest-944bd6d8d-x7mcl"
I0416 21:37:58.983873       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 21:38:02.429118       1 gc_controller.go:144] GC'ing orphaned
I0416 21:38:02.433723       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:38:02.647403       1 controller.go:123] Found 0 jobs
I0416 21:38:02.650194       1 controller.go:139] Found 0 cronjobs
I0416 21:38:02.650206       1 controller.go:142] Found 0 groups
I0416 21:38:05.002865       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:38:05.608668       1 wrap.go:47] GET /healthz: (90.293µs) 200 [kube-probe/1.15+ 127.0.0.1:44176]
I0416 21:38:09.790511       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 21:38:11.772879       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:11.802734       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:12.096565       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:38:12.274059       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:12.655044       1 controller.go:123] Found 0 jobs
I0416 21:38:12.657822       1 controller.go:139] Found 0 cronjobs
I0416 21:38:12.657836       1 controller.go:142] Found 0 groups
I0416 21:38:13.143703       1 request.go:530] Throttling request took 92.18587ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:38:13.193907       1 request.go:530] Throttling request took 142.361638ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:38:13.243966       1 request.go:530] Throttling request took 192.420888ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:38:13.293890       1 request.go:530] Throttling request took 242.319774ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:38:13.343824       1 request.go:530] Throttling request took 292.262231ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:38:13.393638       1 request.go:530] Throttling request took 342.064401ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:38:13.443889       1 request.go:530] Throttling request took 392.279807ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:38:13.493774       1 request.go:530] Throttling request took 442.185314ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:38:13.496650       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:38:15.608632       1 wrap.go:47] GET /healthz: (82.089µs) 200 [kube-probe/1.15+ 127.0.0.1:44210]
I0416 21:38:21.009786       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 21:38:22.433992       1 gc_controller.go:144] GC'ing orphaned
I0416 21:38:22.439143       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:38:22.661524       1 controller.go:123] Found 0 jobs
I0416 21:38:22.664152       1 controller.go:139] Found 0 cronjobs
I0416 21:38:22.664164       1 controller.go:142] Found 0 groups
I0416 21:38:23.535900       1 pvc_protection_controller.go:280] Got event on pod default/linux-ubuntu-5dbcdfff9d-zl2vx
I0416 21:38:23.536096       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:38:23.536116       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:38:23.536120       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:38:24.563121       1 pvc_protection_controller.go:280] Got event on pod default/linux-ubuntu-5dbcdfff9d-zl2vx
I0416 21:38:24.563257       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name linux-ubuntu-5dbcdfff9d-zl2vx, uid 3404d7c2-f049-4cba-ae4c-f1e066b9aa65, event type update
I0416 21:38:24.563421       1 disruption.go:338] updatePod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:38:24.563438       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:38:24.563443       1 disruption.go:341] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:38:24.571180       1 pvc_protection_controller.go:280] Got event on pod default/linux-ubuntu-5dbcdfff9d-zl2vx
I0416 21:38:24.571257       1 deployment_controller.go:356] Pod linux-ubuntu-5dbcdfff9d-zl2vx deleted.
I0416 21:38:24.571272       1 deployment_controller.go:424] Cannot get replicaset "linux-ubuntu-5dbcdfff9d" for pod "linux-ubuntu-5dbcdfff9d-zl2vx": replicaset.apps "linux-ubuntu-5dbcdfff9d" not found
I0416 21:38:24.571301       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=pods, namespace default, name linux-ubuntu-5dbcdfff9d-zl2vx, uid 3404d7c2-f049-4cba-ae4c-f1e066b9aa65, event type delete
I0416 21:38:24.571384       1 taint_manager.go:391] Noticed pod deletion: types.NamespacedName{Namespace:"default", Name:"linux-ubuntu-5dbcdfff9d-zl2vx"}
I0416 21:38:24.571504       1 disruption.go:367] deletePod called on pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:38:24.571521       1 disruption.go:401] No PodDisruptionBudgets found for pod linux-ubuntu-5dbcdfff9d-zl2vx, PodDisruptionBudget controller will avoid syncing.
I0416 21:38:24.571524       1 disruption.go:370] No matching pdb for pod "linux-ubuntu-5dbcdfff9d-zl2vx"
I0416 21:38:25.609549       1 wrap.go:47] GET /healthz: (89.418µs) 200 [kube-probe/1.15+ 127.0.0.1:44244]
I0416 21:38:25.831489       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:38:27.096832       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:38:27.274767       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:27.292463       1 request.go:530] Throttling request took 91.85555ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:38:27.313509       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:38:27.342476       1 request.go:530] Throttling request took 141.854181ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:38:27.392449       1 request.go:530] Throttling request took 191.809564ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:38:27.442514       1 request.go:530] Throttling request took 241.866563ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:38:27.492508       1 request.go:530] Throttling request took 291.850031ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:38:27.542545       1 request.go:530] Throttling request took 341.889161ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:38:27.592461       1 request.go:530] Throttling request took 391.794202ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:38:27.642469       1 request.go:530] Throttling request took 441.796197ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:38:28.004818       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:38:28.170217       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:28.461576       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:38:29.533729       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:38:32.313968       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:38:32.314051       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:38:32.667981       1 controller.go:123] Found 0 jobs
I0416 21:38:32.670726       1 controller.go:139] Found 0 cronjobs
I0416 21:38:32.670737       1 controller.go:142] Found 0 groups
I0416 21:38:35.608170       1 wrap.go:47] GET /healthz: (82.852µs) 200 [kube-probe/1.15+ 127.0.0.1:44278]
I0416 21:38:40.783096       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 21:38:41.773252       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:41.802998       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:42.097847       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:38:42.275064       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:42.439416       1 gc_controller.go:144] GC'ing orphaned
I0416 21:38:42.443900       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:38:42.560065       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:38:42.674102       1 controller.go:123] Found 0 jobs
I0416 21:38:42.676193       1 controller.go:139] Found 0 cronjobs
I0416 21:38:42.676202       1 controller.go:142] Found 0 groups
I0416 21:38:43.598241       1 request.go:530] Throttling request took 90.329854ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:38:43.648275       1 request.go:530] Throttling request took 140.340772ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:38:43.697544       1 request.go:530] Throttling request took 189.598361ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:38:43.747794       1 request.go:530] Throttling request took 239.846963ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:38:43.797600       1 request.go:530] Throttling request took 289.645112ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:38:43.847608       1 request.go:530] Throttling request took 339.647928ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:38:43.897676       1 request.go:530] Throttling request took 389.708753ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:38:43.947586       1 request.go:530] Throttling request took 439.606145ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:38:43.949901       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:38:45.609092       1 wrap.go:47] GET /healthz: (97.958µs) 200 [kube-probe/1.15+ 127.0.0.1:44330]
I0416 21:38:48.766285       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:38:48.770886       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:38:52.680906       1 controller.go:123] Found 0 jobs
I0416 21:38:52.683220       1 controller.go:139] Found 0 cronjobs
I0416 21:38:52.683255       1 controller.go:142] Found 0 groups
I0416 21:38:55.608464       1 wrap.go:47] GET /healthz: (81.117µs) 200 [kube-probe/1.15+ 127.0.0.1:44366]
I0416 21:38:55.776358       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 139 items received
I0416 21:38:57.098042       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:38:57.275386       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:38:57.745553       1 request.go:530] Throttling request took 91.612305ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:38:57.795494       1 request.go:530] Throttling request took 141.545368ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:38:57.845531       1 request.go:530] Throttling request took 191.572785ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:38:57.895529       1 request.go:530] Throttling request took 241.556286ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:38:57.945602       1 request.go:530] Throttling request took 291.571458ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:38:57.995630       1 request.go:530] Throttling request took 341.619354ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:38:58.045601       1 request.go:530] Throttling request took 391.547138ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:38:58.095604       1 request.go:530] Throttling request took 441.571414ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:39:01.416902       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 21:39:02.444263       1 gc_controller.go:144] GC'ing orphaned
I0416 21:39:02.449065       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:39:02.687667       1 controller.go:123] Found 0 jobs
I0416 21:39:02.690377       1 controller.go:139] Found 0 cronjobs
I0416 21:39:02.690389       1 controller.go:142] Found 0 groups
I0416 21:39:05.608640       1 wrap.go:47] GET /healthz: (88.87µs) 200 [kube-probe/1.15+ 127.0.0.1:44400]
I0416 21:39:06.005183       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:39:11.773584       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:11.803497       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:12.098437       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:39:12.275712       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:12.694570       1 controller.go:123] Found 0 jobs
I0416 21:39:12.697165       1 controller.go:139] Found 0 cronjobs
I0416 21:39:12.697177       1 controller.go:142] Found 0 groups
I0416 21:39:14.050424       1 request.go:530] Throttling request took 91.407924ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:39:14.100358       1 request.go:530] Throttling request took 141.334192ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:39:14.150398       1 request.go:530] Throttling request took 191.369135ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:39:14.200462       1 request.go:530] Throttling request took 241.419275ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:39:14.250371       1 request.go:530] Throttling request took 291.315663ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:39:14.300463       1 request.go:530] Throttling request took 341.39498ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:39:14.350417       1 request.go:530] Throttling request took 391.325041ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:39:14.400488       1 request.go:530] Throttling request took 441.386635ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:39:14.403113       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:39:15.609014       1 wrap.go:47] GET /healthz: (111.853µs) 200 [kube-probe/1.15+ 127.0.0.1:44432]
I0416 21:39:22.451400       1 gc_controller.go:144] GC'ing orphaned
I0416 21:39:22.460370       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:39:22.701211       1 controller.go:123] Found 0 jobs
I0416 21:39:22.703742       1 controller.go:139] Found 0 cronjobs
I0416 21:39:22.703753       1 controller.go:142] Found 0 groups
I0416 21:39:24.785415       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:39:25.608502       1 wrap.go:47] GET /healthz: (95.312µs) 200 [kube-probe/1.15+ 127.0.0.1:44466]
I0416 21:39:25.770014       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 222 items received
I0416 21:39:25.910921       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:39:27.098664       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:39:27.276054       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:27.318894       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:39:28.092758       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:39:28.198900       1 request.go:530] Throttling request took 91.149365ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:39:28.248986       1 request.go:530] Throttling request took 141.226113ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:39:28.298885       1 request.go:530] Throttling request took 191.125957ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:39:28.349174       1 request.go:530] Throttling request took 241.404939ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:39:28.402659       1 request.go:530] Throttling request took 294.881303ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:39:28.448898       1 request.go:530] Throttling request took 341.110241ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:39:28.498964       1 request.go:530] Throttling request took 391.153106ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:39:28.549451       1 request.go:530] Throttling request took 441.635885ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:39:29.713703       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:39:32.319333       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:39:32.319384       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:39:32.707686       1 controller.go:123] Found 0 jobs
I0416 21:39:32.710164       1 controller.go:139] Found 0 cronjobs
I0416 21:39:32.710183       1 controller.go:142] Found 0 groups
I0416 21:39:35.608299       1 wrap.go:47] GET /healthz: (116.427µs) 200 [kube-probe/1.15+ 127.0.0.1:44500]
I0416 21:39:41.773884       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:41.774012       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (5.636µs)
I0416 21:39:41.774477       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:39:41.774951       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (123.724µs)
I0416 21:39:41.775036       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (66.594µs)
I0416 21:39:41.775140       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (67.761µs)
I0416 21:39:41.775214       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (61.437µs)
I0416 21:39:41.778821       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (4.749568ms)
I0416 21:39:41.803877       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:42.098926       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:39:42.276361       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:42.460666       1 gc_controller.go:144] GC'ing orphaned
I0416 21:39:42.464828       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:39:42.715162       1 controller.go:123] Found 0 jobs
I0416 21:39:42.717761       1 controller.go:139] Found 0 cronjobs
I0416 21:39:42.717772       1 controller.go:142] Found 0 groups
I0416 21:39:44.031211       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 21:39:44.503880       1 request.go:530] Throttling request took 91.739252ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:39:44.553657       1 request.go:530] Throttling request took 141.505894ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:39:44.603702       1 request.go:530] Throttling request took 191.524057ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:39:44.653791       1 request.go:530] Throttling request took 241.623741ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:39:44.703719       1 request.go:530] Throttling request took 291.542864ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:39:44.753739       1 request.go:530] Throttling request took 341.534786ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:39:44.803797       1 request.go:530] Throttling request took 391.578717ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:39:44.854844       1 request.go:530] Throttling request took 442.619061ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:39:44.859298       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:39:45.608718       1 wrap.go:47] GET /healthz: (95.685µs) 200 [kube-probe/1.15+ 127.0.0.1:44552]
I0416 21:39:47.579434       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:50.097360       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 21:39:52.722538       1 controller.go:123] Found 0 jobs
I0416 21:39:52.726066       1 controller.go:139] Found 0 cronjobs
I0416 21:39:52.726077       1 controller.go:142] Found 0 groups
I0416 21:39:55.618250       1 wrap.go:47] GET /healthz: (103.408µs) 200 [kube-probe/1.15+ 127.0.0.1:44588]
I0416 21:39:56.795860       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 21:39:57.099115       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:39:57.276687       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:39:58.652492       1 request.go:530] Throttling request took 91.41389ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:39:58.702550       1 request.go:530] Throttling request took 141.45809ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:39:58.752997       1 request.go:530] Throttling request took 191.900539ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:39:58.802540       1 request.go:530] Throttling request took 241.437134ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:39:58.852582       1 request.go:530] Throttling request took 291.450077ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:39:58.902673       1 request.go:530] Throttling request took 341.498426ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:39:58.952494       1 request.go:530] Throttling request took 391.364638ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:39:59.002694       1 request.go:530] Throttling request took 441.541523ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:40:02.465136       1 gc_controller.go:144] GC'ing orphaned
I0416 21:40:02.470201       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:40:02.731133       1 controller.go:123] Found 0 jobs
I0416 21:40:02.736980       1 controller.go:139] Found 0 cronjobs
I0416 21:40:02.736992       1 controller.go:142] Found 0 groups
I0416 21:40:05.609458       1 wrap.go:47] GET /healthz: (81.565µs) 200 [kube-probe/1.15+ 127.0.0.1:44622]
I0416 21:40:06.002549       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:40:06.170749       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 21:40:08.800998       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 451 items received
I0416 21:40:11.774287       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:11.804220       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:12.099339       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:40:12.283022       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:12.740584       1 controller.go:123] Found 0 jobs
I0416 21:40:12.748529       1 controller.go:139] Found 0 cronjobs
I0416 21:40:12.748543       1 controller.go:142] Found 0 groups
I0416 21:40:14.687243       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:40:14.959946       1 request.go:530] Throttling request took 85.307933ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:40:15.009826       1 request.go:530] Throttling request took 135.201907ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:40:15.059879       1 request.go:530] Throttling request took 185.245184ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:40:15.109832       1 request.go:530] Throttling request took 235.193637ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:40:15.159788       1 request.go:530] Throttling request took 285.137354ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:40:15.209818       1 request.go:530] Throttling request took 335.151437ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:40:15.260595       1 request.go:530] Throttling request took 385.919492ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:40:15.309868       1 request.go:530] Throttling request took 435.166408ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:40:15.312266       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:40:15.609345       1 wrap.go:47] GET /healthz: (153.995µs) 200 [kube-probe/1.15+ 127.0.0.1:44654]
I0416 21:40:17.694451       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:40:22.470490       1 gc_controller.go:144] GC'ing orphaned
I0416 21:40:22.475728       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:40:22.756450       1 controller.go:123] Found 0 jobs
I0416 21:40:22.767497       1 controller.go:139] Found 0 cronjobs
I0416 21:40:22.767511       1 controller.go:142] Found 0 groups
I0416 21:40:23.314628       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:25.608626       1 wrap.go:47] GET /healthz: (86.355µs) 200 [kube-probe/1.15+ 127.0.0.1:44688]
I0416 21:40:25.996570       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:40:27.100338       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:40:27.283356       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:27.324116       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:40:28.200898       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:40:28.520871       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 21:40:29.105594       1 request.go:530] Throttling request took 89.672572ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:40:29.155732       1 request.go:530] Throttling request took 139.728622ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:40:29.205729       1 request.go:530] Throttling request took 189.776165ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:40:29.255720       1 request.go:530] Throttling request took 239.753384ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:40:29.305786       1 request.go:530] Throttling request took 289.758744ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:40:29.355647       1 request.go:530] Throttling request took 339.665209ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:40:29.405819       1 request.go:530] Throttling request took 389.829237ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:40:29.456396       1 request.go:530] Throttling request took 440.395295ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:40:29.899363       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:40:32.324590       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:40:32.324631       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:40:32.776610       1 controller.go:123] Found 0 jobs
I0416 21:40:32.783581       1 controller.go:139] Found 0 cronjobs
I0416 21:40:32.783594       1 controller.go:142] Found 0 groups
I0416 21:40:35.056751       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:35.608529       1 wrap.go:47] GET /healthz: (86.822µs) 200 [kube-probe/1.15+ 127.0.0.1:44722]
I0416 21:40:35.793862       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 20 items received
I0416 21:40:39.139396       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:39.139668       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:40:39.139782       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:40:39.139981       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:40:39.471145       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 21:40:40.795844       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 21:40:40.882758       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:41.774624       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:41.804483       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:42.100582       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:40:42.283676       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:42.476040       1 gc_controller.go:144] GC'ing orphaned
I0416 21:40:42.480398       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:40:42.794220       1 controller.go:123] Found 0 jobs
I0416 21:40:42.799799       1 controller.go:139] Found 0 cronjobs
I0416 21:40:42.799813       1 controller.go:142] Found 0 groups
I0416 21:40:45.417963       1 request.go:530] Throttling request took 80.678637ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:40:45.467969       1 request.go:530] Throttling request took 130.67892ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:40:45.518020       1 request.go:530] Throttling request took 180.719333ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:40:45.568041       1 request.go:530] Throttling request took 230.729559ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:40:45.608536       1 wrap.go:47] GET /healthz: (99.091µs) 200 [kube-probe/1.15+ 127.0.0.1:44774]
I0416 21:40:45.618016       1 request.go:530] Throttling request took 280.692329ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:40:45.668004       1 request.go:530] Throttling request took 330.658684ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:40:45.717987       1 request.go:530] Throttling request took 380.638878ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:40:45.768004       1 request.go:530] Throttling request took 430.625786ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:40:45.770391       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:40:51.580032       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.580133       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:40:51.580148       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:40:51.580169       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:40:51.580163959 +0000 UTC m=+2273.733888110)
I0416 21:40:51.580991       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (819.436µs)
I0416 21:40:51.581013       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:40:51.581010278 +0000 UTC m=+2273.734734429)
I0416 21:40:51.581311       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (298.576µs)
I0416 21:40:51.581360       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:40:51.581370       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:40:51.581367286 +0000 UTC m=+2273.735091435)
I0416 21:40:51.582311       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (940.134µs)
I0416 21:40:51.582344       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:40:51.582349       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:40:51.582357       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:40:51.582354779 +0000 UTC m=+2273.736078930)
I0416 21:40:51.582821       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (464.6µs)
I0416 21:40:51.582832       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:40:51.582829903 +0000 UTC m=+2273.736554053)
I0416 21:40:51.583183       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (331.821µs)
I0416 21:40:51.583202       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:40:51.583209       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:40:51.583206947 +0000 UTC m=+2273.736931097)
I0416 21:40:51.583721       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (512.18µs)
I0416 21:40:51.583755       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:40:51.583759       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:40:51.583766       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:40:51.583763653 +0000 UTC m=+2273.737487804)
I0416 21:40:51.586177       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (2.405566ms)
I0416 21:40:51.586217       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:40:51.586203068 +0000 UTC m=+2273.739927218)
I0416 21:40:51.589331       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (3.11769ms)
I0416 21:40:51.599101       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.599192       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:40:51.599935       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b09af211d691, ext:2025993754026, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.600194       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:40:51.600300       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b0d8e3c79c97, ext:2273754008454, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.600360       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:40:51.600426       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:40:51.600431       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b0d8e3c79c97, ext:2273754008454, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.600478       1 update.go:396] Getting unavailable numbers
I0416 21:40:51.600549       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:40:51.600587       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:40:51.600593       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:40:51.600597       1 update.go:68] Marking old pods for deletion
I0416 21:40:51.600605       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b0d8e3cc6cea, ext:2273754324019, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.600626       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:40:51.600654       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:40:51.600675       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:40:51.600758       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:40:51.600823       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.571801ms)
I0416 21:40:51.600891       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:40:51.602498       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b09af1fc567e, ext:2025992345022, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.602745       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:40:51.602755       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b0d8e3ed4462, ext:2273756476541, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.602811       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:40:51.602847       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:40:51.602852       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b0d8e3ed4462, ext:2273756476541, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.602895       1 update.go:396] Getting unavailable numbers
I0416 21:40:51.602985       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:40:51.602991       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:40:51.602997       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:40:51.603001       1 update.go:68] Marking old pods for deletion
I0416 21:40:51.603005       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b0d8e3f11896, ext:2273756727302, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.603011       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:40:51.604267       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:40:51.604511       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:40:51.604674       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:40:51.604685       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (3.779868ms)
I0416 21:40:51.604761       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.604785       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.604813       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.605021       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:40:51.605040       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.605045       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:40:51.605096       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:40:51.605104       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.605106       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:40:51.605127       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:40:51.605134       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.605137       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:40:51.605156       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:40:51.605163       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.605166       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:40:51.605193       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:40:51.605201       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.605204       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:40:51.606291       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:40:51.606322       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606326       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:40:51.606480       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:40:51.606497       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606500       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:40:51.606503       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:40:51.606508       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606510       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:40:51.606554       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:40:51.606562       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606565       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:40:51.606596       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:40:51.606607       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606609       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:40:51.606629       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:40:51.606637       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606640       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:40:51.606671       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:40:51.606680       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606682       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:40:51.606708       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:40:51.606717       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606719       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:40:51.606722       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:40:51.606729       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606731       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:40:51.606754       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:40:51.606759       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606762       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:40:51.606806       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:40:51.606815       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606817       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:40:51.606843       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:40:51.606847       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606849       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:40:51.606875       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:40:51.606884       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606887       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:40:51.606913       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:40:51.606920       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606923       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:40:51.606941       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:40:51.606949       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606951       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:40:51.606954       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:40:51.606963       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.606966       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:40:51.606986       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:40:51.606994       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:40:51.607000       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:40:51.610101       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.610142       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.610302       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.610530       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (237.749µs)
I0416 21:40:51.610616       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.610672       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.610767       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (98.143µs)
I0416 21:40:51.610779       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.610841       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (64.758µs)
I0416 21:40:51.610863       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.610943       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (81.397µs)
I0416 21:40:51.610965       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.611041       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (78.693µs)
I0416 21:40:51.611083       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.611122       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (40.342µs)
I0416 21:40:51.611130       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.611185       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (56.611µs)
I0416 21:40:51.611206       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.611308       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (103.493µs)
I0416 21:40:51.611318       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.611377       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (59.996µs)
I0416 21:40:51.611391       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:40:51.611452       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (62.259µs)
I0416 21:40:51.779747       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:51.810697       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:52.149920       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:52.150034       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:40:52.150068       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.897µs)
I0416 21:40:52.150112       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:40:52.150122       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:40:52.150131       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:40:52.150136       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (594ns)
I0416 21:40:52.150159       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (970ns)
I0416 21:40:52.150192       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (665ns)
I0416 21:40:52.200511       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:52.783112       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 32 items received
I0416 21:40:52.812224       1 controller.go:123] Found 0 jobs
I0416 21:40:52.815078       1 controller.go:139] Found 0 cronjobs
I0416 21:40:52.815101       1 controller.go:142] Found 0 groups
I0416 21:40:55.608103       1 wrap.go:47] GET /healthz: (82.994µs) 200 [kube-probe/1.15+ 127.0.0.1:44810]
I0416 21:40:57.100806       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:40:57.284036       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:40:59.559623       1 request.go:530] Throttling request took 89.108042ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:40:59.609613       1 request.go:530] Throttling request took 139.085291ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:40:59.659522       1 request.go:530] Throttling request took 188.990515ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:40:59.709545       1 request.go:530] Throttling request took 238.996202ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:40:59.760746       1 request.go:530] Throttling request took 290.169993ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:40:59.809575       1 request.go:530] Throttling request took 338.99651ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:40:59.859564       1 request.go:530] Throttling request took 388.981159ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:40:59.909580       1 request.go:530] Throttling request took 438.985944ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:41:02.480719       1 gc_controller.go:144] GC'ing orphaned
I0416 21:41:02.485352       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:41:02.829395       1 controller.go:123] Found 0 jobs
I0416 21:41:02.832205       1 controller.go:139] Found 0 cronjobs
I0416 21:41:02.832217       1 controller.go:142] Found 0 groups
I0416 21:41:03.771294       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 23 items received
I0416 21:41:05.608575       1 wrap.go:47] GET /healthz: (87.516µs) 200 [kube-probe/1.15+ 127.0.0.1:44844]
I0416 21:41:06.999070       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:41:08.776758       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 21:41:11.774982       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:11.804754       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:12.101101       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:41:12.284358       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:12.840197       1 controller.go:123] Found 0 jobs
I0416 21:41:12.844204       1 controller.go:139] Found 0 cronjobs
I0416 21:41:12.844216       1 controller.go:142] Found 0 groups
I0416 21:41:15.608814       1 wrap.go:47] GET /healthz: (95.81µs) 200 [kube-probe/1.15+ 127.0.0.1:44876]
I0416 21:41:15.871625       1 request.go:530] Throttling request took 92.77793ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:41:15.920942       1 request.go:530] Throttling request took 142.066288ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:41:15.971000       1 request.go:530] Throttling request took 192.113395ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:41:16.021345       1 request.go:530] Throttling request took 242.44865ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:41:16.071123       1 request.go:530] Throttling request took 292.223853ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:41:16.121053       1 request.go:530] Throttling request took 342.137438ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:41:16.170929       1 request.go:530] Throttling request took 392.010307ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:41:16.221464       1 request.go:530] Throttling request took 442.513624ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:41:16.223960       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:41:21.759197       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:22.485725       1 gc_controller.go:144] GC'ing orphaned
I0416 21:41:22.489891       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:41:22.850851       1 controller.go:123] Found 0 jobs
I0416 21:41:22.856002       1 controller.go:139] Found 0 cronjobs
I0416 21:41:22.856015       1 controller.go:142] Found 0 groups
I0416 21:41:25.608449       1 wrap.go:47] GET /healthz: (81.722µs) 200 [kube-probe/1.15+ 127.0.0.1:44910]
I0416 21:41:26.076898       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:41:27.101315       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:41:27.284664       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:27.329575       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:41:28.311108       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:41:30.013142       1 request.go:530] Throttling request took 92.665602ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:41:30.050922       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:41:30.063785       1 request.go:530] Throttling request took 143.284488ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:41:30.112937       1 request.go:530] Throttling request took 192.415832ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:41:30.162907       1 request.go:530] Throttling request took 242.365583ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:41:30.212872       1 request.go:530] Throttling request took 292.338353ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:41:30.262982       1 request.go:530] Throttling request took 342.417446ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:41:30.312938       1 request.go:530] Throttling request took 392.384085ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:41:30.363268       1 request.go:530] Throttling request took 442.690638ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:41:31.767718       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 21:41:32.323363       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 35 items received
I0416 21:41:32.330018       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:41:32.330059       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:41:32.790082       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:41:32.868021       1 controller.go:123] Found 0 jobs
I0416 21:41:32.876274       1 controller.go:139] Found 0 cronjobs
I0416 21:41:32.876287       1 controller.go:142] Found 0 groups
I0416 21:41:35.608468       1 wrap.go:47] GET /healthz: (77.344µs) 200 [kube-probe/1.15+ 127.0.0.1:44944]
I0416 21:41:41.775373       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:41.805082       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:42.101614       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:41:42.284998       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:42.491163       1 gc_controller.go:144] GC'ing orphaned
I0416 21:41:42.496917       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:41:42.792274       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 21:41:42.884502       1 controller.go:123] Found 0 jobs
I0416 21:41:42.886899       1 controller.go:139] Found 0 cronjobs
I0416 21:41:42.886912       1 controller.go:142] Found 0 groups
I0416 21:41:43.956360       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 21:41:45.608392       1 wrap.go:47] GET /healthz: (87.815µs) 200 [kube-probe/1.15+ 127.0.0.1:44996]
I0416 21:41:46.324435       1 request.go:530] Throttling request took 92.579052ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:41:46.374445       1 request.go:530] Throttling request took 142.581871ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:41:46.424501       1 request.go:530] Throttling request took 192.598168ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:41:46.474427       1 request.go:530] Throttling request took 242.53136ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:41:46.524493       1 request.go:530] Throttling request took 292.573908ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:41:46.574575       1 request.go:530] Throttling request took 342.650822ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:41:46.624429       1 request.go:530] Throttling request took 392.504009ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:41:46.674539       1 request.go:530] Throttling request took 442.577066ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:41:46.676713       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:41:46.825678       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:41:51.777102       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 21:41:52.896063       1 controller.go:123] Found 0 jobs
I0416 21:41:52.901936       1 controller.go:139] Found 0 cronjobs
I0416 21:41:52.901951       1 controller.go:142] Found 0 groups
I0416 21:41:55.608407       1 wrap.go:47] GET /healthz: (90.326µs) 200 [kube-probe/1.15+ 127.0.0.1:45032]
I0416 21:41:56.810867       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:41:57.101872       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:41:57.285358       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:42:00.465833       1 request.go:530] Throttling request took 93.319994ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:42:00.521251       1 request.go:530] Throttling request took 148.681268ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:42:00.571861       1 request.go:530] Throttling request took 199.298354ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:42:00.615705       1 request.go:530] Throttling request took 243.139005ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:42:00.665756       1 request.go:530] Throttling request took 293.174072ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:42:00.715837       1 request.go:530] Throttling request took 343.246933ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:42:00.765769       1 request.go:530] Throttling request took 393.16594ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:42:00.815766       1 request.go:530] Throttling request took 440.795543ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:42:02.498252       1 gc_controller.go:144] GC'ing orphaned
I0416 21:42:02.502616       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:42:02.911033       1 controller.go:123] Found 0 jobs
I0416 21:42:02.914043       1 controller.go:139] Found 0 cronjobs
I0416 21:42:02.914056       1 controller.go:142] Found 0 groups
I0416 21:42:05.618470       1 wrap.go:47] GET /healthz: (83.871µs) 200 [kube-probe/1.15+ 127.0.0.1:45070]
I0416 21:42:08.000580       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:42:11.311425       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 0 items received
I0416 21:42:11.775709       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:42:11.805679       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 21:42:11.806111       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:42:12.102097       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:42:12.285696       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:42:12.925872       1 controller.go:123] Found 0 jobs
I0416 21:42:12.933151       1 controller.go:139] Found 0 cronjobs
I0416 21:42:12.933165       1 controller.go:142] Found 0 groups
I0416 21:42:14.339458       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 229 items received
I0416 21:42:15.608762       1 wrap.go:47] GET /healthz: (82.615µs) 200 [kube-probe/1.15+ 127.0.0.1:45102]
I0416 21:42:16.779358       1 request.go:530] Throttling request took 91.466969ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:42:16.829030       1 request.go:530] Throttling request took 141.131668ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:42:16.879118       1 request.go:530] Throttling request took 191.211009ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:42:16.929022       1 request.go:530] Throttling request took 241.10166ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:42:16.979043       1 request.go:530] Throttling request took 291.101164ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:42:17.029123       1 request.go:530] Throttling request took 341.160077ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:42:17.079050       1 request.go:530] Throttling request took 391.090408ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:42:17.128967       1 request.go:530] Throttling request took 440.972902ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:42:17.131579       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:42:17.775648       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 0 items received
I0416 21:42:22.502893       1 gc_controller.go:144] GC'ing orphaned
I0416 21:42:22.508551       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:42:22.939430       1 controller.go:123] Found 0 jobs
I0416 21:42:22.946555       1 controller.go:139] Found 0 cronjobs
I0416 21:42:22.946570       1 controller.go:142] Found 0 groups
I0416 21:42:23.935411       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 21:42:25.608587       1 wrap.go:47] GET /healthz: (87.378µs) 200 [kube-probe/1.15+ 127.0.0.1:45136]
I0416 21:42:26.167525       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:42:27.102339       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:42:27.286101       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:42:27.334397       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:42:28.417299       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:42:30.237877       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:42:30.919966       1 request.go:530] Throttling request took 91.174773ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:42:30.969951       1 request.go:530] Throttling request took 141.234892ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:42:31.020015       1 request.go:530] Throttling request took 191.289246ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:42:31.071194       1 request.go:530] Throttling request took 242.463556ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:42:31.119992       1 request.go:530] Throttling request took 291.170848ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:42:31.169807       1 request.go:530] Throttling request took 341.059715ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:42:31.219973       1 request.go:530] Throttling request took 391.203505ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:42:31.270218       1 request.go:530] Throttling request took 441.439172ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:42:31.786390       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 21:42:32.334852       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:42:32.334896       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:42:32.955533       1 controller.go:123] Found 0 jobs
I0416 21:42:32.962182       1 controller.go:139] Found 0 cronjobs
I0416 21:42:32.962195       1 controller.go:142] Found 0 groups
I0416 21:42:33.273874       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 122 items received
I0416 21:42:35.608634       1 wrap.go:47] GET /healthz: (82.782µs) 200 [kube-probe/1.15+ 127.0.0.1:45170]
I0416 21:42:36.122379       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 21:42:39.802346       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
I0416 21:42:41.776605       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:42:41.806345       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:42:42.102670       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:42:42.286415       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:42:42.509014       1 gc_controller.go:144] GC'ing orphaned
I0416 21:42:42.513694       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:42:42.973917       1 controller.go:123] Found 0 jobs
I0416 21:42:42.977904       1 controller.go:139] Found 0 cronjobs
I0416 21:42:42.977917       1 controller.go:142] Found 0 groups
I0416 21:42:45.608404       1 wrap.go:47] GET /healthz: (209.287µs) 200 [kube-probe/1.15+ 127.0.0.1:45222]
I0416 21:42:45.797389       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 21:42:46.783317       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:42:47.232586       1 request.go:530] Throttling request took 91.622574ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:42:47.282544       1 request.go:530] Throttling request took 141.576128ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:42:47.332581       1 request.go:530] Throttling request took 191.600448ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:42:47.382591       1 request.go:530] Throttling request took 241.603409ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:42:47.432602       1 request.go:530] Throttling request took 291.604225ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:42:47.483420       1 request.go:530] Throttling request took 342.385274ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:42:47.532554       1 request.go:530] Throttling request took 391.524678ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:42:47.582590       1 request.go:530] Throttling request took 441.546856ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:42:47.584876       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:42:52.986879       1 controller.go:123] Found 0 jobs
I0416 21:42:52.992080       1 controller.go:139] Found 0 cronjobs
I0416 21:42:52.992098       1 controller.go:142] Found 0 groups
I0416 21:42:55.609413       1 wrap.go:47] GET /healthz: (100.962µs) 200 [kube-probe/1.15+ 127.0.0.1:45258]
I0416 21:42:57.102926       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:42:57.286773       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:01.373201       1 request.go:530] Throttling request took 92.153132ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:43:01.423104       1 request.go:530] Throttling request took 142.045964ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:43:01.473211       1 request.go:530] Throttling request took 192.139019ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:43:01.523352       1 request.go:530] Throttling request took 242.268371ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:43:01.573217       1 request.go:530] Throttling request took 292.127989ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:43:01.623174       1 request.go:530] Throttling request took 342.054385ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:43:01.673162       1 request.go:530] Throttling request took 392.004299ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:43:01.723202       1 request.go:530] Throttling request took 442.059257ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:43:02.514017       1 gc_controller.go:144] GC'ing orphaned
I0416 21:43:02.519482       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:43:03.002446       1 controller.go:123] Found 0 jobs
I0416 21:43:03.006949       1 controller.go:139] Found 0 cronjobs
I0416 21:43:03.006961       1 controller.go:142] Found 0 groups
I0416 21:43:05.609587       1 wrap.go:47] GET /healthz: (89.759µs) 200 [kube-probe/1.15+ 127.0.0.1:45292]
I0416 21:43:08.999935       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:43:11.777058       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:11.807074       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:12.103178       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:43:12.287081       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:13.013453       1 controller.go:123] Found 0 jobs
I0416 21:43:13.023740       1 controller.go:139] Found 0 cronjobs
I0416 21:43:13.023752       1 controller.go:142] Found 0 groups
I0416 21:43:14.828093       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:43:15.609164       1 wrap.go:47] GET /healthz: (92.058µs) 200 [kube-probe/1.15+ 127.0.0.1:45324]
I0416 21:43:17.685369       1 request.go:530] Throttling request took 93.326014ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:43:17.735389       1 request.go:530] Throttling request took 143.322744ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:43:17.785456       1 request.go:530] Throttling request took 193.369855ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:43:17.836860       1 request.go:530] Throttling request took 244.759607ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:43:17.885420       1 request.go:530] Throttling request took 293.331675ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:43:17.935391       1 request.go:530] Throttling request took 343.284047ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:43:17.985421       1 request.go:530] Throttling request took 393.311323ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:43:18.035385       1 request.go:530] Throttling request took 443.260829ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:43:18.037674       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:43:22.519909       1 gc_controller.go:144] GC'ing orphaned
I0416 21:43:22.524982       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:43:23.039324       1 controller.go:123] Found 0 jobs
I0416 21:43:23.044354       1 controller.go:139] Found 0 cronjobs
I0416 21:43:23.044366       1 controller.go:142] Found 0 groups
I0416 21:43:23.790434       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 0 items received
I0416 21:43:25.617491       1 wrap.go:47] GET /healthz: (109.235µs) 200 [kube-probe/1.15+ 127.0.0.1:45356]
I0416 21:43:26.248732       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:43:27.103423       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:43:27.287460       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:27.339432       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:43:28.517659       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:43:29.325924       1 reflector.go:249] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: forcing resync
I0416 21:43:30.422913       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:43:31.825890       1 request.go:530] Throttling request took 90.457316ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:43:31.876017       1 request.go:530] Throttling request took 140.573368ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:43:31.926054       1 request.go:530] Throttling request took 190.57717ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:43:31.976050       1 request.go:530] Throttling request took 240.5629ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:43:32.026027       1 request.go:530] Throttling request took 290.531751ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:43:32.075962       1 request.go:530] Throttling request took 340.45869ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:43:32.126039       1 request.go:530] Throttling request took 390.525757ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:43:32.176713       1 request.go:530] Throttling request took 441.188166ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:43:32.339849       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:43:32.339942       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:43:33.050895       1 controller.go:123] Found 0 jobs
I0416 21:43:33.054942       1 controller.go:139] Found 0 cronjobs
I0416 21:43:33.054958       1 controller.go:142] Found 0 groups
I0416 21:43:34.911693       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 29 items received
I0416 21:43:35.608479       1 wrap.go:47] GET /healthz: (241.668µs) 200 [kube-probe/1.15+ 127.0.0.1:45392]
I0416 21:43:41.777416       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:41.807336       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:42.103697       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:43:42.287838       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:42.525403       1 gc_controller.go:144] GC'ing orphaned
I0416 21:43:42.530279       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:43:42.560346       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:43:43.062588       1 controller.go:123] Found 0 jobs
I0416 21:43:43.069559       1 controller.go:139] Found 0 cronjobs
I0416 21:43:43.069571       1 controller.go:142] Found 0 groups
I0416 21:43:43.457462       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:45.608518       1 wrap.go:47] GET /healthz: (94.149µs) 200 [kube-probe/1.15+ 127.0.0.1:45444]
I0416 21:43:48.138220       1 request.go:530] Throttling request took 91.180351ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:43:48.148132       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:43:48.188248       1 request.go:530] Throttling request took 141.179396ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:43:48.238318       1 request.go:530] Throttling request took 191.249386ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:43:48.288246       1 request.go:530] Throttling request took 241.153307ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:43:48.338224       1 request.go:530] Throttling request took 291.138284ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:43:48.388275       1 request.go:530] Throttling request took 341.155263ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:43:48.438223       1 request.go:530] Throttling request took 391.089155ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:43:48.488290       1 request.go:530] Throttling request took 441.107241ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:43:48.490766       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:43:53.073771       1 controller.go:123] Found 0 jobs
I0416 21:43:53.076206       1 controller.go:139] Found 0 cronjobs
I0416 21:43:53.076217       1 controller.go:142] Found 0 groups
I0416 21:43:55.608386       1 wrap.go:47] GET /healthz: (91.802µs) 200 [kube-probe/1.15+ 127.0.0.1:45480]
I0416 21:43:55.831425       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 19 items received
I0416 21:43:57.103938       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:43:57.288188       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:02.280331       1 request.go:530] Throttling request took 91.555084ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:44:02.330060       1 request.go:530] Throttling request took 141.274964ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:44:02.371375       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 21:44:02.380058       1 request.go:530] Throttling request took 191.253246ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:44:02.430070       1 request.go:530] Throttling request took 241.250784ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:44:02.480345       1 request.go:530] Throttling request took 291.519647ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:44:02.530065       1 request.go:530] Throttling request took 341.221188ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:44:02.530435       1 gc_controller.go:144] GC'ing orphaned
I0416 21:44:02.537469       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:44:02.580074       1 request.go:530] Throttling request took 391.217577ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:44:02.622875       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:02.630053       1 request.go:530] Throttling request took 441.178406ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:44:03.085605       1 controller.go:123] Found 0 jobs
I0416 21:44:03.099840       1 controller.go:139] Found 0 cronjobs
I0416 21:44:03.099866       1 controller.go:142] Found 0 groups
I0416 21:44:05.313388       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 0 items received
I0416 21:44:05.608429       1 wrap.go:47] GET /healthz: (93.179µs) 200 [kube-probe/1.15+ 127.0.0.1:45514]
I0416 21:44:09.789694       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 0 items received
I0416 21:44:09.999626       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:44:11.777701       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:11.778118       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (295.176µs)
I0416 21:44:11.778287       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (112.024µs)
I0416 21:44:11.778341       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (45.922µs)
I0416 21:44:11.778500       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (139.835µs)
I0416 21:44:11.778521       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.42µs)
I0416 21:44:11.778674       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:44:11.782419       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (3.875462ms)
I0416 21:44:11.808269       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:12.104209       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:44:12.288496       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:13.113482       1 controller.go:123] Found 0 jobs
I0416 21:44:13.118502       1 controller.go:139] Found 0 cronjobs
I0416 21:44:13.118514       1 controller.go:142] Found 0 groups
I0416 21:44:15.609333       1 wrap.go:47] GET /healthz: (128.038µs) 200 [kube-probe/1.15+ 127.0.0.1:45546]
I0416 21:44:16.388693       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:18.319646       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 0 items received
I0416 21:44:18.591571       1 request.go:530] Throttling request took 92.564737ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:44:18.641907       1 request.go:530] Throttling request took 142.901985ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:44:18.691333       1 request.go:530] Throttling request took 192.323154ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:44:18.741334       1 request.go:530] Throttling request took 242.307425ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:44:18.791662       1 request.go:530] Throttling request took 292.61288ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:44:18.841263       1 request.go:530] Throttling request took 342.18895ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:44:18.891367       1 request.go:530] Throttling request took 392.276503ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:44:18.941325       1 request.go:530] Throttling request took 442.249495ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:44:18.943834       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:44:22.537790       1 gc_controller.go:144] GC'ing orphaned
I0416 21:44:22.542442       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:44:23.122653       1 controller.go:123] Found 0 jobs
I0416 21:44:23.124920       1 controller.go:139] Found 0 cronjobs
I0416 21:44:23.124931       1 controller.go:142] Found 0 groups
I0416 21:44:23.772871       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 20 items received
I0416 21:44:25.608828       1 wrap.go:47] GET /healthz: (95.477µs) 200 [kube-probe/1.15+ 127.0.0.1:45578]
I0416 21:44:26.338135       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:44:27.104403       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:44:27.288815       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:27.344131       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:44:28.606203       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:44:29.986137       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 21:44:30.648108       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:44:32.344486       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:44:32.344550       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:44:32.733333       1 request.go:530] Throttling request took 93.076149ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:44:32.783324       1 request.go:530] Throttling request took 143.0329ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:44:32.833281       1 request.go:530] Throttling request took 192.988796ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:44:32.883217       1 request.go:530] Throttling request took 242.914181ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:44:32.933278       1 request.go:530] Throttling request took 292.950334ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:44:32.983242       1 request.go:530] Throttling request took 342.902573ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:44:33.033255       1 request.go:530] Throttling request took 392.906441ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:44:33.083224       1 request.go:530] Throttling request took 442.880081ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:44:33.128883       1 controller.go:123] Found 0 jobs
I0416 21:44:33.131044       1 controller.go:139] Found 0 cronjobs
I0416 21:44:33.131056       1 controller.go:142] Found 0 groups
I0416 21:44:35.608489       1 wrap.go:47] GET /healthz: (83.791µs) 200 [kube-probe/1.15+ 127.0.0.1:45614]
I0416 21:44:37.795165       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 21:44:39.796882       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 21:44:41.778024       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:41.808546       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:42.104650       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:44:42.289106       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:42.542803       1 gc_controller.go:144] GC'ing orphaned
I0416 21:44:42.546947       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:44:42.780580       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 104 items received
I0416 21:44:42.805137       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:44:43.136502       1 controller.go:123] Found 0 jobs
I0416 21:44:43.141848       1 controller.go:139] Found 0 cronjobs
I0416 21:44:43.141861       1 controller.go:142] Found 0 groups
I0416 21:44:45.609223       1 wrap.go:47] GET /healthz: (83.155µs) 200 [kube-probe/1.15+ 127.0.0.1:45806]
I0416 21:44:46.898615       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:46.899684       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:46.899921       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:44:46.900044       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:44:46.900134       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:44:46.900571       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:47.213213       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:49.044352       1 request.go:530] Throttling request took 77.270326ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:44:49.094272       1 request.go:530] Throttling request took 127.153233ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:44:49.144370       1 request.go:530] Throttling request took 177.271263ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:44:49.194379       1 request.go:530] Throttling request took 227.27204ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:44:49.244417       1 request.go:530] Throttling request took 277.295538ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:44:49.294353       1 request.go:530] Throttling request took 327.234986ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:44:49.344345       1 request.go:530] Throttling request took 377.220244ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:44:49.394370       1 request.go:530] Throttling request took 427.211272ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:44:49.397557       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:44:53.145486       1 controller.go:123] Found 0 jobs
I0416 21:44:53.147947       1 controller.go:139] Found 0 cronjobs
I0416 21:44:53.147959       1 controller.go:142] Found 0 groups
I0416 21:44:55.610205       1 wrap.go:47] GET /healthz: (90.274µs) 200 [kube-probe/1.15+ 127.0.0.1:45846]
I0416 21:44:57.104875       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:44:57.289424       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.337959       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.340118       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.340209       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.340313       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:44:59.340328       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:44:59.340350       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:44:59.340344582 +0000 UTC m=+2521.494068718)
I0416 21:44:59.341538       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.188848ms)
I0416 21:44:59.341569       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:44:59.341563859 +0000 UTC m=+2521.495287996)
I0416 21:44:59.342037       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (471.664µs)
I0416 21:44:59.342064       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:44:59.342074       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:44:59.342071302 +0000 UTC m=+2521.495795438)
I0416 21:44:59.342400       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (327.389µs)
I0416 21:44:59.342445       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:44:59.342450       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:44:59.342463       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:44:59.342455602 +0000 UTC m=+2521.496179738)
I0416 21:44:59.343095       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (637.942µs)
I0416 21:44:59.343107       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:44:59.34310472 +0000 UTC m=+2521.496828857)
I0416 21:44:59.343499       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (392.471µs)
I0416 21:44:59.343513       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:44:59.343520       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:44:59.343518007 +0000 UTC m=+2521.497242144)
I0416 21:44:59.343871       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (351.712µs)
I0416 21:44:59.343891       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:44:59.343895       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:44:59.343901       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:44:59.343899436 +0000 UTC m=+2521.497623573)
I0416 21:44:59.344331       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (429.582µs)
I0416 21:44:59.344339       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:44:59.34433711 +0000 UTC m=+2521.498061248)
I0416 21:44:59.345171       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (830.788µs)
I0416 21:44:59.359097       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.359183       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:44:59.359196       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:44:59.360747       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b0d8e3f11896, ext:2273756727302, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.360985       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:44:59.361057       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b116d5853e9c, ext:2521514778002, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.361069       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:44:59.361108       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:44:59.361113       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b116d5853e9c, ext:2521514778002, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.361157       1 update.go:396] Getting unavailable numbers
I0416 21:44:59.361224       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:44:59.361272       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:44:59.361279       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:44:59.361283       1 update.go:68] Marking old pods for deletion
I0416 21:44:59.361286       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b116d588c63e, ext:2521515009318, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.361298       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:44:59.361350       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:44:59.361371       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:44:59.361453       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:44:59.361499       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.285165ms)
I0416 21:44:59.361960       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b0d8e3cc6cea, ext:2273754324019, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.362038       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:44:59.362123       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b116d59589cf, ext:2521515845839, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.362145       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:44:59.362171       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:44:59.362175       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b116d59589cf, ext:2521515845839, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.362198       1 update.go:396] Getting unavailable numbers
I0416 21:44:59.362246       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:44:59.362318       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:44:59.362322       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:44:59.362325       1 update.go:68] Marking old pods for deletion
I0416 21:44:59.362329       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b116d598ac6d, ext:2521516051300, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.362334       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:44:59.362357       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:44:59.362406       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:44:59.362442       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:44:59.362515       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (991.274µs)
I0416 21:44:59.366996       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.367018       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.367030       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.367066       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.367406       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:44:59.367442       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367446       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:44:59.367516       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:44:59.367525       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367528       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:44:59.367568       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:44:59.367578       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367581       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:44:59.367606       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:44:59.367613       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367615       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:44:59.367659       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:44:59.367667       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367670       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:44:59.367762       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:44:59.367773       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367777       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:44:59.367779       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:44:59.367796       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367799       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:44:59.367877       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:44:59.367898       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367901       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:44:59.367904       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:44:59.367908       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367910       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:44:59.367949       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:44:59.367956       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.367958       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:44:59.368092       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:44:59.368105       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368108       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:44:59.368131       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:44:59.368139       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368141       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:44:59.368184       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:44:59.368192       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368195       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:44:59.368218       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:44:59.368243       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368245       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:44:59.368266       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:44:59.368274       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368276       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:44:59.368300       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:44:59.368308       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368343       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:44:59.368380       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:44:59.368389       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368392       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:44:59.368395       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:44:59.368398       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368400       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:44:59.368444       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:44:59.368453       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368455       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:44:59.368513       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:44:59.368521       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368523       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:44:59.368552       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:44:59.368560       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368562       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:44:59.368590       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:44:59.368599       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:44:59.368605       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:44:59.370042       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.370181       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.370417       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (258.672µs)
I0416 21:44:59.370452       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.370514       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.370599       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (88.912µs)
I0416 21:44:59.370611       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.370877       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (265.189µs)
I0416 21:44:59.370914       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.371023       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (111.767µs)
I0416 21:44:59.371047       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.371118       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (73.851µs)
I0416 21:44:59.371141       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.371190       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (50.619µs)
I0416 21:44:59.371199       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.371262       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (64.533µs)
I0416 21:44:59.371283       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.371392       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (109.671µs)
I0416 21:44:59.371442       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.371546       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.371588       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (43.348µs)
I0416 21:44:59.371601       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.371616       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.371671       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.371704       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:44:59.371752       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (49.26µs)
I0416 21:44:59.418007       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.502347       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.539908       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.570730       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.687332       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.760731       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.860446       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.909950       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:44:59.910046       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:44:59.910091       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.762µs)
I0416 21:44:59.910118       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:44:59.910123       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (590ns)
I0416 21:44:59.910132       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:44:59.910151       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:44:59.910162       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (402ns)
I0416 21:44:59.910170       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (291ns)
I0416 21:44:59.960497       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:00.116724       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:02.547286       1 gc_controller.go:144] GC'ing orphaned
I0416 21:45:02.551536       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:45:03.163383       1 controller.go:123] Found 0 jobs
I0416 21:45:03.171989       1 controller.go:139] Found 0 cronjobs
I0416 21:45:03.172003       1 controller.go:142] Found 0 groups
I0416 21:45:03.187867       1 request.go:530] Throttling request took 76.620131ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:45:03.238020       1 request.go:530] Throttling request took 126.765494ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:45:03.288008       1 request.go:530] Throttling request took 176.706065ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:45:03.337997       1 request.go:530] Throttling request took 226.675321ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:45:03.388058       1 request.go:530] Throttling request took 276.702463ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:45:03.437998       1 request.go:530] Throttling request took 326.676831ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:45:03.488044       1 request.go:530] Throttling request took 376.687963ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:45:03.538267       1 request.go:530] Throttling request took 426.902794ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:45:05.608181       1 wrap.go:47] GET /healthz: (88.712µs) 200 [kube-probe/1.15+ 127.0.0.1:45880]
I0416 21:45:10.998166       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:45:11.778360       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:11.808816       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:12.105255       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:45:12.290036       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:13.177479       1 controller.go:123] Found 0 jobs
I0416 21:45:13.180065       1 controller.go:139] Found 0 cronjobs
I0416 21:45:13.180079       1 controller.go:142] Found 0 groups
I0416 21:45:15.608538       1 wrap.go:47] GET /healthz: (86.815µs) 200 [kube-probe/1.15+ 127.0.0.1:45912]
I0416 21:45:19.498071       1 request.go:530] Throttling request took 86.556964ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:45:19.548003       1 request.go:530] Throttling request took 136.497477ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:45:19.597981       1 request.go:530] Throttling request took 186.452593ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:45:19.648046       1 request.go:530] Throttling request took 236.505848ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:45:19.697970       1 request.go:530] Throttling request took 286.426561ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:45:19.747962       1 request.go:530] Throttling request took 336.411218ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:45:19.797969       1 request.go:530] Throttling request took 386.404271ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:45:19.848103       1 request.go:530] Throttling request took 436.481786ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:45:19.850495       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:45:21.012247       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 21:45:21.466049       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:45:22.551824       1 gc_controller.go:144] GC'ing orphaned
I0416 21:45:22.555883       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:45:23.183902       1 controller.go:123] Found 0 jobs
I0416 21:45:23.186371       1 controller.go:139] Found 0 cronjobs
I0416 21:45:23.186388       1 controller.go:142] Found 0 groups
I0416 21:45:25.451536       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:25.608636       1 wrap.go:47] GET /healthz: (96.937µs) 200 [kube-probe/1.15+ 127.0.0.1:45944]
I0416 21:45:26.425657       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:45:27.105525       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:45:27.290342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:27.349441       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:45:28.688610       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:45:30.815683       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:45:32.349821       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:45:32.349886       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:45:33.189715       1 controller.go:123] Found 0 jobs
I0416 21:45:33.191836       1 controller.go:139] Found 0 cronjobs
I0416 21:45:33.191846       1 controller.go:142] Found 0 groups
I0416 21:45:33.641170       1 request.go:530] Throttling request took 93.375087ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:45:33.691256       1 request.go:530] Throttling request took 143.442774ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:45:33.741294       1 request.go:530] Throttling request took 193.469873ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:45:33.791212       1 request.go:530] Throttling request took 243.383198ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:45:33.842125       1 request.go:530] Throttling request took 294.28851ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:45:33.891165       1 request.go:530] Throttling request took 343.323598ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:45:33.941252       1 request.go:530] Throttling request took 393.379587ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:45:33.991206       1 request.go:530] Throttling request took 443.347874ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:45:35.608617       1 wrap.go:47] GET /healthz: (80.199µs) 200 [kube-probe/1.15+ 127.0.0.1:45980]
I0416 21:45:40.099837       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 21:45:41.778643       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:41.809075       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:42.105887       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:45:42.290688       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:45:42.556370       1 gc_controller.go:144] GC'ing orphaned
I0416 21:45:42.560997       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:45:43.195072       1 controller.go:123] Found 0 jobs
I0416 21:45:43.197191       1 controller.go:139] Found 0 cronjobs
I0416 21:45:43.197203       1 controller.go:142] Found 0 groups
I0416 21:45:44.226153       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 21:45:45.608442       1 wrap.go:47] GET /healthz: (76.644µs) 200 [kube-probe/1.15+ 127.0.0.1:46032]
I0416 21:45:49.951206       1 request.go:530] Throttling request took 91.16287ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:45:50.001340       1 request.go:530] Throttling request took 141.289344ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:45:50.051341       1 request.go:530] Throttling request took 191.28565ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:45:50.101330       1 request.go:530] Throttling request took 241.241595ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:45:50.151334       1 request.go:530] Throttling request took 291.26226ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:45:50.201291       1 request.go:530] Throttling request took 341.203334ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:45:50.251347       1 request.go:530] Throttling request took 391.253662ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:45:50.301330       1 request.go:530] Throttling request took 441.227043ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:45:50.303772       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:45:53.000432       1 deployment_controller.go:562] Started syncing deployment "default/linux-nginx" (2019-04-16 21:45:53.000413547 +0000 UTC m=+2575.154137683)
I0416 21:45:53.000479       1 deployment_controller.go:573] Deployment default/linux-nginx has been deleted
I0416 21:45:53.000490       1 deployment_controller.go:564] Finished syncing deployment "default/linux-nginx" (73.804µs)
I0416 21:45:53.201311       1 controller.go:123] Found 0 jobs
I0416 21:45:53.203747       1 controller.go:139] Found 0 cronjobs
I0416 21:45:53.203758       1 controller.go:142] Found 0 groups
I0416 21:45:55.608556       1 wrap.go:47] GET /healthz: (84.15µs) 200 [kube-probe/1.15+ 127.0.0.1:46068]
I0416 21:45:57.106117       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:45:57.291035       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:46:02.033390       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 21:46:02.561403       1 gc_controller.go:144] GC'ing orphaned
I0416 21:46:02.566642       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:46:03.211817       1 controller.go:123] Found 0 jobs
I0416 21:46:03.214775       1 controller.go:139] Found 0 cronjobs
I0416 21:46:03.214788       1 controller.go:142] Found 0 groups
I0416 21:46:04.004451       1 deployment_controller.go:562] Started syncing deployment "default/linux-ubuntu" (2019-04-16 21:46:04.00443889 +0000 UTC m=+2586.158163027)
I0416 21:46:04.004513       1 deployment_controller.go:573] Deployment default/linux-ubuntu has been deleted
I0416 21:46:04.004519       1 deployment_controller.go:564] Finished syncing deployment "default/linux-ubuntu" (76.619µs)
I0416 21:46:04.095313       1 request.go:530] Throttling request took 92.09393ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:46:04.145311       1 request.go:530] Throttling request took 142.08471ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:46:04.195303       1 request.go:530] Throttling request took 192.066782ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:46:04.246355       1 request.go:530] Throttling request took 243.098182ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:46:04.295256       1 request.go:530] Throttling request took 290.885922ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:46:04.345337       1 request.go:530] Throttling request took 340.949446ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:46:04.395320       1 request.go:530] Throttling request took 390.91463ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:46:04.445339       1 request.go:530] Throttling request took 440.921596ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:46:05.608470       1 wrap.go:47] GET /healthz: (79.625µs) 200 [kube-probe/1.15+ 127.0.0.1:46102]
I0416 21:46:10.419550       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 21:46:11.779020       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:46:11.809390       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:46:11.999635       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:46:12.106488       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:46:12.291408       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:46:13.219299       1 controller.go:123] Found 0 jobs
I0416 21:46:13.222664       1 controller.go:139] Found 0 cronjobs
I0416 21:46:13.222678       1 controller.go:142] Found 0 groups
I0416 21:46:14.968938       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:46:15.000445       1 deployment_controller.go:562] Started syncing deployment "default/windows-nettest" (2019-04-16 21:46:15.000422828 +0000 UTC m=+2597.154146978)
I0416 21:46:15.000492       1 deployment_controller.go:573] Deployment default/windows-nettest has been deleted
I0416 21:46:15.000497       1 deployment_controller.go:564] Finished syncing deployment "default/windows-nettest" (71.493µs)
I0416 21:46:15.608627       1 wrap.go:47] GET /healthz: (81.674µs) 200 [kube-probe/1.15+ 127.0.0.1:46134]
I0416 21:46:18.697105       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:46:20.404421       1 request.go:530] Throttling request took 92.476191ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:46:20.456071       1 request.go:530] Throttling request took 144.101994ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:46:20.504464       1 request.go:530] Throttling request took 192.488827ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:46:20.555478       1 request.go:530] Throttling request took 243.509227ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:46:20.604498       1 request.go:530] Throttling request took 292.506366ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:46:20.654415       1 request.go:530] Throttling request took 342.417884ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:46:20.704470       1 request.go:530] Throttling request took 392.448859ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:46:20.754456       1 request.go:530] Throttling request took 442.445935ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:46:20.759422       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:46:20.788522       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 21:46:22.566876       1 gc_controller.go:144] GC'ing orphaned
I0416 21:46:22.573296       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:46:23.226603       1 controller.go:123] Found 0 jobs
I0416 21:46:23.229013       1 controller.go:139] Found 0 cronjobs
I0416 21:46:23.229027       1 controller.go:142] Found 0 groups
I0416 21:46:25.608539       1 wrap.go:47] GET /healthz: (78.891µs) 200 [kube-probe/1.15+ 127.0.0.1:46166]
I0416 21:46:26.000482       1 deployment_controller.go:562] Started syncing deployment "default/windows-powershell" (2019-04-16 21:46:26.000462087 +0000 UTC m=+2608.154186238)
I0416 21:46:26.000533       1 deployment_controller.go:573] Deployment default/windows-powershell has been deleted
I0416 21:46:26.000538       1 deployment_controller.go:564] Finished syncing deployment "default/windows-powershell" (73.256µs)
I0416 21:46:26.512489       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:46:27.106688       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:46:27.291686       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:46:27.356787       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:46:28.773573       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:46:31.042090       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:46:32.357123       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:46:32.357198       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:46:33.233653       1 controller.go:123] Found 0 jobs
I0416 21:46:33.236661       1 controller.go:139] Found 0 cronjobs
I0416 21:46:33.236683       1 controller.go:142] Found 0 groups
I0416 21:46:34.548161       1 request.go:530] Throttling request took 90.689141ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:46:34.598704       1 request.go:530] Throttling request took 141.215806ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:46:34.648312       1 request.go:530] Throttling request took 190.809543ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:46:34.698274       1 request.go:530] Throttling request took 240.695404ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:46:34.748376       1 request.go:530] Throttling request took 290.803637ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:46:34.768547       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:46:34.798314       1 request.go:530] Throttling request took 340.731602ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:46:34.848338       1 request.go:530] Throttling request took 390.750228ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:46:34.898354       1 request.go:530] Throttling request took 440.756447ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:46:35.608624       1 wrap.go:47] GET /healthz: (80.214µs) 200 [kube-probe/1.15+ 127.0.0.1:46202]
I0416 21:46:41.779332       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:46:41.809652       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:46:42.106990       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:46:42.291950       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:46:42.574393       1 gc_controller.go:144] GC'ing orphaned
I0416 21:46:42.579174       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:46:43.241486       1 controller.go:123] Found 0 jobs
I0416 21:46:43.244023       1 controller.go:139] Found 0 cronjobs
I0416 21:46:43.244039       1 controller.go:142] Found 0 groups
I0416 21:46:44.787761       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:46:45.608542       1 wrap.go:47] GET /healthz: (82.078µs) 200 [kube-probe/1.15+ 127.0.0.1:46254]
I0416 21:46:50.859914       1 request.go:530] Throttling request took 90.493812ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:46:50.909892       1 request.go:530] Throttling request took 140.46227ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:46:50.959939       1 request.go:530] Throttling request took 190.500469ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:46:51.009899       1 request.go:530] Throttling request took 240.44028ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:46:51.060405       1 request.go:530] Throttling request took 290.939881ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:46:51.109819       1 request.go:530] Throttling request took 340.34727ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:46:51.159885       1 request.go:530] Throttling request took 390.410129ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:46:51.209911       1 request.go:530] Throttling request took 440.426007ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:46:51.212174       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:46:53.247880       1 controller.go:123] Found 0 jobs
I0416 21:46:53.250924       1 controller.go:139] Found 0 cronjobs
I0416 21:46:53.250937       1 controller.go:142] Found 0 groups
I0416 21:46:55.608498       1 wrap.go:47] GET /healthz: (83.779µs) 200 [kube-probe/1.15+ 127.0.0.1:46290]
I0416 21:46:57.107407       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:46:57.292403       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:02.579451       1 gc_controller.go:144] GC'ing orphaned
I0416 21:47:02.583953       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:47:03.254683       1 controller.go:123] Found 0 jobs
I0416 21:47:03.257163       1 controller.go:139] Found 0 cronjobs
I0416 21:47:03.257175       1 controller.go:142] Found 0 groups
I0416 21:47:03.600284       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:05.001348       1 request.go:530] Throttling request took 91.177402ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:47:05.051286       1 request.go:530] Throttling request took 141.121403ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:47:05.101197       1 request.go:530] Throttling request took 191.023442ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:47:05.151264       1 request.go:530] Throttling request took 241.040632ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:47:05.201216       1 request.go:530] Throttling request took 291.011441ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:47:05.251272       1 request.go:530] Throttling request took 341.047367ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:47:05.301340       1 request.go:530] Throttling request took 391.117278ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:47:05.351252       1 request.go:530] Throttling request took 441.009467ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:47:05.608600       1 wrap.go:47] GET /healthz: (113.846µs) 200 [kube-probe/1.15+ 127.0.0.1:46324]
I0416 21:47:06.772038       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 230 items received
I0416 21:47:08.782372       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 21:47:11.779662       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:11.792413       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 21:47:11.809930       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:12.004348       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:47:12.107695       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:47:12.292554       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:13.261555       1 controller.go:123] Found 0 jobs
I0416 21:47:13.263945       1 controller.go:139] Found 0 cronjobs
I0416 21:47:13.263957       1 controller.go:142] Found 0 groups
I0416 21:47:15.608740       1 wrap.go:47] GET /healthz: (91.608µs) 200 [kube-probe/1.15+ 127.0.0.1:46356]
I0416 21:47:16.786501       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 21:47:21.312683       1 request.go:530] Throttling request took 91.987764ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:47:21.362649       1 request.go:530] Throttling request took 141.948729ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:47:21.412703       1 request.go:530] Throttling request took 191.984299ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:47:21.463349       1 request.go:530] Throttling request took 242.612151ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:47:21.512672       1 request.go:530] Throttling request took 291.935713ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:47:21.562693       1 request.go:530] Throttling request took 341.946344ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:47:21.612692       1 request.go:530] Throttling request took 391.940836ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:47:21.662641       1 request.go:530] Throttling request took 441.865314ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:47:21.665043       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:47:21.797823       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 21:47:22.172955       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 21:47:22.584288       1 gc_controller.go:144] GC'ing orphaned
I0416 21:47:22.588780       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:47:23.267854       1 controller.go:123] Found 0 jobs
I0416 21:47:23.270622       1 controller.go:139] Found 0 cronjobs
I0416 21:47:23.270647       1 controller.go:142] Found 0 groups
I0416 21:47:24.362997       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:25.608406       1 wrap.go:47] GET /healthz: (85.888µs) 200 [kube-probe/1.15+ 127.0.0.1:46388]
I0416 21:47:26.596895       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:47:27.107920       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:47:27.292728       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:27.362617       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:47:28.867930       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:47:30.773178       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:47:31.249543       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:47:32.363481       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:47:32.363522       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:47:33.274889       1 controller.go:123] Found 0 jobs
I0416 21:47:33.277886       1 controller.go:139] Found 0 cronjobs
I0416 21:47:33.277898       1 controller.go:142] Found 0 groups
I0416 21:47:35.454314       1 request.go:530] Throttling request took 91.37242ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:47:35.503970       1 request.go:530] Throttling request took 140.999663ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:47:35.554277       1 request.go:530] Throttling request took 191.274759ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:47:35.604005       1 request.go:530] Throttling request took 241.017195ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:47:35.608500       1 wrap.go:47] GET /healthz: (95.514µs) 200 [kube-probe/1.15+ 127.0.0.1:46424]
I0416 21:47:35.653922       1 request.go:530] Throttling request took 290.927041ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:47:35.703978       1 request.go:530] Throttling request took 340.974649ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:47:35.753943       1 request.go:530] Throttling request took 390.933261ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:47:35.803927       1 request.go:530] Throttling request took 440.908461ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:47:36.773845       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 0 items received
I0416 21:47:38.313998       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 0 items received
I0416 21:47:41.780019       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:41.810201       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:42.108208       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:47:42.293342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:42.589076       1 gc_controller.go:144] GC'ing orphaned
I0416 21:47:42.593722       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:47:42.778408       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 0 items received
I0416 21:47:43.281326       1 controller.go:123] Found 0 jobs
I0416 21:47:43.284038       1 controller.go:139] Found 0 cronjobs
I0416 21:47:43.284062       1 controller.go:142] Found 0 groups
I0416 21:47:45.608428       1 wrap.go:47] GET /healthz: (258.067µs) 200 [kube-probe/1.15+ 127.0.0.1:46476]
I0416 21:47:48.716856       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:51.765909       1 request.go:530] Throttling request took 84.305826ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:47:51.816659       1 request.go:530] Throttling request took 135.052711ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:47:51.865587       1 request.go:530] Throttling request took 183.965367ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:47:51.915606       1 request.go:530] Throttling request took 233.972189ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:47:51.965559       1 request.go:530] Throttling request took 283.917902ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:47:52.015578       1 request.go:530] Throttling request took 333.924797ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:47:52.065960       1 request.go:530] Throttling request took 384.292666ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:47:52.115572       1 request.go:530] Throttling request took 433.910795ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:47:52.117878       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:47:53.288576       1 controller.go:123] Found 0 jobs
I0416 21:47:53.291413       1 controller.go:139] Found 0 cronjobs
I0416 21:47:53.291424       1 controller.go:142] Found 0 groups
I0416 21:47:55.608520       1 wrap.go:47] GET /healthz: (90.374µs) 200 [kube-probe/1.15+ 127.0.0.1:46512]
I0416 21:47:57.108446       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:47:57.293691       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:47:57.720504       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:02.594024       1 gc_controller.go:144] GC'ing orphaned
I0416 21:48:02.598455       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:48:02.794359       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 21:48:03.295261       1 controller.go:123] Found 0 jobs
I0416 21:48:03.297485       1 controller.go:139] Found 0 cronjobs
I0416 21:48:03.297497       1 controller.go:142] Found 0 groups
I0416 21:48:03.778762       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 21:48:05.608559       1 wrap.go:47] GET /healthz: (77.192µs) 200 [kube-probe/1.15+ 127.0.0.1:46546]
I0416 21:48:05.906739       1 request.go:530] Throttling request took 92.495931ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:48:05.956616       1 request.go:530] Throttling request took 142.362856ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:48:06.006724       1 request.go:530] Throttling request took 192.45718ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:48:06.057089       1 request.go:530] Throttling request took 242.807436ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:48:06.106701       1 request.go:530] Throttling request took 292.413876ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:48:06.156655       1 request.go:530] Throttling request took 342.357579ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:48:06.206656       1 request.go:530] Throttling request took 392.344052ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:48:06.256635       1 request.go:530] Throttling request took 442.312558ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:48:11.780390       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:11.810493       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:12.000346       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:48:12.108748       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:48:12.293944       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:12.667273       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:13.301725       1 controller.go:123] Found 0 jobs
I0416 21:48:13.304424       1 controller.go:139] Found 0 cronjobs
I0416 21:48:13.304436       1 controller.go:142] Found 0 groups
I0416 21:48:15.608551       1 wrap.go:47] GET /healthz: (81.09µs) 200 [kube-probe/1.15+ 127.0.0.1:46578]
I0416 21:48:16.803175       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 485 items received
I0416 21:48:21.523677       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 21:48:22.218487       1 request.go:530] Throttling request took 93.555646ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:48:22.268517       1 request.go:530] Throttling request took 143.57051ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:48:22.318539       1 request.go:530] Throttling request took 193.580098ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:48:22.368637       1 request.go:530] Throttling request took 243.690977ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:48:22.418474       1 request.go:530] Throttling request took 293.504759ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:48:22.469608       1 request.go:530] Throttling request took 344.630415ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:48:22.520901       1 request.go:530] Throttling request took 395.914763ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:48:22.569056       1 request.go:530] Throttling request took 444.057798ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:48:22.573167       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:48:22.598705       1 gc_controller.go:144] GC'ing orphaned
I0416 21:48:22.603311       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:48:23.308719       1 controller.go:123] Found 0 jobs
I0416 21:48:23.310946       1 controller.go:139] Found 0 cronjobs
I0416 21:48:23.310956       1 controller.go:142] Found 0 groups
I0416 21:48:25.608551       1 wrap.go:47] GET /healthz: (107.734µs) 200 [kube-probe/1.15+ 127.0.0.1:46614]
I0416 21:48:26.685648       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:48:27.108962       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:48:27.294214       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:27.369011       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:48:28.949017       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:48:29.342570       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 187 items received
I0416 21:48:31.419646       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:48:32.369499       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:48:32.369539       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:48:33.314959       1 controller.go:123] Found 0 jobs
I0416 21:48:33.318098       1 controller.go:139] Found 0 cronjobs
I0416 21:48:33.318123       1 controller.go:142] Found 0 groups
I0416 21:48:35.607598       1 wrap.go:47] GET /healthz: (84.709µs) 200 [kube-probe/1.15+ 127.0.0.1:46648]
I0416 21:48:36.359978       1 request.go:530] Throttling request took 74.713915ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:48:36.412991       1 request.go:530] Throttling request took 127.715399ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:48:36.460133       1 request.go:530] Throttling request took 174.84422ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:48:36.510000       1 request.go:530] Throttling request took 224.700309ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:48:36.559996       1 request.go:530] Throttling request took 274.599013ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:48:36.609988       1 request.go:530] Throttling request took 324.510035ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:48:36.659974       1 request.go:530] Throttling request took 374.480118ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:48:36.709958       1 request.go:530] Throttling request took 424.462074ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:48:41.780783       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:41.780919       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (8.527µs)
I0416 21:48:41.781439       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:48:41.781968       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (139.18µs)
I0416 21:48:41.782058       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (66.6µs)
I0416 21:48:41.782146       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (70.095µs)
I0416 21:48:41.784381       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (65.149µs)
I0416 21:48:41.786199       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (5.22002ms)
I0416 21:48:41.810830       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:42.109376       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:48:42.294441       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:42.561422       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:48:42.604462       1 gc_controller.go:144] GC'ing orphaned
I0416 21:48:42.608543       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:48:43.324659       1 controller.go:123] Found 0 jobs
I0416 21:48:43.327925       1 controller.go:139] Found 0 cronjobs
I0416 21:48:43.327938       1 controller.go:142] Found 0 groups
I0416 21:48:43.770428       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 21:48:43.796045       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 0 items received
I0416 21:48:45.608915       1 wrap.go:47] GET /healthz: (99.919µs) 200 [kube-probe/1.15+ 127.0.0.1:46702]
I0416 21:48:52.675056       1 request.go:530] Throttling request took 90.88606ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:48:52.725296       1 request.go:530] Throttling request took 141.128949ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:48:52.774661       1 request.go:530] Throttling request took 190.458576ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:48:52.824663       1 request.go:530] Throttling request took 240.449436ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:48:52.874706       1 request.go:530] Throttling request took 290.401597ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:48:52.924703       1 request.go:530] Throttling request took 340.471194ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:48:52.974703       1 request.go:530] Throttling request took 390.466892ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:48:53.024806       1 request.go:530] Throttling request took 440.560827ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:48:53.027250       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:48:53.331893       1 controller.go:123] Found 0 jobs
I0416 21:48:53.334397       1 controller.go:139] Found 0 cronjobs
I0416 21:48:53.334410       1 controller.go:142] Found 0 groups
I0416 21:48:54.092220       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:54.659657       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:48:54.659945       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:48:54.660060       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:48:54.660169       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:48:55.609604       1 wrap.go:47] GET /healthz: (89.091µs) 200 [kube-probe/1.15+ 127.0.0.1:46738]
I0416 21:48:57.109597       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:48:57.294766       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:02.608839       1 gc_controller.go:144] GC'ing orphaned
I0416 21:49:02.613442       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:49:03.338469       1 controller.go:123] Found 0 jobs
I0416 21:49:03.341310       1 controller.go:139] Found 0 cronjobs
I0416 21:49:03.341336       1 controller.go:142] Found 0 groups
I0416 21:49:04.798321       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 21:49:05.608593       1 wrap.go:47] GET /healthz: (198.149µs) 200 [kube-probe/1.15+ 127.0.0.1:46772]
I0416 21:49:06.813111       1 request.go:530] Throttling request took 91.475593ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:49:06.863107       1 request.go:530] Throttling request took 141.458526ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:49:06.913121       1 request.go:530] Throttling request took 191.463822ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:49:06.963156       1 request.go:530] Throttling request took 241.492714ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:49:07.013155       1 request.go:530] Throttling request took 291.468293ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:49:07.063470       1 request.go:530] Throttling request took 341.719403ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:49:07.101664       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.101755       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:49:07.101770       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:49:07.101791       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:49:07.101786586 +0000 UTC m=+2769.255510721)
I0416 21:49:07.103222       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.429351ms)
I0416 21:49:07.105529       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:49:07.105516985 +0000 UTC m=+2769.259241121)
I0416 21:49:07.106424       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (901.303µs)
I0416 21:49:07.106497       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:49:07.106510       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:49:07.106506684 +0000 UTC m=+2769.260230819)
I0416 21:49:07.107816       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (1.301495ms)
I0416 21:49:07.107897       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:49:07.107903       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:49:07.107913       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:49:07.107909977 +0000 UTC m=+2769.261634114)
I0416 21:49:07.110929       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (3.010512ms)
I0416 21:49:07.110982       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:49:07.110978897 +0000 UTC m=+2769.264703048)
I0416 21:49:07.111467       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (485.579µs)
I0416 21:49:07.111499       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:49:07.111508       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:49:07.111517       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:49:07.111513858 +0000 UTC m=+2769.265237995)
I0416 21:49:07.111923       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (406.497µs)
I0416 21:49:07.111941       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:49:07.111930272 +0000 UTC m=+2769.265654410)
I0416 21:49:07.113451       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (1.514049ms)
I0416 21:49:07.113493       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:49:07.113507       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:49:07.113503743 +0000 UTC m=+2769.267227881)
I0416 21:49:07.116510       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (2.999523ms)
I0416 21:49:07.116566       1 request.go:530] Throttling request took 394.887105ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:49:07.121362       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.121437       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:49:07.122008       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b116d598ac6d, ext:2521516051300, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.122310       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:49:07.122323       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b154c74a7101, ext:2769276043256, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.122382       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:49:07.122419       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:49:07.122424       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b154c74a7101, ext:2769276043256, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.122455       1 update.go:396] Getting unavailable numbers
I0416 21:49:07.122542       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:49:07.122548       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:49:07.122553       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:49:07.122558       1 update.go:68] Marking old pods for deletion
I0416 21:49:07.122561       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b154c74e1dad, ext:2769276284153, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.122567       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:49:07.122592       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:49:07.122617       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:49:07.122714       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:49:07.122720       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.257342ms)
I0416 21:49:07.122755       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:49:07.124887       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b116d588c63e, ext:2521515009318, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.125137       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:49:07.125147       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b154c7758c5d, ext:2769278868308, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.125203       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:49:07.125273       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:49:07.125278       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b154c7758c5d, ext:2769278868308, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.125311       1 update.go:396] Getting unavailable numbers
I0416 21:49:07.125419       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:49:07.125425       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:49:07.125430       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:49:07.125435       1 update.go:68] Marking old pods for deletion
I0416 21:49:07.125438       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b154c77a0264, ext:2769279160672, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.125444       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:49:07.125468       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:49:07.125511       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:49:07.125610       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:49:07.125617       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.851177ms)
I0416 21:49:07.130464       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.130514       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.130526       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.130569       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.130717       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.130813       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.130989       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (183.626µs)
I0416 21:49:07.131159       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:49:07.131195       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.131199       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:49:07.131316       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:49:07.131333       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.131336       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:49:07.131357       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.131459       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (104.382µs)
I0416 21:49:07.131486       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.131528       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (42.315µs)
I0416 21:49:07.131579       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.131614       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.131691       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (79.324µs)
I0416 21:49:07.131764       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:49:07.131772       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.131775       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:49:07.131808       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.131892       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (83.723µs)
I0416 21:49:07.131972       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:49:07.131983       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.131986       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:49:07.132021       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.132081       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (62.295µs)
I0416 21:49:07.132090       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.132137       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (48.89µs)
I0416 21:49:07.132151       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:49:07.132161       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132164       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:49:07.132184       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.132323       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (140.579µs)
I0416 21:49:07.132372       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.132423       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (52.962µs)
I0416 21:49:07.132447       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:49:07.132459       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132462       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:49:07.132527       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:49:07.132573       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (62.104µs)
I0416 21:49:07.132612       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:49:07.132621       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132624       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:49:07.132626       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:49:07.132638       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132641       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:49:07.132686       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:49:07.132693       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132695       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:49:07.132719       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:49:07.132726       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132729       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:49:07.132771       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:49:07.132778       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132780       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:49:07.132808       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:49:07.132818       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132821       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:49:07.132864       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:49:07.132872       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132874       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:49:07.132894       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:49:07.132901       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132903       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:49:07.132947       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:49:07.132958       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132963       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:49:07.132965       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:49:07.132969       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.132971       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:49:07.133010       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:49:07.133018       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.133020       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:49:07.133091       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:49:07.133098       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.133100       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:49:07.133124       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:49:07.133132       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.133134       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:49:07.133151       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:49:07.133171       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.133174       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:49:07.133177       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:49:07.133183       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.133185       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:49:07.133202       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:49:07.133208       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:49:07.133210       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:49:07.163165       1 request.go:530] Throttling request took 441.438407ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:49:07.300037       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.330701       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.669920       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:07.670048       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:49:07.670080       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.671µs)
I0416 21:49:07.670106       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:49:07.670113       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:49:07.670138       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:49:07.670143       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (423ns)
I0416 21:49:07.670156       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (523ns)
I0416 21:49:07.670165       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (281ns)
I0416 21:49:07.720504       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:11.781105       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:11.811128       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:12.109916       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:49:12.295014       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:13.001562       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:49:13.345397       1 controller.go:123] Found 0 jobs
I0416 21:49:13.348084       1 controller.go:139] Found 0 cronjobs
I0416 21:49:13.348096       1 controller.go:142] Found 0 groups
I0416 21:49:15.109758       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:49:15.608546       1 wrap.go:47] GET /healthz: (95.082µs) 200 [kube-probe/1.15+ 127.0.0.1:46806]
I0416 21:49:22.613776       1 gc_controller.go:144] GC'ing orphaned
I0416 21:49:22.618144       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:49:23.129092       1 request.go:530] Throttling request took 92.919897ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:49:23.177791       1 request.go:530] Throttling request took 141.597316ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:49:23.227988       1 request.go:530] Throttling request took 191.762919ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:49:23.277872       1 request.go:530] Throttling request took 241.659027ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:49:23.328091       1 request.go:530] Throttling request took 291.870022ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:49:23.353751       1 controller.go:123] Found 0 jobs
I0416 21:49:23.356850       1 controller.go:139] Found 0 cronjobs
I0416 21:49:23.356863       1 controller.go:142] Found 0 groups
I0416 21:49:23.377852       1 request.go:530] Throttling request took 341.596691ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:49:23.427749       1 request.go:530] Throttling request took 391.516545ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:49:23.473378       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 21:49:23.477760       1 request.go:530] Throttling request took 441.474219ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:49:23.479886       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:49:25.608486       1 wrap.go:47] GET /healthz: (102.889µs) 200 [kube-probe/1.15+ 127.0.0.1:46838]
I0416 21:49:26.783810       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:49:27.110113       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:49:27.295495       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:27.374890       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:49:29.044943       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:49:29.321841       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 0 items received
I0416 21:49:29.828288       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:49:31.617803       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:49:32.375284       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:49:32.375349       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:49:33.362875       1 controller.go:123] Found 0 jobs
I0416 21:49:33.367965       1 controller.go:139] Found 0 cronjobs
I0416 21:49:33.367981       1 controller.go:142] Found 0 groups
I0416 21:49:33.958613       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 21:49:35.609557       1 wrap.go:47] GET /healthz: (107.19µs) 200 [kube-probe/1.15+ 127.0.0.1:46872]
I0416 21:49:37.266134       1 request.go:530] Throttling request took 92.150518ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:49:37.316339       1 request.go:530] Throttling request took 142.301112ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:49:37.366888       1 request.go:530] Throttling request took 192.830747ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:49:37.416053       1 request.go:530] Throttling request took 241.994874ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:49:37.466352       1 request.go:530] Throttling request took 292.286855ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:49:37.519391       1 request.go:530] Throttling request took 345.298733ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:49:37.566373       1 request.go:530] Throttling request took 392.257204ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:49:37.616034       1 request.go:530] Throttling request took 441.864269ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:49:41.781420       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:41.811410       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:42.110402       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:49:42.295761       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:42.618446       1 gc_controller.go:144] GC'ing orphaned
I0416 21:49:42.622992       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:49:43.372265       1 controller.go:123] Found 0 jobs
I0416 21:49:43.374470       1 controller.go:139] Found 0 cronjobs
I0416 21:49:43.374481       1 controller.go:142] Found 0 groups
I0416 21:49:44.331502       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 32 items received
I0416 21:49:45.608677       1 wrap.go:47] GET /healthz: (99.856µs) 200 [kube-probe/1.15+ 127.0.0.1:46926]
I0416 21:49:52.804467       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
I0416 21:49:53.378171       1 controller.go:123] Found 0 jobs
I0416 21:49:53.380501       1 controller.go:139] Found 0 cronjobs
I0416 21:49:53.380513       1 controller.go:142] Found 0 groups
I0416 21:49:53.580389       1 request.go:530] Throttling request took 92.652328ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:49:53.630330       1 request.go:530] Throttling request took 142.578456ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:49:53.680332       1 request.go:530] Throttling request took 192.570778ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:49:53.730357       1 request.go:530] Throttling request took 242.576362ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:49:53.780379       1 request.go:530] Throttling request took 292.581094ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:49:53.830373       1 request.go:530] Throttling request took 342.57289ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:49:53.880399       1 request.go:530] Throttling request took 392.595896ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:49:53.930432       1 request.go:530] Throttling request took 442.620935ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:49:53.933033       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:49:55.608192       1 wrap.go:47] GET /healthz: (77.293µs) 200 [kube-probe/1.15+ 127.0.0.1:46962]
I0416 21:49:57.110601       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:49:57.296086       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:49:58.799343       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 21:50:02.623274       1 gc_controller.go:144] GC'ing orphaned
I0416 21:50:02.631830       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:50:03.384681       1 controller.go:123] Found 0 jobs
I0416 21:50:03.387774       1 controller.go:139] Found 0 cronjobs
I0416 21:50:03.387787       1 controller.go:142] Found 0 groups
I0416 21:50:05.608536       1 wrap.go:47] GET /healthz: (91.101µs) 200 [kube-probe/1.15+ 127.0.0.1:46996]
I0416 21:50:07.718967       1 request.go:530] Throttling request took 91.427991ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:50:07.768986       1 request.go:530] Throttling request took 141.432189ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:50:07.818994       1 request.go:530] Throttling request took 191.405606ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:50:07.869028       1 request.go:530] Throttling request took 241.454433ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:50:07.918963       1 request.go:530] Throttling request took 291.384535ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:50:07.969113       1 request.go:530] Throttling request took 341.505669ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:50:08.019525       1 request.go:530] Throttling request took 391.887471ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:50:08.068996       1 request.go:530] Throttling request took 441.351761ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:50:08.315630       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 0 items received
I0416 21:50:11.781724       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:11.791490       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 0 items received
I0416 21:50:11.811696       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:12.110901       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:50:12.276330       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 138 items received
I0416 21:50:12.296426       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:13.002855       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:50:13.391936       1 controller.go:123] Found 0 jobs
I0416 21:50:13.394891       1 controller.go:139] Found 0 cronjobs
I0416 21:50:13.394909       1 controller.go:142] Found 0 groups
I0416 21:50:15.608111       1 wrap.go:47] GET /healthz: (80.068µs) 200 [kube-probe/1.15+ 127.0.0.1:47028]
I0416 21:50:22.632078       1 gc_controller.go:144] GC'ing orphaned
I0416 21:50:22.637008       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:50:22.833743       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 0 items received
I0416 21:50:23.399030       1 controller.go:123] Found 0 jobs
I0416 21:50:23.402207       1 controller.go:139] Found 0 cronjobs
I0416 21:50:23.402221       1 controller.go:142] Found 0 groups
I0416 21:50:23.743182       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:24.033745       1 request.go:530] Throttling request took 90.373772ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:50:24.083653       1 request.go:530] Throttling request took 140.261897ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:50:24.133574       1 request.go:530] Throttling request took 190.18712ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:50:24.183650       1 request.go:530] Throttling request took 240.218117ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:50:24.233623       1 request.go:530] Throttling request took 290.201501ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:50:24.284015       1 request.go:530] Throttling request took 340.57172ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:50:24.333624       1 request.go:530] Throttling request took 390.186155ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:50:24.383632       1 request.go:530] Throttling request took 440.164309ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:50:24.385823       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:50:25.608647       1 wrap.go:47] GET /healthz: (89.981µs) 200 [kube-probe/1.15+ 127.0.0.1:47060]
I0416 21:50:26.878598       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:50:27.111250       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:50:27.296715       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:27.380793       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:50:29.132320       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:50:31.917294       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:50:32.381270       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:50:32.381313       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:50:33.407676       1 controller.go:123] Found 0 jobs
I0416 21:50:33.410407       1 controller.go:139] Found 0 cronjobs
I0416 21:50:33.410419       1 controller.go:142] Found 0 groups
I0416 21:50:35.608620       1 wrap.go:47] GET /healthz: (84.34µs) 200 [kube-probe/1.15+ 127.0.0.1:47094]
I0416 21:50:38.173503       1 request.go:530] Throttling request took 92.695399ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:50:38.222778       1 request.go:530] Throttling request took 141.920264ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:50:38.272815       1 request.go:530] Throttling request took 191.972216ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:50:38.322786       1 request.go:530] Throttling request took 241.918253ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:50:38.372786       1 request.go:530] Throttling request took 291.914298ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:50:38.422773       1 request.go:530] Throttling request took 341.88771ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:50:38.472824       1 request.go:530] Throttling request took 391.913679ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:50:38.523215       1 request.go:530] Throttling request took 442.307894ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:50:41.782035       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:41.812301       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:42.111570       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:50:42.297007       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:42.637394       1 gc_controller.go:144] GC'ing orphaned
I0416 21:50:42.643920       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:50:43.413872       1 controller.go:123] Found 0 jobs
I0416 21:50:43.416061       1 controller.go:139] Found 0 cronjobs
I0416 21:50:43.416072       1 controller.go:142] Found 0 groups
I0416 21:50:45.608784       1 wrap.go:47] GET /healthz: (89.712µs) 200 [kube-probe/1.15+ 127.0.0.1:47148]
I0416 21:50:45.785434       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 0 items received
I0416 21:50:46.103156       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:50:53.419872       1 controller.go:123] Found 0 jobs
I0416 21:50:53.421780       1 controller.go:139] Found 0 cronjobs
I0416 21:50:53.421791       1 controller.go:142] Found 0 groups
I0416 21:50:54.486253       1 request.go:530] Throttling request took 84.84446ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:50:54.536260       1 request.go:530] Throttling request took 134.844682ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:50:54.586292       1 request.go:530] Throttling request took 184.884203ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:50:54.636260       1 request.go:530] Throttling request took 234.829808ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:50:54.686196       1 request.go:530] Throttling request took 284.75599ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:50:54.736263       1 request.go:530] Throttling request took 334.793525ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:50:54.786251       1 request.go:530] Throttling request took 384.775887ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:50:54.788220       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 21:50:54.836315       1 request.go:530] Throttling request took 434.837549ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:50:54.838448       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:50:55.608416       1 wrap.go:47] GET /healthz: (89.67µs) 200 [kube-probe/1.15+ 127.0.0.1:47184]
I0416 21:50:56.988555       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 21:50:57.111800       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:50:57.297337       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:02.644283       1 gc_controller.go:144] GC'ing orphaned
I0416 21:51:02.648988       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:51:03.426090       1 controller.go:123] Found 0 jobs
I0416 21:51:03.429059       1 controller.go:139] Found 0 cronjobs
I0416 21:51:03.429071       1 controller.go:142] Found 0 groups
I0416 21:51:05.608806       1 wrap.go:47] GET /healthz: (97.692µs) 200 [kube-probe/1.15+ 127.0.0.1:47218]
I0416 21:51:08.626099       1 request.go:530] Throttling request took 91.45181ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:51:08.675973       1 request.go:530] Throttling request took 141.344956ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:51:08.726094       1 request.go:530] Throttling request took 191.436161ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:51:08.776466       1 request.go:530] Throttling request took 241.816722ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:51:08.826021       1 request.go:530] Throttling request took 291.342521ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:51:08.876131       1 request.go:530] Throttling request took 341.434055ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:51:08.926107       1 request.go:530] Throttling request took 391.389105ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:51:08.976146       1 request.go:530] Throttling request took 441.428744ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:51:10.792299       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:51:11.782367       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:11.812555       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:12.112109       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:51:12.297629       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:13.433668       1 controller.go:123] Found 0 jobs
I0416 21:51:13.436403       1 controller.go:139] Found 0 cronjobs
I0416 21:51:13.436425       1 controller.go:142] Found 0 groups
I0416 21:51:14.002648       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:51:15.609684       1 wrap.go:47] GET /healthz: (85.855µs) 200 [kube-probe/1.15+ 127.0.0.1:47250]
I0416 21:51:15.775748       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 0 items received
I0416 21:51:22.649282       1 gc_controller.go:144] GC'ing orphaned
I0416 21:51:22.654463       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:51:23.443842       1 controller.go:123] Found 0 jobs
I0416 21:51:23.448399       1 controller.go:139] Found 0 cronjobs
I0416 21:51:23.448412       1 controller.go:142] Found 0 groups
I0416 21:51:24.102032       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 21:51:24.939057       1 request.go:530] Throttling request took 89.516021ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:51:24.989107       1 request.go:530] Throttling request took 139.556118ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:51:25.039065       1 request.go:530] Throttling request took 189.505023ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:51:25.092932       1 request.go:530] Throttling request took 239.513085ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:51:25.139106       1 request.go:530] Throttling request took 289.522744ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:51:25.189162       1 request.go:530] Throttling request took 339.56397ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:51:25.239124       1 request.go:530] Throttling request took 389.497755ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:51:25.289456       1 request.go:530] Throttling request took 439.815482ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:51:25.291783       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:51:25.373654       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 21:51:25.608588       1 wrap.go:47] GET /healthz: (119.519µs) 200 [kube-probe/1.15+ 127.0.0.1:47282]
I0416 21:51:26.968628       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:51:27.112472       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:51:27.297923       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:27.389774       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:51:28.036363       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 21:51:29.211276       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:51:32.086945       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:51:32.390594       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:51:32.390635       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:51:33.467163       1 controller.go:123] Found 0 jobs
I0416 21:51:33.470462       1 controller.go:139] Found 0 cronjobs
I0416 21:51:33.470487       1 controller.go:142] Found 0 groups
I0416 21:51:35.608779       1 wrap.go:47] GET /healthz: (86.151µs) 200 [kube-probe/1.15+ 127.0.0.1:47316]
I0416 21:51:36.937755       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 21:51:38.121353       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:38.785457       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:51:39.052307       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:39.080278       1 request.go:530] Throttling request took 79.856696ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:51:39.129149       1 request.go:530] Throttling request took 128.747114ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:51:39.179199       1 request.go:530] Throttling request took 176.85586ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:51:39.229282       1 request.go:530] Throttling request took 226.899107ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:51:39.279334       1 request.go:530] Throttling request took 276.953269ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:51:39.329161       1 request.go:530] Throttling request took 326.787014ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:51:39.379308       1 request.go:530] Throttling request took 376.927738ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:51:39.429198       1 request.go:530] Throttling request took 426.807666ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:51:41.782812       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:41.799710       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 21:51:41.812877       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:42.114348       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:51:42.298217       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:42.655852       1 gc_controller.go:144] GC'ing orphaned
I0416 21:51:42.667913       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:51:42.700106       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:51:43.475112       1 controller.go:123] Found 0 jobs
I0416 21:51:43.477444       1 controller.go:139] Found 0 cronjobs
I0416 21:51:43.477454       1 controller.go:142] Found 0 groups
I0416 21:51:43.808560       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 21:51:45.608300       1 wrap.go:47] GET /healthz: (118.376µs) 200 [kube-probe/1.15+ 127.0.0.1:47370]
I0416 21:51:49.285548       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:51:53.481640       1 controller.go:123] Found 0 jobs
I0416 21:51:53.483924       1 controller.go:139] Found 0 cronjobs
I0416 21:51:53.483934       1 controller.go:142] Found 0 groups
I0416 21:51:55.392654       1 request.go:530] Throttling request took 81.666543ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:51:55.442435       1 request.go:530] Throttling request took 131.403903ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:51:55.492424       1 request.go:530] Throttling request took 181.409976ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:51:55.542833       1 request.go:530] Throttling request took 231.792195ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:51:55.592352       1 request.go:530] Throttling request took 281.31573ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:51:55.608591       1 wrap.go:47] GET /healthz: (92.713µs) 200 [kube-probe/1.15+ 127.0.0.1:47406]
I0416 21:51:55.642510       1 request.go:530] Throttling request took 331.36859ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:51:55.692387       1 request.go:530] Throttling request took 381.339092ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:51:55.742783       1 request.go:530] Throttling request took 431.710842ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:51:55.745387       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:51:57.114550       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:51:57.298472       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:02.668250       1 gc_controller.go:144] GC'ing orphaned
I0416 21:52:02.672561       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:52:03.487854       1 controller.go:123] Found 0 jobs
I0416 21:52:03.489882       1 controller.go:139] Found 0 cronjobs
I0416 21:52:03.489895       1 controller.go:142] Found 0 groups
I0416 21:52:05.608523       1 wrap.go:47] GET /healthz: (82.1µs) 200 [kube-probe/1.15+ 127.0.0.1:47440]
I0416 21:52:05.784571       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 133 items received
I0416 21:52:09.531946       1 request.go:530] Throttling request took 91.776907ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:52:09.582097       1 request.go:530] Throttling request took 141.908861ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:52:09.631954       1 request.go:530] Throttling request took 191.749583ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:52:09.682115       1 request.go:530] Throttling request took 241.872577ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:52:09.732187       1 request.go:530] Throttling request took 291.81805ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:52:09.782191       1 request.go:530] Throttling request took 341.854798ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:52:09.832107       1 request.go:530] Throttling request took 391.801508ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:52:09.882224       1 request.go:530] Throttling request took 441.91356ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:52:11.774734       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 151 items received
I0416 21:52:11.783223       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:11.792857       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 0 items received
I0416 21:52:11.813181       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:12.114875       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:52:12.298795       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:13.493758       1 controller.go:123] Found 0 jobs
I0416 21:52:13.496267       1 controller.go:139] Found 0 cronjobs
I0416 21:52:13.496280       1 controller.go:142] Found 0 groups
W0416 21:52:14.957398       1 reflector.go:303] k8s.io/client-go/informers/factory.go:133: watch of *v1beta1.Event ended with: The resourceVersion for the provided watch is too old.
I0416 21:52:14.914548       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 0 items received
W0416 21:52:14.957398       1 reflector.go:303] k8s.io/client-go/informers/factory.go:133: watch of *v1beta1.Event ended with: The resourceVersion for the provided watch is too old.
I0416 21:52:15.003712       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:52:15.250532       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:52:15.609338       1 wrap.go:47] GET /healthz: (104.468µs) 200 [kube-probe/1.15+ 127.0.0.1:47472]
I0416 21:52:15.957691       1 reflector.go:166] Listing and watching *v1beta1.Event from k8s.io/client-go/informers/factory.go:133
I0416 21:52:22.672838       1 gc_controller.go:144] GC'ing orphaned
I0416 21:52:22.677839       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:52:22.732922       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:23.500359       1 controller.go:123] Found 0 jobs
I0416 21:52:23.502991       1 controller.go:139] Found 0 cronjobs
I0416 21:52:23.503003       1 controller.go:142] Found 0 groups
I0416 21:52:25.608500       1 wrap.go:47] GET /healthz: (87.867µs) 200 [kube-probe/1.15+ 127.0.0.1:47506]
I0416 21:52:25.807920       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:52:25.846436       1 request.go:530] Throttling request took 91.475055ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:52:25.896360       1 request.go:530] Throttling request took 141.394942ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:52:25.946330       1 request.go:530] Throttling request took 191.356617ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:52:25.996386       1 request.go:530] Throttling request took 241.394973ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:52:26.046264       1 request.go:530] Throttling request took 291.24011ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:52:26.096356       1 request.go:530] Throttling request took 341.3315ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:52:26.146351       1 request.go:530] Throttling request took 391.322538ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:52:26.196417       1 request.go:530] Throttling request took 441.377412ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:52:26.198770       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:52:27.057204       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:52:27.115087       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:52:27.299139       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:27.398351       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:52:29.296790       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:52:32.250847       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:52:32.399006       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:52:32.399137       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:52:33.507271       1 controller.go:123] Found 0 jobs
I0416 21:52:33.510028       1 controller.go:139] Found 0 cronjobs
I0416 21:52:33.510041       1 controller.go:142] Found 0 groups
I0416 21:52:35.124756       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 21:52:35.469182       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:52:35.608495       1 wrap.go:47] GET /healthz: (86.324µs) 200 [kube-probe/1.15+ 127.0.0.1:47540]
I0416 21:52:39.985464       1 request.go:530] Throttling request took 93.440965ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:52:40.035087       1 request.go:530] Throttling request took 142.974561ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:52:40.085091       1 request.go:530] Throttling request took 193.042662ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:52:40.135069       1 request.go:530] Throttling request took 243.00898ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:52:40.185041       1 request.go:530] Throttling request took 292.960058ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:52:40.235026       1 request.go:530] Throttling request took 342.932286ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:52:40.285069       1 request.go:530] Throttling request took 392.971761ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:52:40.335130       1 request.go:530] Throttling request took 443.030775ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:52:41.783569       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:41.813508       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:42.115344       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:52:42.300349       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:42.678371       1 gc_controller.go:144] GC'ing orphaned
I0416 21:52:42.684465       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:52:43.513011       1 controller.go:123] Found 0 jobs
I0416 21:52:43.515380       1 controller.go:139] Found 0 cronjobs
I0416 21:52:43.515393       1 controller.go:142] Found 0 groups
I0416 21:52:45.608530       1 wrap.go:47] GET /healthz: (97.284µs) 200 [kube-probe/1.15+ 127.0.0.1:47592]
I0416 21:52:53.519238       1 controller.go:123] Found 0 jobs
I0416 21:52:53.521373       1 controller.go:139] Found 0 cronjobs
I0416 21:52:53.521384       1 controller.go:142] Found 0 groups
I0416 21:52:55.608455       1 wrap.go:47] GET /healthz: (76.421µs) 200 [kube-probe/1.15+ 127.0.0.1:47630]
I0416 21:52:56.299142       1 request.go:530] Throttling request took 91.920136ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:52:56.350366       1 request.go:530] Throttling request took 143.085788ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:52:56.399803       1 request.go:530] Throttling request took 192.523481ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:52:56.449352       1 request.go:530] Throttling request took 242.045994ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:52:56.499242       1 request.go:530] Throttling request took 291.901995ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:52:56.549196       1 request.go:530] Throttling request took 341.869846ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:52:56.599299       1 request.go:530] Throttling request took 391.889369ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:52:56.649643       1 request.go:530] Throttling request took 442.296549ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:52:56.652341       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:52:57.115494       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:52:57.300632       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:52:58.228158       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 21:52:58.421730       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 21:53:01.797166       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 21:53:02.418804       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:02.420399       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:02.420616       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:53:02.420765       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:53:02.420857       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:53:02.423509       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:02.684731       1 gc_controller.go:144] GC'ing orphaned
I0416 21:53:02.688897       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:53:03.525162       1 controller.go:123] Found 0 jobs
I0416 21:53:03.527606       1 controller.go:139] Found 0 cronjobs
I0416 21:53:03.527619       1 controller.go:142] Found 0 groups
I0416 21:53:05.608392       1 wrap.go:47] GET /healthz: (93.069µs) 200 [kube-probe/1.15+ 127.0.0.1:47664]
I0416 21:53:10.439347       1 request.go:530] Throttling request took 91.435412ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:53:10.489398       1 request.go:530] Throttling request took 141.471405ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:53:10.539342       1 request.go:530] Throttling request took 191.410341ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:53:10.589379       1 request.go:530] Throttling request took 241.430412ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:53:10.639353       1 request.go:530] Throttling request took 291.404153ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:53:10.689371       1 request.go:530] Throttling request took 341.401315ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:53:10.739405       1 request.go:530] Throttling request took 391.390444ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:53:10.789371       1 request.go:530] Throttling request took 441.383988ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:53:10.794540       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 21:53:11.783944       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:11.784520       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:53:11.784985       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (145.956µs)
I0416 21:53:11.785047       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (45.055µs)
I0416 21:53:11.785147       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (74.851µs)
I0416 21:53:11.785196       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (43.042µs)
I0416 21:53:11.785214       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (997ns)
I0416 21:53:11.798722       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (14.639138ms)
I0416 21:53:11.813765       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:12.115748       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:53:12.301009       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:13.531437       1 controller.go:123] Found 0 jobs
I0416 21:53:13.534108       1 controller.go:139] Found 0 cronjobs
I0416 21:53:13.534119       1 controller.go:142] Found 0 groups
I0416 21:53:14.859318       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.861712       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.861810       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.861915       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:53:14.861930       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:53:14.861950       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:53:14.861945795 +0000 UTC m=+3017.015669934)
I0416 21:53:14.863169       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.218318ms)
I0416 21:53:14.863195       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:53:14.863192801 +0000 UTC m=+3017.016916940)
I0416 21:53:14.863671       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (476.432µs)
I0416 21:53:14.863717       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:53:14.863722       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:53:14.863732       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:53:14.863728914 +0000 UTC m=+3017.017453050)
I0416 21:53:14.864030       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (299.734µs)
I0416 21:53:14.864040       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:53:14.864038193 +0000 UTC m=+3017.017762330)
I0416 21:53:14.864970       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (912.538µs)
I0416 21:53:14.865028       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:53:14.865053       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:53:14.865035816 +0000 UTC m=+3017.018759952)
I0416 21:53:14.865584       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (545.941µs)
I0416 21:53:14.865604       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:53:14.865613       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:53:14.865610069 +0000 UTC m=+3017.019334208)
I0416 21:53:14.865994       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (380.872µs)
I0416 21:53:14.866019       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:53:14.866023       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:53:14.866030       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:53:14.866027868 +0000 UTC m=+3017.019752006)
I0416 21:53:14.866495       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (462.194µs)
I0416 21:53:14.866504       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:53:14.866502489 +0000 UTC m=+3017.020226625)
I0416 21:53:14.867429       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (923.243µs)
I0416 21:53:14.884359       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.884454       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:53:14.884481       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:53:14.885244       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b154c74e1dad, ext:2769276284153, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.885432       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:53:14.885586       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b192b4c8ed5c, ext:3017039307358, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.885650       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:53:14.885700       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:53:14.885705       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b192b4c8ed5c, ext:3017039307358, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.885736       1 update.go:396] Getting unavailable numbers
I0416 21:53:14.885761       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:53:14.885893       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:53:14.885899       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:53:14.885903       1 update.go:68] Marking old pods for deletion
I0416 21:53:14.885907       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b192b4cdd8f3, ext:3017039629788, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.885914       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:53:14.885961       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:53:14.885983       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:53:14.886035       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:53:14.886111       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.612491ms)
I0416 21:53:14.887156       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b154c77a0264, ext:2769279160672, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.887362       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:53:14.887371       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b192b4e42e81, ext:3017041093496, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.887379       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:53:14.887467       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:53:14.887492       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b192b4e42e81, ext:3017041093496, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.887529       1 update.go:396] Getting unavailable numbers
I0416 21:53:14.887628       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:53:14.887633       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:53:14.887650       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:53:14.887654       1 update.go:68] Marking old pods for deletion
I0416 21:53:14.887658       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b192b4e88f64, ext:3017041380429, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.887664       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:53:14.887691       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:53:14.887713       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:53:14.887828       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:53:14.887835       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (1.700059ms)
I0416 21:53:14.890457       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.890623       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.890724       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.890755       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.890768       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.890967       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:53:14.891018       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.891023       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:53:14.891082       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:53:14.891093       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.891096       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:53:14.891136       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:53:14.891145       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.891148       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:53:14.891176       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.891282       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.891408       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (132.225µs)
I0416 21:53:14.891439       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:53:14.891448       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.891451       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:53:14.891522       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:53:14.891536       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.891539       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:53:14.891587       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.891652       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (68.369µs)
I0416 21:53:14.891662       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.891703       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (42.64µs)
I0416 21:53:14.891716       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:53:14.891725       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.891727       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:53:14.891754       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.891825       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (72.799µs)
I0416 21:53:14.891857       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.891944       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (91.095µs)
I0416 21:53:14.891977       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:53:14.891985       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.891988       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:53:14.891992       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:53:14.892001       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.892003       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:53:14.892037       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:53:14.892046       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.892048       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:53:14.892058       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.892105       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (48.6µs)
I0416 21:53:14.892120       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.892176       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (56.761µs)
I0416 21:53:14.892186       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.892442       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (254.188µs)
I0416 21:53:14.892485       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.892556       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (70.513µs)
I0416 21:53:14.892598       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:53:14.892609       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.892611       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:53:14.892631       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:53:14.892852       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (221.237µs)
I0416 21:53:14.892947       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:53:14.892956       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.892959       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:53:14.892996       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:53:14.893006       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893009       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:53:14.893036       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:53:14.893040       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893043       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:53:14.893078       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:53:14.893090       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893092       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:53:14.893095       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:53:14.893101       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893104       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:53:14.893127       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:53:14.893152       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893155       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:53:14.893201       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:53:14.893209       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893211       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:53:14.893262       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:53:14.893270       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893272       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:53:14.893324       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:53:14.893333       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893336       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:53:14.893380       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:53:14.893387       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893389       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:53:14.893405       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:53:14.893415       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893417       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:53:14.893432       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:53:14.893438       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:53:14.893441       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:53:14.893760       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.893838       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.893867       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.893973       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:14.938053       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:15.004333       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:53:15.060177       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:15.093534       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:15.207201       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:15.280657       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:15.380477       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:15.429943       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:15.430048       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:53:15.430080       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.518µs)
I0416 21:53:15.430107       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:53:15.430126       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:53:15.430134       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:53:15.430140       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (526ns)
I0416 21:53:15.430152       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (447ns)
I0416 21:53:15.430161       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (276ns)
I0416 21:53:15.480606       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:15.618640       1 wrap.go:47] GET /healthz: (93.205µs) 200 [kube-probe/1.15+ 127.0.0.1:47696]
I0416 21:53:15.636682       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:17.805887       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 299 items received
I0416 21:53:22.689251       1 gc_controller.go:144] GC'ing orphaned
I0416 21:53:22.693695       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:53:23.538163       1 controller.go:123] Found 0 jobs
I0416 21:53:23.540482       1 controller.go:139] Found 0 cronjobs
I0416 21:53:23.540492       1 controller.go:142] Found 0 groups
I0416 21:53:25.608501       1 wrap.go:47] GET /healthz: (104.388µs) 200 [kube-probe/1.15+ 127.0.0.1:47728]
I0416 21:53:26.752837       1 request.go:530] Throttling request took 93.086161ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:53:26.802851       1 request.go:530] Throttling request took 143.120863ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:53:26.853090       1 request.go:530] Throttling request took 193.35637ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:53:26.902871       1 request.go:530] Throttling request took 243.12376ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:53:26.952807       1 request.go:530] Throttling request took 293.058743ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:53:27.003260       1 request.go:530] Throttling request took 343.475986ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:53:27.052825       1 request.go:530] Throttling request took 389.896ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:53:27.102823       1 request.go:530] Throttling request took 439.844794ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:53:27.104906       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:53:27.116376       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:53:27.147685       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:53:27.301274       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:27.404289       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:53:29.326151       1 reflector.go:249] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: forcing resync
I0416 21:53:29.371894       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:53:32.404793       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:53:32.515719       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:53:33.544088       1 controller.go:123] Found 0 jobs
I0416 21:53:33.546246       1 controller.go:139] Found 0 cronjobs
I0416 21:53:33.546258       1 controller.go:142] Found 0 groups
I0416 21:53:35.608533       1 wrap.go:47] GET /healthz: (93.395µs) 200 [kube-probe/1.15+ 127.0.0.1:47762]
I0416 21:53:37.405190       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:53:40.892093       1 request.go:530] Throttling request took 92.075792ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:53:40.942143       1 request.go:530] Throttling request took 142.105669ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:53:40.992133       1 request.go:530] Throttling request took 192.084933ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:53:41.042157       1 request.go:530] Throttling request took 242.096328ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:53:41.092743       1 request.go:530] Throttling request took 292.675373ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:53:41.142151       1 request.go:530] Throttling request took 342.055414ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:53:41.192119       1 request.go:530] Throttling request took 392.03135ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:53:41.242219       1 request.go:530] Throttling request took 442.11978ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:53:41.784281       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:41.814106       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:42.117124       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:53:42.302342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:42.562348       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:53:42.693965       1 gc_controller.go:144] GC'ing orphaned
I0416 21:53:42.699378       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:53:43.550211       1 controller.go:123] Found 0 jobs
I0416 21:53:43.552761       1 controller.go:139] Found 0 cronjobs
I0416 21:53:43.552772       1 controller.go:142] Found 0 groups
I0416 21:53:43.886031       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:45.608533       1 wrap.go:47] GET /healthz: (80.998µs) 200 [kube-probe/1.15+ 127.0.0.1:47814]
I0416 21:53:46.770678       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:53:53.556976       1 controller.go:123] Found 0 jobs
I0416 21:53:53.559779       1 controller.go:139] Found 0 cronjobs
I0416 21:53:53.559789       1 controller.go:142] Found 0 groups
I0416 21:53:55.608694       1 wrap.go:47] GET /healthz: (107.221µs) 200 [kube-probe/1.15+ 127.0.0.1:47852]
I0416 21:53:57.122017       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:53:57.205448       1 request.go:530] Throttling request took 83.448467ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:53:57.255447       1 request.go:530] Throttling request took 133.424519ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:53:57.302606       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:53:57.305510       1 request.go:530] Throttling request took 183.415217ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:53:57.355660       1 request.go:530] Throttling request took 233.550447ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:53:57.405444       1 request.go:530] Throttling request took 283.322555ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:53:57.455457       1 request.go:530] Throttling request took 333.250561ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:53:57.505466       1 request.go:530] Throttling request took 383.249118ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:53:57.555459       1 request.go:530] Throttling request took 433.238988ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:53:57.557771       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:54:02.699787       1 gc_controller.go:144] GC'ing orphaned
I0416 21:54:02.704459       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:54:03.563714       1 controller.go:123] Found 0 jobs
I0416 21:54:03.566014       1 controller.go:139] Found 0 cronjobs
I0416 21:54:03.566026       1 controller.go:142] Found 0 groups
I0416 21:54:05.609343       1 wrap.go:47] GET /healthz: (83.992µs) 200 [kube-probe/1.15+ 127.0.0.1:47886]
I0416 21:54:07.843274       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:09.781013       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 21:54:11.344924       1 request.go:530] Throttling request took 93.298954ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:54:11.394909       1 request.go:530] Throttling request took 143.277131ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:54:11.444912       1 request.go:530] Throttling request took 193.272469ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:54:11.494911       1 request.go:530] Throttling request took 243.266541ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:54:11.544957       1 request.go:530] Throttling request took 293.300771ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:54:11.594946       1 request.go:530] Throttling request took 343.225833ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:54:11.644903       1 request.go:530] Throttling request took 393.22887ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:54:11.694956       1 request.go:530] Throttling request took 443.192431ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:54:11.784585       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:11.814451       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:12.122352       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:54:12.302909       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:13.570052       1 controller.go:123] Found 0 jobs
I0416 21:54:13.572204       1 controller.go:139] Found 0 cronjobs
I0416 21:54:13.572214       1 controller.go:142] Found 0 groups
I0416 21:54:13.790698       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 21:54:15.608411       1 wrap.go:47] GET /healthz: (85.908µs) 200 [kube-probe/1.15+ 127.0.0.1:47918]
I0416 21:54:16.004904       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:54:22.704752       1 gc_controller.go:144] GC'ing orphaned
I0416 21:54:22.709338       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:54:23.575851       1 controller.go:123] Found 0 jobs
I0416 21:54:23.578178       1 controller.go:139] Found 0 cronjobs
I0416 21:54:23.578188       1 controller.go:142] Found 0 groups
I0416 21:54:25.608667       1 wrap.go:47] GET /healthz: (105.382µs) 200 [kube-probe/1.15+ 127.0.0.1:47950]
I0416 21:54:27.122726       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:54:27.234608       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:54:27.303214       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:27.411626       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:54:27.658185       1 request.go:530] Throttling request took 90.900197ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:54:27.708185       1 request.go:530] Throttling request took 140.892369ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:54:27.758908       1 request.go:530] Throttling request took 191.594193ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:54:27.808187       1 request.go:530] Throttling request took 240.879022ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:54:27.858328       1 request.go:530] Throttling request took 291.006469ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:54:27.908275       1 request.go:530] Throttling request took 340.913645ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:54:27.958352       1 request.go:530] Throttling request took 390.983071ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:54:28.008282       1 request.go:530] Throttling request took 440.892426ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:54:28.010725       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:54:29.462882       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:54:32.412078       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:54:32.789463       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:54:33.582111       1 controller.go:123] Found 0 jobs
I0416 21:54:33.584324       1 controller.go:139] Found 0 cronjobs
I0416 21:54:33.584335       1 controller.go:142] Found 0 groups
I0416 21:54:35.608628       1 wrap.go:47] GET /healthz: (81.653µs) 200 [kube-probe/1.15+ 127.0.0.1:47984]
I0416 21:54:36.475896       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 21:54:37.412522       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:54:39.789614       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 21:54:41.784874       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:41.797275       1 request.go:530] Throttling request took 91.570647ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:54:41.814710       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:41.847298       1 request.go:530] Throttling request took 141.619527ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:54:41.897365       1 request.go:530] Throttling request took 191.586644ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:54:41.947202       1 request.go:530] Throttling request took 241.494018ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:54:41.997317       1 request.go:530] Throttling request took 291.597302ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:54:42.047329       1 request.go:530] Throttling request took 341.602407ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:54:42.097320       1 request.go:530] Throttling request took 391.51516ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:54:42.123006       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:54:42.147306       1 request.go:530] Throttling request took 441.561935ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:54:42.303554       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:42.709575       1 gc_controller.go:144] GC'ing orphaned
I0416 21:54:42.713926       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:54:43.591324       1 controller.go:123] Found 0 jobs
I0416 21:54:43.594916       1 controller.go:139] Found 0 cronjobs
I0416 21:54:43.594942       1 controller.go:142] Found 0 groups
I0416 21:54:43.781171       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 0 items received
I0416 21:54:45.608115       1 wrap.go:47] GET /healthz: (81.767µs) 200 [kube-probe/1.15+ 127.0.0.1:48036]
I0416 21:54:46.175135       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 21:54:49.830427       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 21:54:53.598891       1 controller.go:123] Found 0 jobs
I0416 21:54:53.601432       1 controller.go:139] Found 0 cronjobs
I0416 21:54:53.601444       1 controller.go:142] Found 0 groups
I0416 21:54:55.608733       1 wrap.go:47] GET /healthz: (84.397µs) 200 [kube-probe/1.15+ 127.0.0.1:48074]
I0416 21:54:57.123275       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:54:57.303841       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:54:58.111248       1 request.go:530] Throttling request took 92.601284ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:54:58.161244       1 request.go:530] Throttling request took 142.586685ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:54:58.211269       1 request.go:530] Throttling request took 192.604226ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:54:58.261323       1 request.go:530] Throttling request took 242.660112ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:54:58.311333       1 request.go:530] Throttling request took 292.644817ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:54:58.361305       1 request.go:530] Throttling request took 342.618681ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:54:58.411299       1 request.go:530] Throttling request took 392.590535ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:54:58.461310       1 request.go:530] Throttling request took 442.601635ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:54:58.463486       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:55:02.714184       1 gc_controller.go:144] GC'ing orphaned
I0416 21:55:02.718415       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:55:03.575295       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:03.605240       1 controller.go:123] Found 0 jobs
I0416 21:55:03.607427       1 controller.go:139] Found 0 cronjobs
I0416 21:55:03.607439       1 controller.go:142] Found 0 groups
I0416 21:55:03.788700       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 21:55:05.608541       1 wrap.go:47] GET /healthz: (92.51µs) 200 [kube-probe/1.15+ 127.0.0.1:48108]
I0416 21:55:08.015445       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 21:55:10.525649       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 21:55:11.785182       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:11.814976       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:12.123595       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:55:12.251599       1 request.go:530] Throttling request took 91.052373ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:55:12.301470       1 request.go:530] Throttling request took 140.927441ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:55:12.304342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:12.352350       1 request.go:530] Throttling request took 191.802872ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:55:12.401460       1 request.go:530] Throttling request took 240.805829ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:55:12.451353       1 request.go:530] Throttling request took 290.683006ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:55:12.502012       1 request.go:530] Throttling request took 341.33242ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:55:12.551657       1 request.go:530] Throttling request took 390.945383ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:55:12.602632       1 request.go:530] Throttling request took 441.877648ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:55:13.611820       1 controller.go:123] Found 0 jobs
I0416 21:55:13.614328       1 controller.go:139] Found 0 cronjobs
I0416 21:55:13.614340       1 controller.go:142] Found 0 groups
I0416 21:55:15.391280       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:55:15.608403       1 wrap.go:47] GET /healthz: (94.435µs) 200 [kube-probe/1.15+ 127.0.0.1:48140]
I0416 21:55:17.006282       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:55:18.772995       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 21:55:20.384137       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:22.718705       1 gc_controller.go:144] GC'ing orphaned
I0416 21:55:22.722748       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:55:23.619613       1 controller.go:123] Found 0 jobs
I0416 21:55:23.625847       1 controller.go:139] Found 0 cronjobs
I0416 21:55:23.625878       1 controller.go:142] Found 0 groups
I0416 21:55:25.608538       1 wrap.go:47] GET /healthz: (87.305µs) 200 [kube-probe/1.15+ 127.0.0.1:48172]
I0416 21:55:27.123826       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:55:27.304609       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:27.326894       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:55:27.417409       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:55:28.563846       1 request.go:530] Throttling request took 92.059931ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:55:28.614421       1 request.go:530] Throttling request took 142.613311ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:55:28.664986       1 request.go:530] Throttling request took 193.173183ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:55:28.713927       1 request.go:530] Throttling request took 242.099324ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:55:28.763935       1 request.go:530] Throttling request took 292.100781ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:55:28.816012       1 request.go:530] Throttling request took 344.15484ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:55:28.863956       1 request.go:530] Throttling request took 392.108447ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:55:28.913987       1 request.go:530] Throttling request took 442.130148ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:55:28.916439       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:55:29.555697       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:55:32.417823       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:55:33.008141       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:55:33.630111       1 controller.go:123] Found 0 jobs
I0416 21:55:33.632561       1 controller.go:139] Found 0 cronjobs
I0416 21:55:33.632571       1 controller.go:142] Found 0 groups
I0416 21:55:35.608581       1 wrap.go:47] GET /healthz: (99.191µs) 200 [kube-probe/1.15+ 127.0.0.1:48206]
I0416 21:55:37.418163       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:55:37.836085       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 0 items received
I0416 21:55:41.785633       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:41.815285       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:42.124099       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:55:42.304990       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:42.705649       1 request.go:530] Throttling request took 84.995931ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:55:42.722984       1 gc_controller.go:144] GC'ing orphaned
I0416 21:55:42.727282       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:55:42.755508       1 request.go:530] Throttling request took 134.912627ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:55:42.805562       1 request.go:530] Throttling request took 184.941139ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:55:42.855938       1 request.go:530] Throttling request took 235.311056ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:55:42.905495       1 request.go:530] Throttling request took 284.860046ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:55:42.956326       1 request.go:530] Throttling request took 335.679421ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:55:43.005488       1 request.go:530] Throttling request took 384.839726ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:55:43.055579       1 request.go:530] Throttling request took 434.921259ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:55:43.637324       1 controller.go:123] Found 0 jobs
I0416 21:55:43.639521       1 controller.go:139] Found 0 cronjobs
I0416 21:55:43.639531       1 controller.go:142] Found 0 groups
I0416 21:55:45.608143       1 wrap.go:47] GET /healthz: (90.39µs) 200 [kube-probe/1.15+ 127.0.0.1:48258]
I0416 21:55:49.800069       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 21:55:49.854238       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:50.798459       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 0 items received
I0416 21:55:51.373504       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:53.643237       1 controller.go:123] Found 0 jobs
I0416 21:55:53.645505       1 controller.go:139] Found 0 cronjobs
I0416 21:55:53.645515       1 controller.go:142] Found 0 groups
I0416 21:55:55.608460       1 wrap.go:47] GET /healthz: (90.954µs) 200 [kube-probe/1.15+ 127.0.0.1:48296]
I0416 21:55:56.345828       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 222 items received
I0416 21:55:56.775308       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:55:57.124516       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:55:57.305353       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:55:59.017121       1 request.go:530] Throttling request took 91.811731ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:55:59.067481       1 request.go:530] Throttling request took 142.145211ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:55:59.117075       1 request.go:530] Throttling request took 191.746173ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:55:59.167041       1 request.go:530] Throttling request took 241.694703ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:55:59.217349       1 request.go:530] Throttling request took 292.003416ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:55:59.267075       1 request.go:530] Throttling request took 341.713686ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:55:59.317343       1 request.go:530] Throttling request took 391.97856ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:55:59.367021       1 request.go:530] Throttling request took 441.641553ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:55:59.369463       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:56:02.727616       1 gc_controller.go:144] GC'ing orphaned
I0416 21:56:02.732067       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:56:03.649297       1 controller.go:123] Found 0 jobs
I0416 21:56:03.651703       1 controller.go:139] Found 0 cronjobs
I0416 21:56:03.651715       1 controller.go:142] Found 0 groups
I0416 21:56:05.608585       1 wrap.go:47] GET /healthz: (86.739µs) 200 [kube-probe/1.15+ 127.0.0.1:48330]
I0416 21:56:11.785924       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:11.815581       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:12.124832       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:56:12.305611       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:13.160242       1 request.go:530] Throttling request took 92.316015ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:56:13.210317       1 request.go:530] Throttling request took 142.393801ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:56:13.260311       1 request.go:530] Throttling request took 192.375528ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:56:13.310656       1 request.go:530] Throttling request took 242.723088ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:56:13.360284       1 request.go:530] Throttling request took 292.301701ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:56:13.410243       1 request.go:530] Throttling request took 342.257872ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:56:13.460297       1 request.go:530] Throttling request took 392.314056ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:56:13.510248       1 request.go:530] Throttling request took 442.230153ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:56:13.655439       1 controller.go:123] Found 0 jobs
I0416 21:56:13.658222       1 controller.go:139] Found 0 cronjobs
I0416 21:56:13.658251       1 controller.go:142] Found 0 groups
I0416 21:56:15.614090       1 wrap.go:47] GET /healthz: (92.176µs) 200 [kube-probe/1.15+ 127.0.0.1:48362]
I0416 21:56:18.008293       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:56:22.732438       1 gc_controller.go:144] GC'ing orphaned
I0416 21:56:22.737163       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:56:23.662180       1 controller.go:123] Found 0 jobs
I0416 21:56:23.664760       1 controller.go:139] Found 0 cronjobs
I0416 21:56:23.664772       1 controller.go:142] Found 0 groups
I0416 21:56:23.728541       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:25.608514       1 wrap.go:47] GET /healthz: (89.925µs) 200 [kube-probe/1.15+ 127.0.0.1:48394]
I0416 21:56:27.125245       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:56:27.305915       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:27.415851       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:56:27.424365       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:56:28.333730       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 26 items received
I0416 21:56:28.375936       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 21:56:29.470052       1 request.go:530] Throttling request took 90.952769ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:56:29.520122       1 request.go:530] Throttling request took 140.851779ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:56:29.570007       1 request.go:530] Throttling request took 190.875932ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:56:29.619924       1 request.go:530] Throttling request took 240.776026ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:56:29.633759       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:56:29.672546       1 request.go:530] Throttling request took 293.38841ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:56:29.720049       1 request.go:530] Throttling request took 340.872865ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:56:29.774150       1 request.go:530] Throttling request took 394.944148ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:56:29.820328       1 request.go:530] Throttling request took 441.122332ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:56:29.823961       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:56:32.424806       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:56:33.281261       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:56:33.669010       1 controller.go:123] Found 0 jobs
I0416 21:56:33.671790       1 controller.go:139] Found 0 cronjobs
I0416 21:56:33.671802       1 controller.go:142] Found 0 groups
I0416 21:56:35.608531       1 wrap.go:47] GET /healthz: (90.335µs) 200 [kube-probe/1.15+ 127.0.0.1:48428]
I0416 21:56:37.425268       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:56:38.323817       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 0 items received
I0416 21:56:41.786261       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:41.815906       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:42.125530       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:56:42.306249       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:42.737527       1 gc_controller.go:144] GC'ing orphaned
I0416 21:56:42.743484       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:56:43.614728       1 request.go:530] Throttling request took 91.982404ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:56:43.664316       1 request.go:530] Throttling request took 141.541184ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:56:43.675305       1 controller.go:123] Found 0 jobs
I0416 21:56:43.677810       1 controller.go:139] Found 0 cronjobs
I0416 21:56:43.677832       1 controller.go:142] Found 0 groups
I0416 21:56:43.714341       1 request.go:530] Throttling request took 191.571853ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:56:43.764345       1 request.go:530] Throttling request took 241.564598ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:56:43.814397       1 request.go:530] Throttling request took 291.586872ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:56:43.864375       1 request.go:530] Throttling request took 341.579594ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:56:43.916395       1 request.go:530] Throttling request took 393.593195ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:56:43.963418       1 request.go:530] Throttling request took 440.600276ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:56:45.608551       1 wrap.go:47] GET /healthz: (88.753µs) 200 [kube-probe/1.15+ 127.0.0.1:48482]
I0416 21:56:52.787772       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 0 items received
I0416 21:56:53.681812       1 controller.go:123] Found 0 jobs
I0416 21:56:53.684868       1 controller.go:139] Found 0 cronjobs
I0416 21:56:53.684882       1 controller.go:142] Found 0 groups
I0416 21:56:55.610102       1 wrap.go:47] GET /healthz: (119.25µs) 200 [kube-probe/1.15+ 127.0.0.1:48520]
I0416 21:56:57.125777       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:56:57.306628       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:56:59.924438       1 request.go:530] Throttling request took 92.207004ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:56:59.974353       1 request.go:530] Throttling request took 142.12815ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:57:00.024517       1 request.go:530] Throttling request took 192.265847ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:57:00.074309       1 request.go:530] Throttling request took 242.031269ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:57:00.124476       1 request.go:530] Throttling request took 292.191015ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:57:00.174440       1 request.go:530] Throttling request took 342.145385ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:57:00.224470       1 request.go:530] Throttling request took 392.167847ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:57:00.274862       1 request.go:530] Throttling request took 442.530477ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:57:00.277288       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:57:02.743800       1 gc_controller.go:144] GC'ing orphaned
I0416 21:57:02.748418       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:57:02.784981       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 21:57:02.794694       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 21:57:03.689004       1 controller.go:123] Found 0 jobs
I0416 21:57:03.691731       1 controller.go:139] Found 0 cronjobs
I0416 21:57:03.691743       1 controller.go:142] Found 0 groups
I0416 21:57:04.028920       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:05.608560       1 wrap.go:47] GET /healthz: (85.328µs) 200 [kube-probe/1.15+ 127.0.0.1:48554]
I0416 21:57:05.779657       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 0 items received
I0416 21:57:10.180380       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:10.180732       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:57:10.180858       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:57:10.180952       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:57:11.786612       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:11.816182       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:12.125993       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:57:12.306957       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:13.695854       1 controller.go:123] Found 0 jobs
I0416 21:57:13.698733       1 controller.go:139] Found 0 cronjobs
I0416 21:57:13.698746       1 controller.go:142] Found 0 groups
I0416 21:57:14.066583       1 request.go:530] Throttling request took 91.461041ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:57:14.116485       1 request.go:530] Throttling request took 141.351199ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:57:14.166320       1 request.go:530] Throttling request took 191.184095ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:57:14.216462       1 request.go:530] Throttling request took 241.241264ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:57:14.266324       1 request.go:530] Throttling request took 291.169885ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:57:14.316460       1 request.go:530] Throttling request took 341.275025ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:57:14.366355       1 request.go:530] Throttling request took 391.160171ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:57:14.416416       1 request.go:530] Throttling request took 441.213659ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:57:15.608775       1 wrap.go:47] GET /healthz: (105.793µs) 200 [kube-probe/1.15+ 127.0.0.1:48586]
I0416 21:57:15.807059       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
I0416 21:57:18.010890       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:57:19.316493       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 0 items received
I0416 21:57:22.621898       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.622006       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 21:57:22.622034       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 21:57:22.622056       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 21:57:22.6220511 +0000 UTC m=+3264.775775237)
I0416 21:57:22.623001       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (944.158µs)
I0416 21:57:22.623048       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 21:57:22.623045158 +0000 UTC m=+3264.776769294)
I0416 21:57:22.623387       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (340.127µs)
I0416 21:57:22.623409       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 21:57:22.623415       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 21:57:22.623425       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 21:57:22.623422085 +0000 UTC m=+3264.777146221)
I0416 21:57:22.624281       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (856.819µs)
I0416 21:57:22.624295       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 21:57:22.624293232 +0000 UTC m=+3264.778017368)
I0416 21:57:22.624690       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (395.534µs)
I0416 21:57:22.624709       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 21:57:22.624716       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 21:57:22.624723       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 21:57:22.624721352 +0000 UTC m=+3264.778445488)
I0416 21:57:22.625100       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (376.362µs)
I0416 21:57:22.625109       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 21:57:22.625107172 +0000 UTC m=+3264.778831309)
I0416 21:57:22.625560       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (450.796µs)
I0416 21:57:22.625572       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 21:57:22.625577       1 deployment_controller.go:175] Updating deployment coredns
I0416 21:57:22.625588       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 21:57:22.625582365 +0000 UTC m=+3264.779306501)
I0416 21:57:22.626458       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (872.102µs)
I0416 21:57:22.626484       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 21:57:22.626481155 +0000 UTC m=+3264.780205291)
I0416 21:57:22.627124       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (641.013µs)
I0416 21:57:22.644451       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.644542       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 21:57:22.646031       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b192b4e88f64, ext:3017041380429, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.646330       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:57:22.646414       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b1d0a68772b5, ext:3264800135094, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.646485       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:57:22.646542       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:57:22.646547       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b1d0a68772b5, ext:3264800135094, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.646587       1 update.go:396] Getting unavailable numbers
I0416 21:57:22.646659       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:57:22.646707       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 21:57:22.646713       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:57:22.646718       1 update.go:68] Marking old pods for deletion
I0416 21:57:22.646722       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b1d0a68c2a83, ext:3264800444271, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.646728       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 21:57:22.646775       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 21:57:22.646800       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:57:22.646889       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 21:57:22.646935       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.351911ms)
I0416 21:57:22.646977       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 21:57:22.647521       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b192b4cdd8f3, ext:3017039629788, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.647684       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:57:22.647692       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b1d0a69af8b5, ext:3264801414573, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.647763       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:57:22.647811       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:57:22.647816       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b1d0a69af8b5, ext:3264801414573, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.647849       1 update.go:396] Getting unavailable numbers
I0416 21:57:22.647946       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:57:22.647953       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 21:57:22.647957       1 update.go:58] Marking all unavailable old pods for deletion
I0416 21:57:22.647978       1 update.go:68] Marking old pods for deletion
I0416 21:57:22.647981       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b1d0a69f63dc, ext:3264801704230, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.647988       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 21:57:22.648009       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 21:57:22.648058       1 daemon_controller.go:1149] Updating daemon set status
I0416 21:57:22.648185       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 21:57:22.648190       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.203198ms)
I0416 21:57:22.650482       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.650658       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.650814       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:57:22.650850       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.650854       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 21:57:22.650896       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:57:22.650913       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.650916       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 21:57:22.650982       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.650999       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.651040       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:57:22.651050       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651052       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 21:57:22.651102       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:57:22.651109       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651111       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 21:57:22.651115       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 21:57:22.651124       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651127       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 21:57:22.651155       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:57:22.651163       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651166       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 21:57:22.651213       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:57:22.651220       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651223       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 21:57:22.651266       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:57:22.651271       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651274       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 21:57:22.651319       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:57:22.651327       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651330       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 21:57:22.651357       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:57:22.651367       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651370       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 21:57:22.651388       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:57:22.651397       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651399       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 21:57:22.651423       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:57:22.651432       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651440       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 21:57:22.651465       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:57:22.651535       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651537       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 21:57:22.651563       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:57:22.651570       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651572       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 21:57:22.651575       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:57:22.651581       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651584       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 21:57:22.651607       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:57:22.651615       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651617       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 21:57:22.651665       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 21:57:22.651676       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651679       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 21:57:22.651707       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:57:22.651715       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651717       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 21:57:22.651735       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 21:57:22.651744       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651747       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 21:57:22.651774       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:57:22.651778       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651780       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 21:57:22.651800       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 21:57:22.651809       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651811       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 21:57:22.651828       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:57:22.651836       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 21:57:22.651839       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 21:57:22.652067       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.652160       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652290       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (137.36µs)
I0416 21:57:22.652343       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652428       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (86.994µs)
I0416 21:57:22.652438       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652536       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (99.218µs)
I0416 21:57:22.652561       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652623       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (63.759µs)
I0416 21:57:22.652644       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652706       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (64.928µs)
I0416 21:57:22.652725       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652766       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (42.705µs)
I0416 21:57:22.652775       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652838       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (60.236µs)
I0416 21:57:22.652856       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652904       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (49.429µs)
I0416 21:57:22.652920       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.652966       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (47.075µs)
I0416 21:57:22.652981       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 21:57:22.653076       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (97.028µs)
I0416 21:57:22.654785       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.748783       1 gc_controller.go:144] GC'ing orphaned
I0416 21:57:22.752962       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:57:22.820411       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:22.853560       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:23.190033       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:23.190124       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:57:23.190156       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (2.864µs)
I0416 21:57:23.190200       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 21:57:23.190208       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:57:23.190216       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 21:57:23.190221       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (414ns)
I0416 21:57:23.190256       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (475ns)
I0416 21:57:23.190264       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (294ns)
I0416 21:57:23.240628       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:23.702575       1 controller.go:123] Found 0 jobs
I0416 21:57:23.705331       1 controller.go:139] Found 0 cronjobs
I0416 21:57:23.705341       1 controller.go:142] Found 0 groups
I0416 21:57:25.608853       1 wrap.go:47] GET /healthz: (117.521µs) 200 [kube-probe/1.15+ 127.0.0.1:48618]
I0416 21:57:27.126368       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:57:27.307211       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:27.499073       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:57:29.583428       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:29.714266       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:57:30.377768       1 request.go:530] Throttling request took 91.288441ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:57:30.427880       1 request.go:530] Throttling request took 141.382109ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:57:30.477888       1 request.go:530] Throttling request took 191.33695ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:57:30.527785       1 request.go:530] Throttling request took 241.272533ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:57:30.577785       1 request.go:530] Throttling request took 291.242525ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:57:30.627721       1 request.go:530] Throttling request took 341.179793ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:57:30.677760       1 request.go:530] Throttling request took 391.208832ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:57:30.727815       1 request.go:530] Throttling request took 441.221427ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:57:30.730214       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:57:32.430012       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:57:32.430100       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:57:33.491337       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:57:33.710009       1 controller.go:123] Found 0 jobs
I0416 21:57:33.712374       1 controller.go:139] Found 0 cronjobs
I0416 21:57:33.712385       1 controller.go:142] Found 0 groups
I0416 21:57:35.608707       1 wrap.go:47] GET /healthz: (88.244µs) 200 [kube-probe/1.15+ 127.0.0.1:48652]
I0416 21:57:37.430325       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:57:41.786959       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:41.787380       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (286.354µs)
I0416 21:57:41.787511       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (81.941µs)
I0416 21:57:41.787591       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (72.014µs)
I0416 21:57:41.787617       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.308µs)
I0416 21:57:41.787826       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 21:57:41.791031       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (140.517µs)
I0416 21:57:41.793219       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (5.562688ms)
I0416 21:57:41.816568       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:42.126723       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:57:42.307496       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:42.753351       1 gc_controller.go:144] GC'ing orphaned
I0416 21:57:42.761840       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:57:43.716416       1 controller.go:123] Found 0 jobs
I0416 21:57:43.719295       1 controller.go:139] Found 0 cronjobs
I0416 21:57:43.719308       1 controller.go:142] Found 0 groups
I0416 21:57:43.971330       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 0 items received
I0416 21:57:44.318358       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 0 items received
I0416 21:57:44.520350       1 request.go:530] Throttling request took 92.441313ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:57:44.569693       1 request.go:530] Throttling request took 141.760515ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:57:44.620353       1 request.go:530] Throttling request took 192.428091ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:57:44.669485       1 request.go:530] Throttling request took 241.537789ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:57:44.719810       1 request.go:530] Throttling request took 288.965479ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:57:44.769473       1 request.go:530] Throttling request took 338.611643ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:57:44.820339       1 request.go:530] Throttling request took 389.467033ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:57:44.869649       1 request.go:530] Throttling request took 438.752702ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:57:45.608584       1 wrap.go:47] GET /healthz: (124.191µs) 200 [kube-probe/1.15+ 127.0.0.1:48704]
I0416 21:57:53.723406       1 controller.go:123] Found 0 jobs
I0416 21:57:53.726821       1 controller.go:139] Found 0 cronjobs
I0416 21:57:53.726833       1 controller.go:142] Found 0 groups
I0416 21:57:55.608358       1 wrap.go:47] GET /healthz: (130.372µs) 200 [kube-probe/1.15+ 127.0.0.1:48740]
I0416 21:57:57.126933       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:57:57.307785       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:57:57.790305       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 21:57:58.796418       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 21:58:00.830846       1 request.go:530] Throttling request took 90.963933ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:58:00.880845       1 request.go:530] Throttling request took 140.978675ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:58:00.930854       1 request.go:530] Throttling request took 190.982509ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:58:00.980854       1 request.go:530] Throttling request took 240.972447ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:58:01.031175       1 request.go:530] Throttling request took 291.281009ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:58:01.080868       1 request.go:530] Throttling request took 340.968853ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:58:01.130829       1 request.go:530] Throttling request took 390.915031ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:58:01.180869       1 request.go:530] Throttling request took 440.925737ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:58:01.183267       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:58:02.762150       1 gc_controller.go:144] GC'ing orphaned
I0416 21:58:02.766406       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:58:03.739318       1 controller.go:123] Found 0 jobs
I0416 21:58:03.744729       1 controller.go:139] Found 0 cronjobs
I0416 21:58:03.744741       1 controller.go:142] Found 0 groups
I0416 21:58:05.608533       1 wrap.go:47] GET /healthz: (90.919µs) 200 [kube-probe/1.15+ 127.0.0.1:48776]
I0416 21:58:11.787589       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:58:11.816867       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:58:12.127155       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:58:12.308141       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:58:13.748693       1 controller.go:123] Found 0 jobs
I0416 21:58:13.750923       1 controller.go:139] Found 0 cronjobs
I0416 21:58:13.750934       1 controller.go:142] Found 0 groups
I0416 21:58:13.794858       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 0 items received
I0416 21:58:14.972776       1 request.go:530] Throttling request took 92.613999ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:58:15.022764       1 request.go:530] Throttling request took 142.595109ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:58:15.072774       1 request.go:530] Throttling request took 192.59526ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:58:15.122681       1 request.go:530] Throttling request took 242.487366ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:58:15.172726       1 request.go:530] Throttling request took 292.483074ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:58:15.222710       1 request.go:530] Throttling request took 342.456304ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:58:15.273175       1 request.go:530] Throttling request took 392.900388ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:58:15.322715       1 request.go:530] Throttling request took 442.431426ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:58:15.532299       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 21:58:15.610979       1 wrap.go:47] GET /healthz: (1.143152ms) 200 [kube-probe/1.15+ 127.0.0.1:48808]
I0416 21:58:18.011398       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:58:22.766726       1 gc_controller.go:144] GC'ing orphaned
I0416 21:58:22.770643       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:58:23.757629       1 controller.go:123] Found 0 jobs
I0416 21:58:23.763122       1 controller.go:139] Found 0 cronjobs
I0416 21:58:23.763136       1 controller.go:142] Found 0 groups
I0416 21:58:24.960654       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 21:58:25.608453       1 wrap.go:47] GET /healthz: (91.762µs) 200 [kube-probe/1.15+ 127.0.0.1:48840]
I0416 21:58:27.127367       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:58:27.308409       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:58:27.597751       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:58:29.029325       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:58:29.826327       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:58:31.283783       1 request.go:530] Throttling request took 91.356101ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:58:31.333735       1 request.go:530] Throttling request took 141.284473ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:58:31.383754       1 request.go:530] Throttling request took 191.288077ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:58:31.433737       1 request.go:530] Throttling request took 241.257697ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:58:31.483959       1 request.go:530] Throttling request took 291.473485ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:58:31.533664       1 request.go:530] Throttling request took 341.150382ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:58:31.583734       1 request.go:530] Throttling request took 391.210539ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:58:31.633747       1 request.go:530] Throttling request took 441.213444ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:58:31.636251       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:58:32.434745       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:58:32.434789       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:58:33.729994       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:58:33.767433       1 controller.go:123] Found 0 jobs
I0416 21:58:33.770370       1 controller.go:139] Found 0 cronjobs
I0416 21:58:33.770382       1 controller.go:142] Found 0 groups
I0416 21:58:35.608462       1 wrap.go:47] GET /healthz: (87.715µs) 200 [kube-probe/1.15+ 127.0.0.1:48874]
I0416 21:58:37.435144       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:58:41.788025       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:58:41.817537       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:58:42.127563       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:58:42.309180       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:58:42.562748       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 21:58:42.771715       1 gc_controller.go:144] GC'ing orphaned
I0416 21:58:42.778978       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:58:43.774167       1 controller.go:123] Found 0 jobs
I0416 21:58:43.776287       1 controller.go:139] Found 0 cronjobs
I0416 21:58:43.776297       1 controller.go:142] Found 0 groups
I0416 21:58:45.425681       1 request.go:530] Throttling request took 92.767793ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:58:45.475822       1 request.go:530] Throttling request took 142.904454ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:58:45.526108       1 request.go:530] Throttling request took 193.167659ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:58:45.575560       1 request.go:530] Throttling request took 242.623953ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:58:45.608750       1 wrap.go:47] GET /healthz: (101.652µs) 200 [kube-probe/1.15+ 127.0.0.1:48926]
I0416 21:58:45.625595       1 request.go:530] Throttling request took 292.643279ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:58:45.675470       1 request.go:530] Throttling request took 342.518506ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:58:45.725599       1 request.go:530] Throttling request took 392.631097ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:58:45.775561       1 request.go:530] Throttling request took 442.57436ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:58:53.779841       1 controller.go:123] Found 0 jobs
I0416 21:58:53.786917       1 controller.go:139] Found 0 cronjobs
I0416 21:58:53.786931       1 controller.go:142] Found 0 groups
I0416 21:58:55.608615       1 wrap.go:47] GET /healthz: (92.211µs) 200 [kube-probe/1.15+ 127.0.0.1:48962]
I0416 21:58:57.127765       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:58:57.309511       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:01.716016       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:01.737102       1 request.go:530] Throttling request took 91.272847ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:59:01.787029       1 request.go:530] Throttling request took 141.185562ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:59:01.837735       1 request.go:530] Throttling request took 191.859334ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:59:01.886808       1 request.go:530] Throttling request took 240.946868ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:59:01.937577       1 request.go:530] Throttling request took 291.70366ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:59:01.986775       1 request.go:530] Throttling request took 340.894668ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:59:02.036857       1 request.go:530] Throttling request took 390.963174ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:59:02.086704       1 request.go:530] Throttling request took 440.83243ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:59:02.089823       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:59:02.779405       1 gc_controller.go:144] GC'ing orphaned
I0416 21:59:02.783665       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:59:02.800518       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 21:59:03.791634       1 controller.go:123] Found 0 jobs
I0416 21:59:03.801806       1 controller.go:139] Found 0 cronjobs
I0416 21:59:03.801820       1 controller.go:142] Found 0 groups
I0416 21:59:05.608813       1 wrap.go:47] GET /healthz: (87.098µs) 200 [kube-probe/1.15+ 127.0.0.1:48998]
I0416 21:59:11.788397       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:11.817835       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:12.128007       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:59:12.309790       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:13.805581       1 controller.go:123] Found 0 jobs
I0416 21:59:13.807933       1 controller.go:139] Found 0 cronjobs
I0416 21:59:13.807945       1 controller.go:142] Found 0 groups
I0416 21:59:15.609142       1 wrap.go:47] GET /healthz: (101.629µs) 200 [kube-probe/1.15+ 127.0.0.1:49032]
I0416 21:59:15.878730       1 request.go:530] Throttling request took 87.949368ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:59:15.928242       1 request.go:530] Throttling request took 137.436694ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:59:15.978247       1 request.go:530] Throttling request took 187.436067ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:59:16.028252       1 request.go:530] Throttling request took 237.426932ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:59:16.078214       1 request.go:530] Throttling request took 287.378052ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:59:16.128159       1 request.go:530] Throttling request took 337.318478ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:59:16.178168       1 request.go:530] Throttling request took 387.306818ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:59:16.228218       1 request.go:530] Throttling request took 437.354557ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:59:17.039254       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 21:59:18.011562       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:59:20.014165       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:22.783976       1 gc_controller.go:144] GC'ing orphaned
I0416 21:59:22.790815       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:59:23.812118       1 controller.go:123] Found 0 jobs
I0416 21:59:23.815069       1 controller.go:139] Found 0 cronjobs
I0416 21:59:23.815094       1 controller.go:142] Found 0 groups
I0416 21:59:25.608534       1 wrap.go:47] GET /healthz: (89.424µs) 200 [kube-probe/1.15+ 127.0.0.1:49064]
I0416 21:59:27.128198       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:59:27.310104       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:27.680340       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 21:59:29.907381       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 21:59:30.801347       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 21:59:32.192528       1 request.go:530] Throttling request took 91.478887ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:59:32.242993       1 request.go:530] Throttling request took 141.903935ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:59:32.292501       1 request.go:530] Throttling request took 191.432912ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:59:32.342556       1 request.go:530] Throttling request took 241.451852ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:59:32.392544       1 request.go:530] Throttling request took 291.447427ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:59:32.440783       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 21:59:32.440821       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 21:59:32.442554       1 request.go:530] Throttling request took 341.430509ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:59:32.492546       1 request.go:530] Throttling request took 391.417227ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:59:32.542688       1 request.go:530] Throttling request took 441.439896ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:59:32.545607       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 21:59:33.819415       1 controller.go:123] Found 0 jobs
I0416 21:59:33.822492       1 controller.go:139] Found 0 cronjobs
I0416 21:59:33.822504       1 controller.go:142] Found 0 groups
I0416 21:59:33.974107       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 21:59:35.608527       1 wrap.go:47] GET /healthz: (81.851µs) 200 [kube-probe/1.15+ 127.0.0.1:49098]
I0416 21:59:37.441135       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 21:59:38.712118       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 21:59:41.788755       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:41.818153       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:42.128368       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:59:42.310378       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:42.791123       1 gc_controller.go:144] GC'ing orphaned
I0416 21:59:42.798449       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 21:59:43.830887       1 controller.go:123] Found 0 jobs
I0416 21:59:43.837689       1 controller.go:139] Found 0 cronjobs
I0416 21:59:43.837703       1 controller.go:142] Found 0 groups
I0416 21:59:45.608467       1 wrap.go:47] GET /healthz: (95.609µs) 200 [kube-probe/1.15+ 127.0.0.1:49150]
I0416 21:59:46.331673       1 request.go:530] Throttling request took 88.042307ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 21:59:46.381512       1 request.go:530] Throttling request took 137.872197ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 21:59:46.431516       1 request.go:530] Throttling request took 187.87005ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 21:59:46.481523       1 request.go:530] Throttling request took 237.853577ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 21:59:46.531624       1 request.go:530] Throttling request took 287.92231ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 21:59:46.581652       1 request.go:530] Throttling request took 337.957382ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 21:59:46.631508       1 request.go:530] Throttling request took 387.811841ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 21:59:46.681470       1 request.go:530] Throttling request took 437.763061ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 21:59:50.422910       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 21:59:53.841607       1 controller.go:123] Found 0 jobs
I0416 21:59:53.844243       1 controller.go:139] Found 0 cronjobs
I0416 21:59:53.844263       1 controller.go:142] Found 0 groups
I0416 21:59:55.608436       1 wrap.go:47] GET /healthz: (88.654µs) 200 [kube-probe/1.15+ 127.0.0.1:49186]
I0416 21:59:57.128593       1 pv_controller_base.go:407] resyncing PV controller
I0416 21:59:57.310639       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:02.646131       1 request.go:530] Throttling request took 91.881853ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:00:02.696115       1 request.go:530] Throttling request took 141.821067ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:00:02.746159       1 request.go:530] Throttling request took 191.896842ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:00:02.796080       1 request.go:530] Throttling request took 241.795501ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:00:02.798979       1 gc_controller.go:144] GC'ing orphaned
I0416 22:00:02.803255       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:00:02.846160       1 request.go:530] Throttling request took 291.867349ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:00:02.896165       1 request.go:530] Throttling request took 341.858492ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:00:02.946142       1 request.go:530] Throttling request took 391.830467ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:00:02.996171       1 request.go:530] Throttling request took 441.843894ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:00:02.998571       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:00:03.776968       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 235 items received
I0416 22:00:03.794694       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 0 items received
I0416 22:00:03.848641       1 controller.go:123] Found 0 jobs
I0416 22:00:03.851186       1 controller.go:139] Found 0 cronjobs
I0416 22:00:03.851197       1 controller.go:142] Found 0 groups
I0416 22:00:05.608866       1 wrap.go:47] GET /healthz: (94.935µs) 200 [kube-probe/1.15+ 127.0.0.1:49226]
I0416 22:00:08.278726       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 178 items received
I0416 22:00:11.789073       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:11.818569       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:12.128850       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:00:12.310894       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:13.854876       1 controller.go:123] Found 0 jobs
I0416 22:00:13.856787       1 controller.go:139] Found 0 cronjobs
I0416 22:00:13.856797       1 controller.go:142] Found 0 groups
I0416 22:00:14.811558       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 22:00:15.423880       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 22:00:15.609497       1 wrap.go:47] GET /healthz: (96.916µs) 200 [kube-probe/1.15+ 127.0.0.1:49260]
I0416 22:00:15.786499       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 146 items received
I0416 22:00:16.786224       1 request.go:530] Throttling request took 94.490514ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:00:16.834182       1 request.go:530] Throttling request took 142.419568ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:00:16.884206       1 request.go:530] Throttling request took 192.437986ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:00:16.934144       1 request.go:530] Throttling request took 242.366846ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:00:16.984264       1 request.go:530] Throttling request took 292.418009ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:00:17.034215       1 request.go:530] Throttling request took 342.421019ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:00:17.084201       1 request.go:530] Throttling request took 392.399297ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:00:17.134145       1 request.go:530] Throttling request took 442.335772ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:00:19.012493       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:00:19.832971       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:00:22.805582       1 gc_controller.go:144] GC'ing orphaned
I0416 22:00:22.810867       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:00:23.481643       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 22:00:23.860917       1 controller.go:123] Found 0 jobs
I0416 22:00:23.863786       1 controller.go:139] Found 0 cronjobs
I0416 22:00:23.863799       1 controller.go:142] Found 0 groups
I0416 22:00:24.171676       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:25.126858       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 22:00:25.609007       1 wrap.go:47] GET /healthz: (84.086µs) 200 [kube-probe/1.15+ 127.0.0.1:49292]
I0416 22:00:26.527640       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 22:00:26.782879       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 22:00:27.129169       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:00:27.311155       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:27.775973       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:00:27.808320       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 428 items received
I0416 22:00:27.998606       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 22:00:30.002270       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:00:32.446671       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:00:32.446710       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:00:33.099075       1 request.go:530] Throttling request took 91.794408ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:00:33.149123       1 request.go:530] Throttling request took 141.828459ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:00:33.199266       1 request.go:530] Throttling request took 191.947792ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:00:33.249197       1 request.go:530] Throttling request took 241.889678ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:00:33.299328       1 request.go:530] Throttling request took 292.011503ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:00:33.349352       1 request.go:530] Throttling request took 342.028227ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:00:33.399275       1 request.go:530] Throttling request took 391.926501ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:00:33.449278       1 request.go:530] Throttling request took 441.940992ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:00:33.451723       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:00:33.868966       1 controller.go:123] Found 0 jobs
I0416 22:00:33.874275       1 controller.go:139] Found 0 cronjobs
I0416 22:00:33.874288       1 controller.go:142] Found 0 groups
I0416 22:00:34.168319       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:00:34.797039       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 22:00:35.104007       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 22:00:35.608618       1 wrap.go:47] GET /healthz: (87.189µs) 200 [kube-probe/1.15+ 127.0.0.1:49326]
I0416 22:00:37.447031       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:00:40.940270       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 22:00:41.789296       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:41.818769       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:42.129359       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:00:42.311365       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:42.811086       1 gc_controller.go:144] GC'ing orphaned
I0416 22:00:42.817630       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:00:43.878031       1 controller.go:123] Found 0 jobs
I0416 22:00:43.880162       1 controller.go:139] Found 0 cronjobs
I0416 22:00:43.880173       1 controller.go:142] Found 0 groups
I0416 22:00:45.608615       1 wrap.go:47] GET /healthz: (72.718µs) 200 [kube-probe/1.15+ 127.0.0.1:49378]
I0416 22:00:46.471423       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:00:46.773050       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 22:00:47.237032       1 request.go:530] Throttling request took 92.972612ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:00:47.287104       1 request.go:530] Throttling request took 143.030121ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:00:47.337264       1 request.go:530] Throttling request took 193.133221ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:00:47.387084       1 request.go:530] Throttling request took 243.001908ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:00:47.436993       1 request.go:530] Throttling request took 292.90655ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:00:47.487065       1 request.go:530] Throttling request took 342.969732ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:00:47.537321       1 request.go:530] Throttling request took 393.213387ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:00:47.587092       1 request.go:530] Throttling request took 442.977411ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:00:47.787555       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 22:00:48.801680       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 22:00:51.323581       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:53.884449       1 controller.go:123] Found 0 jobs
I0416 22:00:53.887046       1 controller.go:139] Found 0 cronjobs
I0416 22:00:53.887060       1 controller.go:142] Found 0 groups
I0416 22:00:55.608352       1 wrap.go:47] GET /healthz: (120.707µs) 200 [kube-probe/1.15+ 127.0.0.1:49414]
I0416 22:00:57.129587       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:00:57.311661       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:00:58.777899       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 0 items received
I0416 22:01:02.817976       1 gc_controller.go:144] GC'ing orphaned
I0416 22:01:02.822477       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:01:03.552165       1 request.go:530] Throttling request took 91.66207ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:01:03.602175       1 request.go:530] Throttling request took 141.65061ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:01:03.652170       1 request.go:530] Throttling request took 191.621683ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:01:03.702178       1 request.go:530] Throttling request took 241.625285ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:01:03.752180       1 request.go:530] Throttling request took 291.609912ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:01:03.802178       1 request.go:530] Throttling request took 341.595879ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:01:03.852177       1 request.go:530] Throttling request took 391.59349ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:01:03.891264       1 controller.go:123] Found 0 jobs
I0416 22:01:03.894060       1 controller.go:139] Found 0 cronjobs
I0416 22:01:03.894073       1 controller.go:142] Found 0 groups
I0416 22:01:03.902210       1 request.go:530] Throttling request took 441.606307ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:01:03.904409       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:01:05.608447       1 wrap.go:47] GET /healthz: (99.952µs) 200 [kube-probe/1.15+ 127.0.0.1:49452]
I0416 22:01:11.789620       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:11.819019       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:12.017757       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 22:01:12.129834       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:01:12.311965       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:12.792676       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 22:01:13.897761       1 controller.go:123] Found 0 jobs
I0416 22:01:13.900894       1 controller.go:139] Found 0 cronjobs
I0416 22:01:13.900908       1 controller.go:142] Found 0 groups
I0416 22:01:15.608555       1 wrap.go:47] GET /healthz: (89.272µs) 200 [kube-probe/1.15+ 127.0.0.1:49484]
I0416 22:01:15.673131       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 22:01:16.801364       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 0 items received
I0416 22:01:17.689594       1 request.go:530] Throttling request took 92.703939ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:01:17.739619       1 request.go:530] Throttling request took 142.722914ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:01:17.789586       1 request.go:530] Throttling request took 192.681466ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:01:17.839690       1 request.go:530] Throttling request took 242.763534ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:01:17.889615       1 request.go:530] Throttling request took 292.686575ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:01:17.938831       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:17.939617       1 request.go:530] Throttling request took 342.687559ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:01:17.941450       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:17.941757       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:01:17.941871       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:01:17.942001       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:01:17.944108       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:17.989671       1 request.go:530] Throttling request took 392.729664ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:01:18.039693       1 request.go:530] Throttling request took 442.733416ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:01:20.014952       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:01:22.822829       1 gc_controller.go:144] GC'ing orphaned
I0416 22:01:22.827565       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:01:23.904817       1 controller.go:123] Found 0 jobs
I0416 22:01:23.907664       1 controller.go:139] Found 0 cronjobs
I0416 22:01:23.907675       1 controller.go:142] Found 0 groups
I0416 22:01:25.608559       1 wrap.go:47] GET /healthz: (105.504µs) 200 [kube-probe/1.15+ 127.0.0.1:49516]
I0416 22:01:25.838381       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 0 items received
I0416 22:01:27.130033       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:01:27.312283       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:27.865335       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:01:30.111061       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:01:30.381024       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.382102       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.382192       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.382276       1 deployment_controller.go:175] Updating deployment coredns
I0416 22:01:30.382294       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 22:01:30.382316       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 22:01:30.382310874 +0000 UTC m=+3512.536035024)
I0416 22:01:30.383218       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (904.037µs)
I0416 22:01:30.383877       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 22:01:30.38386688 +0000 UTC m=+3512.537591032)
I0416 22:01:30.384533       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (661.375µs)
I0416 22:01:30.384869       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 22:01:30.384901       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 22:01:30.384897214 +0000 UTC m=+3512.538621364)
I0416 22:01:30.386519       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (1.617573ms)
I0416 22:01:30.388284       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 22:01:30.388324       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 22:01:30.388305377 +0000 UTC m=+3512.542029528)
I0416 22:01:30.389054       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (731.538µs)
I0416 22:01:30.389112       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 22:01:30.389117       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 22:01:30.389142       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 22:01:30.389138552 +0000 UTC m=+3512.542862704)
I0416 22:01:30.394766       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (5.599731ms)
I0416 22:01:30.394812       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 22:01:30.394808168 +0000 UTC m=+3512.548532318)
I0416 22:01:30.395795       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (983.239µs)
I0416 22:01:30.395852       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 22:01:30.395865       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 22:01:30.395861855 +0000 UTC m=+3512.549586006)
I0416 22:01:30.397060       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (1.191642ms)
I0416 22:01:30.397111       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 22:01:30.397123       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 22:01:30.397119621 +0000 UTC m=+3512.550843772)
I0416 22:01:30.397444       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (322.356µs)
I0416 22:01:30.404509       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.404601       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 22:01:30.404623       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 22:01:30.406144       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b1d0a68c2a83, ext:3264800444271, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.406764       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:01:30.406778       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b20e983ee144, ext:3512560498237, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.406852       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:01:30.406909       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:01:30.406915       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b20e983ee144, ext:3512560498237, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.406954       1 update.go:396] Getting unavailable numbers
I0416 22:01:30.407066       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:01:30.407073       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 22:01:30.407080       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:01:30.407084       1 update.go:68] Marking old pods for deletion
I0416 22:01:30.407088       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b20e9843a775, ext:3512560811117, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.407095       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:01:30.407116       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:01:30.407151       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:01:30.407257       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:01:30.407264       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.623759ms)
I0416 22:01:30.407720       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b1d0a69f63dc, ext:3264801704230, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.407824       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:01:30.407877       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b20e984fa98e, ext:3512561598088, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.407885       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:01:30.407913       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:01:30.407917       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b20e984fa98e, ext:3512561598088, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.407957       1 update.go:396] Getting unavailable numbers
I0416 22:01:30.408025       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:01:30.408059       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 22:01:30.408069       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:01:30.408073       1 update.go:68] Marking old pods for deletion
I0416 22:01:30.408076       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b20e9852b837, ext:3512561798511, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.408082       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:01:30.408127       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:01:30.408149       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:01:30.408247       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:01:30.408280       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (977.838µs)
I0416 22:01:30.414048       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.414316       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.414534       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (226.932µs)
I0416 22:01:30.414615       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.414750       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.414774       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.414786       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.414834       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.415003       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:01:30.415022       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.415026       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:01:30.415042       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.415118       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.415134       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.415208       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.415374       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:01:30.415406       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.415409       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:01:30.415438       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.415543       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (109.225µs)
I0416 22:01:30.415576       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.415623       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (49.669µs)
I0416 22:01:30.415667       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.415756       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (90.604µs)
I0416 22:01:30.415792       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:01:30.415797       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.415814       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:01:30.415837       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.415927       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (92.407µs)
I0416 22:01:30.415954       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:01:30.415979       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.415982       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:01:30.416039       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.416110       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (72.25µs)
I0416 22:01:30.416122       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:01:30.416148       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416151       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:01:30.416192       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.416276       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (85.418µs)
I0416 22:01:30.416285       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.416348       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (64.33µs)
I0416 22:01:30.416361       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:01:30.416386       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416389       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:01:30.416417       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.416475       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (59.757µs)
I0416 22:01:30.416501       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 22:01:30.416550       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (51.908µs)
I0416 22:01:30.416561       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:01:30.416572       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416575       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:01:30.416606       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:01:30.416627       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416630       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:01:30.416655       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:01:30.416663       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416666       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:01:30.416669       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:01:30.416676       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416689       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:01:30.416725       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:01:30.416734       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416736       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:01:30.416801       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 22:01:30.416812       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416814       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 22:01:30.416869       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 22:01:30.416877       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416880       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 22:01:30.416904       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:01:30.416911       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416914       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:01:30.416964       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 22:01:30.416973       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416976       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 22:01:30.416979       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:01:30.416982       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.416985       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:01:30.417027       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:01:30.417034       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.417036       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:01:30.417058       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:01:30.417070       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.417073       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:01:30.417131       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:01:30.417139       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.417141       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:01:30.417174       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:01:30.417182       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.417184       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:01:30.417207       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:01:30.417213       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.417216       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:01:30.417251       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 22:01:30.417257       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 22:01:30.417260       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 22:01:30.458189       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.580519       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.613594       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.727209       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.800638       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.900535       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.950026       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:30.950124       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:01:30.950177       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (3.854µs)
I0416 22:01:30.950203       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:01:30.950212       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:01:30.950220       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:01:30.950255       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (493ns)
I0416 22:01:30.950271       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (567ns)
I0416 22:01:30.950279       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (314ns)
I0416 22:01:31.000635       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:31.156618       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:32.453339       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:01:32.453378       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:01:33.933652       1 controller.go:123] Found 0 jobs
I0416 22:01:33.935938       1 controller.go:139] Found 0 cronjobs
I0416 22:01:33.935949       1 controller.go:142] Found 0 groups
I0416 22:01:34.005048       1 request.go:530] Throttling request took 91.169882ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:01:34.055030       1 request.go:530] Throttling request took 141.147072ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:01:34.104958       1 request.go:530] Throttling request took 191.142343ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:01:34.154996       1 request.go:530] Throttling request took 241.159737ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:01:34.204982       1 request.go:530] Throttling request took 291.139322ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:01:34.254956       1 request.go:530] Throttling request took 341.093745ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:01:34.304985       1 request.go:530] Throttling request took 391.107916ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:01:34.355003       1 request.go:530] Throttling request took 441.116666ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:01:34.357640       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:01:34.530609       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:01:35.609061       1 wrap.go:47] GET /healthz: (98.979µs) 200 [kube-probe/1.15+ 127.0.0.1:49550]
I0416 22:01:37.454094       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:01:41.790049       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:41.819323       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:42.130371       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:01:42.312633       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:42.828121       1 gc_controller.go:144] GC'ing orphaned
I0416 22:01:42.833141       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:01:43.945429       1 controller.go:123] Found 0 jobs
I0416 22:01:43.950834       1 controller.go:139] Found 0 cronjobs
I0416 22:01:43.950846       1 controller.go:142] Found 0 groups
I0416 22:01:45.608876       1 wrap.go:47] GET /healthz: (97.368µs) 200 [kube-probe/1.15+ 127.0.0.1:49604]
I0416 22:01:48.142631       1 request.go:530] Throttling request took 91.889911ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:01:48.192885       1 request.go:530] Throttling request took 142.139211ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:01:48.242876       1 request.go:530] Throttling request took 192.118078ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:01:48.292560       1 request.go:530] Throttling request took 241.78045ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:01:48.342575       1 request.go:530] Throttling request took 291.797473ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:01:48.392593       1 request.go:530] Throttling request took 341.789488ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:01:48.442619       1 request.go:530] Throttling request took 391.807912ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:01:48.492564       1 request.go:530] Throttling request took 441.744071ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:01:50.810944       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:01:53.955029       1 controller.go:123] Found 0 jobs
I0416 22:01:53.957618       1 controller.go:139] Found 0 cronjobs
I0416 22:01:53.957630       1 controller.go:142] Found 0 groups
I0416 22:01:54.483406       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:01:55.609303       1 wrap.go:47] GET /healthz: (117.633µs) 200 [kube-probe/1.15+ 127.0.0.1:49656]
I0416 22:01:57.130572       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:01:57.313342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:02.833437       1 gc_controller.go:144] GC'ing orphaned
I0416 22:02:02.838005       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:02:03.961520       1 controller.go:123] Found 0 jobs
I0416 22:02:03.964501       1 controller.go:139] Found 0 cronjobs
I0416 22:02:03.964513       1 controller.go:142] Found 0 groups
I0416 22:02:04.458100       1 request.go:530] Throttling request took 89.904936ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:02:04.508132       1 request.go:530] Throttling request took 139.926608ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:02:04.558423       1 request.go:530] Throttling request took 190.209836ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:02:04.608036       1 request.go:530] Throttling request took 239.809705ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:02:04.658150       1 request.go:530] Throttling request took 289.920564ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:02:04.708069       1 request.go:530] Throttling request took 339.827479ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:02:04.758127       1 request.go:530] Throttling request took 389.873355ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:02:04.808198       1 request.go:530] Throttling request took 439.887383ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:02:04.810750       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:02:05.608676       1 wrap.go:47] GET /healthz: (106.882µs) 200 [kube-probe/1.15+ 127.0.0.1:49692]
I0416 22:02:06.775360       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 22:02:11.790404       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:11.790917       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 22:02:11.791915       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (249.202µs)
I0416 22:02:11.792000       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (65.142µs)
I0416 22:02:11.792112       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (87.121µs)
I0416 22:02:11.792264       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (118.078µs)
I0416 22:02:11.792277       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.122µs)
I0416 22:02:11.796054       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (5.513791ms)
I0416 22:02:11.819900       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:12.131123       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:02:12.313660       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:13.968542       1 controller.go:123] Found 0 jobs
I0416 22:02:13.971606       1 controller.go:139] Found 0 cronjobs
I0416 22:02:13.971619       1 controller.go:142] Found 0 groups
I0416 22:02:15.608374       1 wrap.go:47] GET /healthz: (92.575µs) 200 [kube-probe/1.15+ 127.0.0.1:49724]
I0416 22:02:18.595793       1 request.go:530] Throttling request took 91.319045ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:02:18.645795       1 request.go:530] Throttling request took 141.304545ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:02:18.695754       1 request.go:530] Throttling request took 191.274327ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:02:18.745995       1 request.go:530] Throttling request took 241.447657ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:02:18.795832       1 request.go:530] Throttling request took 291.289286ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:02:18.845853       1 request.go:530] Throttling request took 341.291537ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:02:18.895771       1 request.go:530] Throttling request took 391.20897ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:02:18.945831       1 request.go:530] Throttling request took 441.260503ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:02:19.230626       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 22:02:21.017601       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:02:22.838365       1 gc_controller.go:144] GC'ing orphaned
I0416 22:02:22.842787       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:02:23.975256       1 controller.go:123] Found 0 jobs
I0416 22:02:23.977797       1 controller.go:139] Found 0 cronjobs
I0416 22:02:23.977808       1 controller.go:142] Found 0 groups
I0416 22:02:25.608667       1 wrap.go:47] GET /healthz: (105.405µs) 200 [kube-probe/1.15+ 127.0.0.1:49756]
I0416 22:02:27.131355       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:02:27.313957       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:27.949835       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:02:30.203005       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:02:32.462306       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:02:32.462358       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:02:33.981422       1 controller.go:123] Found 0 jobs
I0416 22:02:33.983523       1 controller.go:139] Found 0 cronjobs
I0416 22:02:33.983534       1 controller.go:142] Found 0 groups
I0416 22:02:34.813528       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:02:34.912083       1 request.go:530] Throttling request took 87.990929ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:02:34.962117       1 request.go:530] Throttling request took 138.011376ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:02:35.012095       1 request.go:530] Throttling request took 187.979534ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:02:35.062187       1 request.go:530] Throttling request took 238.065409ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:02:35.112127       1 request.go:530] Throttling request took 287.994806ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:02:35.162075       1 request.go:530] Throttling request took 337.938122ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:02:35.212048       1 request.go:530] Throttling request took 387.903857ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:02:35.262131       1 request.go:530] Throttling request took 437.965734ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:02:35.264459       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:02:35.608502       1 wrap.go:47] GET /healthz: (86.253µs) 200 [kube-probe/1.15+ 127.0.0.1:49790]
I0416 22:02:37.462708       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:02:41.791293       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:41.820240       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:42.131701       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:02:42.314360       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:42.779296       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 22:02:42.843446       1 gc_controller.go:144] GC'ing orphaned
I0416 22:02:42.853362       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:02:43.048352       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:43.987943       1 controller.go:123] Found 0 jobs
I0416 22:02:43.990423       1 controller.go:139] Found 0 cronjobs
I0416 22:02:43.990435       1 controller.go:142] Found 0 groups
I0416 22:02:45.608519       1 wrap.go:47] GET /healthz: (101.318µs) 200 [kube-probe/1.15+ 127.0.0.1:49842]
I0416 22:02:45.799400       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 22:02:48.654777       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:02:49.048941       1 request.go:530] Throttling request took 90.99037ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:02:49.098876       1 request.go:530] Throttling request took 140.963557ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:02:49.148855       1 request.go:530] Throttling request took 190.932735ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:02:49.198876       1 request.go:530] Throttling request took 240.932937ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:02:49.248932       1 request.go:530] Throttling request took 290.957362ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:02:49.298937       1 request.go:530] Throttling request took 340.936237ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:02:49.349441       1 request.go:530] Throttling request took 391.444312ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:02:49.398924       1 request.go:530] Throttling request took 440.921148ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:02:49.792958       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 22:02:53.994594       1 controller.go:123] Found 0 jobs
I0416 22:02:54.001415       1 controller.go:139] Found 0 cronjobs
I0416 22:02:54.001429       1 controller.go:142] Found 0 groups
I0416 22:02:55.608646       1 wrap.go:47] GET /healthz: (85.967µs) 200 [kube-probe/1.15+ 127.0.0.1:49878]
I0416 22:02:57.131964       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:02:57.314680       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:02.853701       1 gc_controller.go:144] GC'ing orphaned
I0416 22:03:02.858403       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:03:04.005520       1 controller.go:123] Found 0 jobs
I0416 22:03:04.008222       1 controller.go:139] Found 0 cronjobs
I0416 22:03:04.008247       1 controller.go:142] Found 0 groups
I0416 22:03:05.365386       1 request.go:530] Throttling request took 86.639096ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:03:05.415170       1 request.go:530] Throttling request took 136.399113ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:03:05.465104       1 request.go:530] Throttling request took 186.326006ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:03:05.515153       1 request.go:530] Throttling request took 236.36323ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:03:05.565144       1 request.go:530] Throttling request took 286.338597ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:03:05.608661       1 wrap.go:47] GET /healthz: (124.651µs) 200 [kube-probe/1.15+ 127.0.0.1:49912]
I0416 22:03:05.615064       1 request.go:530] Throttling request took 336.254577ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:03:05.665032       1 request.go:530] Throttling request took 386.212071ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:03:05.715120       1 request.go:530] Throttling request took 436.291533ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:03:05.717265       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:03:11.791642       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:11.820510       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:12.132340       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:03:12.314970       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:14.012544       1 controller.go:123] Found 0 jobs
I0416 22:03:14.015449       1 controller.go:139] Found 0 cronjobs
I0416 22:03:14.015460       1 controller.go:142] Found 0 groups
I0416 22:03:15.608411       1 wrap.go:47] GET /healthz: (194.19µs) 200 [kube-probe/1.15+ 127.0.0.1:49952]
I0416 22:03:16.177553       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 22:03:19.501968       1 request.go:530] Throttling request took 85.114031ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:03:19.551972       1 request.go:530] Throttling request took 135.111114ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:03:19.601945       1 request.go:530] Throttling request took 185.05126ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:03:19.651929       1 request.go:530] Throttling request took 235.026108ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:03:19.701964       1 request.go:530] Throttling request took 285.009803ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:03:19.751951       1 request.go:530] Throttling request took 335.030696ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:03:19.790843       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 22:03:19.801917       1 request.go:530] Throttling request took 384.987707ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:03:19.851968       1 request.go:530] Throttling request took 435.026051ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:03:22.025658       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:03:22.858749       1 gc_controller.go:144] GC'ing orphaned
I0416 22:03:22.863879       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:03:24.019945       1 controller.go:123] Found 0 jobs
I0416 22:03:24.022835       1 controller.go:139] Found 0 cronjobs
I0416 22:03:24.022849       1 controller.go:142] Found 0 groups
I0416 22:03:25.608636       1 wrap.go:47] GET /healthz: (102.795µs) 200 [kube-probe/1.15+ 127.0.0.1:49988]
I0416 22:03:27.132598       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:03:27.315328       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:28.038084       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:03:29.326444       1 reflector.go:249] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: forcing resync
I0416 22:03:30.324926       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:03:32.469012       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:03:32.469048       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:03:34.027199       1 controller.go:123] Found 0 jobs
I0416 22:03:34.029632       1 controller.go:139] Found 0 cronjobs
I0416 22:03:34.029642       1 controller.go:142] Found 0 groups
I0416 22:03:35.016655       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:03:35.612712       1 wrap.go:47] GET /healthz: (106.265µs) 200 [kube-probe/1.15+ 127.0.0.1:50024]
I0416 22:03:35.817644       1 request.go:530] Throttling request took 92.767036ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:03:35.867649       1 request.go:530] Throttling request took 142.448642ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:03:35.917631       1 request.go:530] Throttling request took 192.4145ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:03:35.967761       1 request.go:530] Throttling request took 242.538369ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:03:36.017702       1 request.go:530] Throttling request took 292.459613ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:03:36.067663       1 request.go:530] Throttling request took 342.421134ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:03:36.117711       1 request.go:530] Throttling request took 392.460521ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:03:36.167692       1 request.go:530] Throttling request took 442.412697ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:03:36.171214       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:03:37.469455       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:03:37.787206       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 22:03:41.791903       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:41.821084       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:42.132874       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:03:42.315616       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:42.563059       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 22:03:42.802196       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 22:03:42.875443       1 gc_controller.go:144] GC'ing orphaned
I0416 22:03:42.889717       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:03:44.033054       1 controller.go:123] Found 0 jobs
I0416 22:03:44.035206       1 controller.go:139] Found 0 cronjobs
I0416 22:03:44.035249       1 controller.go:142] Found 0 groups
I0416 22:03:44.314534       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:45.336832       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 30 items received
I0416 22:03:45.608475       1 wrap.go:47] GET /healthz: (100.77µs) 200 [kube-probe/1.15+ 127.0.0.1:50076]
I0416 22:03:49.954909       1 request.go:530] Throttling request took 92.307836ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:03:50.005030       1 request.go:530] Throttling request took 142.41737ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:03:50.054971       1 request.go:530] Throttling request took 192.35972ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:03:50.104910       1 request.go:530] Throttling request took 242.29139ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:03:50.154927       1 request.go:530] Throttling request took 292.301438ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:03:50.204951       1 request.go:530] Throttling request took 342.31687ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:03:50.254992       1 request.go:530] Throttling request took 392.348387ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:03:50.304975       1 request.go:530] Throttling request took 442.322511ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:03:50.991586       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:03:54.039008       1 controller.go:123] Found 0 jobs
I0416 22:03:54.041167       1 controller.go:139] Found 0 cronjobs
I0416 22:03:54.041177       1 controller.go:142] Found 0 groups
I0416 22:03:55.608533       1 wrap.go:47] GET /healthz: (81.973µs) 200 [kube-probe/1.15+ 127.0.0.1:50112]
I0416 22:03:57.133113       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:03:57.315891       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:02.797006       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 22:04:02.890078       1 gc_controller.go:144] GC'ing orphaned
I0416 22:04:02.895146       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:04:04.045093       1 controller.go:123] Found 0 jobs
I0416 22:04:04.047287       1 controller.go:139] Found 0 cronjobs
I0416 22:04:04.047297       1 controller.go:142] Found 0 groups
I0416 22:04:05.608569       1 wrap.go:47] GET /healthz: (92.448µs) 200 [kube-probe/1.15+ 127.0.0.1:50146]
I0416 22:04:06.271837       1 request.go:530] Throttling request took 91.018411ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:04:06.321779       1 request.go:530] Throttling request took 140.949731ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:04:06.362630       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 244 items received
I0416 22:04:06.371851       1 request.go:530] Throttling request took 191.015418ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:04:06.421766       1 request.go:530] Throttling request took 240.919977ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:04:06.471738       1 request.go:530] Throttling request took 290.882689ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:04:06.521809       1 request.go:530] Throttling request took 340.943927ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:04:06.571823       1 request.go:530] Throttling request took 390.951402ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:04:06.621733       1 request.go:530] Throttling request took 440.837951ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:04:06.624513       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:04:11.792169       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:11.821414       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:12.133397       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:04:12.316205       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:13.073558       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:14.051910       1 controller.go:123] Found 0 jobs
I0416 22:04:14.054778       1 controller.go:139] Found 0 cronjobs
I0416 22:04:14.054792       1 controller.go:142] Found 0 groups
I0416 22:04:15.608668       1 wrap.go:47] GET /healthz: (99.591µs) 200 [kube-probe/1.15+ 127.0.0.1:50182]
I0416 22:04:15.814036       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 22:04:20.408092       1 request.go:530] Throttling request took 87.095184ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:04:20.458216       1 request.go:530] Throttling request took 137.214123ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:04:20.508332       1 request.go:530] Throttling request took 187.335136ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:04:20.558219       1 request.go:530] Throttling request took 237.20872ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:04:20.608220       1 request.go:530] Throttling request took 287.20019ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:04:20.658312       1 request.go:530] Throttling request took 337.154245ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:04:20.708145       1 request.go:530] Throttling request took 387.091527ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:04:20.758136       1 request.go:530] Throttling request took 437.073836ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:04:22.021385       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:04:22.897403       1 gc_controller.go:144] GC'ing orphaned
I0416 22:04:22.902041       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:04:24.058718       1 controller.go:123] Found 0 jobs
I0416 22:04:24.061058       1 controller.go:139] Found 0 cronjobs
I0416 22:04:24.061070       1 controller.go:142] Found 0 groups
I0416 22:04:25.608508       1 wrap.go:47] GET /healthz: (94.597µs) 200 [kube-probe/1.15+ 127.0.0.1:50214]
I0416 22:04:27.133777       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:04:27.317031       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:28.121187       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:04:28.169636       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-master.1596104b47d84adc, uid 77fb3bf0-d9d7-4a36-ae28-d6e353f3191e, event type delete
I0416 22:04:28.169780       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-zcdpb.1596104869f49e65, uid d3ed14fb-8027-49ae-a98e-4eef4aec72b5, event type delete
I0416 22:04:28.169792       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88.159610486a03b277, uid 13f0b1d0-807e-42f6-b616-4081e25955b8, event type delete
I0416 22:04:28.169800       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns.159610486777a367, uid ce146278-1eed-4fbe-8578-f2431d9c6d25, event type delete
I0416 22:04:28.169846       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.159610489b4e7ba7, uid c1e389c5-c770-4a2b-9a91-8ebdf1057fa6, event type delete
I0416 22:04:28.169853       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768.159610489b41fb03, uid 2c269429-486c-45f5-83f2-20645a68d9cc, event type delete
I0416 22:04:28.169861       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4.159610489a9f3dba, uid b51e7508-a36e-408b-880e-f8ae1d7f73a8, event type delete
I0416 22:04:28.171632       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4-26sjq.1596104974969956, uid e251d942-8509-42c1-8908-df5881c850d0, event type delete
I0416 22:04:28.171747       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4.159610497486cf93, uid 8f8fc5c6-367e-4bac-90fe-863f8f117604, event type delete
I0416 22:04:28.171755       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler.1596104973ec2d2b, uid 88e93b11-e334-4ae8-bf05-48d13bdc894c, event type delete
I0416 22:04:28.171763       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596104aaae3b2e0, uid 741d402e-9108-4715-9d95-83c8f0958746, event type delete
I0416 22:04:28.171818       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596104aed1a721e, uid 479de6e4-6170-4832-b9c7-4844fd8925df, event type delete
I0416 22:04:28.171825       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596104df30c3fb4, uid f3a743cc-9ec0-498b-ad4a-7d0e27fb5a73, event type delete
I0416 22:04:28.171833       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596104e46720da8, uid 75c1fca7-9c00-4290-bb54-8d772484a598, event type delete
I0416 22:04:28.171876       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596104e53f1c016, uid 2a5b53c9-c786-4db5-956d-bc618eb2aefa, event type delete
I0416 22:04:28.171896       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596104e544b1834, uid df4e941c-12da-473d-b37e-e10074d0b2c7, event type delete
I0416 22:04:28.171904       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596104e620ba800, uid 0867a0a6-fb86-46d0-88ea-901f8aa65ace, event type delete
I0416 22:04:28.171944       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596104e71b85b0f, uid 50646907-aa4d-477f-a257-bedfa48f8146, event type delete
I0416 22:04:28.171951       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0.1596104aa43ba97f, uid ff561715-adf9-45d4-899c-8caab252f0b3, event type delete
I0416 22:04:28.171981       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.159610487dc57316, uid ab502637-0747-4321-ab2f-3850a61cb790, event type delete
I0416 22:04:28.172017       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485.159610487db7c3f1, uid 020f40c6-c48b-45ea-9141-88c4f4a60e9a, event type delete
I0416 22:04:28.172024       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1.159610487ceca7fe, uid dcd513e5-c4ed-4f1e-bcd5-3223a1771473, event type delete
I0416 22:04:28.172030       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name ingress-gce-lock.15961044fc6cb9d9, uid 12a1a32c-e4ee-48fe-9266-d08a242367fb, event type delete
I0416 22:04:28.172093       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-controller-manager.159610448ca5f7b0, uid 10241327-c63a-4536-908d-cb4bb1c2002d, event type delete
I0416 22:04:28.172099       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df-4ggmd.15961049dd02d3c4, uid 97fe3ea9-3ae9-4c2f-a81e-5660a6e96a49, event type delete
I0416 22:04:28.172106       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df.1596104892bf6746, uid a05725be-bba0-406a-8a13-d8432dad7193, event type delete
I0416 22:04:28.172160       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df.15961049de0788a4, uid 349a735d-66cb-471d-86e7-551d14fff0b4, event type delete
I0416 22:04:28.172168       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler.1596104891f921ab, uid beef042c-0de9-4ab4-9d57-f04a57b80610, event type delete
I0416 22:04:28.172177       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-scheduler.15961044a76fbe2c, uid e9e85a14-eeed-4f0a-ae7e-e1ebf1962212, event type delete
I0416 22:04:28.172241       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8-t5nl6.15961049d75f7ff0, uid 0eea4951-f550-45f2-9d2e-f733c501a925, event type delete
I0416 22:04:28.172249       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8.159610488772cf9e, uid 800d5d3d-55ce-4b47-b643-5d556395a7f1, event type delete
I0416 22:04:28.172256       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8.15961049d765bf31, uid 121308fe-08c2-4df0-ad0b-dec3163f73a2, event type delete
I0416 22:04:28.172295       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard.15961048860ff10b, uid 12592ac5-62e0-4bc6-98cd-cf025fc42a6d, event type delete
I0416 22:04:28.172301       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.1596104870b9455d, uid 361b7ec8-6664-4303-8cff-a9ce25839cd6, event type delete
I0416 22:04:28.172321       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9.1596104870fd0265, uid a6e7243f-fee6-46a8-bb0f-725c93f2c045, event type delete
I0416 22:04:28.172365       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend.1596104870302a1d, uid d6da6eb8-a442-44c3-91da-15bf35c63490, event type delete
I0416 22:04:28.172373       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104aada6b981, uid 4f7f5dcc-12a8-4c30-b4a2-b5f566240fd8, event type delete
I0416 22:04:28.172379       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104b14ca5a9e, uid b195a020-3f9e-481e-8654-b58304b55a03, event type delete
I0416 22:04:28.172619       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104b560f1555, uid ae6310ca-aa74-4d49-82a5-1055009155c7, event type delete
I0416 22:04:28.172633       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104bd86ee24c, uid d4c130df-e8a2-4e9f-8ff5-e978f8b89ee6, event type delete
I0416 22:04:28.172642       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104bfd7ae890, uid 0b4290b8-bdc7-48bf-bd47-e7bc649f89c6, event type delete
I0416 22:04:28.172699       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104bfdf051f3, uid dc2aa2fc-7740-4715-a7aa-a983fe3e9535, event type delete
I0416 22:04:28.172708       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104cb0b4d840, uid af06a15a-8da1-4cac-814f-9aa2b16cf17c, event type delete
I0416 22:04:28.172714       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104d437edc39, uid c0bcdebd-3604-4c2e-a26f-f82df84e6b05, event type delete
I0416 22:04:28.172770       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-ll5kc.1596104d65cb1742, uid 52852ba9-a395-4bc1-a61f-10a5174e4755, event type delete
I0416 22:04:28.172777       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1.1596104aa40c3cdb, uid bf12f4b0-581d-48de-b409-d7c771436a32, event type delete
I0416 22:04:28.172784       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.15961048f331ed7f, uid 308bb2cc-5fae-431a-a295-06b5de08cf94, event type delete
I0416 22:04:28.172814       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf.15961048f33a7f01, uid 254c0ba0-3e09-4aa8-a811-06f7655fec6d, event type delete
I0416 22:04:28.172843       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1.15961048efc221b9, uid 16904e21-1ec5-41cf-bfda-8e6f20bbd16d, event type delete
I0416 22:04:30.441769       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:04:32.476349       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:04:32.476390       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:04:34.076691       1 controller.go:123] Found 0 jobs
I0416 22:04:34.078933       1 controller.go:139] Found 0 cronjobs
I0416 22:04:34.078944       1 controller.go:142] Found 0 groups
I0416 22:04:35.355086       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:04:35.608482       1 wrap.go:47] GET /healthz: (77.316µs) 200 [kube-probe/1.15+ 127.0.0.1:50248]
I0416 22:04:36.725040       1 request.go:530] Throttling request took 92.612862ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:04:36.775058       1 request.go:530] Throttling request took 142.571652ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:04:36.825027       1 request.go:530] Throttling request took 192.572891ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:04:36.875017       1 request.go:530] Throttling request took 242.560273ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:04:36.925042       1 request.go:530] Throttling request took 292.57303ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:04:36.975007       1 request.go:530] Throttling request took 342.524359ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:04:37.025066       1 request.go:530] Throttling request took 392.580746ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:04:37.075001       1 request.go:530] Throttling request took 442.495205ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:04:37.077176       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:04:37.476619       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:04:39.249342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:39.786984       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 0 items received
I0416 22:04:41.792453       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:41.821720       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:42.134041       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:04:42.317314       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:42.902285       1 gc_controller.go:144] GC'ing orphaned
I0416 22:04:42.908397       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:04:44.088690       1 controller.go:123] Found 0 jobs
I0416 22:04:44.091569       1 controller.go:139] Found 0 cronjobs
I0416 22:04:44.091582       1 controller.go:142] Found 0 groups
I0416 22:04:45.610668       1 wrap.go:47] GET /healthz: (80.501µs) 200 [kube-probe/1.15+ 127.0.0.1:50296]
I0416 22:04:50.864277       1 request.go:530] Throttling request took 92.348416ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:04:50.914253       1 request.go:530] Throttling request took 142.222057ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:04:50.964174       1 request.go:530] Throttling request took 192.219994ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:04:51.014270       1 request.go:530] Throttling request took 242.298024ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:04:51.064308       1 request.go:530] Throttling request took 292.261323ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:04:51.114196       1 request.go:530] Throttling request took 342.222832ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:04:51.164138       1 request.go:530] Throttling request took 392.147622ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:04:51.214211       1 request.go:530] Throttling request took 442.213434ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:04:52.781722       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 0 items received
I0416 22:04:54.100026       1 controller.go:123] Found 0 jobs
I0416 22:04:54.102253       1 controller.go:139] Found 0 cronjobs
I0416 22:04:54.102262       1 controller.go:142] Found 0 groups
I0416 22:04:55.608517       1 wrap.go:47] GET /healthz: (70.407µs) 200 [kube-probe/1.15+ 127.0.0.1:50336]
I0416 22:04:57.134349       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:04:57.317660       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:04:59.318695       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 0 items received
I0416 22:05:02.908678       1 gc_controller.go:144] GC'ing orphaned
I0416 22:05:02.912437       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:05:04.110107       1 controller.go:123] Found 0 jobs
I0416 22:05:04.116706       1 controller.go:139] Found 0 cronjobs
I0416 22:05:04.116719       1 controller.go:142] Found 0 groups
I0416 22:05:05.608428       1 wrap.go:47] GET /healthz: (96.41µs) 200 [kube-probe/1.15+ 127.0.0.1:50370]
I0416 22:05:07.177581       1 request.go:530] Throttling request took 92.047465ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:05:07.227625       1 request.go:530] Throttling request took 142.083025ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:05:07.277657       1 request.go:530] Throttling request took 192.106137ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:05:07.327511       1 request.go:530] Throttling request took 241.952417ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:05:07.377576       1 request.go:530] Throttling request took 292.0009ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:05:07.428087       1 request.go:530] Throttling request took 342.501361ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:05:07.477580       1 request.go:530] Throttling request took 391.976293ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:05:07.527617       1 request.go:530] Throttling request took 441.984207ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:05:07.530003       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:05:07.802725       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 22:05:09.382314       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 22:05:11.792674       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:11.822332       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:12.134688       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:05:12.319131       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:14.120267       1 controller.go:123] Found 0 jobs
I0416 22:05:14.122551       1 controller.go:139] Found 0 cronjobs
I0416 22:05:14.122563       1 controller.go:142] Found 0 groups
I0416 22:05:15.608603       1 wrap.go:47] GET /healthz: (95.821µs) 200 [kube-probe/1.15+ 127.0.0.1:50404]
I0416 22:05:19.937423       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:21.316995       1 request.go:530] Throttling request took 92.101966ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:05:21.367351       1 request.go:530] Throttling request took 142.453051ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:05:21.416927       1 request.go:530] Throttling request took 192.026183ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:05:21.466991       1 request.go:530] Throttling request took 242.061849ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:05:21.516949       1 request.go:530] Throttling request took 292.022284ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:05:21.567167       1 request.go:530] Throttling request took 342.211885ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:05:21.616942       1 request.go:530] Throttling request took 392.000044ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:05:21.667040       1 request.go:530] Throttling request took 442.007013ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:05:22.912721       1 gc_controller.go:144] GC'ing orphaned
I0416 22:05:22.917083       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:05:23.024245       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:05:24.126328       1 controller.go:123] Found 0 jobs
I0416 22:05:24.128673       1 controller.go:139] Found 0 cronjobs
I0416 22:05:24.128685       1 controller.go:142] Found 0 groups
I0416 22:05:25.608405       1 wrap.go:47] GET /healthz: (114.193µs) 200 [kube-probe/1.15+ 127.0.0.1:50436]
I0416 22:05:25.701424       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:25.701702       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:05:25.701872       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:05:25.702024       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:05:27.134963       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:05:27.319450       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:28.203992       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:05:30.530388       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:05:30.798587       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 22:05:32.481934       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:05:32.481973       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:05:34.132337       1 controller.go:123] Found 0 jobs
I0416 22:05:34.134833       1 controller.go:139] Found 0 cronjobs
I0416 22:05:34.134845       1 controller.go:142] Found 0 groups
I0416 22:05:35.603278       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:05:35.607999       1 wrap.go:47] GET /healthz: (88.432µs) 200 [kube-probe/1.15+ 127.0.0.1:50470]
I0416 22:05:37.482349       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:05:37.630688       1 request.go:530] Throttling request took 91.908192ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:05:37.680742       1 request.go:530] Throttling request took 141.95277ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:05:37.730755       1 request.go:530] Throttling request took 191.94276ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:05:37.780672       1 request.go:530] Throttling request took 241.853393ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:05:37.830714       1 request.go:530] Throttling request took 291.90712ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:05:37.880644       1 request.go:530] Throttling request took 341.829223ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:05:37.930666       1 request.go:530] Throttling request took 391.843284ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:05:37.980705       1 request.go:530] Throttling request took 441.873989ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:05:37.982861       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:05:38.142120       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.142208       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 22:05:38.142311       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 22:05:38.142333       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 22:05:38.142328037 +0000 UTC m=+3760.296052176)
I0416 22:05:38.143532       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (1.199332ms)
I0416 22:05:38.143564       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 22:05:38.143561587 +0000 UTC m=+3760.297285724)
I0416 22:05:38.144031       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (467.801µs)
I0416 22:05:38.144078       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 22:05:38.144088       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 22:05:38.144085173 +0000 UTC m=+3760.297809310)
I0416 22:05:38.144508       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (420.884µs)
I0416 22:05:38.144551       1 deployment_controller.go:175] Updating deployment coredns
I0416 22:05:38.144557       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 22:05:38.144565       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 22:05:38.144562079 +0000 UTC m=+3760.298286215)
I0416 22:05:38.145222       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (648.791µs)
I0416 22:05:38.145252       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 22:05:38.145249713 +0000 UTC m=+3760.298973851)
I0416 22:05:38.145690       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (437.881µs)
I0416 22:05:38.145715       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 22:05:38.145738       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 22:05:38.145735332 +0000 UTC m=+3760.299459469)
I0416 22:05:38.146093       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (355.717µs)
I0416 22:05:38.146110       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 22:05:38.146114       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 22:05:38.146121       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 22:05:38.146118429 +0000 UTC m=+3760.299842567)
I0416 22:05:38.146595       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (474.049µs)
I0416 22:05:38.146606       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 22:05:38.146603669 +0000 UTC m=+3760.300327805)
I0416 22:05:38.147448       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (841.05µs)
I0416 22:05:38.164498       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.164595       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 22:05:38.166028       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b20e9843a775, ext:3512560811117, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.166446       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:05:38.166458       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b24c89ebe57f, ext:3760320178806, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.166525       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:05:38.166576       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:05:38.166582       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b24c89ebe57f, ext:3760320178806, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.166613       1 update.go:396] Getting unavailable numbers
I0416 22:05:38.166713       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:05:38.166733       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 22:05:38.166740       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:05:38.166744       1 update.go:68] Marking old pods for deletion
I0416 22:05:38.166747       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b24c89f05708, ext:3760320470001, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.166753       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:05:38.166776       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:05:38.166796       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:05:38.166903       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:05:38.166910       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.275603ms)
I0416 22:05:38.166959       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 22:05:38.167444       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b20e9852b837, ext:3512561798511, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.167525       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:05:38.167611       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b24c89fd80bb, ext:3760321332668, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.167659       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:05:38.167683       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:05:38.167687       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b24c89fd80bb, ext:3760321332668, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.167729       1 update.go:396] Getting unavailable numbers
I0416 22:05:38.167755       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:05:38.167844       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 22:05:38.167849       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:05:38.167853       1 update.go:68] Marking old pods for deletion
I0416 22:05:38.167871       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b24c8a017ca0, ext:3760321593751, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.167877       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:05:38.167897       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:05:38.167916       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:05:38.167962       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:05:38.168033       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.034562ms)
I0416 22:05:38.174175       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.174411       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.174626       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (223.992µs)
I0416 22:05:38.174706       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.174792       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (88.166µs)
I0416 22:05:38.174803       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.174853       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (51.421µs)
I0416 22:05:38.174871       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.174977       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (106.875µs)
I0416 22:05:38.175013       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.175165       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (152.631µs)
I0416 22:05:38.175176       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.175220       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (45.387µs)
I0416 22:05:38.175258       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.175335       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (78.935µs)
I0416 22:05:38.175344       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.175387       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (44.019µs)
I0416 22:05:38.175420       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.175461       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (42.497µs)
I0416 22:05:38.175490       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 22:05:38.175526       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (37.771µs)
I0416 22:05:38.175631       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.175740       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.175767       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.175782       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.175811       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.175978       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:05:38.176004       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176008       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:05:38.176053       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:05:38.176068       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176070       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:05:38.176111       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:05:38.176117       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176120       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:05:38.176144       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:05:38.176151       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176153       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:05:38.176179       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:05:38.176184       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176186       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:05:38.176242       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:05:38.176251       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176254       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:05:38.176279       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:05:38.176287       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176290       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:05:38.176327       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:05:38.176334       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176337       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:05:38.176340       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:05:38.176348       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176350       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:05:38.176374       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:05:38.176381       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176384       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:05:38.176402       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:05:38.176408       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176411       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:05:38.176453       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 22:05:38.176461       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176464       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 22:05:38.176466       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:05:38.176470       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176472       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:05:38.176494       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 22:05:38.176502       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176504       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 22:05:38.176522       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 22:05:38.176528       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176532       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 22:05:38.176561       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:05:38.176568       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176570       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:05:38.176604       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:05:38.176613       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176615       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:05:38.176619       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 22:05:38.176626       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176628       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 22:05:38.176654       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:05:38.176662       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176665       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:05:38.176713       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:05:38.176720       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176722       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:05:38.176740       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:05:38.176749       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176752       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:05:38.176765       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:05:38.176772       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:05:38.176775       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:05:38.340727       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.373551       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.710012       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:38.710109       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:05:38.710139       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (3.383µs)
I0416 22:05:38.710166       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:05:38.710172       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (704ns)
I0416 22:05:38.710180       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:05:38.710188       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:05:38.710199       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (403ns)
I0416 22:05:38.710207       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (289ns)
I0416 22:05:38.760677       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:39.041796       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 22:05:41.792971       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:41.822776       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:42.135284       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:05:42.320356       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:42.917384       1 gc_controller.go:144] GC'ing orphaned
I0416 22:05:42.923204       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:05:44.139424       1 controller.go:123] Found 0 jobs
I0416 22:05:44.142291       1 controller.go:139] Found 0 cronjobs
I0416 22:05:44.142305       1 controller.go:142] Found 0 groups
I0416 22:05:45.630664       1 wrap.go:47] GET /healthz: (91.043µs) 200 [kube-probe/1.15+ 127.0.0.1:50522]
I0416 22:05:47.809740       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
I0416 22:05:51.774373       1 request.go:530] Throttling request took 95.759791ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:05:51.819549       1 request.go:530] Throttling request took 140.912753ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:05:51.871340       1 request.go:530] Throttling request took 192.696756ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:05:51.919570       1 request.go:530] Throttling request took 240.910665ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:05:51.969583       1 request.go:530] Throttling request took 290.924236ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:05:52.019608       1 request.go:530] Throttling request took 340.931742ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:05:52.069473       1 request.go:530] Throttling request took 390.792687ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:05:52.119649       1 request.go:530] Throttling request took 440.955184ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:05:52.974560       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 49 items received
I0416 22:05:53.790126       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 0 items received
I0416 22:05:54.146771       1 controller.go:123] Found 0 jobs
I0416 22:05:54.149801       1 controller.go:139] Found 0 cronjobs
I0416 22:05:54.149813       1 controller.go:142] Found 0 groups
I0416 22:05:55.608375       1 wrap.go:47] GET /healthz: (150.043µs) 200 [kube-probe/1.15+ 127.0.0.1:50558]
I0416 22:05:57.135484       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:05:57.320726       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:05:57.796825       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 0 items received
I0416 22:06:02.923440       1 gc_controller.go:144] GC'ing orphaned
I0416 22:06:02.928357       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:06:03.813493       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 22:06:04.153677       1 controller.go:123] Found 0 jobs
I0416 22:06:04.155886       1 controller.go:139] Found 0 cronjobs
I0416 22:06:04.155896       1 controller.go:142] Found 0 groups
I0416 22:06:05.608639       1 wrap.go:47] GET /healthz: (84.556µs) 200 [kube-probe/1.15+ 127.0.0.1:50592]
I0416 22:06:08.083419       1 request.go:530] Throttling request took 91.708825ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:06:08.133391       1 request.go:530] Throttling request took 141.679729ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:06:08.183415       1 request.go:530] Throttling request took 191.691599ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:06:08.233490       1 request.go:530] Throttling request took 241.75577ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:06:08.283434       1 request.go:530] Throttling request took 291.690645ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:06:08.333400       1 request.go:530] Throttling request took 341.637532ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:06:08.383431       1 request.go:530] Throttling request took 391.657697ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:06:08.433453       1 request.go:530] Throttling request took 441.672497ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:06:08.436305       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:06:11.794287       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:11.823777       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:12.135763       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:06:12.321012       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:13.779049       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 184 items received
I0416 22:06:14.160066       1 controller.go:123] Found 0 jobs
I0416 22:06:14.162410       1 controller.go:139] Found 0 cronjobs
I0416 22:06:14.162421       1 controller.go:142] Found 0 groups
I0416 22:06:15.608398       1 wrap.go:47] GET /healthz: (92.911µs) 200 [kube-probe/1.15+ 127.0.0.1:50626]
I0416 22:06:17.295453       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:22.223132       1 request.go:530] Throttling request took 92.792324ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:06:22.273189       1 request.go:530] Throttling request took 142.805432ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:06:22.323141       1 request.go:530] Throttling request took 192.739743ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:06:22.373123       1 request.go:530] Throttling request took 242.722792ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:06:22.423152       1 request.go:530] Throttling request took 292.743416ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:06:22.473171       1 request.go:530] Throttling request took 342.75161ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:06:22.523121       1 request.go:530] Throttling request took 392.695267ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:06:22.573118       1 request.go:530] Throttling request took 442.684376ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:06:22.928686       1 gc_controller.go:144] GC'ing orphaned
I0416 22:06:22.933574       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:06:24.024306       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:06:24.166566       1 controller.go:123] Found 0 jobs
I0416 22:06:24.168981       1 controller.go:139] Found 0 cronjobs
I0416 22:06:24.169005       1 controller.go:142] Found 0 groups
I0416 22:06:24.380173       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:25.000720       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 22:06:25.608710       1 wrap.go:47] GET /healthz: (104.481µs) 200 [kube-probe/1.15+ 127.0.0.1:50658]
I0416 22:06:27.136008       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:06:27.321326       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:28.284070       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:06:28.326114       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 0 items received
I0416 22:06:28.792387       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 22:06:28.803352       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 0 items received
I0416 22:06:29.803273       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 22:06:30.615141       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:06:32.487901       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:06:32.487958       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:06:34.172556       1 controller.go:123] Found 0 jobs
I0416 22:06:34.175009       1 controller.go:139] Found 0 cronjobs
I0416 22:06:34.175021       1 controller.go:142] Found 0 groups
I0416 22:06:35.608211       1 wrap.go:47] GET /healthz: (83.712µs) 200 [kube-probe/1.15+ 127.0.0.1:50692]
I0416 22:06:35.794770       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:06:37.488330       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:06:38.536877       1 request.go:530] Throttling request took 92.257114ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:06:38.586790       1 request.go:530] Throttling request took 142.147614ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:06:38.636816       1 request.go:530] Throttling request took 192.157265ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:06:38.686872       1 request.go:530] Throttling request took 242.206301ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:06:38.736906       1 request.go:530] Throttling request took 292.218419ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:06:38.787161       1 request.go:530] Throttling request took 342.455727ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:06:38.836873       1 request.go:530] Throttling request took 392.142717ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:06:38.886935       1 request.go:530] Throttling request took 442.192148ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:06:38.889354       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:06:41.794603       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:41.795062       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (350.101µs)
I0416 22:06:41.795193       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (77.909µs)
I0416 22:06:41.795328       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (127.49µs)
I0416 22:06:41.795353       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.782µs)
I0416 22:06:41.795574       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 22:06:41.795966       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (64.892µs)
I0416 22:06:41.799264       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (3.890359ms)
I0416 22:06:41.825880       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:42.136541       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:06:42.322352       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:06:42.934408       1 gc_controller.go:144] GC'ing orphaned
I0416 22:06:42.938981       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:06:44.177650       1 controller.go:123] Found 0 jobs
I0416 22:06:44.179518       1 controller.go:139] Found 0 cronjobs
I0416 22:06:44.179528       1 controller.go:142] Found 0 groups
I0416 22:06:45.608637       1 wrap.go:47] GET /healthz: (430.377µs) 200 [kube-probe/1.15+ 127.0.0.1:50744]
I0416 22:06:52.675797       1 request.go:530] Throttling request took 92.378882ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:06:52.725860       1 request.go:530] Throttling request took 142.435268ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:06:52.775945       1 request.go:530] Throttling request took 192.484235ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:06:52.825913       1 request.go:530] Throttling request took 242.430564ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:06:52.875816       1 request.go:530] Throttling request took 292.357895ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:06:52.925888       1 request.go:530] Throttling request took 342.420569ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:06:52.975892       1 request.go:530] Throttling request took 392.409541ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:06:53.025866       1 request.go:530] Throttling request took 442.380188ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:06:54.185462       1 controller.go:123] Found 0 jobs
I0416 22:06:54.188213       1 controller.go:139] Found 0 cronjobs
I0416 22:06:54.188242       1 controller.go:142] Found 0 groups
I0416 22:06:55.611786       1 wrap.go:47] GET /healthz: (95.251µs) 200 [kube-probe/1.15+ 127.0.0.1:50780]
I0416 22:06:56.320405       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 0 items received
I0416 22:06:57.136808       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:06:57.322770       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:02.939440       1 gc_controller.go:144] GC'ing orphaned
I0416 22:07:02.944434       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:07:04.191831       1 controller.go:123] Found 0 jobs
I0416 22:07:04.194593       1 controller.go:139] Found 0 cronjobs
I0416 22:07:04.194606       1 controller.go:142] Found 0 groups
I0416 22:07:04.457419       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:05.608395       1 wrap.go:47] GET /healthz: (157.594µs) 200 [kube-probe/1.15+ 127.0.0.1:50814]
I0416 22:07:08.989926       1 request.go:530] Throttling request took 94.382648ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:07:09.039870       1 request.go:530] Throttling request took 144.329801ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:07:09.093652       1 request.go:530] Throttling request took 198.093352ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:07:09.139873       1 request.go:530] Throttling request took 244.30731ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:07:09.189931       1 request.go:530] Throttling request took 294.33845ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:07:09.239897       1 request.go:530] Throttling request took 344.317269ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:07:09.290266       1 request.go:530] Throttling request took 394.696384ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:07:09.339954       1 request.go:530] Throttling request took 444.340686ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:07:09.342041       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:07:11.794887       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:11.826269       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:12.137108       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:07:12.323168       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:14.198335       1 controller.go:123] Found 0 jobs
I0416 22:07:14.200498       1 controller.go:139] Found 0 cronjobs
I0416 22:07:14.200510       1 controller.go:142] Found 0 groups
I0416 22:07:15.608749       1 wrap.go:47] GET /healthz: (85.653µs) 200 [kube-probe/1.15+ 127.0.0.1:50848]
I0416 22:07:15.954883       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 22:07:16.962672       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 22:07:22.944727       1 gc_controller.go:144] GC'ing orphaned
I0416 22:07:22.949302       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:07:23.128532       1 request.go:530] Throttling request took 91.740536ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:07:23.178540       1 request.go:530] Throttling request took 141.737078ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:07:23.228672       1 request.go:530] Throttling request took 191.860466ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:07:23.278652       1 request.go:530] Throttling request took 241.831293ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:07:23.328565       1 request.go:530] Throttling request took 291.733608ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:07:23.378614       1 request.go:530] Throttling request took 341.761734ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:07:23.428632       1 request.go:530] Throttling request took 391.767192ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:07:23.478607       1 request.go:530] Throttling request took 441.726081ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:07:23.789666       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 22:07:24.027984       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:07:24.204715       1 controller.go:123] Found 0 jobs
I0416 22:07:24.207382       1 controller.go:139] Found 0 cronjobs
I0416 22:07:24.207393       1 controller.go:142] Found 0 groups
I0416 22:07:24.529893       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 22:07:25.608618       1 wrap.go:47] GET /healthz: (102.952µs) 200 [kube-probe/1.15+ 127.0.0.1:50880]
I0416 22:07:27.137348       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:07:27.323395       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:28.366644       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:07:30.707870       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:07:32.495188       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:07:32.495223       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:07:34.211678       1 controller.go:123] Found 0 jobs
I0416 22:07:34.214480       1 controller.go:139] Found 0 cronjobs
I0416 22:07:34.214491       1 controller.go:142] Found 0 groups
I0416 22:07:34.780087       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 0 items received
I0416 22:07:34.813735       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:35.608716       1 wrap.go:47] GET /healthz: (93.748µs) 200 [kube-probe/1.15+ 127.0.0.1:50914]
I0416 22:07:35.817780       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.159610742db284f7, uid a709a88b-6d26-4fd6-a88d-491aef2f9f34, event type delete
I0416 22:07:35.817899       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.1596107439b5fda2, uid 456cb65f-a128-42e9-8d7d-892a7435caf3, event type delete
I0416 22:07:35.817910       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.1596107439b9fbe8, uid 21d72e03-b740-4d75-864c-31fd73268f50, event type delete
I0416 22:07:35.817918       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.1596107439be04e5, uid 31a179ee-7234-4bfb-96e1-a3b91c413772, event type delete
I0416 22:07:35.817956       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.159610743c1620d2, uid bbddbe72-f0d3-4076-9a49-8441eb435a74, event type delete
I0416 22:07:35.817963       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.159610745badb731, uid 4c538d5c-bd73-4e54-b2ad-4e7e21db3a51, event type delete
I0416 22:07:35.817970       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.15961074e0230cb8, uid f9baa9fc-50be-4c0d-8486-3354037c305e, event type delete
I0416 22:07:35.818019       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.1596107531c9a38a, uid 5e901066-5f4a-47d3-8060-d30b4aca4625, event type delete
I0416 22:07:35.818030       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-zcdpb.1596104aa15f71d0, uid 0ee6c42a-c49a-4af6-9976-d9d69bac505a, event type delete
I0416 22:07:35.818038       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-zcdpb.159610743e0a685f, uid b22eb248-6740-458f-821f-f2dc1009f12f, event type delete
I0416 22:07:35.818075       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-zcdpb.15961074434a951c, uid e07bfd68-0b39-457f-ab0b-f146db68835a, event type delete
I0416 22:07:35.818082       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-zcdpb.159610756dbbcc4a, uid 5257d933-0fea-476f-b1ef-76f3f573c373, event type delete
I0416 22:07:35.818089       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-zcdpb.15961077b436eb5e, uid f4a272ff-1053-4e7a-86f8-d4277cf8f884, event type delete
I0416 22:07:35.818138       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-zcdpb.15961077d5f8b685, uid 3924b504-4005-4126-b5e6-49c536f026b7, event type delete
I0416 22:07:35.818146       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-zcdpb.15961078039a8d44, uid 64db7ab9-7eb8-442e-b2c2-034a33a9eda7, event type delete
I0416 22:07:35.818153       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.1596104abedf4c1e, uid eec9b5d5-2243-4ac6-a14b-61a1b7c6e895, event type delete
I0416 22:07:35.818187       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.159610743e321a22, uid 7b546369-a527-46da-9dfe-3f9291428dbb, event type delete
I0416 22:07:35.818196       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.1596107444fbec8d, uid 3a29802e-7d4e-4cfd-ac95-346604dc7aad, event type delete
I0416 22:07:35.818204       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.159610748ab647ff, uid 5d62bfd4-b5f7-4701-bf32-ac1adf9936f6, event type delete
I0416 22:07:35.818217       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.1596107565c59bd6, uid de9f3507-dd80-4384-941c-f857a74dc3fd, event type delete
I0416 22:07:35.819861       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.159610784a51a519, uid fee7aabb-14c8-47b3-8ed0-93eff8c02556, event type delete
I0416 22:07:35.819942       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.15961078c4148671, uid 32a87fd8-a1c0-4a29-881c-56f1bffb2bc5, event type delete
I0416 22:07:35.819951       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.15961078e411ff64, uid a96d0596-ffd3-4251-ae9e-45fd3efafcee, event type delete
I0416 22:07:35.819959       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.15961078e442a8d3, uid 9d995437-b178-49e5-96bb-607464b7a9d0, event type delete
I0416 22:07:35.820021       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.15961078fb9c8946, uid 280b4645-79c1-4f31-a43a-8b3d28cc5d35, event type delete
I0416 22:07:35.820030       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name event-exporter-v0.2.4-65d8d98768-n6vvr.159610792652d5de, uid a9523191-00b3-4512-b7d5-1a3954e84f5d, event type delete
I0416 22:07:35.820038       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4-26sjq.1596104acbfd325f, uid bd01033e-f38c-4a0f-b296-f5d48018a53a, event type delete
I0416 22:07:35.820092       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4-26sjq.159610743e64867f, uid a22b8638-733f-4f47-98d2-5c3876620bf8, event type delete
I0416 22:07:35.820100       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4-26sjq.1596107443ba03f0, uid 12609e31-f215-4884-ac21-8243c4fede6b, event type delete
I0416 22:07:35.820108       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4-26sjq.1596107582aa8977, uid 86b78914-5d39-4e45-8c9b-1289f5d20b03, event type delete
I0416 22:07:35.820141       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4-26sjq.15961079f61f479a, uid ae3a363f-7c10-4dd5-800d-c684e188035d, event type delete
I0416 22:07:35.820161       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4-26sjq.1596107a0438c8f6, uid 29404e1b-aef0-4100-ac2c-4bf8be36acb9, event type delete
I0416 22:07:35.820170       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-scaler-7db4984bf4-26sjq.1596107a1f46c947, uid f59733bb-7841-4614-9dfc-ab9e71cf9673, event type delete
I0416 22:07:35.820207       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c.1596107442df7b62, uid 142061fe-710a-48af-90a6-82eada074790, event type delete
I0416 22:07:35.820213       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c.159610748b363c40, uid e08b9b4b-df26-4955-b52d-97d535681387, event type delete
I0416 22:07:35.820220       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c.159610748b65ec86, uid 7e885b4b-3a81-459d-a168-4ab0b9063e50, event type delete
I0416 22:07:35.820287       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c.1596107546c10e63, uid 1ef95946-3fbd-4e79-b032-8da5f00a1b2d, event type delete
I0416 22:07:35.820295       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c.1596107c0f37f187, uid eb1ec8f7-837c-46a9-b1f2-48ce0d90a837, event type delete
I0416 22:07:35.820302       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c.1596107c0f3c6962, uid 86546e9e-300a-4bdf-a8a7-1158a3964c6e, event type delete
I0416 22:07:35.820362       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c.1596107c0fd257b3, uid 3f0a911d-5945-4a50-8a7c-1ff6b239e51e, event type delete
I0416 22:07:35.820370       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-4tl8c.1596107c0fe340d9, uid 5780c5db-7bde-4e00-9f6a-88b35f08e2b4, event type delete
I0416 22:07:35.820377       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-n97bf.1596107b9784cb1a, uid 5bea4e38-cc6d-49b7-827c-f21a78d6dc7f, event type delete
I0416 22:07:35.820429       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-n97bf.1596107c01c164a5, uid 21d1e04f-0f54-4300-8789-ecbd849535f1, event type delete
I0416 22:07:35.820436       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-n97bf.1596107c0f89d972, uid bea6d5cf-9fab-4535-9997-f99368dd4420, event type delete
I0416 22:07:35.820444       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-n97bf.1596107c1d889cd7, uid a1d5afba-2ef6-4e54-90f6-3c48c67a516a, event type delete
I0416 22:07:35.820493       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-n97bf.1596107c2a3ff0e4, uid e28ce5fd-b7e7-4f8b-b280-a4430abd138e, event type delete
I0416 22:07:35.820500       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-n97bf.1596107c2ab77348, uid 291aafd1-2c13-46b2-a0b3-2516cac9193e, event type delete
I0416 22:07:35.820507       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-n97bf.1596107c33553dd5, uid 15e801b6-5c4e-4fa3-901f-8b7a2d941ee9, event type delete
I0416 22:07:35.825867       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-n97bf.1596107c41ae4b42, uid b1dfceb2-f2a2-4b90-b6d2-2414b854f269, event type delete
I0416 22:07:35.825981       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596107c53c4dff0, uid 6780ca47-1578-4276-a294-b3bfc113bc7d, event type delete
I0416 22:07:35.825993       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-vqwbk.1596107c53e22a9b, uid 2985bf9d-8407-454f-9803-4cb8bb80f5d5, event type delete
I0416 22:07:35.826028       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0.159610743f7d0261, uid 8e5da3c0-8569-4bb9-8f00-8658020e1e28, event type delete
I0416 22:07:35.826038       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0.1596107ae274681f, uid f209d7c6-be67-4c66-94c2-de6bc7ad43fd, event type delete
I0416 22:07:35.826045       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0.1596107b96acb421, uid eff18e01-407d-456a-85f8-0968ec2442fe, event type delete
I0416 22:07:35.826101       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0.1596107c531751cd, uid a62e0c08-2100-4ad1-9290-695eaf78bc39, event type delete
I0416 22:07:35.826107       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.1596104ab7a9718a, uid e7f814eb-dc3e-45b9-9e48-f719fc2abc90, event type delete
I0416 22:07:35.826114       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.159610743e631ac6, uid e7a0858a-5602-4dd9-a0e6-e9525cc4b326, event type delete
I0416 22:07:35.826167       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.15961074448e6681, uid 71a86e81-fd7a-4944-a4b2-31de58897fa5, event type delete
I0416 22:07:35.826176       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.159610748b4110f8, uid 4887fafa-9a39-42d9-b4e6-2c9eee284c44, event type delete
I0416 22:07:35.826183       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.159610748b6e0623, uid e692f780-c48c-46bd-8f15-7b308fa201bf, event type delete
I0416 22:07:35.826285       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.1596107590a16643, uid 6c86f0d9-7eaa-46fd-a671-dbef3f8a7061, event type delete
I0416 22:07:35.826311       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.15961078e9852298, uid dcf8fb8e-b141-4f96-975b-c01763a5f1e9, event type delete
I0416 22:07:35.826319       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.15961078ff69f93f, uid ab65062f-c188-41c7-baca-1bb2a3fdfec6, event type delete
I0416 22:07:35.826359       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.159610792a2975fd, uid 55adc1fd-d1fa-4d47-a543-25a65fecc802, event type delete
I0416 22:07:35.826372       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.159610792a85b0f6, uid abfeb73c-0aff-459d-9327-15276705f007, event type delete
I0416 22:07:35.826394       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.1596107953fca3f3, uid 126ca54f-aa31-482b-a035-5a854888aae8, event type delete
I0416 22:07:35.826433       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.159610799ffae406, uid 55988686-092a-49e8-8e4b-17c7ecd1b493, event type delete
I0416 22:07:35.826439       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.1596107b9c9d2fab, uid be301299-bbd1-4246-b1b6-8849cf91fcc6, event type delete
I0416 22:07:35.826446       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485-5td9x.1596107b9cae97fc, uid 53a36707-8688-4537-b3e5-3f70ada49b20, event type delete
I0416 22:07:35.826502       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-5858bf5485.1596107b9b205e06, uid fc149104-fafc-49d8-b4fb-f44df22cf26e, event type delete
I0416 22:07:35.826509       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-77858557dc-gwsdj.1596107a07e59dc8, uid f8279cfc-6db8-403f-bf81-f890aee5d26f, event type delete
I0416 22:07:35.826525       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-77858557dc-gwsdj.1596107a83589112, uid eb42b51f-41ed-4c2a-8ab5-777ce716c883, event type delete
I0416 22:07:35.826579       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-77858557dc-gwsdj.1596107a9b07bcd5, uid db6ff93e-cc9e-4b09-8ca2-c6458e64a130, event type delete
I0416 22:07:35.826587       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-77858557dc-gwsdj.1596107ad54176cc, uid c42f6571-ae82-4d4a-bee8-5970fffd0c9c, event type delete
I0416 22:07:35.826594       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-77858557dc-gwsdj.1596107ad66e05ff, uid c9881c29-2466-41ad-ab6f-f01e1e752762, event type delete
I0416 22:07:35.826648       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-77858557dc-gwsdj.1596107af6e74f8b, uid 7b8288e1-dfd5-45b8-b02e-10db3215705a, event type delete
I0416 22:07:35.826655       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-77858557dc-gwsdj.1596107b50fea680, uid bd56b3b2-a839-4d42-91b7-3931cd0f689b, event type delete
I0416 22:07:35.826662       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1-77858557dc.1596107a06c602c4, uid d7035ec6-7381-49d5-b31b-6cb6fa9cf28a, event type delete
I0416 22:07:35.826720       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1.1596107a05914197, uid 553c40ac-c59e-4d93-9a4c-b98ba972c998, event type delete
I0416 22:07:35.826728       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name heapster-v1.6.0-beta.1.1596107b99ecdd6e, uid 7df3cfcc-4630-4080-936c-2ee845dfbb2e, event type delete
I0416 22:07:35.826734       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df-4ggmd.1596104abb5dc659, uid 739dce12-4416-4cdc-827e-529225c9c690, event type delete
I0416 22:07:35.826775       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df-4ggmd.159610743cefa345, uid 03aca6f2-58d3-40e1-8074-8d11f58b0b68, event type delete
I0416 22:07:35.826796       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df-4ggmd.15961074429ba5a9, uid 52307c78-6e21-460d-a6ff-edd3968c9c0e, event type delete
I0416 22:07:35.826803       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df-4ggmd.15961075602ce891, uid 73508d7e-bf53-4f91-9945-47cd7279177a, event type delete
I0416 22:07:35.826841       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df-4ggmd.15961076ee235218, uid 9f2e32a3-5145-4c52-8c76-577c779be0c0, event type delete
I0416 22:07:35.826848       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df-4ggmd.1596107712595511, uid 1529a577-f1b2-4384-a325-79a5c158218b, event type delete
I0416 22:07:35.826855       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-dns-autoscaler-97df449df-4ggmd.1596107739973108, uid f0fa479b-325b-4ec9-a04f-33575c28e6cd, event type delete
I0416 22:07:35.826912       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-proxy-e2e-test-peterhornyack-minion-group-06gd.15961074a32429d8, uid af78203c-f7b7-4779-84f3-9a95cba95512, event type delete
I0416 22:07:35.826920       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-proxy-e2e-test-peterhornyack-minion-group-06gd.15961074b3d3357a, uid 8918a1eb-0a44-4d43-ae45-707bc6c2c8cc, event type delete
I0416 22:07:35.826928       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kube-proxy-e2e-test-peterhornyack-minion-group-06gd.15961074d97140e8, uid 4df41d8b-39a4-4186-bb2a-ca46f4560ced, event type delete
I0416 22:07:35.826981       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8-t5nl6.1596104ab958c164, uid 30a2f88e-117e-4109-a0d6-62e03cf85571, event type delete
I0416 22:07:35.826989       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8-t5nl6.159610743ceed99d, uid 554cf0e6-67ab-4db8-ae73-403cd8c28d5a, event type delete
I0416 22:07:35.826996       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8-t5nl6.1596107442a2aaf8, uid 8f785ffd-0c6d-41fc-9414-acdeaf921063, event type delete
I0416 22:07:35.827053       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8-t5nl6.15961075a3c3a44e, uid b58bbbf3-efe2-4895-8aee-4e8a93acb04e, event type delete
I0416 22:07:35.827061       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8-t5nl6.15961079a4da4c38, uid f9a72764-06ba-4cfe-9f1a-78da3d8b2ed2, event type delete
I0416 22:07:35.827068       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8-t5nl6.15961079d1e4b72d, uid 124f9f95-1a44-4ffc-8430-0b1973b730f0, event type delete
I0416 22:07:35.827118       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name kubernetes-dashboard-85bcf5dbf8-t5nl6.1596107a0cce9022, uid 2fe5e58c-e1de-4e86-90a8-e44a6e21038d, event type delete
I0416 22:07:35.827126       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.1596104ac4faef73, uid e03acab5-1d7b-4556-a3ba-b6c67dfcba61, event type delete
I0416 22:07:35.827133       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.159610743f76cb22, uid 99880d1b-b8e7-4865-a884-0906fa9c35fc, event type delete
I0416 22:07:35.827172       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.159610744576f3ac, uid 43ba8784-d957-4ef3-a94c-652cd603ff54, event type delete
I0416 22:07:35.827179       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.159610748b681653, uid 957ed491-1527-4c6a-8c48-7dc3b483e20b, event type delete
I0416 22:07:35.827206       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.15961076e376bbe7, uid 971024c4-60c1-44bd-a3ea-95fa47717bb4, event type delete
I0416 22:07:35.829433       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.15961077771294b9, uid 416b25bc-a0c3-4025-9fec-623ebebea254, event type delete
I0416 22:07:35.829455       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.15961077d34d1eb8, uid 3e6eda02-b59e-4991-8a14-517cbc9d5149, event type delete
I0416 22:07:35.829463       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name l7-default-backend-8f479dd9-wbtkw.1596107969b4878e, uid 462514bf-c36c-494f-bf17-0cf999c958af, event type delete
I0416 22:07:35.829545       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.15961074435d35e6, uid be09f945-01a8-4980-a7a6-09b43e93bb8b, event type delete
I0416 22:07:35.829554       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.159610748b6a8541, uid a83bafa3-b071-4dfe-9d21-52309b058a71, event type delete
I0416 22:07:35.829561       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.159610754e30a241, uid a9a6482d-36d5-4ade-8e55-6d417a312b27, event type delete
I0416 22:07:35.829627       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.1596107610730775, uid 0965f5ba-71ab-4f8a-90c0-6f22b5db7ef7, event type delete
I0416 22:07:35.829635       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.15961076f36e7a2b, uid 3899650e-2446-4b3a-bbf5-5032db8825e0, event type delete
I0416 22:07:35.829643       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.15961077536630df, uid a2c3fb33-f69d-42d8-b415-cf7068b93d5d, event type delete
I0416 22:07:35.829715       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.159610775393eadf, uid 1f386b0c-17cd-421f-a13e-6eb9338d8822, event type delete
I0416 22:07:35.829725       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.15961078c236b7f0, uid 5e06fa4e-e0d7-4d33-bd5a-d54df69970c7, event type delete
I0416 22:07:35.829739       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.15961078e454a582, uid f3ade500-0cfa-4d78-9569-0216b63a00ee, event type delete
I0416 22:07:35.829793       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1-m4h7x.1596107951504c0f, uid fb2b7443-1bc2-4a52-b36f-b24f2d24f916, event type delete
I0416 22:07:35.829801       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metadata-proxy-v0.1.1596107441c52cff, uid cdb1a472-b0f8-49d3-a7fc-7a362174828f, event type delete
I0416 22:07:35.829809       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.1596104aad0adc24, uid c64f8be4-a0b4-4be3-a191-ad75fa3da308, event type delete
I0416 22:07:35.829869       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.159610743caf7d9b, uid 3c3b21ae-8b54-44dd-839f-bbee14026f77, event type delete
I0416 22:07:35.829876       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.1596107442b6337d, uid e54aec89-6346-49c1-804f-682ebcdb2945, event type delete
I0416 22:07:35.829884       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.15961075313ddeca, uid 2877a3a3-51ef-4b2b-bb71-6ad8db97cbb4, event type delete
I0416 22:07:35.829936       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.15961076ee9ef070, uid a7d6315b-327a-4d89-b306-548c5c2846d5, event type delete
I0416 22:07:35.829945       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.1596107717f3afd9, uid 41fd67e0-b995-4f25-a09c-cfb191a25f7f, event type delete
I0416 22:07:35.829952       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.1596107745ea6977, uid 227cd8e3-6e2d-4dbf-a9d2-fc480c7d3925, event type delete
I0416 22:07:35.830004       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.159610774a396fe9, uid 472204e5-051d-4500-99b1-5d777fc3c911, event type delete
I0416 22:07:35.830012       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.15961078c647336d, uid 46ffb334-3cbc-49d2-812d-70e7b1f7e641, event type delete
I0416 22:07:35.830022       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.15961078ed10341c, uid f8df503e-e2e6-47f4-b9a3-bf1938cd3119, event type delete
I0416 22:07:35.830067       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.1596107921e15b91, uid 1472317a-b1e8-4c89-9988-f0eac49f0ba2, event type delete
I0416 22:07:35.830091       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.1596107acf3a232f, uid 1478f0bc-c6c4-4ca8-8281-0e68693004c5, event type delete
I0416 22:07:35.830098       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf-xl48c.1596107acf3ea987, uid 2b3b2558-1bca-4ac1-94b1-f4727a236312, event type delete
I0416 22:07:35.830135       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-677c578bdf.1596107acea23526, uid a318a5fc-d2fb-4a76-b386-f28066df74e7, event type delete
I0416 22:07:35.830144       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-7d9cf58c5c-xrmt9.159610793d8a3a3d, uid fd8b59b0-6151-4069-9e03-cd69207a9b3f, event type delete
I0416 22:07:35.830163       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-7d9cf58c5c-xrmt9.15961079dfda86c2, uid 7255ff1d-912c-42bf-be4f-2dd2d94526ba, event type delete
I0416 22:07:35.830210       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-7d9cf58c5c-xrmt9.15961079f3471182, uid b24e40cc-5275-4838-86ed-297f6719ea7f, event type delete
I0416 22:07:35.830219       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-7d9cf58c5c-xrmt9.1596107a394f3e82, uid 00153495-2ae9-4a98-b2ec-2a2a0b29e4d9, event type delete
I0416 22:07:35.831262       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-7d9cf58c5c-xrmt9.1596107a39852e52, uid 311fdb86-0332-478f-b7b4-ffb49b02debb, event type delete
I0416 22:07:35.831364       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-7d9cf58c5c-xrmt9.1596107a4ecc0bf5, uid b0dde78f-7d4c-40e8-b7c6-927576ec4252, event type delete
I0416 22:07:35.831394       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-7d9cf58c5c-xrmt9.1596107a86079ad4, uid c0acd573-ad03-414c-9b4e-e0d78a0bdd4c, event type delete
I0416 22:07:35.831402       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1-7d9cf58c5c.159610793c549668, uid 29249f12-ca97-4581-a1b1-f69c0fb7f800, event type delete
I0416 22:07:35.831450       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1.159610793b56af39, uid e33d7700-20ce-4cd5-8550-8074b0733d08, event type delete
I0416 22:07:35.831459       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name metrics-server-v0.3.1.1596107acd513b72, uid 06429261-5add-4fd7-9be9-275633cf673f, event type delete
I0416 22:07:35.992743       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:07:37.495599       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:07:39.442494       1 request.go:530] Throttling request took 92.279905ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:07:39.492494       1 request.go:530] Throttling request took 142.268843ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:07:39.542520       1 request.go:530] Throttling request took 192.285528ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:07:39.592494       1 request.go:530] Throttling request took 242.249757ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:07:39.642484       1 request.go:530] Throttling request took 292.232578ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:07:39.692483       1 request.go:530] Throttling request took 342.222994ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:07:39.742510       1 request.go:530] Throttling request took 390.189054ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:07:39.792455       1 request.go:530] Throttling request took 440.127519ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:07:39.794853       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:07:41.795159       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:41.826451       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:42.137586       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:07:42.324353       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:42.949643       1 gc_controller.go:144] GC'ing orphaned
I0416 22:07:42.954316       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:07:43.813041       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:07:43.835040       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:07:44.220905       1 controller.go:123] Found 0 jobs
I0416 22:07:44.225321       1 controller.go:139] Found 0 cronjobs
I0416 22:07:44.225334       1 controller.go:142] Found 0 groups
I0416 22:07:45.608419       1 wrap.go:47] GET /healthz: (102.506µs) 200 [kube-probe/1.15+ 127.0.0.1:50966]
I0416 22:07:49.109420       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 22:07:51.560411       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:53.583254       1 request.go:530] Throttling request took 90.943532ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:07:53.599194       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:07:53.633267       1 request.go:530] Throttling request took 140.949855ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:07:53.683202       1 request.go:530] Throttling request took 190.884834ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:07:53.733347       1 request.go:530] Throttling request took 241.022315ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:07:53.783279       1 request.go:530] Throttling request took 290.949719ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:07:53.833361       1 request.go:530] Throttling request took 341.024385ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:07:53.883290       1 request.go:530] Throttling request took 390.950067ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:07:53.933352       1 request.go:530] Throttling request took 440.985769ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:07:53.948625       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:07:54.229382       1 controller.go:123] Found 0 jobs
I0416 22:07:54.231635       1 controller.go:139] Found 0 cronjobs
I0416 22:07:54.231645       1 controller.go:142] Found 0 groups
I0416 22:07:55.608543       1 wrap.go:47] GET /healthz: (93.871µs) 200 [kube-probe/1.15+ 127.0.0.1:51002]
I0416 22:07:57.137830       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:07:57.324631       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:07:57.797145       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 0 items received
I0416 22:08:02.954599       1 gc_controller.go:144] GC'ing orphaned
I0416 22:08:02.959276       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:08:03.775123       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 22:08:04.237572       1 controller.go:123] Found 0 jobs
I0416 22:08:04.242778       1 controller.go:139] Found 0 cronjobs
I0416 22:08:04.242792       1 controller.go:142] Found 0 groups
I0416 22:08:04.280930       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 143 items received
I0416 22:08:05.608351       1 wrap.go:47] GET /healthz: (110.428µs) 200 [kube-probe/1.15+ 127.0.0.1:51038]
I0416 22:08:07.714968       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 22:08:07.784780       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 22:08:09.895294       1 request.go:530] Throttling request took 92.711485ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:08:09.945421       1 request.go:530] Throttling request took 142.789152ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:08:09.995319       1 request.go:530] Throttling request took 192.721506ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:08:10.045310       1 request.go:530] Throttling request took 242.689036ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:08:10.095300       1 request.go:530] Throttling request took 292.674326ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:08:10.145290       1 request.go:530] Throttling request took 342.653389ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:08:10.195304       1 request.go:530] Throttling request took 392.660103ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:08:10.245338       1 request.go:530] Throttling request took 442.685518ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:08:10.247601       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:08:11.796865       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:08:11.826681       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:08:12.138545       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:08:12.324964       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:08:14.247201       1 controller.go:123] Found 0 jobs
I0416 22:08:14.250217       1 controller.go:139] Found 0 cronjobs
I0416 22:08:14.250244       1 controller.go:142] Found 0 groups
I0416 22:08:14.811199       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 466 items received
I0416 22:08:15.608673       1 wrap.go:47] GET /healthz: (91.874µs) 200 [kube-probe/1.15+ 127.0.0.1:51074]
I0416 22:08:22.959569       1 gc_controller.go:144] GC'ing orphaned
I0416 22:08:22.964385       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:08:24.033689       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:08:24.036109       1 request.go:530] Throttling request took 90.923614ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:08:24.086147       1 request.go:530] Throttling request took 140.944966ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:08:24.136114       1 request.go:530] Throttling request took 190.890318ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:08:24.186168       1 request.go:530] Throttling request took 240.930444ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:08:24.236102       1 request.go:530] Throttling request took 290.852547ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:08:24.254526       1 controller.go:123] Found 0 jobs
I0416 22:08:24.256799       1 controller.go:139] Found 0 cronjobs
I0416 22:08:24.256811       1 controller.go:142] Found 0 groups
I0416 22:08:24.286104       1 request.go:530] Throttling request took 340.828844ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:08:24.336132       1 request.go:530] Throttling request took 390.839705ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:08:24.386146       1 request.go:530] Throttling request took 440.833741ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:08:25.608600       1 wrap.go:47] GET /healthz: (129.384µs) 200 [kube-probe/1.15+ 127.0.0.1:51108]
I0416 22:08:26.129394       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 22:08:27.138865       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:08:27.325303       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:08:28.455829       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:08:30.795449       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:08:32.500952       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:08:32.500989       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:08:34.260461       1 controller.go:123] Found 0 jobs
I0416 22:08:34.262553       1 controller.go:139] Found 0 cronjobs
I0416 22:08:34.262562       1 controller.go:142] Found 0 groups
I0416 22:08:35.608476       1 wrap.go:47] GET /healthz: (90.429µs) 200 [kube-probe/1.15+ 127.0.0.1:51142]
I0416 22:08:36.209523       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:08:37.501421       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:08:40.348155       1 request.go:530] Throttling request took 91.56809ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:08:40.398165       1 request.go:530] Throttling request took 141.559061ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:08:40.448115       1 request.go:530] Throttling request took 191.502506ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:08:40.498140       1 request.go:530] Throttling request took 241.502449ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:08:40.548160       1 request.go:530] Throttling request took 291.526382ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:08:40.598159       1 request.go:530] Throttling request took 341.512791ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:08:40.648102       1 request.go:530] Throttling request took 391.448241ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:08:40.698108       1 request.go:530] Throttling request took 441.442495ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:08:40.701183       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:08:41.371864       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-xtf58.1596107f87275113, uid ac519ba4-7ba3-48fe-acbf-9b3e5a3dff9a, event type delete
I0416 22:08:41.371958       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-xtf58.1596107fbaac33d4, uid eb11a466-a1c6-47ef-be41-066f88db6aea, event type delete
I0416 22:08:41.371970       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-xtf58.1596107fc542da85, uid db2dabaa-1293-409b-8d8b-08037d15ad4e, event type delete
I0416 22:08:41.371978       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-xtf58.1596107fd4e313d0, uid c37534ac-f14f-47d7-9c24-551a099c906f, event type delete
I0416 22:08:41.372019       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-xtf58.1596107fd5599930, uid a02b3992-bc8b-4661-8f4e-0b1fb0aa242b, event type delete
I0416 22:08:41.372026       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-xtf58.1596107fe87c452f, uid ae0057c8-51b1-4b43-8622-a361713c5c3e, event type delete
I0416 22:08:41.372032       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0-xtf58.159610800705c47a, uid 7b310662-973c-44c1-8d2f-bdf0293f0122, event type delete
I0416 22:08:41.372040       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name fluentd-gcp-v3.2.0.1596107f8443e1e0, uid b8e8292a-40dd-4873-a5df-8607fad301d3, event type delete
I0416 22:08:41.797141       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:08:41.826891       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:08:42.139429       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:08:42.326169       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:08:42.563366       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 22:08:42.965397       1 gc_controller.go:144] GC'ing orphaned
I0416 22:08:42.970333       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:08:44.266721       1 controller.go:123] Found 0 jobs
I0416 22:08:44.269119       1 controller.go:139] Found 0 cronjobs
I0416 22:08:44.269138       1 controller.go:142] Found 0 groups
I0416 22:08:44.801898       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 22:08:45.179839       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 22:08:45.391399       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:08:45.608474       1 wrap.go:47] GET /healthz: (107.159µs) 200 [kube-probe/1.15+ 127.0.0.1:51194]
I0416 22:08:47.794886       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 22:08:48.783663       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 22:08:49.019741       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 22:08:49.340748       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 22 items received
I0416 22:08:54.272911       1 controller.go:123] Found 0 jobs
I0416 22:08:54.274995       1 controller.go:139] Found 0 cronjobs
I0416 22:08:54.275006       1 controller.go:142] Found 0 groups
I0416 22:08:54.488992       1 request.go:530] Throttling request took 91.78234ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:08:54.539072       1 request.go:530] Throttling request took 141.851143ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:08:54.589074       1 request.go:530] Throttling request took 191.840631ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:08:54.638966       1 request.go:530] Throttling request took 241.7352ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:08:54.689002       1 request.go:530] Throttling request took 291.750367ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:08:54.739016       1 request.go:530] Throttling request took 341.765861ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:08:54.788995       1 request.go:530] Throttling request took 391.728295ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:08:54.839004       1 request.go:530] Throttling request took 441.724055ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:08:55.609567       1 wrap.go:47] GET /healthz: (84.176µs) 200 [kube-probe/1.15+ 127.0.0.1:51230]
I0416 22:08:57.139684       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:08:57.326357       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:02.971681       1 gc_controller.go:144] GC'ing orphaned
I0416 22:09:02.976297       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:09:04.278843       1 controller.go:123] Found 0 jobs
I0416 22:09:04.281075       1 controller.go:139] Found 0 cronjobs
I0416 22:09:04.281086       1 controller.go:142] Found 0 groups
I0416 22:09:05.608470       1 wrap.go:47] GET /healthz: (159.376µs) 200 [kube-probe/1.15+ 127.0.0.1:51264]
I0416 22:09:05.840775       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 0 items received
I0416 22:09:10.801554       1 request.go:530] Throttling request took 93.393433ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:09:10.851568       1 request.go:530] Throttling request took 141.253367ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:09:10.901691       1 request.go:530] Throttling request took 191.35429ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:09:10.951586       1 request.go:530] Throttling request took 241.233104ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:09:11.001636       1 request.go:530] Throttling request took 291.269216ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:09:11.052083       1 request.go:530] Throttling request took 341.666534ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:09:11.101595       1 request.go:530] Throttling request took 391.206614ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:09:11.151640       1 request.go:530] Throttling request took 441.210681ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:09:11.154339       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:09:11.797429       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:11.827163       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:12.139931       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:09:12.326598       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:14.284807       1 controller.go:123] Found 0 jobs
I0416 22:09:14.287058       1 controller.go:139] Found 0 cronjobs
I0416 22:09:14.287077       1 controller.go:142] Found 0 groups
I0416 22:09:15.608658       1 wrap.go:47] GET /healthz: (79.109µs) 200 [kube-probe/1.15+ 127.0.0.1:51296]
I0416 22:09:22.976591       1 gc_controller.go:144] GC'ing orphaned
I0416 22:09:22.981361       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:09:24.290834       1 controller.go:123] Found 0 jobs
I0416 22:09:24.293417       1 controller.go:139] Found 0 cronjobs
I0416 22:09:24.293430       1 controller.go:142] Found 0 groups
I0416 22:09:24.941408       1 request.go:530] Throttling request took 91.014926ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:09:24.991382       1 request.go:530] Throttling request took 140.962973ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:09:25.041669       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:09:25.041750       1 request.go:530] Throttling request took 191.365609ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:09:25.092736       1 request.go:530] Throttling request took 242.302301ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:09:25.141560       1 request.go:530] Throttling request took 291.118371ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:09:25.191437       1 request.go:530] Throttling request took 340.974326ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:09:25.241529       1 request.go:530] Throttling request took 391.050127ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:09:25.291855       1 request.go:530] Throttling request took 441.387121ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:09:25.608593       1 wrap.go:47] GET /healthz: (98.027µs) 200 [kube-probe/1.15+ 127.0.0.1:51330]
I0416 22:09:27.140340       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:09:27.326849       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:28.549400       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:09:30.788603       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 167 items received
I0416 22:09:30.879815       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:09:32.508002       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:09:32.508039       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:09:33.458923       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:33.461916       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:33.462103       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:09:33.462115       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:09:33.462606       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:09:33.465629       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:34.297859       1 controller.go:123] Found 0 jobs
I0416 22:09:34.300674       1 controller.go:139] Found 0 cronjobs
I0416 22:09:34.300687       1 controller.go:142] Found 0 groups
I0416 22:09:35.608867       1 wrap.go:47] GET /healthz: (120.239µs) 200 [kube-probe/1.15+ 127.0.0.1:51364]
I0416 22:09:36.524347       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:09:37.508343       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:09:39.777428       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 0 items received
I0416 22:09:41.254975       1 request.go:530] Throttling request took 92.409276ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:09:41.304898       1 request.go:530] Throttling request took 142.326646ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:09:41.354782       1 request.go:530] Throttling request took 192.202324ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:09:41.404960       1 request.go:530] Throttling request took 242.280598ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:09:41.454995       1 request.go:530] Throttling request took 292.398532ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:09:41.504928       1 request.go:530] Throttling request took 342.312879ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:09:41.555141       1 request.go:530] Throttling request took 392.516105ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:09:41.604817       1 request.go:530] Throttling request took 442.181753ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:09:41.606965       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:09:41.769038       1 serviceaccounts_controller.go:186] Finished syncing namespace "services-1982" (21.732584ms)
I0416 22:09:41.797743       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:41.803853       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 22:09:41.827338       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:41.921813       1 endpoints_controller.go:540] Update endpoints for services-1982/multi-endpoint-test, ready: 0 not ready: 0
I0416 22:09:41.930428       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (8.690665ms)
I0416 22:09:42.011524       1 pvc_protection_controller.go:280] Got event on pod services-1982/pod1
I0416 22:09:42.012127       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"services-1982", Name:"pod1"}
I0416 22:09:42.012303       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (45.155µs)
I0416 22:09:42.012363       1 disruption.go:326] addPod called on pod "pod1"
I0416 22:09:42.012375       1 disruption.go:401] No PodDisruptionBudgets found for pod pod1, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:42.012378       1 disruption.go:329] No matching pdb for pod "pod1"
I0416 22:09:42.018917       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"services-1982", Name:"pod1"}
I0416 22:09:42.019157       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (51µs)
I0416 22:09:42.019242       1 disruption.go:338] updatePod called on pod "pod1"
I0416 22:09:42.019252       1 disruption.go:401] No PodDisruptionBudgets found for pod pod1, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:42.019256       1 disruption.go:341] No matching pdb for pod "pod1"
I0416 22:09:42.030863       1 disruption.go:338] updatePod called on pod "pod1"
I0416 22:09:42.030882       1 disruption.go:401] No PodDisruptionBudgets found for pod pod1, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:42.030886       1 disruption.go:341] No matching pdb for pod "pod1"
I0416 22:09:42.134807       1 gen.go:6086] GCEForwardingRules.Get(context.Background.WithDeadline(2019-04-16 23:09:41.922153189 +0000 UTC m=+7604.075877340 [59m59.787338948s]), Key{"a8ccf63dea5544dd9a7293c30315f1fa", region: "us-central1"}) = <nil>, googleapi: Error 404: The resource 'projects/peterhornyack-prod-no-enforcer/regions/us-central1/forwardingRules/a8ccf63dea5544dd9a7293c30315f1fa' was not found, notFound
I0416 22:09:42.134894       1 service_controller.go:330] Not persisting unchanged LoadBalancerStatus for service services-1982/multi-endpoint-test to registry.
I0416 22:09:42.134904       1 service_controller.go:716] Finished syncing service "services-1982/multi-endpoint-test" (212.759259ms)
I0416 22:09:42.141313       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:09:42.327292       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:42.981686       1 gc_controller.go:144] GC'ing orphaned
I0416 22:09:42.986320       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:09:44.304403       1 controller.go:123] Found 0 jobs
I0416 22:09:44.306653       1 controller.go:139] Found 0 cronjobs
I0416 22:09:44.306665       1 controller.go:142] Found 0 groups
I0416 22:09:45.608505       1 wrap.go:47] GET /healthz: (74.263µs) 200 [kube-probe/1.15+ 127.0.0.1:51422]
I0416 22:09:45.901061       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.902267       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.902354       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.902430       1 deployment_controller.go:175] Updating deployment coredns
I0416 22:09:45.902445       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 22:09:45.902466       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 22:09:45.902461189 +0000 UTC m=+4008.056185327)
I0416 22:09:45.903300       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (834.613µs)
I0416 22:09:45.903323       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 22:09:45.903320664 +0000 UTC m=+4008.057044802)
I0416 22:09:45.903652       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (329.688µs)
I0416 22:09:45.903698       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 22:09:45.903707       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 22:09:45.90370463 +0000 UTC m=+4008.057428768)
I0416 22:09:45.904113       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (406.048µs)
I0416 22:09:45.904138       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 22:09:45.904147       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 22:09:45.904144275 +0000 UTC m=+4008.057868414)
I0416 22:09:45.904717       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (569.632µs)
I0416 22:09:45.904745       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 22:09:45.904750       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 22:09:45.904757       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 22:09:45.904754337 +0000 UTC m=+4008.058478476)
I0416 22:09:45.905673       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (913.444µs)
I0416 22:09:45.905688       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 22:09:45.905685464 +0000 UTC m=+4008.059409602)
I0416 22:09:45.906682       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (992.557µs)
I0416 22:09:45.906720       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 22:09:45.906731       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 22:09:45.906728062 +0000 UTC m=+4008.060452210)
I0416 22:09:45.907583       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (851.338µs)
I0416 22:09:45.907611       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 22:09:45.907619       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 22:09:45.907616683 +0000 UTC m=+4008.061340819)
I0416 22:09:45.907931       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (312.809µs)
I0416 22:09:45.924547       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.924626       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 22:09:45.924641       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 22:09:45.926044       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b24c89f05708, ext:3760320470001, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.926407       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:09:45.926419       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b28a7737fab4, ext:4008080139695, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.926431       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:09:45.926486       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:09:45.926492       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b28a7737fab4, ext:4008080139695, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.926521       1 update.go:396] Getting unavailable numbers
I0416 22:09:45.926613       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:09:45.926619       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 22:09:45.926625       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:09:45.926641       1 update.go:68] Marking old pods for deletion
I0416 22:09:45.926645       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b28a773b76fc, ext:4008080368144, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.926652       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:09:45.926676       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:09:45.926696       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:09:45.926804       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:09:45.926811       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.152691ms)
I0416 22:09:45.927304       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b24c8a017ca0, ext:3760321593751, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.927465       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:09:45.927472       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b28a77481213, ext:4008081194249, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.927479       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:09:45.927542       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:09:45.927547       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b28a77481213, ext:4008081194249, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.927590       1 update.go:396] Getting unavailable numbers
I0416 22:09:45.927736       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:09:45.927742       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 22:09:45.927747       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:09:45.927750       1 update.go:68] Marking old pods for deletion
I0416 22:09:45.927770       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b28a774c609a, ext:4008081476482, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.927778       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:09:45.927801       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:09:45.927824       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:09:45.927940       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:09:45.927945       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.108997ms)
I0416 22:09:45.937014       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937126       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937256       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.937434       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (186.808µs)
I0416 22:09:45.937502       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937594       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937614       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937626       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937655       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937676       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937805       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937821       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.937913       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:45.938048       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:09:45.938068       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.938072       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:09:45.938163       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.938480       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (319.072µs)
I0416 22:09:45.938498       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.938564       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (68.6µs)
I0416 22:09:45.938605       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:09:45.938617       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.938621       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:09:45.938649       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.938727       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (79.313µs)
I0416 22:09:45.938817       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.938892       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (77.2µs)
I0416 22:09:45.938905       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:09:45.938914       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.938917       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:09:45.938939       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:09:45.938945       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.938950       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:09:45.938986       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 22:09:45.938994       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.938997       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 22:09:45.939049       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.939099       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (37.762µs)
I0416 22:09:45.939109       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.939156       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (48.961µs)
I0416 22:09:45.939203       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.939309       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (106.857µs)
I0416 22:09:45.939356       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:09:45.939365       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.939369       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:09:45.939389       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.939449       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (62.243µs)
I0416 22:09:45.939472       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 22:09:45.939530       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (58.306µs)
I0416 22:09:45.939570       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:09:45.939593       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.939596       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:09:45.939627       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:09:45.939631       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.939634       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:09:45.939690       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:09:45.939697       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.939700       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:09:45.939726       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:09:45.939737       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.939752       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:09:45.939771       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:09:45.939781       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.939783       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:09:45.939786       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:09:45.939794       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.939797       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:09:45.939818       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:09:45.939836       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.939839       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:09:45.940062       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:09:45.940072       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940074       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:09:45.940098       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:09:45.940104       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940107       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:09:45.940151       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:09:45.940158       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940161       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:09:45.940164       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 22:09:45.940170       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940172       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 22:09:45.940216       1 disruption.go:338] updatePod called on pod "pod1"
I0416 22:09:45.940222       1 disruption.go:401] No PodDisruptionBudgets found for pod pod1, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940243       1 disruption.go:341] No matching pdb for pod "pod1"
I0416 22:09:45.940285       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:09:45.940292       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940295       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:09:45.940326       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 22:09:45.940335       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940338       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 22:09:45.940366       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:09:45.940371       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940373       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:09:45.940407       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 22:09:45.940416       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940418       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 22:09:45.940421       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:09:45.940428       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:45.940431       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:09:45.979327       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:46.100844       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:46.133595       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:46.247379       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:46.320562       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:46.420535       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:46.470019       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:46.470107       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:09:46.470152       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (2.494µs)
I0416 22:09:46.470353       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:09:46.470363       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:09:46.470373       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:09:46.470380       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (1.105µs)
I0416 22:09:46.470394       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (439ns)
I0416 22:09:46.470402       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (320ns)
I0416 22:09:46.520647       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:46.676643       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:50.233006       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 22:09:50.966284       1 endpoints_controller.go:489] Failed to find port for service services-1982/multi-endpoint-test: no suitable port for manifest: 2f7abcb1-719c-4928-8e77-0e353c23710b
I0416 22:09:50.966421       1 endpoints_controller.go:540] Update endpoints for services-1982/multi-endpoint-test, ready: 1 not ready: 0
I0416 22:09:50.966695       1 disruption.go:338] updatePod called on pod "pod1"
I0416 22:09:50.966708       1 disruption.go:401] No PodDisruptionBudgets found for pod pod1, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:50.966714       1 disruption.go:341] No matching pdb for pod "pod1"
I0416 22:09:50.976364       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (10.13799ms)
I0416 22:09:51.889852       1 pvc_protection_controller.go:280] Got event on pod services-1982/pod2
I0416 22:09:51.889942       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"services-1982", Name:"pod2"}
I0416 22:09:51.890060       1 endpoints_controller.go:489] Failed to find port for service services-1982/multi-endpoint-test: no suitable port for manifest: 2f7abcb1-719c-4928-8e77-0e353c23710b
I0416 22:09:51.890158       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (152.774µs)
I0416 22:09:51.890199       1 disruption.go:326] addPod called on pod "pod2"
I0416 22:09:51.890210       1 disruption.go:401] No PodDisruptionBudgets found for pod pod2, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:51.890213       1 disruption.go:329] No matching pdb for pod "pod2"
I0416 22:09:51.898665       1 taint_manager.go:406] Noticed pod update: types.NamespacedName{Namespace:"services-1982", Name:"pod2"}
I0416 22:09:51.898785       1 endpoints_controller.go:489] Failed to find port for service services-1982/multi-endpoint-test: no suitable port for manifest: 2f7abcb1-719c-4928-8e77-0e353c23710b
I0416 22:09:51.898851       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (92.464µs)
I0416 22:09:51.898888       1 disruption.go:338] updatePod called on pod "pod2"
I0416 22:09:51.898914       1 disruption.go:401] No PodDisruptionBudgets found for pod pod2, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:51.898922       1 disruption.go:341] No matching pdb for pod "pod2"
I0416 22:09:51.911213       1 disruption.go:338] updatePod called on pod "pod2"
I0416 22:09:51.911254       1 disruption.go:401] No PodDisruptionBudgets found for pod pod2, PodDisruptionBudget controller will avoid syncing.
I0416 22:09:51.911259       1 disruption.go:341] No matching pdb for pod "pod2"
I0416 22:09:54.310842       1 controller.go:123] Found 0 jobs
I0416 22:09:54.313360       1 controller.go:139] Found 0 cronjobs
I0416 22:09:54.313374       1 controller.go:142] Found 0 groups
I0416 22:09:55.394967       1 request.go:530] Throttling request took 92.036137ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:09:55.445025       1 request.go:530] Throttling request took 142.087445ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:09:55.494881       1 request.go:530] Throttling request took 191.919923ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:09:55.544884       1 request.go:530] Throttling request took 241.91275ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:09:55.594888       1 request.go:530] Throttling request took 291.912109ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:09:55.608125       1 wrap.go:47] GET /healthz: (71.023µs) 200 [kube-probe/1.15+ 127.0.0.1:51458]
I0416 22:09:55.644956       1 request.go:530] Throttling request took 341.968045ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:09:55.694946       1 request.go:530] Throttling request took 391.955768ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:09:55.745084       1 request.go:530] Throttling request took 442.082605ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:09:57.141565       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:09:57.327550       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:09:57.798955       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 22:10:02.986768       1 gc_controller.go:144] GC'ing orphaned
I0416 22:10:02.990817       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:10:04.317359       1 controller.go:123] Found 0 jobs
I0416 22:10:04.319633       1 controller.go:139] Found 0 cronjobs
I0416 22:10:04.319645       1 controller.go:142] Found 0 groups
I0416 22:10:05.608473       1 wrap.go:47] GET /healthz: (156.292µs) 200 [kube-probe/1.15+ 127.0.0.1:51492]
I0416 22:10:05.712027       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:10.294282       1 endpoints_controller.go:489] Failed to find port for service services-1982/multi-endpoint-test: no suitable port for manifest: 2f7abcb1-719c-4928-8e77-0e353c23710b
I0416 22:10:10.294296       1 endpoints_controller.go:489] Failed to find port for service services-1982/multi-endpoint-test: no suitable port for manifest: 58ba6151-890b-4724-9c49-0bb763eba1f3
I0416 22:10:10.294456       1 endpoints_controller.go:540] Update endpoints for services-1982/multi-endpoint-test, ready: 2 not ready: 0
I0416 22:10:10.294746       1 disruption.go:338] updatePod called on pod "pod2"
I0416 22:10:10.294758       1 disruption.go:401] No PodDisruptionBudgets found for pod pod2, PodDisruptionBudget controller will avoid syncing.
I0416 22:10:10.294762       1 disruption.go:341] No matching pdb for pod "pod2"
I0416 22:10:10.300300       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (6.047899ms)
I0416 22:10:11.207809       1 endpoints_controller.go:489] Failed to find port for service services-1982/multi-endpoint-test: no suitable port for manifest: 58ba6151-890b-4724-9c49-0bb763eba1f3
I0416 22:10:11.207920       1 endpoints_controller.go:540] Update endpoints for services-1982/multi-endpoint-test, ready: 1 not ready: 0
I0416 22:10:11.208205       1 disruption.go:338] updatePod called on pod "pod1"
I0416 22:10:11.208323       1 disruption.go:401] No PodDisruptionBudgets found for pod pod1, PodDisruptionBudget controller will avoid syncing.
I0416 22:10:11.208328       1 disruption.go:341] No matching pdb for pod "pod1"
I0416 22:10:11.218348       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (10.562509ms)
I0416 22:10:11.340165       1 endpoints_controller.go:540] Update endpoints for services-1982/multi-endpoint-test, ready: 0 not ready: 0
I0416 22:10:11.340449       1 disruption.go:338] updatePod called on pod "pod2"
I0416 22:10:11.340477       1 disruption.go:401] No PodDisruptionBudgets found for pod pod2, PodDisruptionBudget controller will avoid syncing.
I0416 22:10:11.340481       1 disruption.go:341] No matching pdb for pod "pod2"
I0416 22:10:11.349427       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (9.313238ms)
I0416 22:10:11.427331       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=services, namespace services-1982, name multi-endpoint-test, uid 8ccf63de-a554-4dd9-a729-3c30315f1fa8, event type delete
I0416 22:10:11.427429       1 service_controller.go:729] Service has been deleted services-1982/multi-endpoint-test. Attempting to cleanup load balancer resources
I0416 22:10:11.427435       1 service_controller.go:716] Finished syncing service "services-1982/multi-endpoint-test" (13.354µs)
I0416 22:10:11.433049       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=endpoints, namespace services-1982, name multi-endpoint-test, uid 8dad1932-d3e4-4ce6-831b-bb010224d2e9, event type delete
I0416 22:10:11.433958       1 endpoints_controller.go:401] Finished syncing service "services-1982/multi-endpoint-test" endpoints. (6.869007ms)
I0416 22:10:11.521528       1 serviceaccounts_controller.go:186] Finished syncing namespace "services-1982" (3.012µs)
I0416 22:10:11.707510       1 request.go:530] Throttling request took 92.42199ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:10:11.757728       1 request.go:530] Throttling request took 142.615231ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:10:11.797991       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:11.807490       1 request.go:530] Throttling request took 192.373909ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:10:11.827541       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:11.857622       1 request.go:530] Throttling request took 242.477641ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:10:11.907466       1 request.go:530] Throttling request took 292.338361ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:10:11.957616       1 request.go:530] Throttling request took 342.455597ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:10:12.007520       1 request.go:530] Throttling request took 392.354263ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:10:12.061705       1 request.go:530] Throttling request took 446.53883ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:10:12.063786       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:10:12.141964       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:10:12.327803       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:13.365577       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 183 items received
I0416 22:10:14.323252       1 controller.go:123] Found 0 jobs
I0416 22:10:14.325070       1 controller.go:139] Found 0 cronjobs
I0416 22:10:14.325081       1 controller.go:142] Found 0 groups
I0416 22:10:14.426373       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 22:10:15.475014       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:10:15.607973       1 wrap.go:47] GET /healthz: (77.063µs) 200 [kube-probe/1.15+ 127.0.0.1:51524]
I0416 22:10:16.095737       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 22:10:16.484048       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 22:10:16.534196       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:16.751223       1 serviceaccounts_controller.go:186] Finished syncing namespace "services-1982" (4.804µs)
I0416 22:10:16.751289       1 tokens_controller.go:251] syncServiceAccount(services-1982/default), service account deleted, removing tokens
I0416 22:10:16.751662       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=serviceaccounts, namespace services-1982, name default, uid dbe520b7-885b-4644-9d3f-d07e72963a3f, event type delete
I0416 22:10:16.778362       1 resource_quota_monitor.go:354] QuotaMonitor process object: /v1, Resource=secrets, namespace services-1982, name default-token-4gsnk, uid d06b36e3-352a-4e28-927b-4342acd69d65, event type delete
I0416 22:10:16.795431       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod1.159613e1d8459270, uid 5bbc3471-9594-4a5c-a78f-abfeefa2b387, event type delete
I0416 22:10:16.804345       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod1.159613e315941094, uid 7ab08db3-3ef2-4d04-9856-cd3677c63982, event type delete
I0416 22:10:16.809545       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod1.159613e31e0bad2c, uid 727b556a-4734-447c-af40-00ed77bc9502, event type delete
I0416 22:10:16.812968       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod1.159613e39b4c6204, uid 051a71cb-2064-4f6c-8f11-124e04272196, event type delete
I0416 22:10:16.817862       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod1.159613e8a085be28, uid 2d8d1294-3373-4546-a224-dfd5a47c9484, event type delete
I0416 22:10:16.821265       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod2.159613e425250d81, uid c0639851-ad0f-4ac7-a1cf-f58f650a2b10, event type delete
I0416 22:10:16.824459       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod2.159613e764e6d9c0, uid 939d9c68-0976-4921-a05f-cd6637882b46, event type delete
I0416 22:10:16.827483       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod2.159613e767d010c0, uid bee4ff11-6e7b-4acc-a971-98b03f5bce6d, event type delete
I0416 22:10:16.831487       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace services-1982, name pod2.159613e7f7aade78, uid 2d78029f-5f04-43ee-9045-d5c1e2c22b65, event type delete
I0416 22:10:17.066648       1 namespaced_resources_deleter.go:512] namespace controller - deleteAllContent - namespace: services-1982, estimate: 30
I0416 22:10:17.066676       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (544.885907ms)
I0416 22:10:17.066684       1 namespace_controller.go:143] Content remaining in namespace services-1982, waiting 16 seconds
I0416 22:10:22.991486       1 gc_controller.go:144] GC'ing orphaned
I0416 22:10:22.998270       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:10:24.328652       1 controller.go:123] Found 0 jobs
I0416 22:10:24.330883       1 controller.go:139] Found 0 cronjobs
I0416 22:10:24.330895       1 controller.go:142] Found 0 groups
I0416 22:10:24.600272       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:25.608203       1 wrap.go:47] GET /healthz: (76.745µs) 200 [kube-probe/1.15+ 127.0.0.1:51558]
I0416 22:10:25.847731       1 request.go:530] Throttling request took 92.571057ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:10:25.897736       1 request.go:530] Throttling request took 142.567966ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:10:25.947676       1 request.go:530] Throttling request took 192.483936ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:10:25.997655       1 request.go:530] Throttling request took 242.455447ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:10:26.047628       1 request.go:530] Throttling request took 292.421646ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:10:26.049850       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:10:26.097953       1 request.go:530] Throttling request took 342.738386ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:10:26.147713       1 request.go:530] Throttling request took 392.486411ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:10:26.197709       1 request.go:530] Throttling request took 442.474912ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:10:27.142219       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:10:27.328274       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:28.656253       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:10:30.789134       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 2 items received
I0416 22:10:31.003808       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:10:32.532467       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:10:32.532504       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:10:33.081635       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:33.309981       1 namespaced_resources_deleter.go:512] namespace controller - deleteAllContent - namespace: services-1982, estimate: 30
I0416 22:10:33.309997       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (242.640167ms)
I0416 22:10:33.310007       1 namespace_controller.go:143] Content remaining in namespace services-1982, waiting 16 seconds
I0416 22:10:33.942430       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 22:10:34.334328       1 controller.go:123] Found 0 jobs
I0416 22:10:34.336361       1 controller.go:139] Found 0 cronjobs
I0416 22:10:34.336372       1 controller.go:142] Found 0 groups
I0416 22:10:35.608300       1 wrap.go:47] GET /healthz: (116.484µs) 200 [kube-probe/1.15+ 127.0.0.1:51592]
I0416 22:10:36.698850       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:10:37.532773       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:10:41.798303       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:41.827778       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:42.142609       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:10:42.176143       1 request.go:530] Throttling request took 71.042814ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:10:42.226336       1 request.go:530] Throttling request took 121.222438ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:10:42.276827       1 request.go:530] Throttling request took 171.708847ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:10:42.326136       1 request.go:530] Throttling request took 220.986981ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:10:42.328808       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:42.376218       1 request.go:530] Throttling request took 271.076026ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:10:42.426340       1 request.go:530] Throttling request took 321.199722ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:10:42.477343       1 request.go:530] Throttling request took 372.197668ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:10:42.526155       1 request.go:530] Throttling request took 421.000888ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:10:42.528223       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:10:42.998708       1 gc_controller.go:144] GC'ing orphaned
I0416 22:10:43.002208       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:10:44.339903       1 controller.go:123] Found 0 jobs
I0416 22:10:44.341843       1 controller.go:139] Found 0 cronjobs
I0416 22:10:44.341866       1 controller.go:142] Found 0 groups
I0416 22:10:45.608364       1 wrap.go:47] GET /healthz: (77.073µs) 200 [kube-probe/1.15+ 127.0.0.1:51644]
E0416 22:10:49.581686       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:49.827145       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:50.098116       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:50.463030       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:50.676422       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:50.916989       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:49.581686       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:49.827145       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:50.098116       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:50.463030       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:50.676422       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:50.916989       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:49.313798       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:49.581657       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (271.399128ms)
E0416 22:10:49.581686       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:49.589480       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:49.827115       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (240.199354ms)
E0416 22:10:49.827145       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:49.840381       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:50.098083       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (260.75477ms)
E0416 22:10:50.098116       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:50.121407       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:50.462996       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (344.612202ms)
E0416 22:10:50.463030       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:50.506242       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:50.676393       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (173.105517ms)
E0416 22:10:50.676422       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:50.763547       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:50.916944       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (159.347761ms)
E0416 22:10:50.916989       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:51.080218       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
E0416 22:10:51.288916       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:51.958344       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:52.832441       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:51.288916       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:51.958344       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:52.832441       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:51.276053       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (198.848154ms)
E0416 22:10:51.288916       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:51.617686       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:51.958314       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (349.243359ms)
E0416 22:10:51.958344       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:52.602165       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:52.832398       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (233.064982ms)
E0416 22:10:52.832441       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:54.361995       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:54.361995       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:54.115203       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:54.347149       1 controller.go:123] Found 0 jobs
I0416 22:10:54.353152       1 controller.go:139] Found 0 cronjobs
I0416 22:10:54.353164       1 controller.go:142] Found 0 groups
I0416 22:10:54.361954       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (249.31262ms)
E0416 22:10:54.361995       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:54.457413       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-windows-node-group-31ht.1596109e6ff2663c, uid 000d5b23-f7d6-47d8-b2c3-f3fe973c8908, event type delete
I0416 22:10:54.457509       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-windows-node-group-31ht.1596109e72644354, uid 1617f9a0-3795-4649-95dd-12edc3bb79a4, event type delete
I0416 22:10:54.457520       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-windows-node-group-31ht.1596109f2c5a681a, uid 109d0729-ff95-493c-80d9-a31c085e7c2e, event type delete
I0416 22:10:54.457527       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-windows-node-group-31ht.159610a0b7c79c28, uid 8abf5dfa-ab3f-4058-8812-20c048fc5f9f, event type delete
I0416 22:10:54.457586       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-6mpws.1596109ed63fadb9, uid 49e2bd5c-c658-4a90-b224-11d50c2d5f42, event type delete
I0416 22:10:54.457594       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-6mpws.1596109f14bfc4bf, uid adbbc5f3-9bc7-4b62-9063-5da417e658b3, event type delete
I0416 22:10:54.457601       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-6mpws.1596109f19b26ae8, uid 3dd9e9c9-f647-4f0d-b456-fe0ee1797be9, event type delete
I0416 22:10:54.457658       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88-6mpws.1596109f26d07c12, uid 0ac50936-846d-47a7-8a68-e8062f65e3a3, event type delete
I0416 22:10:54.457665       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns-5b969f4c88.1596109ed56b4eb3, uid fce69a60-ad17-4938-b152-89c8bc6c08a7, event type delete
I0416 22:10:54.457670       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace kube-system, name coredns.1596109ed3accca5, uid 2253147b-1ce8-4460-a9ca-9791f2fe2143, event type delete
I0416 22:10:55.608609       1 wrap.go:47] GET /healthz: (82.277µs) 200 [kube-probe/1.15+ 127.0.0.1:51682]
E0416 22:10:57.299989       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:10:57.299989       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:56.302510       1 request.go:530] Throttling request took 89.442268ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:10:56.352720       1 request.go:530] Throttling request took 139.613708ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:10:56.402336       1 request.go:530] Throttling request took 189.199338ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:10:56.452303       1 request.go:530] Throttling request took 239.200929ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:10:56.502412       1 request.go:530] Throttling request took 289.191864ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:10:56.552668       1 request.go:530] Throttling request took 339.541792ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:10:56.554212       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:10:56.602389       1 request.go:530] Throttling request took 389.235609ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:10:56.652303       1 request.go:530] Throttling request took 439.146471ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:10:56.792610       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 10 items received
I0416 22:10:56.925332       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:10:57.142884       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:10:57.299957       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (377.685606ms)
E0416 22:10:57.299989       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:10:57.328991       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
E0416 22:11:02.781109       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:11:02.781109       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:11:02.423770       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:11:02.781060       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (360.780656ms)
E0416 22:11:02.781109       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:11:03.002492       1 gc_controller.go:144] GC'ing orphaned
I0416 22:11:03.007262       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:11:04.357463       1 controller.go:123] Found 0 jobs
I0416 22:11:04.359605       1 controller.go:139] Found 0 cronjobs
I0416 22:11:04.359620       1 controller.go:142] Found 0 groups
I0416 22:11:05.608308       1 wrap.go:47] GET /healthz: (109.306µs) 200 [kube-probe/1.15+ 127.0.0.1:51716]
I0416 22:11:06.804100       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 22:11:11.798550       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:11.798875       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (218.057µs)
I0416 22:11:11.798997       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (79.362µs)
I0416 22:11:11.799042       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (38.281µs)
I0416 22:11:11.799118       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (62.368µs)
I0416 22:11:11.799141       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (866ns)
I0416 22:11:11.799312       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 22:11:11.803404       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (4.248775ms)
I0416 22:11:11.828011       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:12.143344       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:11:12.329336       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:12.628733       1 request.go:530] Throttling request took 93.822802ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:11:12.678677       1 request.go:530] Throttling request took 143.766265ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:11:12.728731       1 request.go:530] Throttling request took 193.804193ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:11:12.778762       1 request.go:530] Throttling request took 243.814927ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:11:12.828743       1 request.go:530] Throttling request took 293.791821ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
E0416 22:11:13.259340       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:11:13.259340       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:11:12.878709       1 request.go:530] Throttling request took 343.751996ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:11:12.928788       1 request.go:530] Throttling request took 393.819351ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:11:12.978795       1 request.go:530] Throttling request took 443.819804ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:11:12.981007       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:11:13.024912       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:11:13.259294       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (237.939659ms)
E0416 22:11:13.259340       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:11:14.363447       1 controller.go:123] Found 0 jobs
I0416 22:11:14.365534       1 controller.go:139] Found 0 cronjobs
I0416 22:11:14.365546       1 controller.go:142] Found 0 groups
I0416 22:11:15.608475       1 wrap.go:47] GET /healthz: (74.735µs) 200 [kube-probe/1.15+ 127.0.0.1:51752]
I0416 22:11:16.384661       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 22:11:23.007594       1 gc_controller.go:144] GC'ing orphaned
I0416 22:11:23.014563       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:11:24.369555       1 controller.go:123] Found 0 jobs
I0416 22:11:24.371469       1 controller.go:139] Found 0 cronjobs
I0416 22:11:24.371479       1 controller.go:142] Found 0 groups
I0416 22:11:25.609575       1 wrap.go:47] GET /healthz: (90.785µs) 200 [kube-probe/1.15+ 127.0.0.1:51786]
I0416 22:11:26.074039       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:11:26.755315       1 request.go:530] Throttling request took 92.303944ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:11:26.805329       1 request.go:530] Throttling request took 142.310932ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:11:26.855319       1 request.go:530] Throttling request took 192.28802ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:11:26.905322       1 request.go:530] Throttling request took 242.279813ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:11:26.955309       1 request.go:530] Throttling request took 292.257297ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:11:27.005337       1 request.go:530] Throttling request took 342.277335ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:11:27.055319       1 request.go:530] Throttling request took 392.239544ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:11:27.105248       1 request.go:530] Throttling request took 442.152557ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:11:27.143591       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:11:27.329524       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:28.740678       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:11:31.106439       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:11:32.539128       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:11:32.539163       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
E0416 22:11:33.954942       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:11:33.954942       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:11:33.743411       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:11:33.954908       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (215.227562ms)
E0416 22:11:33.954942       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:11:34.375326       1 controller.go:123] Found 0 jobs
I0416 22:11:34.377308       1 controller.go:139] Found 0 cronjobs
I0416 22:11:34.377318       1 controller.go:142] Found 0 groups
I0416 22:11:35.608702       1 wrap.go:47] GET /healthz: (96.943µs) 200 [kube-probe/1.15+ 127.0.0.1:51820]
I0416 22:11:36.877571       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:11:37.003038       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 22:11:37.320982       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 2 items received
I0416 22:11:37.542411       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:11:41.798876       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:41.828630       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:42.144093       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:11:42.329735       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:43.015122       1 gc_controller.go:144] GC'ing orphaned
I0416 22:11:43.018943       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:11:43.082060       1 request.go:530] Throttling request took 92.253117ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:11:43.132035       1 request.go:530] Throttling request took 142.223622ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:11:43.182439       1 request.go:530] Throttling request took 192.605792ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:11:43.232187       1 request.go:530] Throttling request took 242.356693ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:11:43.282446       1 request.go:530] Throttling request took 292.607758ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:11:43.332109       1 request.go:530] Throttling request took 342.250699ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:11:43.382676       1 request.go:530] Throttling request took 392.804494ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:11:43.432205       1 request.go:530] Throttling request took 442.329966ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:11:43.434509       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:11:43.795302       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 22:11:44.380690       1 controller.go:123] Found 0 jobs
I0416 22:11:44.383438       1 controller.go:139] Found 0 cronjobs
I0416 22:11:44.383449       1 controller.go:142] Found 0 groups
I0416 22:11:45.609516       1 wrap.go:47] GET /healthz: (94.91µs) 200 [kube-probe/1.15+ 127.0.0.1:51872]
I0416 22:11:52.129038       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:54.389619       1 controller.go:123] Found 0 jobs
I0416 22:11:54.391887       1 controller.go:139] Found 0 cronjobs
I0416 22:11:54.391899       1 controller.go:142] Found 0 groups
I0416 22:11:55.608313       1 wrap.go:47] GET /healthz: (148.121µs) 200 [kube-probe/1.15+ 127.0.0.1:51908]
I0416 22:11:55.781380       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 170 items received
I0416 22:11:57.144306       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:11:57.207599       1 request.go:530] Throttling request took 84.380017ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:11:57.257622       1 request.go:530] Throttling request took 134.37313ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:11:57.307626       1 request.go:530] Throttling request took 184.338746ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:11:57.328309       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 0 items received
I0416 22:11:57.330347       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:11:57.357650       1 request.go:530] Throttling request took 234.32569ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:11:57.407682       1 request.go:530] Throttling request took 284.354418ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:11:57.458352       1 request.go:530] Throttling request took 335.032466ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:11:57.508358       1 request.go:530] Throttling request took 385.036368ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:11:57.558350       1 request.go:530] Throttling request took 435.017688ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:12:03.019294       1 gc_controller.go:144] GC'ing orphaned
I0416 22:12:03.023763       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:12:04.395786       1 controller.go:123] Found 0 jobs
I0416 22:12:04.398067       1 controller.go:139] Found 0 cronjobs
I0416 22:12:04.398076       1 controller.go:142] Found 0 groups
I0416 22:12:05.608810       1 wrap.go:47] GET /healthz: (87.839µs) 200 [kube-probe/1.15+ 127.0.0.1:51942]
I0416 22:12:10.845338       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:11.799213       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:11.828905       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:12.144574       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:12:12.330846       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:12.811896       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StorageClass total 0 items received
E0416 22:12:15.078754       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:12:15.078754       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:12:13.535000       1 request.go:530] Throttling request took 92.842797ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:12:13.584975       1 request.go:530] Throttling request took 142.794001ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:12:13.635044       1 request.go:530] Throttling request took 192.846618ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:12:13.684974       1 request.go:530] Throttling request took 242.758155ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:12:13.734991       1 request.go:530] Throttling request took 292.767696ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:12:13.784992       1 request.go:530] Throttling request took 342.761449ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:12:13.835016       1 request.go:530] Throttling request took 392.790174ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:12:13.885046       1 request.go:530] Throttling request took 442.809257ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:12:13.888388       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:12:14.402204       1 controller.go:123] Found 0 jobs
I0416 22:12:14.404247       1 controller.go:139] Found 0 cronjobs
I0416 22:12:14.404256       1 controller.go:142] Found 0 groups
I0416 22:12:14.918895       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:12:15.078706       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (163.44004ms)
E0416 22:12:15.078754       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:12:15.608577       1 wrap.go:47] GET /healthz: (105.315µs) 200 [kube-probe/1.15+ 127.0.0.1:51974]
I0416 22:12:22.805395       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 0 items received
I0416 22:12:23.024068       1 gc_controller.go:144] GC'ing orphaned
I0416 22:12:23.028714       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:12:24.408145       1 controller.go:123] Found 0 jobs
I0416 22:12:24.410192       1 controller.go:139] Found 0 cronjobs
I0416 22:12:24.410202       1 controller.go:142] Found 0 groups
I0416 22:12:25.609592       1 wrap.go:47] GET /healthz: (83.252µs) 200 [kube-probe/1.15+ 127.0.0.1:52008]
I0416 22:12:27.059911       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:12:27.144886       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:12:27.331112       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:27.661119       1 request.go:530] Throttling request took 91.452445ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:12:27.711209       1 request.go:530] Throttling request took 141.533413ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:12:27.761581       1 request.go:530] Throttling request took 191.864246ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:12:27.811347       1 request.go:530] Throttling request took 241.61053ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:12:27.862333       1 request.go:530] Throttling request took 292.599426ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:12:27.911323       1 request.go:530] Throttling request took 341.59259ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:12:27.961199       1 request.go:530] Throttling request took 391.461177ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:12:28.011444       1 request.go:530] Throttling request took 441.697809ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:12:28.834597       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:12:31.222376       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:12:32.552389       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:12:32.552422       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:12:34.413898       1 controller.go:123] Found 0 jobs
I0416 22:12:34.416104       1 controller.go:139] Found 0 cronjobs
I0416 22:12:34.416114       1 controller.go:142] Found 0 groups
I0416 22:12:35.608602       1 wrap.go:47] GET /healthz: (85.899µs) 200 [kube-probe/1.15+ 127.0.0.1:52042]
I0416 22:12:37.115479       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:12:37.552830       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:12:41.799767       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:41.829212       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:42.145145       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:12:42.331713       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:43.029447       1 gc_controller.go:144] GC'ing orphaned
I0416 22:12:43.034649       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:12:43.988953       1 request.go:530] Throttling request took 89.922495ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:12:44.038982       1 request.go:530] Throttling request took 139.937205ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:12:44.089110       1 request.go:530] Throttling request took 190.060818ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:12:44.139022       1 request.go:530] Throttling request took 239.958509ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:12:44.188990       1 request.go:530] Throttling request took 289.913928ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:12:44.238903       1 request.go:530] Throttling request took 339.806841ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:12:44.289757       1 request.go:530] Throttling request took 390.575802ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:12:44.338960       1 request.go:530] Throttling request took 439.844745ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:12:44.341334       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:12:44.421180       1 controller.go:123] Found 0 jobs
I0416 22:12:44.424950       1 controller.go:139] Found 0 cronjobs
I0416 22:12:44.424962       1 controller.go:142] Found 0 groups
I0416 22:12:45.608571       1 wrap.go:47] GET /healthz: (82.176µs) 200 [kube-probe/1.15+ 127.0.0.1:52094]
I0416 22:12:52.556684       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.159610b9ef3e77c6, uid ea838200-0c8e-4b05-97dd-28d27d342d09, event type delete
I0416 22:12:52.556814       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.159610b9efcba1c1, uid 75273ce0-8b84-4d69-969a-ca456088c664, event type delete
I0416 22:12:52.556825       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.159610b9ff7fa5a5, uid e65e367b-e6e5-49e8-9342-42a68bc8fcba, event type delete
I0416 22:12:52.556832       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.159610ba32c07341, uid 39434203-af61-4054-9b18-0d10f4efc132, event type delete
I0416 22:12:52.556847       1 resource_quota_monitor.go:354] QuotaMonitor process object: events.k8s.io/v1beta1, Resource=events, namespace default, name e2e-test-peterhornyack-minion-group-06gd.159610ba75277220, uid 5276a49b-5a69-4b08-9e9f-fc73f3f0503f, event type delete
I0416 22:12:53.793416       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 22:12:54.431263       1 controller.go:123] Found 0 jobs
I0416 22:12:54.433833       1 controller.go:139] Found 0 cronjobs
I0416 22:12:54.433844       1 controller.go:142] Found 0 groups
I0416 22:12:54.769800       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:55.608564       1 wrap.go:47] GET /healthz: (89.784µs) 200 [kube-probe/1.15+ 127.0.0.1:52130]
I0416 22:12:57.145408       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:12:57.332009       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:12:58.114397       1 request.go:530] Throttling request took 89.624591ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:12:58.164361       1 request.go:530] Throttling request took 139.572177ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:12:58.214329       1 request.go:530] Throttling request took 189.530269ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:12:58.264455       1 request.go:530] Throttling request took 239.638063ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:12:58.314410       1 request.go:530] Throttling request took 289.581088ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:12:58.364414       1 request.go:530] Throttling request took 339.576948ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:12:58.414352       1 request.go:530] Throttling request took 389.49696ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:12:58.464460       1 request.go:530] Throttling request took 439.54148ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:13:00.964937       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 22:13:03.034942       1 gc_controller.go:144] GC'ing orphaned
I0416 22:13:03.039743       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:13:04.437740       1 controller.go:123] Found 0 jobs
I0416 22:13:04.439970       1 controller.go:139] Found 0 cronjobs
I0416 22:13:04.439979       1 controller.go:142] Found 0 groups
I0416 22:13:05.113505       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 22:13:05.608746       1 wrap.go:47] GET /healthz: (86.697µs) 200 [kube-probe/1.15+ 127.0.0.1:52164]
I0416 22:13:11.800044       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:11.815577       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 22:13:11.830773       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:12.145651       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:13:12.332646       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:14.442323       1 request.go:530] Throttling request took 91.126432ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:13:14.446036       1 controller.go:123] Found 0 jobs
I0416 22:13:14.448277       1 controller.go:139] Found 0 cronjobs
I0416 22:13:14.448288       1 controller.go:142] Found 0 groups
I0416 22:13:14.491785       1 request.go:530] Throttling request took 140.580067ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:13:14.541786       1 request.go:530] Throttling request took 190.56729ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:13:14.577608       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:14.591776       1 request.go:530] Throttling request took 240.546375ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:13:14.641773       1 request.go:530] Throttling request took 290.541224ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:13:14.691791       1 request.go:530] Throttling request took 340.545309ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:13:14.741869       1 request.go:530] Throttling request took 390.579555ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:13:14.791824       1 request.go:530] Throttling request took 440.531225ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:13:14.794263       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:13:15.608645       1 wrap.go:47] GET /healthz: (130.338µs) 200 [kube-probe/1.15+ 127.0.0.1:52196]
I0416 22:13:16.236614       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 22:13:18.789131       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PodTemplate total 0 items received
I0416 22:13:23.040156       1 gc_controller.go:144] GC'ing orphaned
I0416 22:13:23.044446       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:13:24.454097       1 controller.go:123] Found 0 jobs
I0416 22:13:24.457055       1 controller.go:139] Found 0 cronjobs
I0416 22:13:24.457067       1 controller.go:142] Found 0 groups
I0416 22:13:25.608442       1 wrap.go:47] GET /healthz: (102.568µs) 200 [kube-probe/1.15+ 127.0.0.1:52228]
I0416 22:13:26.799123       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 22:13:27.051608       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:13:27.145826       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:13:27.336329       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:28.567277       1 request.go:530] Throttling request took 88.360406ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:13:28.617308       1 request.go:530] Throttling request took 138.383898ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:13:28.667200       1 request.go:530] Throttling request took 188.265667ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:13:28.717201       1 request.go:530] Throttling request took 238.26048ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:13:28.767268       1 request.go:530] Throttling request took 288.299833ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:13:28.817223       1 request.go:530] Throttling request took 338.253478ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:13:28.867412       1 request.go:530] Throttling request took 388.446601ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:13:28.915076       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:13:28.917102       1 request.go:530] Throttling request took 438.116622ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:13:29.326672       1 reflector.go:249] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: forcing resync
I0416 22:13:31.321566       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:13:32.557960       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:13:32.557993       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:13:34.460932       1 controller.go:123] Found 0 jobs
I0416 22:13:34.463053       1 controller.go:139] Found 0 cronjobs
I0416 22:13:34.463064       1 controller.go:142] Found 0 groups
I0416 22:13:35.608439       1 wrap.go:47] GET /healthz: (71.635µs) 200 [kube-probe/1.15+ 127.0.0.1:52264]
E0416 22:13:37.339872       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:13:37.339872       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:13:37.002496       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:13:37.286833       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:13:37.339838       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (340.772297ms)
E0416 22:13:37.339872       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:13:37.558283       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:13:41.222033       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:41.222377       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:13:41.222624       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:13:41.222630       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:13:41.800408       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:41.831027       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:42.146339       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:13:42.337627       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:42.563853       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 22:13:43.045377       1 gc_controller.go:144] GC'ing orphaned
I0416 22:13:43.049073       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:13:44.466811       1 controller.go:123] Found 0 jobs
I0416 22:13:44.469030       1 controller.go:139] Found 0 cronjobs
I0416 22:13:44.469042       1 controller.go:142] Found 0 groups
I0416 22:13:44.743138       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:44.895562       1 request.go:530] Throttling request took 92.728188ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:13:44.945648       1 request.go:530] Throttling request took 142.799334ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:13:44.996720       1 request.go:530] Throttling request took 193.862187ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:13:45.046196       1 request.go:530] Throttling request took 243.340979ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:13:45.095521       1 request.go:530] Throttling request took 292.65734ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:13:45.145522       1 request.go:530] Throttling request took 342.646923ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:13:45.195571       1 request.go:530] Throttling request took 392.64706ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:13:45.245607       1 request.go:530] Throttling request took 442.701028ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:13:45.248833       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:13:45.608440       1 wrap.go:47] GET /healthz: (100.785µs) 200 [kube-probe/1.15+ 127.0.0.1:52316]
I0416 22:13:47.044054       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:48.133854       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.VolumeAttachment total 0 items received
I0416 22:13:53.662300       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.662403       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 22:13:53.662417       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 22:13:53.662436       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 22:13:53.662431792 +0000 UTC m=+4255.816155929)
I0416 22:13:53.663072       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (637.12µs)
I0416 22:13:53.663097       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 22:13:53.663094702 +0000 UTC m=+4255.816818840)
I0416 22:13:53.663851       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (754.442µs)
I0416 22:13:53.663874       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 22:13:53.663880       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 22:13:53.663889       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 22:13:53.663886307 +0000 UTC m=+4255.817610446)
I0416 22:13:53.664550       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (659.975µs)
I0416 22:13:53.664572       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 22:13:53.664568896 +0000 UTC m=+4255.818293032)
I0416 22:13:53.664975       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (403.938µs)
I0416 22:13:53.664996       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 22:13:53.665017       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 22:13:53.665024       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 22:13:53.665022411 +0000 UTC m=+4255.818746550)
I0416 22:13:53.665447       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (422.736µs)
I0416 22:13:53.665456       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 22:13:53.665453984 +0000 UTC m=+4255.819178120)
I0416 22:13:53.666331       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (874.974µs)
I0416 22:13:53.666347       1 deployment_controller.go:175] Updating deployment coredns
I0416 22:13:53.666354       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 22:13:53.666361       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 22:13:53.666358457 +0000 UTC m=+4255.820082595)
I0416 22:13:53.666927       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (566.515µs)
I0416 22:13:53.666938       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 22:13:53.666935569 +0000 UTC m=+4255.820659706)
I0416 22:13:53.667388       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (450.543µs)
I0416 22:13:53.684521       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.684616       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 22:13:53.685902       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b28a773b76fc, ext:4008080368144, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.686213       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:13:53.686324       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b2c868e868a5, ext:4255840043942, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.686433       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:13:53.686489       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:13:53.686495       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b2c868e868a5, ext:4255840043942, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.686549       1 update.go:396] Getting unavailable numbers
I0416 22:13:53.686627       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:13:53.686660       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 22:13:53.686666       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:13:53.686670       1 update.go:68] Marking old pods for deletion
I0416 22:13:53.686674       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b2c868edc905, ext:4255840396269, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.686682       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:13:53.686750       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:13:53.686775       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:13:53.686846       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:13:53.686890       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.23305ms)
I0416 22:13:53.686963       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 22:13:53.687462       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b28a774c609a, ext:4008081476482, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.687617       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:13:53.687625       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b2c868fc4c79, ext:4255841347428, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.687675       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:13:53.687697       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:13:53.687701       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b2c868fc4c79, ext:4255841347428, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.687740       1 update.go:396] Getting unavailable numbers
I0416 22:13:53.687822       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:13:53.687827       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 22:13:53.687832       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:13:53.687835       1 update.go:68] Marking old pods for deletion
I0416 22:13:53.687838       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b2c868ff8eaf, ext:4255841560984, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.687844       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:13:53.687865       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:13:53.687897       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:13:53.688016       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:13:53.688023       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.047221ms)
I0416 22:13:53.699431       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.699592       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.699812       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (215.176µs)
I0416 22:13:53.699857       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.700061       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.700082       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.700091       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.700114       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.700331       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:13:53.700354       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.700358       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:13:53.700412       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.700515       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (105.512µs)
I0416 22:13:53.700540       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.700582       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (56.441µs)
I0416 22:13:53.700622       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:13:53.700633       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.700636       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:13:53.700655       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.700719       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (65.28µs)
I0416 22:13:53.700753       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.700830       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (78.276µs)
I0416 22:13:53.700844       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:13:53.700857       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.700860       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:13:53.700911       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:13:53.700929       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.700931       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:13:53.700995       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.701043       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (49.709µs)
I0416 22:13:53.701051       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.701094       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (44.308µs)
I0416 22:13:53.701106       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:13:53.701113       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701115       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:13:53.701135       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.701192       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (58.11µs)
I0416 22:13:53.701260       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.701297       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (39.349µs)
I0416 22:13:53.701306       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 22:13:53.701339       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (34.58µs)
I0416 22:13:53.701345       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 22:13:53.701356       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701359       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 22:13:53.701365       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:13:53.701369       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701371       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:13:53.701393       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 22:13:53.701401       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701404       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 22:13:53.701435       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 22:13:53.701441       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701443       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 22:13:53.701464       1 disruption.go:338] updatePod called on pod "pod1"
I0416 22:13:53.701471       1 disruption.go:401] No PodDisruptionBudgets found for pod pod1, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701474       1 disruption.go:341] No matching pdb for pod "pod1"
I0416 22:13:53.701498       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:13:53.701505       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701507       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:13:53.701510       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:13:53.701516       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701519       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:13:53.701539       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 22:13:53.701545       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701547       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 22:13:53.701585       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:13:53.701592       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701594       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:13:53.701636       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:13:53.701642       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701645       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:13:53.701661       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:13:53.701667       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701669       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:13:53.701687       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:13:53.701692       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701694       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:13:53.701727       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:13:53.701735       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701737       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:13:53.701763       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:13:53.701773       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701775       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:13:53.701793       1 disruption.go:338] updatePod called on pod "pod2"
I0416 22:13:53.701799       1 disruption.go:401] No PodDisruptionBudgets found for pod pod2, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701802       1 disruption.go:341] No matching pdb for pod "pod2"
I0416 22:13:53.701804       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:13:53.701814       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701816       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:13:53.701836       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:13:53.701845       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701847       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:13:53.701900       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:13:53.701903       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701905       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:13:53.701939       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:13:53.701945       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 22:13:53.701948       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:13:53.860909       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:53.894067       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:54.230042       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:54.230208       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:13:54.230257       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (3.017µs)
I0416 22:13:54.230284       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:13:54.230289       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (482ns)
I0416 22:13:54.230298       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:13:54.230304       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:13:54.230326       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (389ns)
I0416 22:13:54.230335       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (277ns)
I0416 22:13:54.280700       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:54.473088       1 controller.go:123] Found 0 jobs
I0416 22:13:54.475195       1 controller.go:139] Found 0 cronjobs
I0416 22:13:54.475205       1 controller.go:142] Found 0 groups
I0416 22:13:55.608481       1 wrap.go:47] GET /healthz: (151.469µs) 200 [kube-probe/1.15+ 127.0.0.1:52352]
I0416 22:13:55.794170       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolume total 0 items received
I0416 22:13:56.783735       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 0 items received
I0416 22:13:57.146655       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:13:57.338105       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:13:59.019456       1 request.go:530] Throttling request took 91.750244ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:13:59.069590       1 request.go:530] Throttling request took 141.86196ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:13:59.119554       1 request.go:530] Throttling request took 191.804678ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:13:59.169712       1 request.go:530] Throttling request took 241.948922ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:13:59.219939       1 request.go:530] Throttling request took 292.157082ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:13:59.269642       1 request.go:530] Throttling request took 341.846178ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:13:59.319608       1 request.go:530] Throttling request took 391.808403ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:13:59.369502       1 request.go:530] Throttling request took 441.706897ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:14:03.049728       1 gc_controller.go:144] GC'ing orphaned
I0416 22:14:03.054049       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:14:04.479175       1 controller.go:123] Found 0 jobs
I0416 22:14:04.481896       1 controller.go:139] Found 0 cronjobs
I0416 22:14:04.481912       1 controller.go:142] Found 0 groups
I0416 22:14:05.608562       1 wrap.go:47] GET /healthz: (87.68µs) 200 [kube-probe/1.15+ 127.0.0.1:52386]
I0416 22:14:07.813592       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Endpoints total 356 items received
I0416 22:14:11.800722       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:11.831304       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:12.146949       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:14:12.338370       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:13.792068       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 22:14:14.485910       1 controller.go:123] Found 0 jobs
I0416 22:14:14.488200       1 controller.go:139] Found 0 cronjobs
I0416 22:14:14.488210       1 controller.go:142] Found 0 groups
I0416 22:14:15.349511       1 request.go:530] Throttling request took 91.469901ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:14:15.399378       1 request.go:530] Throttling request took 141.321866ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:14:15.449384       1 request.go:530] Throttling request took 191.308462ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:14:15.499365       1 request.go:530] Throttling request took 241.268849ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:14:15.549765       1 request.go:530] Throttling request took 291.669079ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:14:15.599401       1 request.go:530] Throttling request took 341.295099ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:14:15.608558       1 wrap.go:47] GET /healthz: (90.274µs) 200 [kube-probe/1.15+ 127.0.0.1:52418]
I0416 22:14:15.649395       1 request.go:530] Throttling request took 391.281908ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:14:15.699397       1 request.go:530] Throttling request took 441.277923ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:14:15.701949       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:14:15.804343       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CronJob total 0 items received
I0416 22:14:18.294325       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:20.800925       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.MutatingWebhookConfiguration total 0 items received
I0416 22:14:23.054447       1 gc_controller.go:144] GC'ing orphaned
I0416 22:14:23.059064       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:14:24.492252       1 controller.go:123] Found 0 jobs
I0416 22:14:24.494763       1 controller.go:139] Found 0 cronjobs
I0416 22:14:24.494780       1 controller.go:142] Found 0 groups
I0416 22:14:25.608674       1 wrap.go:47] GET /healthz: (106.579µs) 200 [kube-probe/1.15+ 127.0.0.1:52450]
I0416 22:14:27.147403       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:14:27.338711       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:27.782389       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ReplicaSet total 0 items received
I0416 22:14:27.804535       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.RoleBinding total 0 items received
I0416 22:14:28.044602       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:14:29.002675       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:14:29.472315       1 request.go:530] Throttling request took 90.360927ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:14:29.522296       1 request.go:530] Throttling request took 140.312765ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:14:29.572359       1 request.go:530] Throttling request took 190.380402ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:14:29.622322       1 request.go:530] Throttling request took 240.336385ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:14:29.672338       1 request.go:530] Throttling request took 290.346687ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:14:29.722265       1 request.go:530] Throttling request took 340.250809ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:14:29.772330       1 request.go:530] Throttling request took 390.321398ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:14:29.822313       1 request.go:530] Throttling request took 440.277306ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:14:31.424523       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:14:32.568192       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:14:32.568251       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:14:33.044003       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PriorityClass total 0 items received
I0416 22:14:34.498327       1 controller.go:123] Found 0 jobs
I0416 22:14:34.500365       1 controller.go:139] Found 0 cronjobs
I0416 22:14:34.500375       1 controller.go:142] Found 0 groups
I0416 22:14:35.609526       1 wrap.go:47] GET /healthz: (100.576µs) 200 [kube-probe/1.15+ 127.0.0.1:52486]
I0416 22:14:37.514366       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:14:37.568665       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:14:39.978314       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 181 items received
I0416 22:14:41.801051       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:41.805813       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 22:14:41.831628       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:42.147771       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:14:42.339399       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:42.838062       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:14:43.059415       1 gc_controller.go:144] GC'ing orphaned
I0416 22:14:43.065515       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:14:44.504636       1 controller.go:123] Found 0 jobs
I0416 22:14:44.507427       1 controller.go:139] Found 0 cronjobs
I0416 22:14:44.507453       1 controller.go:142] Found 0 groups
I0416 22:14:44.811419       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicationController total 0 items received
I0416 22:14:45.609372       1 wrap.go:47] GET /healthz: (152.68µs) 200 [kube-probe/1.15+ 127.0.0.1:52538]
I0416 22:14:45.802515       1 request.go:530] Throttling request took 92.103379ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:14:45.853355       1 request.go:530] Throttling request took 142.946653ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:14:45.903350       1 request.go:530] Throttling request took 192.925436ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:14:45.953121       1 request.go:530] Throttling request took 242.689508ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:14:46.002950       1 request.go:530] Throttling request took 292.499381ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:14:46.052656       1 request.go:530] Throttling request took 342.181442ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:14:46.102801       1 request.go:530] Throttling request took 392.330382ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:14:46.152606       1 request.go:530] Throttling request took 442.127484ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:14:46.154862       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:14:54.510862       1 controller.go:123] Found 0 jobs
I0416 22:14:54.513845       1 controller.go:139] Found 0 cronjobs
I0416 22:14:54.513858       1 controller.go:142] Found 0 groups
I0416 22:14:55.608441       1 wrap.go:47] GET /healthz: (76.105µs) 200 [kube-probe/1.15+ 127.0.0.1:52574]
I0416 22:14:56.786748       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.ValidatingWebhookConfiguration total 0 items received
I0416 22:14:57.148158       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:14:57.339681       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:14:57.798807       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Role total 0 items received
I0416 22:14:59.925221       1 request.go:530] Throttling request took 92.257ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:14:59.975296       1 request.go:530] Throttling request took 142.28324ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:15:00.025252       1 request.go:530] Throttling request took 192.270696ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:15:00.075188       1 request.go:530] Throttling request took 242.212901ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:15:00.125341       1 request.go:530] Throttling request took 292.357336ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:15:00.175308       1 request.go:530] Throttling request took 342.31369ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:15:00.225192       1 request.go:530] Throttling request took 392.194978ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:15:00.275345       1 request.go:530] Throttling request took 442.325671ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:15:01.800950       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Job total 0 items received
I0416 22:15:03.065777       1 gc_controller.go:144] GC'ing orphaned
I0416 22:15:03.069752       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:15:04.517355       1 controller.go:123] Found 0 jobs
I0416 22:15:04.519533       1 controller.go:139] Found 0 cronjobs
I0416 22:15:04.519544       1 controller.go:142] Found 0 groups
I0416 22:15:05.608527       1 wrap.go:47] GET /healthz: (75.405µs) 200 [kube-probe/1.15+ 127.0.0.1:52608]
I0416 22:15:10.717820       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
I0416 22:15:11.801393       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:11.832010       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:12.148349       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:15:12.339976       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:14.523293       1 controller.go:123] Found 0 jobs
I0416 22:15:14.525686       1 controller.go:139] Found 0 cronjobs
I0416 22:15:14.525697       1 controller.go:142] Found 0 groups
I0416 22:15:15.608535       1 wrap.go:47] GET /healthz: (89.49µs) 200 [kube-probe/1.15+ 127.0.0.1:52640]
I0416 22:15:16.255452       1 request.go:530] Throttling request took 91.437753ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:15:16.305432       1 request.go:530] Throttling request took 141.405216ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:15:16.355298       1 request.go:530] Throttling request took 191.264783ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:15:16.405441       1 request.go:530] Throttling request took 241.385574ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:15:16.455314       1 request.go:530] Throttling request took 291.251756ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:15:16.505384       1 request.go:530] Throttling request took 341.304077ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:15:16.555364       1 request.go:530] Throttling request took 391.287225ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:15:16.605368       1 request.go:530] Throttling request took 441.281087ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:15:16.607612       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:15:18.283353       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Lease total 130 items received
I0416 22:15:18.785819       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 22:15:21.513322       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:15:21.513359       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:15:21.513384       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:15:21.513405       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:15:21.513800       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:15:21.534242       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:15:21.534277       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:15:21.534341       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:15:21.534362       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:15:21.534523       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:15:21.535997       1 controller_utils.go:200] Added [&Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 22:15:21.513514478 +0000 UTC m=+4343.667238614,}] Taint to Node e2e-test-peterhornyack-windows-node-group-31ht
I0416 22:15:21.536048       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-windows-node-group-31ht has no [] Taint
I0416 22:15:21.767051       1 service_controller.go:616] Ignoring node e2e-test-peterhornyack-windows-node-group-31ht with Ready condition status False
I0416 22:15:21.767082       1 service_controller.go:639] Detected change in list of current cluster nodes. New node set: map[e2e-test-peterhornyack-minion-group-06gd:{}]
I0416 22:15:21.767103       1 service_controller.go:647] Successfully updated 7 out of 7 load balancers to direct traffic to the updated set of nodes
I0416 22:15:22.574622       1 node_lifecycle_controller.go:857] ReadyCondition for Node e2e-test-peterhornyack-windows-node-group-31ht transitioned from &NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2019-04-16 22:14:31 +0000 UTC,LastTransitionTime:2019-04-16 21:09:54 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,} to &NodeCondition{Type:Ready,Status:False,LastHeartbeatTime:2019-04-16 22:15:21 +0000 UTC,LastTransitionTime:2019-04-16 22:15:21 +0000 UTC,Reason:KubeletNotReady,Message:PLEG is not healthy: pleg was last seen active 3m6.1481856s ago; threshold is 3m0s.,}
I0416 22:15:22.574718       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:15:22.574751       1 node_lifecycle_controller.go:700] Node e2e-test-peterhornyack-windows-node-group-31ht is NotReady as of 2019-04-16 22:15:22.574734845 +0000 UTC m=+4344.728458982. Adding it to the Taint queue.
I0416 22:15:22.620062       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:15:22.620112       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:15:22.620134       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:15:22.620169       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:15:22.620298       1 taint_manager.go:441] Noticed node update: scheduler.nodeUpdateItem{nodeName:"e2e-test-peterhornyack-windows-node-group-31ht"}
I0416 22:15:22.620326       1 taint_manager.go:446] Updating known taints on node e2e-test-peterhornyack-windows-node-group-31ht: [{node.kubernetes.io/not-ready  NoExecute 2019-04-16 22:15:22 +0000 UTC}]
I0416 22:15:22.620677       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:15:22.622408       1 controller_utils.go:200] Added [&Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoExecute,TimeAdded:2019-04-16 22:15:22.61129983 +0000 UTC m=+4344.765024030,}] Taint to Node e2e-test-peterhornyack-windows-node-group-31ht
I0416 22:15:22.622448       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-windows-node-group-31ht has no [&Taint{Key:node.kubernetes.io/unreachable,Value:,Effect:NoExecute,TimeAdded:<nil>,}] Taint
I0416 22:15:22.626656       1 timed_workers.go:110] Adding TimedWorkerQueue item services-1982/pod1 at 2019-04-16 22:15:22.626627708 +0000 UTC m=+4344.780351912 to be fired at 2019-04-16 22:20:22.626627708 +0000 UTC m=+4644.780351912
I0416 22:15:22.626704       1 timed_workers.go:110] Adding TimedWorkerQueue item services-1982/pod2 at 2019-04-16 22:15:22.626627708 +0000 UTC m=+4344.780351912 to be fired at 2019-04-16 22:20:22.626627708 +0000 UTC m=+4644.780351912
I0416 22:15:23.070146       1 gc_controller.go:144] GC'ing orphaned
I0416 22:15:23.074353       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:15:24.529339       1 controller.go:123] Found 0 jobs
I0416 22:15:24.531920       1 controller.go:139] Found 0 cronjobs
I0416 22:15:24.531934       1 controller.go:142] Found 0 groups
I0416 22:15:25.344223       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:15:25.011042964 +0000 UTC m=+7947.164767150 [59m59.666801739s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc001d3d880] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00077f9d0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176780] Scheduling:0xc00077fab0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc002b4dc80] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc002b4dc20 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:15:25 GMT] Etag:["ttbU4GRqjKzDG5eFrgIqNPjvoRA=/1iJxZ5GO39hruYndzbuiBQRax7o="] Expires:[Tue, 16 Apr 2019 22:15:25 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:15:25.608703       1 wrap.go:47] GET /healthz: (91.14µs) 200 [kube-probe/1.15+ 127.0.0.1:52674]
I0416 22:15:27.148607       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:15:27.340277       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:28.036750       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:15:29.076803       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:15:30.377894       1 request.go:530] Throttling request took 91.264086ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:15:30.427819       1 request.go:530] Throttling request took 141.189804ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:15:30.477834       1 request.go:530] Throttling request took 191.193447ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:15:30.527812       1 request.go:530] Throttling request took 241.170063ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:15:30.577955       1 request.go:530] Throttling request took 291.301152ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:15:30.583434       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:15:30.344549008 +0000 UTC m=+7952.498273269 [59m59.761106324s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc001e10a80] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00039aa10 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176840] Scheduling:0xc00039abd0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001fa9380] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001fa9320 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:15:30 GMT] Etag:["Ky-mHg7rmD-iPLM2XSjdBTd6xKQ=/z-RYfJ2_GO5SJDExJOYyNMUfHGo="] Expires:[Tue, 16 Apr 2019 22:15:30 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:15:30.627803       1 request.go:530] Throttling request took 341.132669ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:15:30.677830       1 request.go:530] Throttling request took 391.159604ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:15:30.727900       1 request.go:530] Throttling request took 441.187421ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:15:31.537578       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:15:32.575526       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:15:32.575566       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:15:34.536376       1 controller.go:123] Found 0 jobs
I0416 22:15:34.538757       1 controller.go:139] Found 0 cronjobs
I0416 22:15:34.538770       1 controller.go:142] Found 0 groups
I0416 22:15:35.609155       1 wrap.go:47] GET /healthz: (87.55µs) 200 [kube-probe/1.15+ 127.0.0.1:52710]
I0416 22:15:35.932204       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:15:35.583870693 +0000 UTC m=+7957.737595000 [59m59.65165788s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc00206bc00] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00047ecb0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0011769c0] Scheduling:0xc000341d50 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001c99080] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001c99020 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:15:35 GMT] Etag:["PjIGXmpLvkvGnnk17RwVVePRGnQ=/7yDbJMKmRNZl1bTnct4ixsPxy88="] Expires:[Tue, 16 Apr 2019 22:15:35 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:15:36.299388       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:37.764245       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:15:41.097631       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:15:40.932750368 +0000 UTC m=+7963.086474885 [59m59.835097014s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc00219ec40] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00077bf80 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176a80] Scheduling:0xc0003841c0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001a9b140] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001a9b080 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:15:41 GMT] Etag:["LzjcIW3-Jmn-KrPJxbwDroJYmiQ=/F0InVfRLU7_js7k0VYxHKO4MoO8="] Expires:[Tue, 16 Apr 2019 22:15:41 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:15:41.571851       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:15:41.801715       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:41.802112       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (270.257µs)
I0416 22:15:41.802291       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (126.356µs)
I0416 22:15:41.802350       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (50.608µs)
I0416 22:15:41.802445       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (74.034µs)
I0416 22:15:41.802465       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.598µs)
I0416 22:15:41.802624       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 22:15:41.806492       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (4.009624ms)
I0416 22:15:41.832338       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:42.148828       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:15:42.341367       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:42.576134       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:15:42.576241       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:15:43.075549       1 gc_controller.go:144] GC'ing orphaned
I0416 22:15:43.082514       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:15:43.779500       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Namespace total 2 items received
I0416 22:15:44.322906       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 3 items received
I0416 22:15:44.542887       1 controller.go:123] Found 0 jobs
I0416 22:15:44.544954       1 controller.go:139] Found 0 cronjobs
I0416 22:15:44.544966       1 controller.go:142] Found 0 groups
I0416 22:15:45.608388       1 wrap.go:47] GET /healthz: (184.598µs) 200 [kube-probe/1.15+ 127.0.0.1:52762]
I0416 22:15:46.292519       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:15:46.098056866 +0000 UTC m=+7968.251781016 [59m59.805529224s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc002293ea0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00033c070 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176c00] Scheduling:0xc00033c150 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc002329200] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc0023291a0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:15:46 GMT] Etag:["UBPql3qL3_CCY76NqBbZbwEwtr8=/mLkVs9VTnHqejl91evPRjJzjKf4="] Expires:[Tue, 16 Apr 2019 22:15:46 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:15:46.708572       1 request.go:530] Throttling request took 91.095223ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:15:46.760712       1 request.go:530] Throttling request took 143.217222ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:15:46.808098       1 request.go:530] Throttling request took 190.615186ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:15:46.858117       1 request.go:530] Throttling request took 240.58716ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:15:46.908253       1 request.go:530] Throttling request took 290.67907ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:15:46.958250       1 request.go:530] Throttling request took 340.691542ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:15:47.008476       1 request.go:530] Throttling request took 390.931877ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:15:47.058136       1 request.go:530] Throttling request took 440.566553ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:15:47.060705       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:15:51.469633       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:15:51.292978581 +0000 UTC m=+7973.446702965 [59m59.823334653s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc0027dee00] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00033ca10 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176cc0] Scheduling:0xc00033cbd0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc002129380] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc002129320 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:15:51 GMT] Etag:["1QoozsCFeS4ZwAzBatarTQ7cuKc=/sxPV2hEdbIoI-Icb9AaFG-_7A4Q="] Expires:[Tue, 16 Apr 2019 22:15:51 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:15:51.599160       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:15:52.576849       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:15:52.697655       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:15:54.343046       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Node total 33 items received
I0416 22:15:54.549019       1 controller.go:123] Found 0 jobs
I0416 22:15:54.551299       1 controller.go:139] Found 0 cronjobs
I0416 22:15:54.551309       1 controller.go:142] Found 0 groups
I0416 22:15:55.608719       1 wrap.go:47] GET /healthz: (86.774µs) 200 [kube-probe/1.15+ 127.0.0.1:52798]
I0416 22:15:56.639587       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:15:56.470035251 +0000 UTC m=+7978.623759499 [59m59.830439419s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc00289fdc0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00033d7a0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176e40] Scheduling:0xc00033d880 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001fa3140] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001fa30e0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:15:56 GMT] Etag:["ESRCrqJShIsGVhVppr4MdRziRJc=/G-UziW7ZYpvYZwMV50yqYjEEfyU="] Expires:[Tue, 16 Apr 2019 22:15:56 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:15:57.149013       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:15:57.341618       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:00.830721       1 request.go:530] Throttling request took 90.9683ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:16:00.880735       1 request.go:530] Throttling request took 140.968451ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:16:00.930715       1 request.go:530] Throttling request took 190.916047ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:16:00.980740       1 request.go:530] Throttling request took 240.935242ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:16:01.030790       1 request.go:530] Throttling request took 290.963163ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:16:01.080726       1 request.go:530] Throttling request took 340.898698ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:16:01.130860       1 request.go:530] Throttling request took 390.920602ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:16:01.180733       1 request.go:530] Throttling request took 440.888788ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:16:01.639222       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:16:01.807949       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:16:01.639934521 +0000 UTC m=+7983.793658675 [59m59.831975645s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc0029e0e00] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc0001fe690 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176fc0] Scheduling:0xc0001fe8c0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc0017cc000] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001785f80 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:16:01 GMT] Etag:["zoab-rScrKzpBmx99TP80EYT7-U=/g0ckoVC8TmpUveyp50QsgLE8koY="] Expires:[Tue, 16 Apr 2019 22:16:01 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:16:02.577636       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:16:03.082796       1 gc_controller.go:144] GC'ing orphaned
I0416 22:16:03.086726       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:16:04.555072       1 controller.go:123] Found 0 jobs
I0416 22:16:04.557603       1 controller.go:139] Found 0 cronjobs
I0416 22:16:04.557615       1 controller.go:142] Found 0 groups
I0416 22:16:05.608340       1 wrap.go:47] GET /healthz: (118.731µs) 200 [kube-probe/1.15+ 127.0.0.1:52844]
I0416 22:16:06.990013       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:16:06.808357213 +0000 UTC m=+7988.962081366 [59m59.818335586s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc0019760e0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc0001ff730 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0016b8000] Scheduling:0xc0001ff810 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001898f00] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001898ea0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:16:07 GMT] Etag:["B-Lr8v5zyroz-BHzShbRUrZmRa0=/R8dlRkrFCqTyr58fxcNhSPRjCNM="] Expires:[Tue, 16 Apr 2019 22:16:07 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:16:11.661478       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:16:11.802095       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:11.832583       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:12.149219       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:16:12.159415       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:16:11.990387591 +0000 UTC m=+7994.144111796 [59m59.830963898s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc001ab4fc0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc0002365b0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0016b8180] Scheduling:0xc000260310 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc0019aacc0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc0019aac60 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:16:12 GMT] Etag:["1QoozsCFeS4ZwAzBatarTQ7cuKc=/sxPV2hEdbIoI-Icb9AaFG-_7A4Q="] Expires:[Tue, 16 Apr 2019 22:16:12 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:16:12.341908       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:12.578330       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:16:14.561328       1 controller.go:123] Found 0 jobs
I0416 22:16:14.563739       1 controller.go:139] Found 0 cronjobs
I0416 22:16:14.563751       1 controller.go:142] Found 0 groups
I0416 22:16:15.608436       1 wrap.go:47] GET /healthz: (201.007µs) 200 [kube-probe/1.15+ 127.0.0.1:52876]
I0416 22:16:16.377445       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 22:16:17.161287       1 request.go:530] Throttling request took 92.012571ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:16:17.211172       1 request.go:530] Throttling request took 141.880817ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:16:17.261268       1 request.go:530] Throttling request took 191.954374ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:16:17.311196       1 request.go:530] Throttling request took 241.890784ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:16:17.361198       1 request.go:530] Throttling request took 291.884729ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:16:17.411284       1 request.go:530] Throttling request took 341.968014ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:16:17.462711       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:16:17.159804477 +0000 UTC m=+7999.313528718 [59m59.697083569s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc00263e0e0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc000528460 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0016b8240] Scheduling:0xc000528690 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc00102fb60] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc00102f1a0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:16:17 GMT] Etag:["f5eXBfdaicifUBHsJd_gs16GomY=/IBSSlrGAFUiDSR-xG19SgeyBv1E="] Expires:[Tue, 16 Apr 2019 22:16:17 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:16:17.462958       1 request.go:530] Throttling request took 393.651041ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:16:17.511317       1 request.go:530] Throttling request took 441.986808ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:16:17.513471       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
E0416 22:16:21.474284       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:16:21.474284       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:16:21.184161       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:16:21.474249       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (293.997827ms)
E0416 22:16:21.474284       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:16:21.686927       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:16:21.686975       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:16:21.687003       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:16:21.687027       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:16:21.687268       1 controller_utils.go:200] Added [] Taint to Node e2e-test-peterhornyack-windows-node-group-31ht
I0416 22:16:21.687591       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:16:21.700821       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:16:21.700854       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:16:21.700897       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:16:21.700920       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:16:21.701054       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:16:21.702040       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-windows-node-group-31ht has no [&Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 22:15:21 +0000 UTC,}] Taint
I0416 22:16:21.777669       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSIDriver total 0 items received
E0416 22:16:22.597722       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod1.1596143f1c7553bd", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod1", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod1", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod1.1596143f1c7553bd" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
E0416 22:16:22.599375       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod2.1596143f1c758c6f", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod2", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod2", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod2.1596143f1c758c6f" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
E0416 22:16:22.597722       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod1.1596143f1c7553bd", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod1", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod1", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod1.1596143f1c7553bd" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
E0416 22:16:22.599375       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod2.1596143f1c758c6f", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod2", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod2", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod2.1596143f1c758c6f" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
I0416 22:16:22.579101       1 node_lifecycle_controller.go:857] ReadyCondition for Node e2e-test-peterhornyack-windows-node-group-31ht transitioned from &NodeCondition{Type:Ready,Status:False,LastHeartbeatTime:2019-04-16 22:16:11 +0000 UTC,LastTransitionTime:2019-04-16 22:15:21 +0000 UTC,Reason:KubeletNotReady,Message:PLEG is not healthy: pleg was last seen active 3m56.2933333s ago; threshold is 3m0s.,} to &NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2019-04-16 22:16:21 +0000 UTC,LastTransitionTime:2019-04-16 22:16:21 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,}
I0416 22:16:22.579151       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:16:22.588019       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:16:22.588071       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:16:22.588100       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:16:22.588126       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:16:22.588286       1 taint_manager.go:441] Noticed node update: scheduler.nodeUpdateItem{nodeName:"e2e-test-peterhornyack-windows-node-group-31ht"}
I0416 22:16:22.588312       1 taint_manager.go:446] Updating known taints on node e2e-test-peterhornyack-windows-node-group-31ht: []
I0416 22:16:22.588618       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:16:22.591725       1 node_lifecycle_controller.go:752] Node e2e-test-peterhornyack-windows-node-group-31ht is healthy again, removing all taints
I0416 22:16:22.595991       1 taint_manager.go:463] All taints were removed from the Node e2e-test-peterhornyack-windows-node-group-31ht. Cancelling all evictions...
I0416 22:16:22.596009       1 timed_workers.go:129] Cancelling TimedWorkerQueue item services-1982/pod1 at 2019-04-16 22:16:22.596005688 +0000 UTC m=+4404.749729863
I0416 22:16:22.596039       1 timed_workers.go:129] Cancelling TimedWorkerQueue item services-1982/pod2 at 2019-04-16 22:16:22.596037586 +0000 UTC m=+4404.749761725
I0416 22:16:22.596508       1 event.go:258] Event(v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod1", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'TaintManagerEviction' Cancelling deletion of Pod services-1982/pod1
I0416 22:16:22.596528       1 event.go:258] Event(v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod2", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'TaintManagerEviction' Cancelling deletion of Pod services-1982/pod2
E0416 22:16:22.597722       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod1.1596143f1c7553bd", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod1", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod1", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod1.1596143f1c7553bd" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
E0416 22:16:22.599375       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod2.1596143f1c758c6f", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod2", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod2", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, Count:1, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod2.1596143f1c758c6f" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
I0416 22:16:23.087029       1 gc_controller.go:144] GC'ing orphaned
I0416 22:16:23.099578       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:16:24.567982       1 controller.go:123] Found 0 jobs
I0416 22:16:24.570481       1 controller.go:139] Found 0 cronjobs
I0416 22:16:24.570494       1 controller.go:142] Found 0 groups
I0416 22:16:25.608380       1 wrap.go:47] GET /healthz: (165.451µs) 200 [kube-probe/1.15+ 127.0.0.1:52908]
I0416 22:16:27.149454       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:16:27.342151       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:28.021906       1 reflector.go:384] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: Watch close - *unstructured.Unstructured total 0 items received
I0416 22:16:29.032940       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:16:29.149333       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:16:31.283791       1 request.go:530] Throttling request took 89.968078ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:16:31.333503       1 request.go:530] Throttling request took 139.690303ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:16:31.383562       1 request.go:530] Throttling request took 188.230487ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:16:31.433580       1 request.go:530] Throttling request took 238.238931ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:16:31.484025       1 request.go:530] Throttling request took 288.647127ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:16:31.533948       1 request.go:530] Throttling request took 338.569347ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:16:31.583605       1 request.go:530] Throttling request took 388.220051ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:16:31.633579       1 request.go:530] Throttling request took 438.171121ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:16:32.592492       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:16:32.799419       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.DaemonSet total 0 items received
I0416 22:16:34.574600       1 controller.go:123] Found 0 jobs
I0416 22:16:34.576840       1 controller.go:139] Found 0 cronjobs
I0416 22:16:34.576850       1 controller.go:142] Found 0 groups
I0416 22:16:35.608739       1 wrap.go:47] GET /healthz: (86.264µs) 200 [kube-probe/1.15+ 127.0.0.1:52944]
I0416 22:16:35.806301       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.NetworkPolicy total 0 items received
I0416 22:16:37.875323       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:16:41.802371       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:41.832848       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:42.149655       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:16:42.343307       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:42.593283       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:16:43.101454       1 gc_controller.go:144] GC'ing orphaned
I0416 22:16:43.109779       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:16:43.218323       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:16:44.235132       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.HorizontalPodAutoscaler total 0 items received
I0416 22:16:44.580488       1 controller.go:123] Found 0 jobs
I0416 22:16:44.582585       1 controller.go:139] Found 0 cronjobs
I0416 22:16:44.582596       1 controller.go:142] Found 0 groups
I0416 22:16:45.608418       1 wrap.go:47] GET /healthz: (92.104µs) 200 [kube-probe/1.15+ 127.0.0.1:52996]
I0416 22:16:47.614157       1 request.go:530] Throttling request took 93.275768ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:16:47.664132       1 request.go:530] Throttling request took 143.244045ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:16:47.714114       1 request.go:530] Throttling request took 193.213839ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:16:47.764135       1 request.go:530] Throttling request took 243.180292ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:16:47.814088       1 request.go:530] Throttling request took 293.167849ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:16:47.864052       1 request.go:530] Throttling request took 340.692029ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:16:47.914089       1 request.go:530] Throttling request took 390.715479ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:16:47.964112       1 request.go:530] Throttling request took 440.723549ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:16:47.966731       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:16:54.586661       1 controller.go:123] Found 0 jobs
I0416 22:16:54.589129       1 controller.go:139] Found 0 cronjobs
I0416 22:16:54.589141       1 controller.go:142] Found 0 groups
I0416 22:16:55.608453       1 wrap.go:47] GET /healthz: (87.428µs) 200 [kube-probe/1.15+ 127.0.0.1:53032]
I0416 22:16:57.149925       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:16:57.182333       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.NetworkPolicy total 0 items received
I0416 22:16:57.343620       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:01.736700       1 request.go:530] Throttling request took 82.937373ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:17:01.767571       1 service_controller.go:639] Detected change in list of current cluster nodes. New node set: map[e2e-test-peterhornyack-minion-group-06gd:{} e2e-test-peterhornyack-windows-node-group-31ht:{}]
I0416 22:17:01.767636       1 service_controller.go:647] Successfully updated 7 out of 7 load balancers to direct traffic to the updated set of nodes
I0416 22:17:01.786851       1 request.go:530] Throttling request took 133.077896ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:17:01.836713       1 request.go:530] Throttling request took 182.922026ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:17:01.886685       1 request.go:530] Throttling request took 232.876132ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:17:01.936708       1 request.go:530] Throttling request took 282.879519ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:17:01.986654       1 request.go:530] Throttling request took 332.836423ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:17:02.036697       1 request.go:530] Throttling request took 382.857706ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:17:02.086699       1 request.go:530] Throttling request took 432.85075ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:17:03.110085       1 gc_controller.go:144] GC'ing orphaned
I0416 22:17:03.114164       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:17:04.593304       1 controller.go:123] Found 0 jobs
I0416 22:17:04.595712       1 controller.go:139] Found 0 cronjobs
I0416 22:17:04.595723       1 controller.go:142] Found 0 groups
I0416 22:17:04.886097       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:05.608587       1 wrap.go:47] GET /healthz: (79.398µs) 200 [kube-probe/1.15+ 127.0.0.1:53066]
I0416 22:17:11.532153       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ResourceQuota total 0 items received
I0416 22:17:11.802692       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:11.833157       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:12.150147       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:17:12.343872       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:14.599426       1 controller.go:123] Found 0 jobs
I0416 22:17:14.603038       1 controller.go:139] Found 0 cronjobs
I0416 22:17:14.603050       1 controller.go:142] Found 0 groups
I0416 22:17:15.608629       1 wrap.go:47] GET /healthz: (72.931µs) 200 [kube-probe/1.15+ 127.0.0.1:53098]
I0416 22:17:18.067162       1 request.go:530] Throttling request took 91.101891ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:17:18.117194       1 request.go:530] Throttling request took 141.127375ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:17:18.167191       1 request.go:530] Throttling request took 191.089177ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:17:18.217144       1 request.go:530] Throttling request took 241.036584ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:17:18.267179       1 request.go:530] Throttling request took 291.064098ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:17:18.317224       1 request.go:530] Throttling request took 341.099954ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:17:18.367158       1 request.go:530] Throttling request took 391.028482ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:17:18.417160       1 request.go:530] Throttling request took 441.020838ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:17:18.419978       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:17:18.477700       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:17:20.791357       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Service total 0 items received
I0416 22:17:20.815961       1 reflector.go:384] pkg/controller/garbagecollector/graph_builder.go:124: Watch close - <nil> total 0 items received
I0416 22:17:21.330526       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CertificateSigningRequest total 0 items received
I0416 22:17:21.789792       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:17:22.596659       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:17:23.114365       1 gc_controller.go:144] GC'ing orphaned
I0416 22:17:23.118465       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:17:24.606971       1 controller.go:123] Found 0 jobs
I0416 22:17:24.609303       1 controller.go:139] Found 0 cronjobs
I0416 22:17:24.609315       1 controller.go:142] Found 0 groups
I0416 22:17:25.608422       1 wrap.go:47] GET /healthz: (86.032µs) 200 [kube-probe/1.15+ 127.0.0.1:53130]
I0416 22:17:27.150345       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:17:27.323489       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Secret total 0 items received
I0416 22:17:27.344109       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:28.375920       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:29.226077       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:17:30.031698       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:17:32.192634       1 request.go:530] Throttling request took 91.919017ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:17:32.242641       1 request.go:530] Throttling request took 141.915892ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:17:32.292624       1 request.go:530] Throttling request took 191.890126ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:17:32.342620       1 request.go:530] Throttling request took 241.879648ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:17:32.392563       1 request.go:530] Throttling request took 291.817783ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:17:32.442641       1 request.go:530] Throttling request took 341.874824ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:17:32.492621       1 request.go:530] Throttling request took 391.832358ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:17:32.543179       1 request.go:530] Throttling request took 442.396329ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:17:32.597408       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:17:34.613242       1 controller.go:123] Found 0 jobs
I0416 22:17:34.615413       1 controller.go:139] Found 0 cronjobs
I0416 22:17:34.615424       1 controller.go:142] Found 0 groups
I0416 22:17:35.608632       1 wrap.go:47] GET /healthz: (86.783µs) 200 [kube-probe/1.15+ 127.0.0.1:53166]
I0416 22:17:37.842860       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Deployment total 0 items received
I0416 22:17:37.997104       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:17:40.034504       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:41.802989       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:41.833369       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:42.150568       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:17:42.345336       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:42.598173       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:17:43.119517       1 gc_controller.go:144] GC'ing orphaned
I0416 22:17:43.132539       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:17:44.619798       1 controller.go:123] Found 0 jobs
I0416 22:17:44.621962       1 controller.go:139] Found 0 cronjobs
I0416 22:17:44.621971       1 controller.go:142] Found 0 groups
I0416 22:17:45.608569       1 wrap.go:47] GET /healthz: (87.135µs) 200 [kube-probe/1.15+ 127.0.0.1:53218]
I0416 22:17:48.520547       1 request.go:530] Throttling request took 89.911684ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:17:48.570536       1 request.go:530] Throttling request took 139.88383ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:17:48.620753       1 request.go:530] Throttling request took 190.086858ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:17:48.670566       1 request.go:530] Throttling request took 239.897909ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:17:48.720547       1 request.go:530] Throttling request took 289.869074ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:17:48.770873       1 request.go:530] Throttling request took 340.17222ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:17:48.820727       1 request.go:530] Throttling request took 390.004858ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:17:48.870547       1 request.go:530] Throttling request took 439.821253ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:17:48.873355       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:17:48.979104       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:48.982561       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:48.982998       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:17:48.983159       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:17:48.983346       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:17:48.986444       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:17:53.783631       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ConfigMap total 179 items received
I0416 22:17:54.626029       1 controller.go:123] Found 0 jobs
I0416 22:17:54.628540       1 controller.go:139] Found 0 cronjobs
I0416 22:17:54.628551       1 controller.go:142] Found 0 groups
I0416 22:17:54.797567       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodSecurityPolicy total 0 items received
I0416 22:17:55.608260       1 wrap.go:47] GET /healthz: (82.73µs) 200 [kube-probe/1.15+ 127.0.0.1:53254]
I0416 22:17:57.150831       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:17:57.345659       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.421040       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.422398       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.422497       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.422591       1 deployment_controller.go:175] Updating deployment event-exporter-v0.2.4
I0416 22:18:01.422604       1 deployment_controller.go:175] Updating deployment metrics-server-v0.3.1
I0416 22:18:01.422625       1 deployment_controller.go:562] Started syncing deployment "kube-system/event-exporter-v0.2.4" (2019-04-16 22:18:01.42262017 +0000 UTC m=+4503.576344307)
I0416 22:18:01.423357       1 deployment_controller.go:564] Finished syncing deployment "kube-system/event-exporter-v0.2.4" (733.496µs)
I0416 22:18:01.423380       1 deployment_controller.go:562] Started syncing deployment "kube-system/metrics-server-v0.3.1" (2019-04-16 22:18:01.423376048 +0000 UTC m=+4503.577100190)
I0416 22:18:01.424483       1 deployment_controller.go:564] Finished syncing deployment "kube-system/metrics-server-v0.3.1" (1.100734ms)
I0416 22:18:01.424542       1 deployment_controller.go:175] Updating deployment coredns
I0416 22:18:01.424556       1 deployment_controller.go:562] Started syncing deployment "kube-system/coredns" (2019-04-16 22:18:01.424552218 +0000 UTC m=+4503.578276356)
I0416 22:18:01.425363       1 deployment_controller.go:564] Finished syncing deployment "kube-system/coredns" (808.252µs)
I0416 22:18:01.425427       1 deployment_controller.go:175] Updating deployment l7-default-backend
I0416 22:18:01.425432       1 deployment_controller.go:175] Updating deployment kube-dns-autoscaler
I0416 22:18:01.425462       1 deployment_controller.go:562] Started syncing deployment "kube-system/l7-default-backend" (2019-04-16 22:18:01.425445809 +0000 UTC m=+4503.579169947)
I0416 22:18:01.425916       1 deployment_controller.go:564] Finished syncing deployment "kube-system/l7-default-backend" (468.173µs)
I0416 22:18:01.425925       1 deployment_controller.go:562] Started syncing deployment "kube-system/kube-dns-autoscaler" (2019-04-16 22:18:01.425923335 +0000 UTC m=+4503.579647471)
I0416 22:18:01.426278       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kube-dns-autoscaler" (353.379µs)
I0416 22:18:01.426302       1 deployment_controller.go:175] Updating deployment heapster-v1.6.0-beta.1
I0416 22:18:01.426323       1 deployment_controller.go:562] Started syncing deployment "kube-system/heapster-v1.6.0-beta.1" (2019-04-16 22:18:01.426307538 +0000 UTC m=+4503.580031678)
I0416 22:18:01.427182       1 deployment_controller.go:564] Finished syncing deployment "kube-system/heapster-v1.6.0-beta.1" (872.229µs)
I0416 22:18:01.427219       1 deployment_controller.go:175] Updating deployment kubernetes-dashboard
I0416 22:18:01.427245       1 deployment_controller.go:562] Started syncing deployment "kube-system/kubernetes-dashboard" (2019-04-16 22:18:01.427241887 +0000 UTC m=+4503.580966037)
I0416 22:18:01.427834       1 deployment_controller.go:564] Finished syncing deployment "kube-system/kubernetes-dashboard" (589.58µs)
I0416 22:18:01.427856       1 deployment_controller.go:175] Updating deployment fluentd-gcp-scaler
I0416 22:18:01.427864       1 deployment_controller.go:562] Started syncing deployment "kube-system/fluentd-gcp-scaler" (2019-04-16 22:18:01.427861848 +0000 UTC m=+4503.581585988)
I0416 22:18:01.428177       1 deployment_controller.go:564] Finished syncing deployment "kube-system/fluentd-gcp-scaler" (313.793µs)
I0416 22:18:01.447650       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.447757       1 daemon_controller.go:183] Updating daemon set fluentd-gcp-v3.2.0
I0416 22:18:01.447773       1 daemon_controller.go:183] Updating daemon set metadata-proxy-v0.1
I0416 22:18:01.449796       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b2c868edc905, ext:4255840396269, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.450151       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:18:01.450177       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b3065ad517cb, ext:4503603897029, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.450260       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:18:01.450332       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:18:01.450340       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b3065ad517cb, ext:4503603897029, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.450379       1 update.go:396] Getting unavailable numbers
I0416 22:18:01.450493       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:18:01.450506       1 update.go:429]  DaemonSet kube-system/fluentd-gcp-v3.2.0, maxUnavailable: 1, numUnavailable: 0
I0416 22:18:01.450512       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:18:01.450516       1 update.go:68] Marking old pods for deletion
I0416 22:18:01.450520       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-v3.2.0", timestamp:time.Time{wall:0xbf25b3065ada5d3d, ext:4503604242470, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.450526       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set fluentd-gcp-v3.2.0: [], creating 0
I0416 22:18:01.450610       1 daemon_controller.go:1082] Pods to delete for daemon set fluentd-gcp-v3.2.0: [], deleting 0
I0416 22:18:01.450651       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:18:01.450759       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:18:01.450767       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/fluentd-gcp-v3.2.0" (2.975148ms)
I0416 22:18:01.451809       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b2c868ff8eaf, ext:4255841560984, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.452100       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:18:01.452119       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b3065af2c02a, ext:4503605840667, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.452129       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:18:01.452177       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:18:01.452185       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b3065af2c02a, ext:4503605840667, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.452217       1 update.go:396] Getting unavailable numbers
I0416 22:18:01.452349       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:18:01.452355       1 update.go:429]  DaemonSet kube-system/metadata-proxy-v0.1, maxUnavailable: 1, numUnavailable: 0
I0416 22:18:01.452359       1 update.go:58] Marking all unavailable old pods for deletion
I0416 22:18:01.452363       1 update.go:68] Marking old pods for deletion
I0416 22:18:01.452366       1 controller_utils.go:219] Setting expectations &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metadata-proxy-v0.1", timestamp:time.Time{wall:0xbf25b3065af68a73, ext:4503606089131, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.452372       1 daemon_controller.go:1006] Nodes needing daemon pods for daemon set metadata-proxy-v0.1: [], creating 0
I0416 22:18:01.452392       1 daemon_controller.go:1082] Pods to delete for daemon set metadata-proxy-v0.1: [], deleting 0
I0416 22:18:01.452434       1 daemon_controller.go:1149] Updating daemon set status
I0416 22:18:01.452546       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:18:01.452552       1 daemon_controller.go:1207] Finished syncing daemon set "kube-system/metadata-proxy-v0.1" (1.753845ms)
I0416 22:18:01.459803       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.459975       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.460066       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-5858bf5485", timestamp:time.Time{wall:0xbf25aee314e7d394, ext:266504461437, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.460274       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-5858bf5485" (216.222µs)
I0416 22:18:01.460474       1 disruption.go:338] updatePod called on pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:18:01.460495       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-apiserver-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.460499       1 disruption.go:341] No matching pdb for pod "kube-apiserver-e2e-test-peterhornyack-master"
I0416 22:18:01.460553       1 disruption.go:338] updatePod called on pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:18:01.460562       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.460565       1 disruption.go:341] No matching pdb for pod "l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master"
I0416 22:18:01.460656       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kube-dns-autoscaler-97df449df", timestamp:time.Time{wall:0xbf25aeadaaa376ba, ext:52869079989, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.460737       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kube-dns-autoscaler-97df449df" (84.129µs)
I0416 22:18:01.460781       1 disruption.go:338] updatePod called on pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:18:01.460788       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-empty-dir-cleanup-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.460791       1 disruption.go:341] No matching pdb for pod "etcd-empty-dir-cleanup-e2e-test-peterhornyack-master"
I0416 22:18:01.460825       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-677c578bdf", timestamp:time.Time{wall:0xbf25aee236957ff0, ext:263069491416, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.460896       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-677c578bdf" (74.999µs)
I0416 22:18:01.460917       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/fluentd-gcp-scaler-7db4984bf4", timestamp:time.Time{wall:0xbf25aead3974a2a1, ext:51117669282, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.461014       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/fluentd-gcp-scaler-7db4984bf4" (99.11µs)
I0416 22:18:01.461024       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/metrics-server-v0.3.1-7d9cf58c5c", timestamp:time.Time{wall:0xbf25aee08a5271d7, ext:256326899415, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.461079       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/metrics-server-v0.3.1-7d9cf58c5c" (56.166µs)
I0416 22:18:01.461120       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-6mpws"
I0416 22:18:01.461131       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-6mpws, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461134       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-6mpws"
I0416 22:18:01.461150       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/heapster-v1.6.0-beta.1-77858557dc", timestamp:time.Time{wall:0xbf25aee161a9bae1, ext:259718495704, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.461203       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/heapster-v1.6.0-beta.1-77858557dc" (55.454µs)
I0416 22:18:01.461276       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/l7-default-backend-8f479dd9", timestamp:time.Time{wall:0xbf25aeac24158742, ext:46759114809, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.461325       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/l7-default-backend-8f479dd9" (50.551µs)
I0416 22:18:01.461338       1 disruption.go:338] updatePod called on pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:18:01.461347       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-scaler-7db4984bf4-26sjq, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461356       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-scaler-7db4984bf4-26sjq"
I0416 22:18:01.461386       1 disruption.go:338] updatePod called on pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:18:01.461394       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-controller-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461397       1 disruption.go:341] No matching pdb for pod "kube-controller-manager-e2e-test-peterhornyack-master"
I0416 22:18:01.461437       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/kubernetes-dashboard-85bcf5dbf8", timestamp:time.Time{wall:0xbf25aeada56c8fe8, ext:52781595880, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.461483       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/kubernetes-dashboard-85bcf5dbf8" (50.122µs)
I0416 22:18:01.461504       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/event-exporter-v0.2.4-65d8d98768", timestamp:time.Time{wall:0xbf25aeac52fd30d8, ext:47472307161, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.461547       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/event-exporter-v0.2.4-65d8d98768" (58.011µs)
I0416 22:18:01.461558       1 disruption.go:338] updatePod called on pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:18:01.461564       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461566       1 disruption.go:341] No matching pdb for pod "etcd-server-e2e-test-peterhornyack-master"
I0416 22:18:01.461604       1 controller_utils.go:185] Controller expectations fulfilled &controller.ControlleeExpectations{add:0, del:0, key:"kube-system/coredns-5b969f4c88", timestamp:time.Time{wall:0xbf25af08e6450284, ext:417795780993, loc:(*time.Location)(0x71c51c0)}}
I0416 22:18:01.461675       1 replica_set.go:566] Finished syncing ReplicaSet "kube-system/coredns-5b969f4c88" (73.129µs)
I0416 22:18:01.461717       1 disruption.go:338] updatePod called on pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:18:01.461728       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-proxy-e2e-test-peterhornyack-minion-group-06gd, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461731       1 disruption.go:341] No matching pdb for pod "kube-proxy-e2e-test-peterhornyack-minion-group-06gd"
I0416 22:18:01.461734       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:18:01.461745       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-n97bf, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461748       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-n97bf"
I0416 22:18:01.461782       1 disruption.go:338] updatePod called on pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:18:01.461792       1 disruption.go:401] No PodDisruptionBudgets found for pod fluentd-gcp-v3.2.0-xtf58, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461794       1 disruption.go:341] No matching pdb for pod "fluentd-gcp-v3.2.0-xtf58"
I0416 22:18:01.461817       1 disruption.go:338] updatePod called on pod "pod2"
I0416 22:18:01.461822       1 disruption.go:401] No PodDisruptionBudgets found for pod pod2, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461825       1 disruption.go:341] No matching pdb for pod "pod2"
I0416 22:18:01.461850       1 disruption.go:338] updatePod called on pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:18:01.461857       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-dns-autoscaler-97df449df-4ggmd, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461860       1 disruption.go:341] No matching pdb for pod "kube-dns-autoscaler-97df449df-4ggmd"
I0416 22:18:01.461882       1 disruption.go:338] updatePod called on pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:18:01.461889       1 disruption.go:401] No PodDisruptionBudgets found for pod event-exporter-v0.2.4-65d8d98768-n6vvr, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461892       1 disruption.go:341] No matching pdb for pod "event-exporter-v0.2.4-65d8d98768-n6vvr"
I0416 22:18:01.461910       1 disruption.go:338] updatePod called on pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:18:01.461917       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-scheduler-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461919       1 disruption.go:341] No matching pdb for pod "kube-scheduler-e2e-test-peterhornyack-master"
I0416 22:18:01.461944       1 disruption.go:338] updatePod called on pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:18:01.461950       1 disruption.go:401] No PodDisruptionBudgets found for pod kube-addon-manager-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461952       1 disruption.go:341] No matching pdb for pod "kube-addon-manager-e2e-test-peterhornyack-master"
I0416 22:18:01.461975       1 disruption.go:338] updatePod called on pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:18:01.461982       1 disruption.go:401] No PodDisruptionBudgets found for pod heapster-v1.6.0-beta.1-77858557dc-gwsdj, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461985       1 disruption.go:341] No matching pdb for pod "heapster-v1.6.0-beta.1-77858557dc-gwsdj"
I0416 22:18:01.461988       1 disruption.go:338] updatePod called on pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:18:01.461995       1 disruption.go:401] No PodDisruptionBudgets found for pod l7-default-backend-8f479dd9-wbtkw, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.461998       1 disruption.go:341] No matching pdb for pod "l7-default-backend-8f479dd9-wbtkw"
I0416 22:18:01.462021       1 disruption.go:338] updatePod called on pod "pod1"
I0416 22:18:01.462027       1 disruption.go:401] No PodDisruptionBudgets found for pod pod1, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.462031       1 disruption.go:341] No matching pdb for pod "pod1"
I0416 22:18:01.462076       1 disruption.go:338] updatePod called on pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:18:01.462083       1 disruption.go:401] No PodDisruptionBudgets found for pod kubernetes-dashboard-85bcf5dbf8-t5nl6, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.462085       1 disruption.go:341] No matching pdb for pod "kubernetes-dashboard-85bcf5dbf8-t5nl6"
I0416 22:18:01.462120       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-ll5kc"
I0416 22:18:01.462129       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-ll5kc, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.462131       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-ll5kc"
I0416 22:18:01.462158       1 disruption.go:338] updatePod called on pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:18:01.462161       1 disruption.go:401] No PodDisruptionBudgets found for pod etcd-server-events-e2e-test-peterhornyack-master, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.462164       1 disruption.go:341] No matching pdb for pod "etcd-server-events-e2e-test-peterhornyack-master"
I0416 22:18:01.462186       1 disruption.go:338] updatePod called on pod "metadata-proxy-v0.1-m4h7x"
I0416 22:18:01.462195       1 disruption.go:401] No PodDisruptionBudgets found for pod metadata-proxy-v0.1-m4h7x, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.462197       1 disruption.go:341] No matching pdb for pod "metadata-proxy-v0.1-m4h7x"
I0416 22:18:01.462200       1 disruption.go:338] updatePod called on pod "coredns-5b969f4c88-zcdpb"
I0416 22:18:01.462207       1 disruption.go:401] No PodDisruptionBudgets found for pod coredns-5b969f4c88-zcdpb, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.462209       1 disruption.go:341] No matching pdb for pod "coredns-5b969f4c88-zcdpb"
I0416 22:18:01.462269       1 disruption.go:338] updatePod called on pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:18:01.462277       1 disruption.go:401] No PodDisruptionBudgets found for pod metrics-server-v0.3.1-7d9cf58c5c-xrmt9, PodDisruptionBudget controller will avoid syncing.
I0416 22:18:01.462279       1 disruption.go:341] No matching pdb for pod "metrics-server-v0.3.1-7d9cf58c5c-xrmt9"
I0416 22:18:01.462670       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.462716       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.462732       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.462744       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.462759       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.462780       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.462879       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.462894       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.499348       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.621728       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.654012       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.767713       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.840574       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.940672       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.990178       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:01.990284       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:18:01.990334       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (3.578µs)
I0416 22:18:01.990364       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:18:01.990369       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (556ns)
I0416 22:18:01.990378       1 certificate_controller.go:82] Updating certificate request node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y
I0416 22:18:01.990386       1 certificate_controller.go:82] Updating certificate request node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg
I0416 22:18:01.990412       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-X0IgxteN_qsI9zGBXYRa33Ae_4rn0iI0m4pwOJvnn1Y" (521ns)
I0416 22:18:01.990422       1 certificate_controller.go:172] Finished syncing certificate request "node-csr-6kp_83WwvoGAteTLTJFM5Khs-ge3d-llD6VAmrWdAWg" (357ns)
I0416 22:18:02.040700       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:02.196964       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:02.646537       1 request.go:530] Throttling request took 91.786576ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:18:02.696585       1 request.go:530] Throttling request took 141.742683ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:18:02.746488       1 request.go:530] Throttling request took 191.700131ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:18:02.796521       1 request.go:530] Throttling request took 241.707742ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:18:02.846568       1 request.go:530] Throttling request took 291.743002ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
E0416 22:18:06.770067       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
E0416 22:18:06.770067       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:18:02.896525       1 request.go:530] Throttling request took 341.714539ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:18:02.946571       1 request.go:530] Throttling request took 391.753967ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:18:02.996628       1 request.go:530] Throttling request took 441.753742ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:18:03.132816       1 gc_controller.go:144] GC'ing orphaned
I0416 22:18:03.137919       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:18:04.632755       1 controller.go:123] Found 0 jobs
I0416 22:18:04.635344       1 controller.go:139] Found 0 cronjobs
I0416 22:18:04.635355       1 controller.go:142] Found 0 groups
I0416 22:18:05.608472       1 wrap.go:47] GET /healthz: (93.441µs) 200 [kube-probe/1.15+ 127.0.0.1:53288]
I0416 22:18:06.425365       1 namespaced_resources_deleter.go:484] namespace controller - deleteAllContent - namespace: services-1982
I0416 22:18:06.770033       1 namespace_controller.go:166] Finished syncing namespace "services-1982" (348.585683ms)
E0416 22:18:06.770067       1 namespace_controller.go:148] unexpected items still remain in namespace: services-1982 for gvr: /v1, Resource=pods
I0416 22:18:11.803324       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:11.833688       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:12.151082       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:18:12.345922       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:14.639395       1 controller.go:123] Found 0 jobs
I0416 22:18:14.641582       1 controller.go:139] Found 0 cronjobs
I0416 22:18:14.641594       1 controller.go:142] Found 0 groups
I0416 22:18:15.608627       1 wrap.go:47] GET /healthz: (86.183µs) 200 [kube-probe/1.15+ 127.0.0.1:53320]
I0416 22:18:16.795272       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.PodDisruptionBudget total 0 items received
I0416 22:18:18.973855       1 request.go:530] Throttling request took 87.970183ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:18:19.023922       1 request.go:530] Throttling request took 138.033316ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:18:19.073919       1 request.go:530] Throttling request took 187.950171ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:18:19.123901       1 request.go:530] Throttling request took 237.99428ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:18:19.173894       1 request.go:530] Throttling request took 287.971099ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:18:19.223955       1 request.go:530] Throttling request took 338.002407ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:18:19.274411       1 request.go:530] Throttling request took 388.448094ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:18:19.323850       1 request.go:530] Throttling request took 437.893389ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:18:19.326610       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:18:20.486197       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ControllerRevision total 0 items received
I0416 22:18:21.900837       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:18:22.604346       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:18:23.138276       1 gc_controller.go:144] GC'ing orphaned
I0416 22:18:23.143396       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:18:24.645605       1 controller.go:123] Found 0 jobs
I0416 22:18:24.648219       1 controller.go:139] Found 0 cronjobs
I0416 22:18:24.648340       1 controller.go:142] Found 0 groups
I0416 22:18:25.608711       1 wrap.go:47] GET /healthz: (87.969µs) 200 [kube-probe/1.15+ 127.0.0.1:53352]
I0416 22:18:27.151363       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:18:27.346558       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:29.305463       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:18:31.024187       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:18:32.605131       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:18:33.099665       1 request.go:530] Throttling request took 91.872922ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:18:33.149715       1 request.go:530] Throttling request took 141.911042ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:18:33.199760       1 request.go:530] Throttling request took 191.953209ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:18:33.249812       1 request.go:530] Throttling request took 241.987592ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:18:33.299654       1 request.go:530] Throttling request took 291.81159ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:18:33.349660       1 request.go:530] Throttling request took 341.80686ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:18:33.399663       1 request.go:530] Throttling request took 391.796886ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:18:33.449922       1 request.go:530] Throttling request took 442.04914ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:18:34.651804       1 controller.go:123] Found 0 jobs
I0416 22:18:34.653804       1 controller.go:139] Found 0 cronjobs
I0416 22:18:34.653813       1 controller.go:142] Found 0 groups
I0416 22:18:35.608380       1 wrap.go:47] GET /healthz: (81.724µs) 200 [kube-probe/1.15+ 127.0.0.1:53386]
I0416 22:18:38.138129       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:18:41.005469       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.PersistentVolumeClaim total 0 items received
I0416 22:18:41.803677       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:41.834035       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:42.151679       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:18:42.347342       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:18:42.564254       1 resource_quota_controller.go:192] Resource quota controller queued all resource quota for full calculation of usage
I0416 22:18:42.605925       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:18:42.794565       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Pod total 0 items received
I0416 22:18:43.144027       1 gc_controller.go:144] GC'ing orphaned
I0416 22:18:43.148320       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:18:43.967258       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRole total 0 items received
I0416 22:18:44.657480       1 controller.go:123] Found 0 jobs
I0416 22:18:44.660313       1 controller.go:139] Found 0 cronjobs
I0416 22:18:44.660326       1 controller.go:142] Found 0 groups
I0416 22:18:45.608539       1 wrap.go:47] GET /healthz: (87.132µs) 200 [kube-probe/1.15+ 127.0.0.1:53440]
I0416 22:18:49.427031       1 request.go:530] Throttling request took 93.321447ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:18:49.477065       1 request.go:530] Throttling request took 143.344457ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:18:49.527017       1 request.go:530] Throttling request took 193.292384ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:18:49.577089       1 request.go:530] Throttling request took 243.352272ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:18:49.627076       1 request.go:530] Throttling request took 293.316359ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:18:49.677080       1 request.go:530] Throttling request took 340.86576ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:18:49.727485       1 request.go:530] Throttling request took 391.225334ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:18:49.777242       1 request.go:530] Throttling request took 440.857933ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:18:49.779454       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:18:53.790753       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Lease total 169 items received
I0416 22:18:54.664163       1 controller.go:123] Found 0 jobs
I0416 22:18:54.666482       1 controller.go:139] Found 0 cronjobs
I0416 22:18:54.666494       1 controller.go:142] Found 0 groups
I0416 22:18:55.608785       1 wrap.go:47] GET /healthz: (93.915µs) 200 [kube-probe/1.15+ 127.0.0.1:53476]
I0416 22:18:57.151984       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:18:57.347674       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:01.753435       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:02.403076       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.StatefulSet total 0 items received
I0416 22:19:03.148509       1 gc_controller.go:144] GC'ing orphaned
I0416 22:19:03.153008       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:19:03.553598       1 request.go:530] Throttling request took 90.655549ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:19:03.603651       1 request.go:530] Throttling request took 140.700896ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:19:03.653562       1 request.go:530] Throttling request took 190.568809ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:19:03.703621       1 request.go:530] Throttling request took 240.643245ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:19:03.753610       1 request.go:530] Throttling request took 290.635743ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:19:03.804353       1 request.go:530] Throttling request took 341.369401ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:19:03.817922       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.LimitRange total 0 items received
I0416 22:19:03.853605       1 request.go:530] Throttling request took 390.59321ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:19:03.903613       1 request.go:530] Throttling request took 440.586017ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:19:04.670914       1 controller.go:123] Found 0 jobs
I0416 22:19:04.673359       1 controller.go:139] Found 0 cronjobs
I0416 22:19:04.673372       1 controller.go:142] Found 0 groups
I0416 22:19:05.608615       1 wrap.go:47] GET /healthz: (103.438µs) 200 [kube-probe/1.15+ 127.0.0.1:53510]
I0416 22:19:06.368342       1 reflector.go:384] pkg/cloudprovider/providers/gce/gce_clusterid.go:116: Watch close - *v1.ConfigMap total 265 items received
I0416 22:19:09.945814       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.RuntimeClass total 0 items received
I0416 22:19:10.807768       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ReplicaSet total 0 items received
I0416 22:19:11.428675       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.CSINode total 0 items received
I0416 22:19:11.803970       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:11.834346       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:12.152315       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:19:12.348041       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:14.677344       1 controller.go:123] Found 0 jobs
I0416 22:19:14.681165       1 controller.go:139] Found 0 cronjobs
I0416 22:19:14.681177       1 controller.go:142] Found 0 groups
I0416 22:19:15.608535       1 wrap.go:47] GET /healthz: (122.268µs) 200 [kube-probe/1.15+ 127.0.0.1:53542]
I0416 22:19:16.518338       1 reflector.go:249] k8s.io/client-go/dynamic/dynamicinformer/informer.go:90: forcing resync
I0416 22:19:18.801302       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ClusterRoleBinding total 0 items received
I0416 22:19:19.880183       1 request.go:530] Throttling request took 86.76894ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:19:19.930157       1 request.go:530] Throttling request took 136.733478ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:19:19.980209       1 request.go:530] Throttling request took 186.776315ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:19:20.030177       1 request.go:530] Throttling request took 236.707438ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:19:20.080935       1 request.go:530] Throttling request took 287.46218ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:19:20.130136       1 request.go:530] Throttling request took 336.662865ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:19:20.181529       1 request.go:530] Throttling request took 388.040277ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:19:20.230145       1 request.go:530] Throttling request took 436.646533ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:19:20.232625       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:19:22.006712       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:19:22.006751       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:19:22.006778       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:19:22.006827       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:19:22.007788       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:19:22.024923       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:19:22.024961       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:19:22.024988       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:19:22.025030       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:19:22.025218       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:19:22.027049       1 controller_utils.go:200] Added [&Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 22:19:22.006972881 +0000 UTC m=+4584.160697160,}] Taint to Node e2e-test-peterhornyack-windows-node-group-31ht
I0416 22:19:22.027100       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-windows-node-group-31ht has no [] Taint
I0416 22:19:22.610351       1 node_lifecycle_controller.go:857] ReadyCondition for Node e2e-test-peterhornyack-windows-node-group-31ht transitioned from &NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2019-04-16 22:18:21 +0000 UTC,LastTransitionTime:2019-04-16 22:16:21 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,} to &NodeCondition{Type:Ready,Status:False,LastHeartbeatTime:2019-04-16 22:19:21 +0000 UTC,LastTransitionTime:2019-04-16 22:19:21 +0000 UTC,Reason:KubeletNotReady,Message:PLEG is not healthy: pleg was last seen active 3m5.5945698s ago; threshold is 3m0s.,}
I0416 22:19:22.610421       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:19:22.610444       1 node_lifecycle_controller.go:700] Node e2e-test-peterhornyack-windows-node-group-31ht is NotReady as of 2019-04-16 22:19:22.610428257 +0000 UTC m=+4584.764152394. Adding it to the Taint queue.
I0416 22:19:22.663758       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:19:22.663915       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:19:22.663954       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:19:22.663995       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:19:22.664155       1 taint_manager.go:441] Noticed node update: scheduler.nodeUpdateItem{nodeName:"e2e-test-peterhornyack-windows-node-group-31ht"}
I0416 22:19:22.664170       1 taint_manager.go:446] Updating known taints on node e2e-test-peterhornyack-windows-node-group-31ht: [{node.kubernetes.io/not-ready  NoExecute 2019-04-16 22:19:22 +0000 UTC}]
I0416 22:19:22.664866       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:19:22.668355       1 controller_utils.go:200] Added [&Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoExecute,TimeAdded:2019-04-16 22:19:22.652678915 +0000 UTC m=+4584.806403425,}] Taint to Node e2e-test-peterhornyack-windows-node-group-31ht
I0416 22:19:22.668391       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-windows-node-group-31ht has no [&Taint{Key:node.kubernetes.io/unreachable,Value:,Effect:NoExecute,TimeAdded:<nil>,}] Taint
I0416 22:19:22.686357       1 timed_workers.go:110] Adding TimedWorkerQueue item services-1982/pod1 at 2019-04-16 22:19:22.686315093 +0000 UTC m=+4584.840039278 to be fired at 2019-04-16 22:24:22.686315093 +0000 UTC m=+4884.840039278
I0416 22:19:22.686384       1 timed_workers.go:110] Adding TimedWorkerQueue item services-1982/pod2 at 2019-04-16 22:19:22.686315093 +0000 UTC m=+4584.840039278 to be fired at 2019-04-16 22:24:22.686315093 +0000 UTC m=+4884.840039278
I0416 22:19:22.700553       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:19:22.479727697 +0000 UTC m=+8184.633451962 [59m59.779164312s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc001eb9260] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00077ef50 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176000] Scheduling:0xc00077f110 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001fa94a0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001fa93e0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:19:22 GMT] Etag:["yS1uIb_5PLcZQzhjFsK2AIno-Y4=/PV6VGKZw9tPy5Ss612bg7CQTrfk="] Expires:[Tue, 16 Apr 2019 22:19:22 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:19:23.153411       1 gc_controller.go:144] GC'ing orphaned
I0416 22:19:23.158789       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:19:24.685029       1 controller.go:123] Found 0 jobs
I0416 22:19:24.687949       1 controller.go:139] Found 0 cronjobs
I0416 22:19:24.687961       1 controller.go:142] Found 0 groups
I0416 22:19:25.608524       1 wrap.go:47] GET /healthz: (91.454µs) 200 [kube-probe/1.15+ 127.0.0.1:53576]
I0416 22:19:27.152665       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:19:27.348987       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:27.880011       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:19:27.700950945 +0000 UTC m=+8189.854675251 [59m59.82091121s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc00216c540] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00039a150 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0011760c0] Scheduling:0xc00039a460 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001c98f00] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001c98ea0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:19:27 GMT] Etag:["3SKhZLDRa2Sr3xvGuQ40eOfow1c=/guMp5_ujubsRjavrYSA35cqUzvU="] Expires:[Tue, 16 Apr 2019 22:19:27 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:19:29.384639       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:19:32.023762       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:19:32.033777       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:19:32.611415       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:19:32.611459       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:19:33.064269       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:19:32.881364854 +0000 UTC m=+8195.035089005 [59m59.817087047s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc00226b5e0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00047e700 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176240] Scheduling:0xc00047e850 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001a9aea0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001a9ae40 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:19:33 GMT] Etag:["4n8blDqgP12S0GOxELHCfXpmFxs=/wLSOSgGTjoq8IA-BrnfAhTbhFDs="] Expires:[Tue, 16 Apr 2019 22:19:33 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:19:34.006796       1 request.go:530] Throttling request took 91.741389ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:19:34.056891       1 request.go:530] Throttling request took 141.733732ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:19:34.106947       1 request.go:530] Throttling request took 191.872766ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:19:34.156844       1 request.go:530] Throttling request took 241.737683ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:19:34.206712       1 request.go:530] Throttling request took 291.608647ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:19:34.256865       1 request.go:530] Throttling request took 341.721822ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:19:34.306827       1 request.go:530] Throttling request took 391.704042ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:19:34.357091       1 request.go:530] Throttling request took 441.963343ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:19:34.692218       1 controller.go:123] Found 0 jobs
I0416 22:19:34.694813       1 controller.go:139] Found 0 cronjobs
I0416 22:19:34.694838       1 controller.go:142] Found 0 groups
I0416 22:19:35.608911       1 wrap.go:47] GET /healthz: (97.037µs) 200 [kube-probe/1.15+ 127.0.0.1:53610]
I0416 22:19:38.279112       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:19:38.064707278 +0000 UTC m=+8200.218431542 [59m59.785584955s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc0027bc620] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00077b8f0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176300] Scheduling:0xc00077b9d0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc00220aba0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc00220ab40 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:19:38 GMT] Etag:["5a43LuduNurI_ytkdHSohZHP9gA=/Ukl_GTcNd8XJ3TJwQdvEoJXAYwA="] Expires:[Tue, 16 Apr 2019 22:19:38 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:19:38.377949       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:19:41.804303       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:41.834676       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:42.056853       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:19:42.152945       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:19:42.349463       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:42.612516       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:19:42.612613       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:19:43.158903       1 gc_controller.go:144] GC'ing orphaned
I0416 22:19:43.165064       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:19:43.538597       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:19:43.279565244 +0000 UTC m=+8205.433289513 [59m59.740958784s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc0028cba40] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc000385260 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176480] Scheduling:0xc0003853b0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc002128ae0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc002128a80 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:19:43 GMT] Etag:["Q1egsMsG0qOQdbMkK8T9sbATvAE=/KxxhMoCCBjgX9HdPZfzbQdMhr9g="] Expires:[Tue, 16 Apr 2019 22:19:43 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:19:44.699119       1 controller.go:123] Found 0 jobs
I0416 22:19:44.701785       1 controller.go:139] Found 0 cronjobs
I0416 22:19:44.701817       1 controller.go:142] Found 0 groups
I0416 22:19:45.608522       1 wrap.go:47] GET /healthz: (94.611µs) 200 [kube-probe/1.15+ 127.0.0.1:53664]
I0416 22:19:48.719476       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:19:48.539068311 +0000 UTC m=+8210.692792567 [59m59.819580473s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc0029e09a0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00033c150 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176540] Scheduling:0xc00033c380 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001fa27e0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001fa2780 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:19:48 GMT] Etag:["CrWnkahF5e2FMlMnbjbrxDzeCqU=/oZgc4mTnryAjLWDCAL73et4oYoE="] Expires:[Tue, 16 Apr 2019 22:19:48 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:19:50.333205       1 request.go:530] Throttling request took 91.639816ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:19:50.383269       1 request.go:530] Throttling request took 141.684244ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:19:50.433205       1 request.go:530] Throttling request took 191.632586ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:19:50.483265       1 request.go:530] Throttling request took 241.659103ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:19:50.533209       1 request.go:530] Throttling request took 291.605716ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:19:50.583458       1 request.go:530] Throttling request took 341.834228ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:19:50.633195       1 request.go:530] Throttling request took 391.566789ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:19:50.683160       1 request.go:530] Throttling request took 441.514937ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:19:50.685544       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:19:52.118259       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:19:52.614491       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:19:53.266420       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:53.906266       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:19:53.719845958 +0000 UTC m=+8215.873570212 [59m59.813571265s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc001731960] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00033cfc0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0011766c0] Scheduling:0xc00033d0a0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc00175d500] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc00175d4a0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:19:53 GMT] Etag:["0piUG3NPaSE1wgYyPdDdgw8PEIU=/t1RBJ4BYjIcaK6FRuPZzoR-Dj58="] Expires:[Tue, 16 Apr 2019 22:19:53 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:19:54.706734       1 controller.go:123] Found 0 jobs
I0416 22:19:54.709856       1 controller.go:139] Found 0 cronjobs
I0416 22:19:54.709870       1 controller.go:142] Found 0 groups
I0416 22:19:55.608556       1 wrap.go:47] GET /healthz: (84.291µs) 200 [kube-probe/1.15+ 127.0.0.1:53700]
I0416 22:19:57.153405       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:19:57.351366       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:19:59.040017       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:19:58.90688966 +0000 UTC m=+8221.060613805 [59m59.866862652s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc001c728c0] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc00033d880 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176780] Scheduling:0xc00033d960 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc0017cc9c0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc0017cc960 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:19:59 GMT] Etag:["dsnR3z9DpVkp8TiZnHNbn7RdM0Y=/9GBcSoysPrGCLeU7XJdE4-p42tw="] Expires:[Tue, 16 Apr 2019 22:19:59 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:20:02.142914       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:20:02.616503       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:20:03.165360       1 gc_controller.go:144] GC'ing orphaned
I0416 22:20:03.169576       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:20:04.274531       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:20:04.040668672 +0000 UTC m=+8226.194392865 [59m59.76612793s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc001d49b20] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc0001fecb0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176900] Scheduling:0xc0001fed90 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001915ce0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001915c80 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:20:04 GMT] Etag:["f5eXBfdaicifUBHsJd_gs16GomY=/IBSSlrGAFUiDSR-xG19SgeyBv1E="] Expires:[Tue, 16 Apr 2019 22:20:04 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:20:04.460195       1 request.go:530] Throttling request took 91.857643ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:20:04.510265       1 request.go:530] Throttling request took 141.880708ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:20:04.560276       1 request.go:530] Throttling request took 191.899309ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:20:04.610198       1 request.go:530] Throttling request took 241.840621ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:20:04.660181       1 request.go:530] Throttling request took 291.81643ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:20:04.710199       1 request.go:530] Throttling request took 341.828193ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:20:04.715128       1 controller.go:123] Found 0 jobs
I0416 22:20:04.717361       1 controller.go:139] Found 0 cronjobs
I0416 22:20:04.717373       1 controller.go:142] Found 0 groups
I0416 22:20:04.760419       1 request.go:530] Throttling request took 392.038592ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:20:04.810199       1 request.go:530] Throttling request took 441.815853ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:20:04.981450       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Event total 3 items received
I0416 22:20:05.608608       1 wrap.go:47] GET /healthz: (100.513µs) 200 [kube-probe/1.15+ 127.0.0.1:53734]
I0416 22:20:09.496432       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:20:09.274983652 +0000 UTC m=+8231.428707807 [59m59.778542538s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc002984b60] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc0001ff730 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0011769c0] Scheduling:0xc0001ff810 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc001401b60] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc001401920 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:20:09 GMT] Etag:["kPr2BgM-mO0UOH6kLdf_n-7gb9Y=/JaF-ht0prsK2iINlTBwYPSsUDzY="] Expires:[Tue, 16 Apr 2019 22:20:09 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:20:11.804624       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:11.805073       1 endpoints_controller.go:401] Finished syncing service "kube-system/heapster" endpoints. (302.743µs)
I0416 22:20:11.805312       1 endpoints_controller.go:401] Finished syncing service "kube-system/kubernetes-dashboard" endpoints. (177.428µs)
I0416 22:20:11.805380       1 endpoints_controller.go:401] Finished syncing service "kube-system/metrics-server" endpoints. (57.843µs)
I0416 22:20:11.805400       1 endpoints_controller.go:401] Finished syncing service "default/kubernetes" endpoints. (1.792µs)
I0416 22:20:11.805603       1 endpoints_controller.go:540] Update endpoints for kube-system/kube-dns, ready: 6 not ready: 0
I0416 22:20:11.806118       1 endpoints_controller.go:401] Finished syncing service "kube-system/default-http-backend" endpoints. (148.583µs)
I0416 22:20:11.816933       1 endpoints_controller.go:401] Finished syncing service "kube-system/kube-dns" endpoints. (11.503763ms)
I0416 22:20:11.835002       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:11.860323       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:12.154210       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:20:12.165457       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:20:12.351654       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:12.617844       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:20:14.721793       1 controller.go:123] Found 0 jobs
I0416 22:20:14.724406       1 controller.go:139] Found 0 cronjobs
I0416 22:20:14.724417       1 controller.go:142] Found 0 groups
I0416 22:20:14.751784       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:20:14.49689382 +0000 UTC m=+8236.650618082 [59m59.745082201s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc002a59b20] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc000260a10 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc001176b40] Scheduling:0xc000260af0 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc000885b00] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc000885aa0 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:20:14 GMT] Etag:["2uxnY3jy0n0Vv_slJPio-ChQKO4=/hpqUOffm2AGn7xGIIY9a7zMYJdE="] Expires:[Tue, 16 Apr 2019 22:20:14 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:20:15.608538       1 wrap.go:47] GET /healthz: (95.284µs) 200 [kube-probe/1.15+ 127.0.0.1:53766]
I0416 22:20:20.043459       1 gen.go:9541] GCEInstances.Get(context.Background.WithDeadline(2019-04-16 23:20:19.752354212 +0000 UTC m=+8241.906078411 [59m59.708873857s]), Key{"e2e-test-peterhornyack-windows-node-group-31ht", zone: "us-central1-b"}) = &{CanIpForward:false CpuPlatform:Intel Haswell CreationTimestamp:2019-04-16T14:02:05.987-07:00 DeletionProtection:false Description: Disks:[0xc00266d260] GuestAccelerators:[] Id:5103335432404073507 Kind:compute#instance LabelFingerprint:42WmSpB8rSM= Labels:map[] MachineType:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/machineTypes/n1-standard-2 Metadata:0xc0001fe1c0 MinCpuPlatform: Name:e2e-test-peterhornyack-windows-node-group-31ht NetworkInterfaces:[0xc0016b8000] Scheduling:0xc0001fe310 SelfLink:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-31ht ServiceAccounts:[0xc0013c49c0] StartRestricted:false Status:RUNNING StatusMessage: Tags:0xc0013c4960 Zone:https://www.googleapis.com/compute/v1/projects/peterhornyack-prod-no-enforcer/zones/us-central1-b ServerResponse:{HTTPStatusCode:200 Header:map[Cache-Control:[private, max-age=0, must-revalidate, no-transform] Content-Type:[application/json; charset=UTF-8] Date:[Tue, 16 Apr 2019 22:20:20 GMT] Etag:["8p_6cbLCpnAIjygyExZNXCiohbY=/NT8IJaUxJuqDq1-5YcLAF7AXZRo="] Expires:[Tue, 16 Apr 2019 22:20:20 GMT] Server:[GSE] Vary:[Origin X-Origin] X-Content-Type-Options:[nosniff] X-Frame-Options:[SAMEORIGIN] X-Xss-Protection:[1; mode=block]]} ForceSendFields:[] NullFields:[]}, <nil>
I0416 22:20:20.786068       1 request.go:530] Throttling request took 91.608557ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:20:20.836163       1 request.go:530] Throttling request took 141.677286ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:20:20.886078       1 request.go:530] Throttling request took 191.589859ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:20:20.936122       1 request.go:530] Throttling request took 241.649368ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:20:20.986088       1 request.go:530] Throttling request took 291.606786ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:20:21.036302       1 request.go:530] Throttling request took 341.762138ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:20:21.086201       1 request.go:530] Throttling request took 391.70112ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:20:21.136095       1 request.go:530] Throttling request took 441.576792ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:20:21.138679       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:20:21.768349       1 service_controller.go:616] Ignoring node e2e-test-peterhornyack-windows-node-group-31ht with Ready condition status False
I0416 22:20:21.768375       1 service_controller.go:639] Detected change in list of current cluster nodes. New node set: map[e2e-test-peterhornyack-minion-group-06gd:{}]
I0416 22:20:21.768397       1 service_controller.go:647] Successfully updated 7 out of 7 load balancers to direct traffic to the updated set of nodes
I0416 22:20:22.116010       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1alpha1.PodPreset total 0 items received
I0416 22:20:22.196851       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:20:22.196900       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:20:22.196929       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:20:22.196979       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:20:22.197221       1 controller_utils.go:200] Added [] Taint to Node e2e-test-peterhornyack-windows-node-group-31ht
I0416 22:20:22.197781       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:20:22.212707       1 controller_utils.go:212] Made sure that Node e2e-test-peterhornyack-windows-node-group-31ht has no [&Taint{Key:node.kubernetes.io/not-ready,Value:,Effect:NoSchedule,TimeAdded:2019-04-16 22:19:22 +0000 UTC,}] Taint
I0416 22:20:22.213088       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:20:22.213132       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:20:22.213159       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:20:22.213179       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:20:22.213360       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
E0416 22:20:22.648036       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod1.1596143f1c7553bd", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod1", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod1", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b329a65d91ac, ext:4644797390485, loc:(*time.Location)(0x71c51c0)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod1.1596143f1c7553bd" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
E0416 22:20:22.654116       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod2.1596143f1c758c6f", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod2", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod2", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b329a65dca3a, ext:4644797404962, loc:(*time.Location)(0x71c51c0)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod2.1596143f1c758c6f" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
E0416 22:20:22.648036       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod1.1596143f1c7553bd", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod1", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod1", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b329a65d91ac, ext:4644797390485, loc:(*time.Location)(0x71c51c0)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod1.1596143f1c7553bd" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
E0416 22:20:22.654116       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod2.1596143f1c758c6f", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod2", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod2", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b329a65dca3a, ext:4644797404962, loc:(*time.Location)(0x71c51c0)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod2.1596143f1c758c6f" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
I0416 22:20:22.620591       1 node_lifecycle_controller.go:857] ReadyCondition for Node e2e-test-peterhornyack-windows-node-group-31ht transitioned from &NodeCondition{Type:Ready,Status:False,LastHeartbeatTime:2019-04-16 22:20:12 +0000 UTC,LastTransitionTime:2019-04-16 22:19:21 +0000 UTC,Reason:KubeletNotReady,Message:PLEG is not healthy: pleg was last seen active 3m55.7513877s ago; threshold is 3m0s.,} to &NodeCondition{Type:Ready,Status:True,LastHeartbeatTime:2019-04-16 22:20:22 +0000 UTC,LastTransitionTime:2019-04-16 22:20:22 +0000 UTC,Reason:KubeletReady,Message:kubelet is posting ready status,}
I0416 22:20:22.622409       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-windows-node-group-31ht ReadyCondition updated. Updating timestamp.
I0416 22:20:22.635561       1 node_lifecycle_controller.go:752] Node e2e-test-peterhornyack-windows-node-group-31ht is healthy again, removing all taints
I0416 22:20:22.635833       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:20:22.635871       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/fluentd-gcp-v3.2.0' for reason: node(s) didn't match node selector
I0416 22:20:22.635904       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:20:22.635939       1 daemon_controller.go:1352] DaemonSet Predicates failed on node e2e-test-peterhornyack-windows-node-group-31ht for ds 'kube-system/metadata-proxy-v0.1' for reason: node(s) didn't match node selector
I0416 22:20:22.636073       1 taint_manager.go:441] Noticed node update: scheduler.nodeUpdateItem{nodeName:"e2e-test-peterhornyack-windows-node-group-31ht"}
I0416 22:20:22.636101       1 taint_manager.go:446] Updating known taints on node e2e-test-peterhornyack-windows-node-group-31ht: []
I0416 22:20:22.636422       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-windows-node-group-31ht"
I0416 22:20:22.643610       1 taint_manager.go:463] All taints were removed from the Node e2e-test-peterhornyack-windows-node-group-31ht. Cancelling all evictions...
I0416 22:20:22.643644       1 timed_workers.go:129] Cancelling TimedWorkerQueue item services-1982/pod1 at 2019-04-16 22:20:22.643639454 +0000 UTC m=+4644.797363620
I0416 22:20:22.643675       1 timed_workers.go:129] Cancelling TimedWorkerQueue item services-1982/pod2 at 2019-04-16 22:20:22.643673764 +0000 UTC m=+4644.797397900
I0416 22:20:22.644205       1 event.go:258] Event(v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod1", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'TaintManagerEviction' Cancelling deletion of Pod services-1982/pod1
I0416 22:20:22.644217       1 event.go:258] Event(v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod2", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'TaintManagerEviction' Cancelling deletion of Pod services-1982/pod2
E0416 22:20:22.648036       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod1.1596143f1c7553bd", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod1", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod1", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386b7bd, ext:4404749755559, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b329a65d91ac, ext:4644797390485, loc:(*time.Location)(0x71c51c0)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod1.1596143f1c7553bd" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
E0416 22:20:22.654116       1 event.go:240] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod2.1596143f1c758c6f", GenerateName:"", Namespace:"services-1982", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"services-1982", Name:"pod2", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"TaintManagerEviction", Message:"Cancelling deletion of Pod services-1982/pod2", Source:v1.EventSource{Component:"taint-controller", Host:""}, FirstTimestamp:v1.Time{Time:time.Time{wall:0xbf25b2eda386f06f, ext:4404749770085, loc:(*time.Location)(0x71c51c0)}}, LastTimestamp:v1.Time{Time:time.Time{wall:0xbf25b329a65dca3a, ext:4644797404962, loc:(*time.Location)(0x71c51c0)}}, Count:2, Type:"Normal", EventTime:v1.MicroTime{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "pod2.1596143f1c758c6f" is forbidden: unable to create new content in namespace services-1982 because it is being terminated' (will not retry!)
I0416 22:20:23.169793       1 gc_controller.go:144] GC'ing orphaned
I0416 22:20:23.174343       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:20:24.732088       1 controller.go:123] Found 0 jobs
I0416 22:20:24.735638       1 controller.go:139] Found 0 cronjobs
I0416 22:20:24.735660       1 controller.go:142] Found 0 groups
I0416 22:20:25.030089       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:25.608557       1 wrap.go:47] GET /healthz: (101.113µs) 200 [kube-probe/1.15+ 127.0.0.1:53798]
I0416 22:20:27.154490       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:20:27.352326       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:28.787826       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1beta1.Ingress total 0 items received
I0416 22:20:29.476522       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:20:32.636780       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-minion-group-06gd ReadyCondition updated. Updating timestamp.
I0416 22:20:33.029080       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-minion-group-06gd"
I0416 22:20:34.739652       1 controller.go:123] Found 0 jobs
I0416 22:20:34.742532       1 controller.go:139] Found 0 cronjobs
I0416 22:20:34.742544       1 controller.go:142] Found 0 groups
I0416 22:20:34.912809       1 request.go:530] Throttling request took 92.835402ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:20:34.962829       1 request.go:530] Throttling request took 142.833469ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:20:35.012824       1 request.go:530] Throttling request took 192.841311ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:20:35.062954       1 request.go:530] Throttling request took 242.960693ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:20:35.112718       1 request.go:530] Throttling request took 292.722583ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:20:35.162829       1 request.go:530] Throttling request took 342.823386ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:20:35.212837       1 request.go:530] Throttling request took 392.823364ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:20:35.262822       1 request.go:530] Throttling request took 442.798585ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:20:35.609634       1 wrap.go:47] GET /healthz: (90.025µs) 200 [kube-probe/1.15+ 127.0.0.1:53832]
I0416 22:20:38.508001       1 attach_detach_controller.go:647] processVolumesInUse for node "e2e-test-peterhornyack-master"
I0416 22:20:41.805267       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:41.836215       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:42.156123       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:20:42.353334       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:20:42.639655       1 node_lifecycle_controller.go:865] Node e2e-test-peterhornyack-master ReadyCondition updated. Updating timestamp.
I0416 22:20:43.175379       1 gc_controller.go:144] GC'ing orphaned
I0416 22:20:43.179356       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:20:44.747149       1 controller.go:123] Found 0 jobs
I0416 22:20:44.749906       1 controller.go:139] Found 0 cronjobs
I0416 22:20:44.749917       1 controller.go:142] Found 0 groups
I0416 22:20:45.608492       1 wrap.go:47] GET /healthz: (76.912µs) 200 [kube-probe/1.15+ 127.0.0.1:53886]
I0416 22:20:45.808121       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.DaemonSet total 0 items received
I0416 22:20:51.239370       1 request.go:530] Throttling request took 91.433477ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:20:51.289782       1 request.go:530] Throttling request took 141.841231ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:20:51.339297       1 request.go:530] Throttling request took 191.345323ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:20:51.389315       1 request.go:530] Throttling request took 241.341349ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:20:51.439270       1 request.go:530] Throttling request took 291.254029ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:20:51.489276       1 request.go:530] Throttling request took 341.236519ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:20:51.540780       1 request.go:530] Throttling request took 392.773444ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:20:51.589302       1 request.go:530] Throttling request took 441.276776ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
I0416 22:20:51.591627       1 resource_quota_controller.go:422] no resource updates from discovery, skipping resource quota sync
I0416 22:20:54.754556       1 controller.go:123] Found 0 jobs
I0416 22:20:54.759216       1 controller.go:139] Found 0 cronjobs
I0416 22:20:54.759311       1 controller.go:142] Found 0 groups
I0416 22:20:55.608858       1 wrap.go:47] GET /healthz: (215.789µs) 200 [kube-probe/1.15+ 127.0.0.1:53922]
I0416 22:20:57.156426       1 pv_controller_base.go:407] resyncing PV controller
I0416 22:20:57.354487       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:21:00.786165       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.Deployment total 0 items received
I0416 22:21:01.325166       1 reflector.go:384] k8s.io/client-go/informers/factory.go:133: Watch close - *v1.ServiceAccount total 0 items received
I0416 22:21:01.774740       1 reflector.go:249] k8s.io/client-go/informers/factory.go:133: forcing resync
I0416 22:21:03.179520       1 gc_controller.go:144] GC'ing orphaned
I0416 22:21:03.185160       1 gc_controller.go:173] GC'ing unscheduled pods which are terminating.
I0416 22:21:04.764364       1 controller.go:123] Found 0 jobs
I0416 22:21:04.767018       1 controller.go:139] Found 0 cronjobs
I0416 22:21:04.767030       1 controller.go:142] Found 0 groups
I0416 22:21:05.365610       1 request.go:530] Throttling request took 85.988632ms, request: GET:https://localhost:443/apis/apiextensions.k8s.io/v1beta1?timeout=32s
I0416 22:21:05.415672       1 request.go:530] Throttling request took 136.054109ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1?timeout=32s
I0416 22:21:05.465631       1 request.go:530] Throttling request took 185.996166ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1beta1?timeout=32s
I0416 22:21:05.515632       1 request.go:530] Throttling request took 235.984593ms, request: GET:https://localhost:443/apis/scheduling.k8s.io/v1alpha1?timeout=32s
I0416 22:21:05.565621       1 request.go:530] Throttling request took 285.930974ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1?timeout=32s
I0416 22:21:05.608921       1 wrap.go:47] GET /healthz: (130.307µs) 200 [kube-probe/1.15+ 127.0.0.1:53956]
I0416 22:21:05.615638       1 request.go:530] Throttling request took 335.963571ms, request: GET:https://localhost:443/apis/coordination.k8s.io/v1beta1?timeout=32s
I0416 22:21:05.665591       1 request.go:530] Throttling request took 385.920669ms, request: GET:https://localhost:443/apis/node.k8s.io/v1beta1?timeout=32s
I0416 22:21:05.715655       1 request.go:530] Throttling request took 435.960744ms, request: GET:https://localhost:443/apis/scalingpolicy.kope.io/v1alpha1?timeout=32s
