++ kubectl get nodes -l beta.kubernetes.io/os=linux -o name
+ LINUX_NODES='node/e2e-test-peterhornyack-master
node/e2e-test-peterhornyack-minion-group-5wdh
node/e2e-test-peterhornyack-minion-group-fzx6'
++ echo node/e2e-test-peterhornyack-master node/e2e-test-peterhornyack-minion-group-5wdh node/e2e-test-peterhornyack-minion-group-fzx6
++ wc -w
+ LINUX_NODE_COUNT=3
+ for node in $LINUX_NODES
+ kubectl taint node node/e2e-test-peterhornyack-master node-under-test=false:NoSchedule
node/e2e-test-peterhornyack-master tainted
+ for node in $LINUX_NODES
+ kubectl taint node node/e2e-test-peterhornyack-minion-group-5wdh node-under-test=false:NoSchedule
node/e2e-test-peterhornyack-minion-group-5wdh tainted
+ for node in $LINUX_NODES
+ kubectl taint node node/e2e-test-peterhornyack-minion-group-fzx6 node-under-test=false:NoSchedule
node/e2e-test-peterhornyack-minion-group-fzx6 tainted
++ kubectl get nodes -l beta.kubernetes.io/os=windows -o name
+ WINDOWS_NODES='node/e2e-test-peterhornyack-windows-node-group-1vjk
node/e2e-test-peterhornyack-windows-node-group-9q9v
node/e2e-test-peterhornyack-windows-node-group-jpxd'
+ for node in $WINDOWS_NODES
+ kubectl taint node node/e2e-test-peterhornyack-windows-node-group-1vjk node.kubernetes.io/os:NoSchedule-
error: taint "node.kubernetes.io/os:NoSchedule" not found
+ for node in $WINDOWS_NODES
+ kubectl taint node node/e2e-test-peterhornyack-windows-node-group-9q9v node.kubernetes.io/os:NoSchedule-
error: taint "node.kubernetes.io/os:NoSchedule" not found
+ for node in $WINDOWS_NODES
+ kubectl taint node node/e2e-test-peterhornyack-windows-node-group-jpxd node.kubernetes.io/os:NoSchedule-
error: taint "node.kubernetes.io/os:NoSchedule" not found
+++ dirname ./run-e2e.sh
++ cd .
++ pwd
+ SCRIPT_ROOT=/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes
+ kubectl create -f /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/prepull.yaml
error: the path "/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/prepull.yaml" does not exist
+ sleep 15m
+ kubectl get pods -o wide
No resources found.
+ kubectl delete -f /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/prepull.yaml
error: the path "/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/prepull.yaml" does not exist
+ sleep 3m
+ curl https://raw.githubusercontent.com/kubernetes-sigs/windows-testing/master/images/image-repo-list -o /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/repo-list.yaml
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   220  100   220    0     0    836      0 --:--:-- --:--:-- --:--:--   836
+ export KUBE_TEST_REPO_LIST=/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/repo-list.yaml
+ KUBE_TEST_REPO_LIST=/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/repo-list.yaml
+ ./hack/ginkgo-e2e.sh --node-os-distro=windows '--ginkgo.focus=\[Conformance\]|\[NodeConformance\]|\[sig-windows\]' '--ginkgo.skip=\[LinuxOnly\]|\[Serial\]|\[Feature:.+\]' --minStartupPods=8 --report-dir=/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/e2e-artifacts --allowed-not-ready-nodes=3
Setting up for KUBERNETES_PROVIDER="gce".
Project: peterhornyack-prod-no-enforcer
Network Project: peterhornyack-prod-no-enforcer
Zone: us-central1-b
Trying to find master named 'e2e-test-peterhornyack-master'
Looking for address 'e2e-test-peterhornyack-master-ip'
Using master: e2e-test-peterhornyack-master (external IP: 146.148.105.213)
May 29 16:51:56.438: INFO: Fetching cloud provider for "gce"
I0529 16:51:56.438943   96922 gce.go:867] Using DefaultTokenSource &oauth2.reuseTokenSource{new:(*oauth2.tokenRefresher)(0xc0018858f0), mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(0xc001c686c0)}
I0529 16:51:56.637906   96922 gce.go:867] Using DefaultTokenSource &oauth2.reuseTokenSource{new:(*oauth2.tokenRefresher)(0xc002c5a150), mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(0xc002c6e120)}
I0529 16:51:56.705173   96922 gce.go:867] Using DefaultTokenSource &oauth2.reuseTokenSource{new:(*oauth2.tokenRefresher)(0xc002a02150), mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(0xc0028fc540)}
W0529 16:51:56.796337   96922 gce.go:465] No network name or URL specified.
I0529 16:51:56.796506   96922 e2e.go:240] Starting e2e run "c50d661b-b0c4-4fe0-8418-3f1e3df24e9d" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: [1m1559173915[0m - Will randomize all specs
Will run [1m345[0m of [1m4083[0m specs

May 29 16:52:00.230: INFO: cluster-master-image: cos-73-11647-163-0
May 29 16:52:00.230: INFO: cluster-node-image: cos-73-11647-163-0
May 29 16:52:00.230: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 16:52:00.235: INFO: Waiting up to 30m0s for all (but 3) nodes to be schedulable
May 29 16:52:00.447: INFO: Unschedulable nodes:
May 29 16:52:00.447: INFO: -> e2e-test-peterhornyack-minion-group-5wdh Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 16:52:00.447: INFO: -> e2e-test-peterhornyack-minion-group-fzx6 Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 16:52:00.447: INFO: ================================
May 29 16:52:00.447: INFO: Waiting up to 10m0s for all pods (need at least 8) in namespace 'kube-system' to be running and ready
May 29 16:52:00.639: INFO: 25 / 25 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 29 16:52:00.639: INFO: expected 9 pod replicas in namespace 'kube-system', 9 are Running and Ready.
May 29 16:52:00.639: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 29 16:52:00.689: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'fluentd-gcp-v3.2.0' (0 seconds elapsed)
May 29 16:52:00.689: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'metadata-proxy-v0.1' (0 seconds elapsed)
May 29 16:52:00.689: INFO: e2e test version: v1.15.0-alpha.1.47+27226dab2f0582-dirty
May 29 16:52:00.730: INFO: kube-apiserver version: v1.15.0-alpha.0.1887+bae0630ef897d6-dirty
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 16:52:00.731: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:52:00.732: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's args [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Variable Expansion
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 16:52:00.733: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename var-expansion
May 29 16:52:00.902: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test substitution in container's args
May 29 16:52:00.991: INFO: Waiting up to 5m0s for pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1" in namespace "var-expansion-9367" to be "success or failure"
May 29 16:52:01.033: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 41.728981ms
May 29 16:52:03.075: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08367022s
May 29 16:52:05.117: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125261515s
May 29 16:52:07.159: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167923942s
May 29 16:52:09.201: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209410942s
May 29 16:52:11.243: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.25128032s
May 29 16:52:13.285: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.293323405s
May 29 16:52:15.327: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.335496979s
May 29 16:52:17.369: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.377405043s
May 29 16:52:19.411: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.419588002s
May 29 16:52:21.453: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 20.461605533s
May 29 16:52:23.495: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.503456016s
May 29 16:52:25.537: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.54521573s
May 29 16:52:27.579: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.587087018s
May 29 16:52:29.621: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 28.629626324s
May 29 16:52:31.663: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 30.672001152s
May 29 16:52:33.705: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 32.713792726s
May 29 16:52:35.747: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 34.755507923s
May 29 16:52:37.789: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 36.797855511s
May 29 16:52:39.831: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 38.839617903s
May 29 16:52:41.873: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 40.881665064s
May 29 16:52:43.915: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 42.923873087s
May 29 16:52:45.957: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 44.96562692s
May 29 16:52:47.999: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 47.00738387s
May 29 16:52:50.041: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 49.049502035s
May 29 16:52:52.083: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 51.09149001s
May 29 16:52:54.125: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 53.133577471s
May 29 16:52:56.167: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 55.175320972s
May 29 16:52:58.209: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 57.217321766s
May 29 16:53:00.251: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 59.259173217s
May 29 16:53:02.293: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.301093962s
May 29 16:53:04.335: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.343074966s
May 29 16:53:06.377: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.385091382s
May 29 16:53:08.419: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.427228434s
May 29 16:53:10.461: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.469337357s
May 29 16:53:12.503: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.511297095s
May 29 16:53:14.544: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.553021917s
May 29 16:53:16.587: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.595427666s
May 29 16:53:18.629: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.637723056s
May 29 16:53:20.671: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.679689225s
May 29 16:53:22.713: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.721489745s
May 29 16:53:24.757: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.765079738s
May 29 16:53:26.798: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.806605075s
May 29 16:53:28.839: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.847984098s
May 29 16:53:30.881: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.890018731s
May 29 16:53:32.923: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.93189222s
May 29 16:53:34.965: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.973864874s
May 29 16:53:37.009: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.017130404s
May 29 16:53:39.050: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.058999084s
May 29 16:53:41.093: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.101359397s
May 29 16:53:43.135: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.143706517s
May 29 16:53:45.184: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.192405915s
May 29 16:53:47.225: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.23385668s
May 29 16:53:49.268: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.27627177s
May 29 16:53:51.309: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.317677874s
May 29 16:53:53.352: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.360310958s
May 29 16:53:55.394: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.402428834s
May 29 16:53:57.436: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.444963035s
May 29 16:53:59.478: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.486964813s
May 29 16:54:01.522: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.530802207s
May 29 16:54:03.564: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.57277025s
May 29 16:54:05.607: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.615338453s
May 29 16:54:07.649: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.657794581s
May 29 16:54:09.692: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.700493211s
May 29 16:54:11.736: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.74437878s
May 29 16:54:13.779: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.787151496s
May 29 16:54:15.821: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.829194589s
May 29 16:54:17.862: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.870794921s
May 29 16:54:19.905: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.913507338s
May 29 16:54:21.947: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.955623817s
May 29 16:54:23.990: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.998890027s
May 29 16:54:26.032: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.04100543s
May 29 16:54:28.074: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.082985463s
May 29 16:54:30.117: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.12505762s
May 29 16:54:32.163: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.171839372s
May 29 16:54:34.210: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.21827918s
May 29 16:54:36.259: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.267747838s
May 29 16:54:38.301: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.30952728s
May 29 16:54:40.343: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.351537654s
May 29 16:54:42.385: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.393756944s
May 29 16:54:44.427: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.43583652s
May 29 16:54:46.469: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.477619207s
May 29 16:54:48.511: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.519715194s
May 29 16:54:50.553: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.56194755s
May 29 16:54:52.598: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.606646716s
May 29 16:54:54.640: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.648553481s
May 29 16:54:56.682: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.690726934s
May 29 16:54:58.724: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.732584086s
May 29 16:55:00.765: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.773911904s
May 29 16:55:02.808: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.816125654s
May 29 16:55:04.850: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.858171104s
May 29 16:55:06.892: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.90036908s
May 29 16:55:08.934: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.942354739s
May 29 16:55:10.976: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.984378275s
May 29 16:55:13.021: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Running", Reason="", readiness=true. Elapsed: 3m12.029914161s
May 29 16:55:15.064: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Running", Reason="", readiness=true. Elapsed: 3m14.072445534s
May 29 16:55:17.107: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 3m16.115062635s
[1mSTEP[0m: Saw pod success
May 29 16:55:17.107: INFO: Pod "var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1" satisfied condition "success or failure"
May 29 16:55:17.168: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-1vjk pod var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 29 16:55:20.295: INFO: Waiting for pod var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1 to disappear
May 29 16:55:20.337: INFO: Pod var-expansion-61a22511-b41f-41c5-8ecb-8360ca243cf1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:55:20.337: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "var-expansion-9367" for this suite.
May 29 16:55:26.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:55:28.088: INFO: namespace var-expansion-9367 deletion completed in 7.708769203s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should support rollover [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 16:55:28.088: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
[It] deployment should support rollover [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 16:55:28.395: INFO: Pod name rollover-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
May 29 16:55:58.480: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 29 16:56:00.522: INFO: Creating deployment "test-rollover-deployment"
May 29 16:56:00.630: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 29 16:56:02.723: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 29 16:56:02.806: INFO: Ensure that both replica sets have 1 created replica
May 29 16:56:02.890: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 29 16:56:02.977: INFO: Updating deployment test-rollover-deployment
May 29 16:56:02.977: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 29 16:56:05.089: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 29 16:56:05.172: INFO: Make sure deployment "test-rollover-deployment" is complete
May 29 16:56:05.256: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:05.256: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770963, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:07.340: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:07.340: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770963, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:09.340: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:09.340: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770963, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:11.342: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:11.342: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770963, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:13.342: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:13.342: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770963, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:15.344: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:15.344: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770974, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:17.347: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:17.348: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770974, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:19.340: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:19.340: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770974, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:21.340: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:21.340: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770974, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:23.340: INFO: all replica sets need to contain the pod-template-hash label
May 29 16:56:23.340: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770974, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694770960, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5688f7697c\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 16:56:25.340: INFO: 
May 29 16:56:25.340: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:60
May 29 16:56:25.465: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-7633,SelfLink:/apis/apps/v1/namespaces/deployment-7633/deployments/test-rollover-deployment,UID:bd915eb4-c01a-4a5a-a009-439028ecba46,ResourceVersion:8224,Generation:2,CreationTimestamp:2019-05-29 16:56:00 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-29 16:56:00 -0700 PDT 2019-05-29 16:56:00 -0700 PDT MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-29 16:56:24 -0700 PDT 2019-05-29 16:56:00 -0700 PDT NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5688f7697c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 29 16:56:25.508: INFO: New ReplicaSet "test-rollover-deployment-5688f7697c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5688f7697c,GenerateName:,Namespace:deployment-7633,SelfLink:/apis/apps/v1/namespaces/deployment-7633/replicasets/test-rollover-deployment-5688f7697c,UID:31dc147e-be04-49e3-a25d-4e111a471b0f,ResourceVersion:8217,Generation:2,CreationTimestamp:2019-05-29 16:56:02 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5688f7697c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bd915eb4-c01a-4a5a-a009-439028ecba46 0xc00127d837 0xc00127d838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5688f7697c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5688f7697c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 29 16:56:25.508: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 29 16:56:25.508: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-7633,SelfLink:/apis/apps/v1/namespaces/deployment-7633/replicasets/test-rollover-controller,UID:d101d5b6-e0b7-4441-8f39-c0858ebca2bf,ResourceVersion:8223,Generation:2,CreationTimestamp:2019-05-29 16:55:28 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bd915eb4-c01a-4a5a-a009-439028ecba46 0xc00127d64f 0xc00127d660}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 16:56:25.509: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-7633,SelfLink:/apis/apps/v1/namespaces/deployment-7633/replicasets/test-rollover-deployment-6455657675,UID:946cf169-d34b-4735-b220-350befc6f7cc,ResourceVersion:8157,Generation:2,CreationTimestamp:2019-05-29 16:56:00 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bd915eb4-c01a-4a5a-a009-439028ecba46 0xc00127d927 0xc00127d928}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 16:56:25.551: INFO: Pod "test-rollover-deployment-5688f7697c-zbttc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5688f7697c-zbttc,GenerateName:test-rollover-deployment-5688f7697c-,Namespace:deployment-7633,SelfLink:/api/v1/namespaces/deployment-7633/pods/test-rollover-deployment-5688f7697c-zbttc,UID:ffc3795f-7e2a-46a7-b84d-79a31c6e14e0,ResourceVersion:8190,Generation:0,CreationTimestamp:2019-05-29 16:56:02 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5688f7697c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5688f7697c 31dc147e-be04-49e3-a25d-4e111a471b0f 0xc002c57937 0xc002c57938}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-h4k8v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-h4k8v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-h4k8v true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c579f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c57a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:56:03 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:56:14 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:56:14 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:56:03 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:10.64.2.4,StartTime:2019-05-29 16:56:03 -0700 PDT,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-29 16:56:12 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/redis:1.0 docker-pullable://e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 docker://f64d6f35e28d1ee878f1098e5cf42bab653bd9ee38ae2be22c26d65975a53076}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:56:25.551: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-7633" for this suite.
May 29 16:56:31.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:56:33.319: INFO: namespace deployment-7633 deletion completed in 7.725447731s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 16:56:33.320: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:56:33.321: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 16:56:33.322: INFO: Driver hostPathSymlink doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:56:33.323: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver hostPathSymlink doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 16:56:33.324: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward api env vars
May 29 16:56:33.541: INFO: Waiting up to 5m0s for pod "downward-api-06327026-461f-45ad-973e-4f8e36518789" in namespace "downward-api-1067" to be "success or failure"
May 29 16:56:33.582: INFO: Pod "downward-api-06327026-461f-45ad-973e-4f8e36518789": Phase="Pending", Reason="", readiness=false. Elapsed: 41.237535ms
May 29 16:56:35.624: INFO: Pod "downward-api-06327026-461f-45ad-973e-4f8e36518789": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083066867s
May 29 16:56:37.667: INFO: Pod "downward-api-06327026-461f-45ad-973e-4f8e36518789": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125644126s
May 29 16:56:39.709: INFO: Pod "downward-api-06327026-461f-45ad-973e-4f8e36518789": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.167732403s
[1mSTEP[0m: Saw pod success
May 29 16:56:39.709: INFO: Pod "downward-api-06327026-461f-45ad-973e-4f8e36518789" satisfied condition "success or failure"
May 29 16:56:39.751: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-1vjk pod downward-api-06327026-461f-45ad-973e-4f8e36518789 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 29 16:56:39.858: INFO: Waiting for pod downward-api-06327026-461f-45ad-973e-4f8e36518789 to disappear
May 29 16:56:39.899: INFO: Pod downward-api-06327026-461f-45ad-973e-4f8e36518789 no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:56:39.899: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-1067" for this suite.
May 29 16:56:46.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:56:47.675: INFO: namespace downward-api-1067 deletion completed in 7.733071801s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 16:56:47.676: INFO: Driver hostPathSymlink doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:56:47.677: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver hostPathSymlink doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run rc[0m 
  [1mshould create an rc from an image  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 16:56:47.678: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run rc
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1370
[It] should create an rc from an image  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: running the image e2eteam/nginx:1.14-alpine
May 29 16:56:47.886: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config run e2e-test-nginx-rc --image=e2eteam/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7746'
May 29 16:56:48.170: INFO: stderr: ""
May 29 16:56:48.170: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
[1mSTEP[0m: verifying the rc e2e-test-nginx-rc was created
[1mSTEP[0m: verifying the pod controlled by rc e2e-test-nginx-rc was created
[1mSTEP[0m: confirm that you can get logs from an rc
May 29 16:56:48.273: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-hfgsz]
May 29 16:56:48.273: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-hfgsz" in namespace "kubectl-7746" to be "running and ready"
May 29 16:56:48.314: INFO: Pod "e2e-test-nginx-rc-hfgsz": Phase="Pending", Reason="", readiness=false. Elapsed: 41.692076ms
May 29 16:56:50.357: INFO: Pod "e2e-test-nginx-rc-hfgsz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083920944s
May 29 16:56:52.402: INFO: Pod "e2e-test-nginx-rc-hfgsz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12875004s
May 29 16:56:54.444: INFO: Pod "e2e-test-nginx-rc-hfgsz": Phase="Pending", Reason="", readiness=false. Elapsed: 6.170943282s
May 29 16:56:56.485: INFO: Pod "e2e-test-nginx-rc-hfgsz": Phase="Running", Reason="", readiness=true. Elapsed: 8.212714519s
May 29 16:56:56.486: INFO: Pod "e2e-test-nginx-rc-hfgsz" satisfied condition "running and ready"
May 29 16:56:56.486: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-hfgsz]
May 29 16:56:56.486: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs rc/e2e-test-nginx-rc --namespace=kubectl-7746'
May 29 16:56:56.865: INFO: stderr: ""
May 29 16:56:56.865: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1375
May 29 16:56:56.865: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete rc e2e-test-nginx-rc --namespace=kubectl-7746'
May 29 16:56:57.156: INFO: stderr: ""
May 29 16:56:57.156: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:56:57.156: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-7746" for this suite.
May 29 16:57:19.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:57:20.932: INFO: namespace kubectl-7746 deletion completed in 23.73286587s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run deployment[0m 
  [1mshould create a deployment from an image  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 16:57:20.932: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1471
[It] should create a deployment from an image  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: running the image e2eteam/nginx:1.14-alpine
May 29 16:57:21.135: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config run e2e-test-nginx-deployment --image=e2eteam/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-6340'
May 29 16:57:21.401: INFO: stderr: ""
May 29 16:57:21.401: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
[1mSTEP[0m: verifying the deployment e2e-test-nginx-deployment was created
[1mSTEP[0m: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1476
May 29 16:57:23.500: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete deployment e2e-test-nginx-deployment --namespace=kubectl-6340'
May 29 16:57:23.800: INFO: stderr: ""
May 29 16:57:23.800: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:57:23.800: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-6340" for this suite.
May 29 16:57:45.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:57:47.598: INFO: namespace kubectl-6340 deletion completed in 23.754696223s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Pods Extended[0m [90m[k8s.io] Pods Set QOS Class[0m 
  [1mshould be submitted and removed  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 16:57:47.599: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 16:57:47.893: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-803" for this suite.
May 29 16:58:10.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 16:58:11.682: INFO: namespace pods-803 deletion completed in 23.74186159s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould not start app containers if init containers fail on a RestartAlways pod [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 16:58:11.682: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
May 29 16:58:11.853: INFO: PodSpec: initContainers in spec.initContainers
May 29 17:01:45.519: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-2b757aeb-a2cb-48d8-96af-8ef886e79aa1", GenerateName:"", Namespace:"init-container-9885", SelfLink:"/api/v1/namespaces/init-container-9885/pods/pod-init-2b757aeb-a2cb-48d8-96af-8ef886e79aa1", UID:"ac494d35-35d3-406a-9971-644ed5c961ce", ResourceVersion:"9081", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694771091, loc:(*time.Location)(0x8175900)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"853459975"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-c9bwm", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0017ae740), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"e2eteam/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c9bwm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"e2eteam/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c9bwm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"e2eteam/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c9bwm", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00238e088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"e2e-test-peterhornyack-windows-node-group-9q9v", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002160180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00238e110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00238e140)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00238e148), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00238e14c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694771091, loc:(*time.Location)(0x8175900)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694771091, loc:(*time.Location)(0x8175900)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694771091, loc:(*time.Location)(0x8175900)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694771091, loc:(*time.Location)(0x8175900)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.40.0.4", PodIP:"10.64.3.4", StartTime:(*v1.Time)(0xc002c68120), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00204a0e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00204a150)}, Ready:false, RestartCount:3, Image:"e2eteam/busybox:1.29", ImageID:"docker-pullable://e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4", ContainerID:"docker://04935ddfae1f92068affa2eeeb8eb2b3b2a6195da5123bff9882bad877b3b525"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c681a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"e2eteam/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002c68160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"e2eteam/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:01:45.519: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "init-container-9885" for this suite.
May 29 17:02:07.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:02:09.290: INFO: namespace init-container-9885 deletion completed in 23.729164305s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen running a container with a new image[0m 
  [1mshould not be able to pull non-existing image from gcr.io [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:359[0m
[BeforeEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:02:09.291: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be able to pull non-existing image from gcr.io [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:359
[1mSTEP[0m: create the container
[1mSTEP[0m: check the container status
[1mSTEP[0m: delete the container
[AfterEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:02:12.774: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-runtime-355" for this suite.
May 29 17:02:18.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:02:20.546: INFO: namespace container-runtime-355 deletion completed in 7.729231413s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:02:20.546: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:02:20.547: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:99
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:02:20.548: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename provisioning
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provision storage with defaults
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147
May 29 17:02:20.717: INFO: In creating storage class object and pvc object for driver - sc: &StorageClass{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:provisioning-6812-gcepd-scm97tr,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Provisioner:kubernetes.io/gce-pd,Parameters:map[string]string{fsType: ntfs,},ReclaimPolicy:nil,MountOptions:[],AllowVolumeExpansion:nil,VolumeBindingMode:*WaitForFirstConsumer,AllowedTopologies:[],}, pvc: &PersistentVolumeClaim{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:pvc-,Namespace:provisioning-6812,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PersistentVolumeClaimSpec{AccessModes:[ReadWriteOnce],Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{storage: {{5368709120 0} {<nil>} 5Gi BinarySI},},},VolumeName:,Selector:nil,StorageClassName:*provisioning-6812-gcepd-scm97tr,VolumeMode:nil,DataSource:nil,},Status:PersistentVolumeClaimStatus{Phase:,AccessModes:[],Capacity:ResourceList{},Conditions:[],},}
[1mSTEP[0m: creating a StorageClass provisioning-6812-gcepd-scm97tr
[1mSTEP[0m: creating a claim
[1mSTEP[0m: checking the created volume is writable on node {Name: Selector:map[] Affinity:nil}
May 29 17:02:20.898: INFO: Waiting up to 15m0s for pod "pvc-volume-tester-writer-xr8z7" in namespace "provisioning-6812" to be "success or failure"
May 29 17:02:20.940: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.712628ms
May 29 17:02:22.982: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08344203s
May 29 17:02:25.024: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125737042s
May 29 17:02:27.066: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167738883s
May 29 17:02:29.114: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.215974063s
May 29 17:02:31.156: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.257481105s
May 29 17:02:33.198: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.299568434s
May 29 17:02:35.240: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.342092383s
May 29 17:02:37.282: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.384188777s
May 29 17:02:39.324: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.42628969s
May 29 17:02:41.366: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.468202301s
May 29 17:02:43.408: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.510037745s
May 29 17:02:45.450: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.552280854s
May 29 17:02:47.493: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Pending", Reason="", readiness=false. Elapsed: 26.594528239s
May 29 17:02:49.538: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Running", Reason="", readiness=true. Elapsed: 28.640264078s
May 29 17:02:51.581: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Running", Reason="", readiness=true. Elapsed: 30.683247855s
May 29 17:02:53.624: INFO: Pod "pvc-volume-tester-writer-xr8z7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.725638069s
[1mSTEP[0m: Saw pod success
May 29 17:02:53.624: INFO: Pod "pvc-volume-tester-writer-xr8z7" satisfied condition "success or failure"
May 29 17:02:53.717: INFO: Pod pvc-volume-tester-writer-xr8z7 has the following logs: 
[1mSTEP[0m: Deleting pod pvc-volume-tester-writer-xr8z7 in namespace provisioning-6812
[1mSTEP[0m: checking the created volume has the correct mount options, is readable and retains data on the same node "e2e-test-peterhornyack-windows-node-group-jpxd"
May 29 17:02:53.903: INFO: Waiting up to 15m0s for pod "pvc-volume-tester-reader-ktg9k" in namespace "provisioning-6812" to be "success or failure"
May 29 17:02:53.960: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 57.161298ms
May 29 17:02:56.002: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.099420307s
May 29 17:02:58.045: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 4.141958207s
May 29 17:03:00.086: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 6.183495051s
May 29 17:03:02.139: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.235981746s
May 29 17:03:04.192: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 10.288891421s
May 29 17:03:06.233: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 12.33032843s
May 29 17:03:08.275: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 14.372226103s
May 29 17:03:10.317: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 16.414271833s
May 29 17:03:12.361: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Pending", Reason="", readiness=false. Elapsed: 18.457803877s
May 29 17:03:14.403: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Running", Reason="", readiness=true. Elapsed: 20.499915602s
May 29 17:03:16.445: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Running", Reason="", readiness=true. Elapsed: 22.541954289s
May 29 17:03:18.487: INFO: Pod "pvc-volume-tester-reader-ktg9k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.58381659s
[1mSTEP[0m: Saw pod success
May 29 17:03:18.487: INFO: Pod "pvc-volume-tester-reader-ktg9k" satisfied condition "success or failure"
May 29 17:03:18.537: INFO: Pod pvc-volume-tester-reader-ktg9k has the following logs: 
mnt\test\data:1:hello world



[1mSTEP[0m: Deleting pod pvc-volume-tester-reader-ktg9k in namespace provisioning-6812
May 29 17:03:18.591: INFO: Waiting up to 5m0s for PersistentVolumeClaims [pvc-j5kkr] to have phase Bound
May 29 17:03:18.633: INFO: PersistentVolumeClaim pvc-j5kkr found and phase=Bound (42.344224ms)
[1mSTEP[0m: checking the claim
[1mSTEP[0m: checking the PV
[1mSTEP[0m: deleting claim "provisioning-6812"/"pvc-j5kkr"
[1mSTEP[0m: deleting the claim's PV "pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc"
May 29 17:03:18.762: INFO: Waiting up to 20m0s for PersistentVolume pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc to get deleted
May 29 17:03:18.805: INFO: PersistentVolume pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc found and phase=Released (43.713428ms)
May 29 17:03:23.852: INFO: PersistentVolume pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc found and phase=Released (5.090505813s)
May 29 17:03:28.894: INFO: PersistentVolume pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc found and phase=Released (10.132344043s)
May 29 17:03:33.936: INFO: PersistentVolume pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc found and phase=Released (15.174651483s)
May 29 17:03:38.978: INFO: PersistentVolume pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc found and phase=Released (20.216598246s)
May 29 17:03:44.020: INFO: PersistentVolume pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc found and phase=Released (25.258209062s)
May 29 17:03:49.061: INFO: PersistentVolume pvc-b01ad3a8-f6cd-4d50-afb5-35d74683cafc was removed
May 29 17:03:49.061: INFO: deleting claim "provisioning-6812"/"pvc-j5kkr"
May 29 17:03:49.103: INFO: deleting storage class provisioning-6812-gcepd-scm97tr
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:03:49.148: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "provisioning-6812" for this suite.
May 29 17:03:55.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:03:56.907: INFO: namespace provisioning-6812 deletion completed in 7.715635284s
[32m•[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:03:56.908: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:03:56.909: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:03:56.910: INFO: Driver aws doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:03:56.912: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver aws doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:03:56.912: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:03:56.914: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl expose[0m 
  [1mshould create services for rc  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:03:56.914: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create services for rc  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating Redis RC
May 29 17:03:57.122: INFO: namespace kubectl-2007
May 29 17:03:57.122: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-2007'
May 29 17:03:59.534: INFO: stderr: ""
May 29 17:03:59.534: INFO: stdout: "replicationcontroller/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
May 29 17:04:00.577: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:00.577: INFO: Found 0 / 1
May 29 17:04:01.576: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:01.576: INFO: Found 0 / 1
May 29 17:04:02.576: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:02.576: INFO: Found 0 / 1
May 29 17:04:03.576: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:03.576: INFO: Found 0 / 1
May 29 17:04:04.576: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:04.576: INFO: Found 0 / 1
May 29 17:04:05.576: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:05.577: INFO: Found 0 / 1
May 29 17:04:06.576: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:06.576: INFO: Found 0 / 1
May 29 17:04:07.578: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:07.578: INFO: Found 1 / 1
May 29 17:04:07.578: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 29 17:04:07.620: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:04:07.620: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 17:04:07.620: INFO: wait on redis-master startup in kubectl-2007 
May 29 17:04:07.620: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs redis-master-25c8n redis-master --namespace=kubectl-2007'
May 29 17:04:07.956: INFO: stderr: ""
May 29 17:04:07.956: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.100 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1968\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n[1968] 30 May 00:04:04.884 # Server started, Redis version 3.2.100\n[1968] 30 May 00:04:04.884 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: exposing RC
May 29 17:04:07.956: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-2007'
May 29 17:04:08.314: INFO: stderr: ""
May 29 17:04:08.314: INFO: stdout: "service/rm2 exposed\n"
May 29 17:04:08.358: INFO: Service rm2 in namespace kubectl-2007 found.
[1mSTEP[0m: exposing service
May 29 17:04:10.443: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-2007'
May 29 17:04:10.767: INFO: stderr: ""
May 29 17:04:10.767: INFO: stdout: "service/rm3 exposed\n"
May 29 17:04:10.810: INFO: Service rm3 in namespace kubectl-2007 found.
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:12.894: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-2007" for this suite.
May 29 17:04:35.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:04:36.664: INFO: namespace kubectl-2007 deletion completed in 23.726942932s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:04:36.664: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:36.665: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run default[0m 
  [1mshould create an rc or deployment from an image  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:04:36.665: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run default
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1334
[It] should create an rc or deployment from an image  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: running the image e2eteam/nginx:1.14-alpine
May 29 17:04:36.833: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config run e2e-test-nginx-deployment --image=e2eteam/nginx:1.14-alpine --namespace=kubectl-6303'
May 29 17:04:37.167: INFO: stderr: ""
May 29 17:04:37.167: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
[1mSTEP[0m: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1340
May 29 17:04:37.235: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete deployment e2e-test-nginx-deployment --namespace=kubectl-6303'
May 29 17:04:37.525: INFO: stderr: ""
May 29 17:04:37.525: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:37.525: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-6303" for this suite.
May 29 17:04:43.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:04:45.301: INFO: namespace kubectl-6303 deletion completed in 7.732850934s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:04:45.301: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
May 29 17:04:51.845: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 718
	[quantile=0.9] = 92258
	[quantile=0.99] = 111702
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 44954
	[quantile=0.9] = 637521
	[quantile=0.99] = 652682
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 8
	[quantile=0.99] = 31
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 19
	[quantile=0.9] = 36
	[quantile=0.99] = 65
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 20
	[quantile=0.99] = 25
For namespace_queue_latency_sum:
	[] = 515
For namespace_queue_latency_count:
	[] = 27
For namespace_retries:
	[] = 28
For namespace_work_duration:
	[quantile=0.5] = 190733
	[quantile=0.9] = 429902
	[quantile=0.99] = 556991
For namespace_work_duration_sum:
	[] = 5640128
For namespace_work_duration_count:
	[] = 27
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:04:51.846: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-2790" for this suite.
May 29 17:04:58.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:04:59.647: INFO: namespace gc-2790 deletion completed in 7.758485581s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:04:59.647: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating pod liveness-http in namespace container-probe-2368
May 29 17:05:11.954: INFO: Started pod liveness-http in namespace container-probe-2368
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 29 17:05:11.996: INFO: Initial restart count of pod liveness-http is 0
May 29 17:05:34.512: INFO: Restart count of pod container-probe-2368/liveness-http is now 1 (22.51593385s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:05:34.564: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-2368" for this suite.
May 29 17:05:40.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:05:42.513: INFO: namespace container-probe-2368 deletion completed in 7.90645272s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] [sig-windows] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: udp[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:61[0m
[BeforeEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:05:42.514: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:32
[It] should function for intra-pod communication: udp
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:61
[1mSTEP[0m: Performing setup for networking test in namespace pod-network-test-9417
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
May 29 17:05:42.715: INFO: Waiting up to 10m0s for all (but 3) nodes to be schedulable
May 29 17:05:42.756: INFO: Unschedulable nodes:
May 29 17:05:42.756: INFO: -> e2e-test-peterhornyack-minion-group-5wdh Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 17:05:42.756: INFO: -> e2e-test-peterhornyack-minion-group-fzx6 Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 17:05:42.756: INFO: ================================
[1mSTEP[0m: Creating test pods
May 29 17:06:15.621: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.2.10:8080/dial?request=hostName&protocol=udp&host=10.64.2.9&port=8081&tries=1'] Namespace:pod-network-test-9417 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:06:15.621: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:06:16.400: INFO: Waiting for endpoints: map[]
May 29 17:06:16.441: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.2.10:8080/dial?request=hostName&protocol=udp&host=10.64.1.32&port=8081&tries=1'] Namespace:pod-network-test-9417 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:06:16.441: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:06:16.819: INFO: Waiting for endpoints: map[]
May 29 17:06:16.861: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.2.10:8080/dial?request=hostName&protocol=udp&host=10.64.3.7&port=8081&tries=1'] Namespace:pod-network-test-9417 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:06:16.861: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:06:17.245: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:06:17.245: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pod-network-test-9417" for this suite.
May 29 17:06:39.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:06:41.049: INFO: namespace pod-network-test-9417 deletion completed in 23.757377202s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:06:41.049: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
[1mSTEP[0m: Gathering metrics
May 29 17:07:11.695: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 753
	[quantile=0.9] = 92361
	[quantile=0.99] = 111702
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 41439
	[quantile=0.9] = 640729
	[quantile=0.99] = 652682
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 8
	[quantile=0.9] = 8
	[quantile=0.99] = 8
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 2120
	[quantile=0.9] = 2120
	[quantile=0.99] = 2120
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 14
	[quantile=0.99] = 46
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 18
	[quantile=0.9] = 34
	[quantile=0.99] = 67
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 14
	[quantile=0.9] = 18
	[quantile=0.99] = 25
For namespace_queue_latency_sum:
	[] = 628
For namespace_queue_latency_count:
	[] = 34
For namespace_retries:
	[] = 35
For namespace_work_duration:
	[quantile=0.5] = 190733
	[quantile=0.9] = 392037
	[quantile=0.99] = 575731
For namespace_work_duration_sum:
	[] = 7112977
For namespace_work_duration_count:
	[] = 34
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:07:11.695: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-5744" for this suite.
May 29 17:07:17.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:07:19.503: INFO: namespace gc-5744 deletion completed in 7.764306018s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:07:19.505: INFO: Driver hostPath doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:07:19.506: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver hostPath doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] [sig-windows] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for intra-pod communication: http[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:48[0m
[BeforeEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:07:19.507: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:32
[It] should function for intra-pod communication: http
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:48
[1mSTEP[0m: Performing setup for networking test in namespace pod-network-test-2811
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
May 29 17:07:19.708: INFO: Waiting up to 10m0s for all (but 3) nodes to be schedulable
May 29 17:07:19.749: INFO: Unschedulable nodes:
May 29 17:07:19.749: INFO: -> e2e-test-peterhornyack-minion-group-5wdh Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 17:07:19.749: INFO: -> e2e-test-peterhornyack-minion-group-fzx6 Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 17:07:19.749: INFO: ================================
[1mSTEP[0m: Creating test pods
May 29 17:07:52.677: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.1.36:8080/dial?request=hostName&protocol=http&host=10.64.2.11&port=8080&tries=1'] Namespace:pod-network-test-2811 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:07:52.677: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:08:14.843: INFO: Failed to execute "curl -g -q -s 'http://10.64.1.36:8080/dial?request=hostName&protocol=http&host=10.64.2.11&port=8080&tries=1'": command terminated with exit code 7, stdout: "", stderr ""
May 29 17:08:14.843: INFO: Waiting for endpoints: map[netserver-0:{}]
May 29 17:08:16.885: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.1.36:8080/dial?request=hostName&protocol=http&host=10.64.2.11&port=8080&tries=1'] Namespace:pod-network-test-2811 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:08:16.885: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:08:17.663: INFO: Waiting for endpoints: map[]
May 29 17:08:17.705: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.1.36:8080/dial?request=hostName&protocol=http&host=10.64.3.9&port=8080&tries=1'] Namespace:pod-network-test-2811 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:08:17.705: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:08:18.090: INFO: Waiting for endpoints: map[]
May 29 17:08:18.132: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.1.36:8080/dial?request=hostName&protocol=http&host=10.64.1.35&port=8080&tries=1'] Namespace:pod-network-test-2811 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:08:18.132: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:08:18.535: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:08:18.536: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pod-network-test-2811" for this suite.
May 29 17:08:40.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:08:42.383: INFO: namespace pod-network-test-2811 deletion completed in 23.803784436s
[32m•[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-windows] Services[0m 
  [1mshould be able to create a functioning NodePort service for Windows[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/service.go:39[0m
[BeforeEach] [sig-windows] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/framework.go:28
[BeforeEach] [sig-windows] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:08:42.383: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-windows] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/service.go:34
[It] should be able to create a functioning NodePort service for Windows
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/service.go:39
[1mSTEP[0m: creating service nodeport-test with type=NodePort in namespace services-4909
[1mSTEP[0m: creating Pod to be part of service nodeport-test
May 29 17:08:42.724: INFO: Waiting up to 2m0s for 1 pods to be created
May 29 17:08:42.777: INFO: Found all 1 pods
May 29 17:08:42.777: INFO: Waiting up to 2m0s for 1 pods to be running and ready: [nodeport-test-fplkp]
May 29 17:08:42.777: INFO: Waiting up to 2m0s for pod "nodeport-test-fplkp" in namespace "services-4909" to be "running and ready"
May 29 17:08:42.819: INFO: Pod "nodeport-test-fplkp": Phase="Pending", Reason="", readiness=false. Elapsed: 41.747868ms
May 29 17:08:44.862: INFO: Pod "nodeport-test-fplkp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084782037s
May 29 17:08:46.904: INFO: Pod "nodeport-test-fplkp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127040393s
May 29 17:08:48.946: INFO: Pod "nodeport-test-fplkp": Phase="Running", Reason="", readiness=false. Elapsed: 6.169338579s
May 29 17:08:50.988: INFO: Pod "nodeport-test-fplkp": Phase="Running", Reason="", readiness=false. Elapsed: 8.21141834s
May 29 17:08:53.030: INFO: Pod "nodeport-test-fplkp": Phase="Running", Reason="", readiness=true. Elapsed: 10.253253788s
May 29 17:08:53.030: INFO: Pod "nodeport-test-fplkp" satisfied condition "running and ready"
May 29 17:08:53.030: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [nodeport-test-fplkp]
[1mSTEP[0m: creating Windows testing Pod
[1mSTEP[0m: checking connectivity Pod to curl http://104.197.5.20:32108
[1mSTEP[0m: checking connectivity of windows-container in pod-ce867205-d1e3-49d8-a31b-791de19e4b1f
May 29 17:09:31.203: INFO: ExecWithOptions {Command:[cmd /c curl.exe http://104.197.5.20:32108 --connect-timeout 10 --fail] Namespace:services-4909 PodName:pod-ce867205-d1e3-49d8-a31b-791de19e4b1f ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:31.203: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-ce867205-d1e3-49d8-a31b-791de19e4b1f
May 29 17:09:32.681: INFO: ExecWithOptions {Command:[cmd /c curl.exe http://104.197.5.20:32108 --connect-timeout 10 --fail] Namespace:services-4909 PodName:pod-ce867205-d1e3-49d8-a31b-791de19e4b1f ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:32.681: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-ce867205-d1e3-49d8-a31b-791de19e4b1f
May 29 17:09:34.052: INFO: ExecWithOptions {Command:[cmd /c curl.exe http://104.197.5.20:32108 --connect-timeout 10 --fail] Namespace:services-4909 PodName:pod-ce867205-d1e3-49d8-a31b-791de19e4b1f ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:34.052: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-ce867205-d1e3-49d8-a31b-791de19e4b1f
May 29 17:09:35.429: INFO: ExecWithOptions {Command:[cmd /c curl.exe http://104.197.5.20:32108 --connect-timeout 10 --fail] Namespace:services-4909 PodName:pod-ce867205-d1e3-49d8-a31b-791de19e4b1f ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:35.430: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-ce867205-d1e3-49d8-a31b-791de19e4b1f
May 29 17:09:36.786: INFO: ExecWithOptions {Command:[cmd /c curl.exe http://104.197.5.20:32108 --connect-timeout 10 --fail] Namespace:services-4909 PodName:pod-ce867205-d1e3-49d8-a31b-791de19e4b1f ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:36.786: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-ce867205-d1e3-49d8-a31b-791de19e4b1f
May 29 17:09:38.170: INFO: ExecWithOptions {Command:[cmd /c curl.exe http://104.197.5.20:32108 --connect-timeout 10 --fail] Namespace:services-4909 PodName:pod-ce867205-d1e3-49d8-a31b-791de19e4b1f ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:38.170: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-ce867205-d1e3-49d8-a31b-791de19e4b1f
May 29 17:09:39.538: INFO: ExecWithOptions {Command:[cmd /c curl.exe http://104.197.5.20:32108 --connect-timeout 10 --fail] Namespace:services-4909 PodName:pod-ce867205-d1e3-49d8-a31b-791de19e4b1f ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:39.538: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-ce867205-d1e3-49d8-a31b-791de19e4b1f
May 29 17:09:40.926: INFO: ExecWithOptions {Command:[cmd /c curl.exe http://104.197.5.20:32108 --connect-timeout 10 --fail] Namespace:services-4909 PodName:pod-ce867205-d1e3-49d8-a31b-791de19e4b1f ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:09:40.926: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[AfterEach] [sig-windows] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:09:41.287: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "services-4909" for this suite.
May 29 17:10:47.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:10:49.083: INFO: namespace services-4909 deletion completed in 1m7.753775887s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:10:49.084: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:10:49.085: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:10:49.086: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:10:49.087: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:10:49.088: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:10:49.089: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-node] ConfigMap[0m 
  [1mshould be consumable via environment variable [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-node] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:10:49.090: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap configmap-2289/configmap-test-e074f7e9-c908-432e-a369-8a16adbea229
[1mSTEP[0m: Creating a pod to test consume configMaps
May 29 17:10:49.390: INFO: Waiting up to 5m0s for pod "pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2" in namespace "configmap-2289" to be "success or failure"
May 29 17:10:49.432: INFO: Pod "pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2": Phase="Pending", Reason="", readiness=false. Elapsed: 41.954853ms
May 29 17:10:51.475: INFO: Pod "pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085203202s
May 29 17:10:53.519: INFO: Pod "pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129480851s
May 29 17:10:55.564: INFO: Pod "pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.173931831s
[1mSTEP[0m: Saw pod success
May 29 17:10:55.564: INFO: Pod "pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2" satisfied condition "success or failure"
May 29 17:10:55.605: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2 container env-test: <nil>
[1mSTEP[0m: delete the pod
May 29 17:10:55.729: INFO: Waiting for pod pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2 to disappear
May 29 17:10:55.770: INFO: Pod pod-configmaps-92c383a2-695a-40c9-87e1-0db03e1b29e2 no longer exists
[AfterEach] [sig-node] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:10:55.770: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-2289" for this suite.
May 29 17:11:01.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:11:03.541: INFO: namespace configmap-2289 deletion completed in 7.728550155s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command that always fails in a pod[0m 
  [1mshould have an terminated reason [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:11:03.541: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[AfterEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:11:11.891: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubelet-test-7782" for this suite.
May 29 17:11:18.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:11:19.657: INFO: namespace kubelet-test-7782 deletion completed in 7.722394401s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:11:19.657: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:11:19.658: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run pod[0m 
  [1mshould create a pod from an image when restart is Never  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:11:19.659: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run pod
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1599
[It] should create a pod from an image when restart is Never  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: running the image e2eteam/nginx:1.14-alpine
May 29 17:11:19.860: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=e2eteam/nginx:1.14-alpine --namespace=kubectl-340'
May 29 17:11:20.131: INFO: stderr: ""
May 29 17:11:20.131: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1604
May 29 17:11:20.173: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete pods e2e-test-nginx-pod --namespace=kubectl-340'
May 29 17:11:22.616: INFO: stderr: ""
May 29 17:11:22.616: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:11:22.616: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-340" for this suite.
May 29 17:11:28.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:11:30.387: INFO: namespace kubectl-340 deletion completed in 7.72858163s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:11:30.388: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:11:30.390: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:11:30.390: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 17:11:30.643: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20" in namespace "downward-api-8112" to be "success or failure"
May 29 17:11:30.685: INFO: Pod "downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20": Phase="Pending", Reason="", readiness=false. Elapsed: 42.11004ms
May 29 17:11:32.730: INFO: Pod "downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086976014s
May 29 17:11:34.772: INFO: Pod "downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20": Phase="Pending", Reason="", readiness=false. Elapsed: 4.129108417s
May 29 17:11:36.814: INFO: Pod "downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20": Phase="Pending", Reason="", readiness=false. Elapsed: 6.171583265s
May 29 17:11:38.856: INFO: Pod "downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20": Phase="Pending", Reason="", readiness=false. Elapsed: 8.21353307s
May 29 17:11:40.898: INFO: Pod "downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.25553976s
[1mSTEP[0m: Saw pod success
May 29 17:11:40.898: INFO: Pod "downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20" satisfied condition "success or failure"
May 29 17:11:40.945: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 17:11:41.045: INFO: Waiting for pod downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20 to disappear
May 29 17:11:41.086: INFO: Pod downwardapi-volume-ccaf1c26-78c2-4359-b48d-49025a44fa20 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:11:41.086: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-8112" for this suite.
May 29 17:11:47.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:11:48.870: INFO: namespace downward-api-8112 deletion completed in 7.740339652s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:11:48.870: INFO: Driver hostPathSymlink doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:11:48.870: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver hostPathSymlink doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:11:48.871: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:11:48.871: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe add, update, and delete watch notifications on configmaps [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:11:48.872: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating a watch on configmaps with label A
[1mSTEP[0m: creating a watch on configmaps with label B
[1mSTEP[0m: creating a watch on configmaps with label A or B
[1mSTEP[0m: creating a configmap with label A and ensuring the correct watchers observe the notification
May 29 17:11:49.235: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-a,UID:6e353a64-9df6-4c4d-9bfc-8a8d4963bb4b,ResourceVersion:10937,Generation:0,CreationTimestamp:2019-05-29 17:11:49 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 17:11:49.235: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-a,UID:6e353a64-9df6-4c4d-9bfc-8a8d4963bb4b,ResourceVersion:10937,Generation:0,CreationTimestamp:2019-05-29 17:11:49 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A and ensuring the correct watchers observe the notification
May 29 17:11:59.322: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-a,UID:6e353a64-9df6-4c4d-9bfc-8a8d4963bb4b,ResourceVersion:10964,Generation:0,CreationTimestamp:2019-05-29 17:11:49 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 29 17:11:59.322: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-a,UID:6e353a64-9df6-4c4d-9bfc-8a8d4963bb4b,ResourceVersion:10964,Generation:0,CreationTimestamp:2019-05-29 17:11:49 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying configmap A again and ensuring the correct watchers observe the notification
May 29 17:12:09.410: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-a,UID:6e353a64-9df6-4c4d-9bfc-8a8d4963bb4b,ResourceVersion:10988,Generation:0,CreationTimestamp:2019-05-29 17:11:49 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 29 17:12:09.410: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-a,UID:6e353a64-9df6-4c4d-9bfc-8a8d4963bb4b,ResourceVersion:10988,Generation:0,CreationTimestamp:2019-05-29 17:11:49 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap A and ensuring the correct watchers observe the notification
May 29 17:12:19.455: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-a,UID:6e353a64-9df6-4c4d-9bfc-8a8d4963bb4b,ResourceVersion:11013,Generation:0,CreationTimestamp:2019-05-29 17:11:49 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 29 17:12:19.456: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-a,UID:6e353a64-9df6-4c4d-9bfc-8a8d4963bb4b,ResourceVersion:11013,Generation:0,CreationTimestamp:2019-05-29 17:11:49 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: creating a configmap with label B and ensuring the correct watchers observe the notification
May 29 17:12:29.503: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-b,UID:40eb1aed-3c52-489a-92d4-28a0023b278d,ResourceVersion:11036,Generation:0,CreationTimestamp:2019-05-29 17:12:29 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 17:12:29.503: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-b,UID:40eb1aed-3c52-489a-92d4-28a0023b278d,ResourceVersion:11036,Generation:0,CreationTimestamp:2019-05-29 17:12:29 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[1mSTEP[0m: deleting configmap B and ensuring the correct watchers observe the notification
May 29 17:12:39.548: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-b,UID:40eb1aed-3c52-489a-92d4-28a0023b278d,ResourceVersion:11059,Generation:0,CreationTimestamp:2019-05-29 17:12:29 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 17:12:39.548: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3435,SelfLink:/api/v1/namespaces/watch-3435/configmaps/e2e-watch-test-configmap-b,UID:40eb1aed-3c52-489a-92d4-28a0023b278d,ResourceVersion:11059,Generation:0,CreationTimestamp:2019-05-29 17:12:29 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:12:49.548: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "watch-3435" for this suite.
May 29 17:12:55.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:12:57.337: INFO: namespace watch-3435 deletion completed in 7.744605316s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:12:57.337: INFO: Driver emptydir doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:12:57.339: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver emptydir doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:12:57.340: INFO: Driver gluster doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:12:57.341: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver gluster doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide host IP as an env var [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:12:57.342: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward api env vars
May 29 17:12:57.636: INFO: Waiting up to 5m0s for pod "downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01" in namespace "downward-api-2450" to be "success or failure"
May 29 17:12:57.678: INFO: Pod "downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01": Phase="Pending", Reason="", readiness=false. Elapsed: 41.651953ms
May 29 17:12:59.722: INFO: Pod "downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086500711s
May 29 17:13:01.764: INFO: Pod "downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128249487s
May 29 17:13:03.806: INFO: Pod "downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.170325451s
[1mSTEP[0m: Saw pod success
May 29 17:13:03.806: INFO: Pod "downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01" satisfied condition "success or failure"
May 29 17:13:03.850: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 29 17:13:03.953: INFO: Waiting for pod downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01 to disappear
May 29 17:13:03.995: INFO: Pod downward-api-92b32be9-5fae-4594-bf0f-f8e40311ed01 no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:13:03.995: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-2450" for this suite.
May 29 17:13:10.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:13:11.785: INFO: namespace downward-api-2450 deletion completed in 7.747216575s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:13:11.785: INFO: Driver emptydir doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:13:11.786: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver emptydir doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould provide secure master service  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:13:11.786: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should provide secure master service  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[AfterEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:13:11.998: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "services-1397" for this suite.
May 29 17:13:18.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:13:19.787: INFO: namespace services-1397 deletion completed in 7.746484049s
[AfterEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[32m•[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould get a host IP [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:13:19.787: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating pod
May 29 17:13:28.174: INFO: Pod pod-hostip-0c4d1ff4-bbfa-4be3-ad64-c8164ff51b26 has hostIP: 10.40.0.3
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:13:28.174: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-6483" for this suite.
May 29 17:13:50.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:13:51.932: INFO: namespace pods-6483 deletion completed in 23.715682876s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected combined[0m 
  [1mshould project all components that make up the projection API [Projection][NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected combined
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:13:51.933: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name configmap-projected-all-test-volume-31234f82-9875-49b0-b2ec-88cfa5ab419f
[1mSTEP[0m: Creating secret with name secret-projected-all-test-volume-5f49b63e-4097-45f8-8b52-53434d92f642
[1mSTEP[0m: Creating a pod to test Check all projections for projected volume plugin
May 29 17:13:52.271: INFO: Waiting up to 5m0s for pod "projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641" in namespace "projected-2980" to be "success or failure"
May 29 17:13:52.313: INFO: Pod "projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641": Phase="Pending", Reason="", readiness=false. Elapsed: 41.658358ms
May 29 17:13:54.355: INFO: Pod "projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083884034s
May 29 17:13:56.397: INFO: Pod "projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126004762s
May 29 17:13:58.440: INFO: Pod "projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168452927s
May 29 17:14:00.482: INFO: Pod "projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641": Phase="Running", Reason="", readiness=true. Elapsed: 8.210327893s
May 29 17:14:02.524: INFO: Pod "projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.25264568s
[1mSTEP[0m: Saw pod success
May 29 17:14:02.524: INFO: Pod "projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641" satisfied condition "success or failure"
May 29 17:14:02.566: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641 container projected-all-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 17:14:02.665: INFO: Waiting for pod projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641 to disappear
May 29 17:14:02.707: INFO: Pod projected-volume-1b8a133b-84cd-4339-9c9c-80c4fb5c7641 no longer exists
[AfterEach] [sig-storage] Projected combined
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:14:02.707: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-2980" for this suite.
May 29 17:14:08.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:14:10.627: INFO: namespace projected-2980 deletion completed in 7.877139257s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl logs[0m 
  [1mshould be able to retrieve and filter logs  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:14:10.628: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl logs
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
[1mSTEP[0m: creating an rc
May 29 17:14:10.809: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-1997'
May 29 17:14:13.217: INFO: stderr: ""
May 29 17:14:13.217: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Waiting for Redis master to start.
May 29 17:14:14.261: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:14:14.261: INFO: Found 0 / 1
May 29 17:14:15.260: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:14:15.260: INFO: Found 0 / 1
May 29 17:14:16.259: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:14:16.260: INFO: Found 0 / 1
May 29 17:14:17.260: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:14:17.260: INFO: Found 0 / 1
May 29 17:14:18.260: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:14:18.260: INFO: Found 0 / 1
May 29 17:14:19.259: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:14:19.259: INFO: Found 0 / 1
May 29 17:14:20.259: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:14:20.259: INFO: Found 1 / 1
May 29 17:14:20.259: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 29 17:14:20.302: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:14:20.302: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[1mSTEP[0m: checking for a matching strings
May 29 17:14:20.302: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs redis-master-4jd5h redis-master --namespace=kubectl-1997'
May 29 17:14:20.614: INFO: stderr: ""
May 29 17:14:20.614: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.100 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 2196\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n[2196] 30 May 00:14:18.145 # Server started, Redis version 3.2.100\n[2196] 30 May 00:14:18.145 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: limiting log lines
May 29 17:14:20.615: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config log redis-master-4jd5h redis-master --namespace=kubectl-1997 --tail=1'
May 29 17:14:20.918: INFO: stderr: ""
May 29 17:14:20.918: INFO: stdout: "[2196] 30 May 00:14:18.145 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: limiting log bytes
May 29 17:14:20.918: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config log redis-master-4jd5h redis-master --namespace=kubectl-1997 --limit-bytes=1'
May 29 17:14:21.226: INFO: stderr: ""
May 29 17:14:21.226: INFO: stdout: " "
[1mSTEP[0m: exposing timestamps
May 29 17:14:21.226: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config log redis-master-4jd5h redis-master --namespace=kubectl-1997 --tail=1 --timestamps'
May 29 17:14:21.535: INFO: stderr: ""
May 29 17:14:21.535: INFO: stdout: "2019-05-30T00:14:18.1894616Z [2196] 30 May 00:14:18.145 * The server is now ready to accept connections on port 6379\n"
[1mSTEP[0m: restricting to a time range
May 29 17:14:24.035: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config log redis-master-4jd5h redis-master --namespace=kubectl-1997 --since=1s'
May 29 17:14:24.356: INFO: stderr: ""
May 29 17:14:24.356: INFO: stdout: ""
May 29 17:14:24.356: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config log redis-master-4jd5h redis-master --namespace=kubectl-1997 --since=24h'
May 29 17:14:24.674: INFO: stderr: ""
May 29 17:14:24.674: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.100 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 2196\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n[2196] 30 May 00:14:18.145 # Server started, Redis version 3.2.100\n[2196] 30 May 00:14:18.145 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1212
[1mSTEP[0m: using delete to clean up resources
May 29 17:14:24.675: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-1997'
May 29 17:14:24.969: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 17:14:24.969: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 29 17:14:24.969: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get rc,svc -l name=nginx --no-headers --namespace=kubectl-1997'
May 29 17:14:25.295: INFO: stderr: "No resources found.\n"
May 29 17:14:25.295: INFO: stdout: ""
May 29 17:14:25.295: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -l name=nginx --namespace=kubectl-1997 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 17:14:25.550: INFO: stderr: ""
May 29 17:14:25.550: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:14:25.550: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-1997" for this suite.
May 29 17:14:31.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:14:33.394: INFO: namespace kubectl-1997 deletion completed in 7.801193461s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for ExternalName services [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-network] DNS
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:14:33.394: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a test externalName service
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5269.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5269.svc.cluster.local; sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5269.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5269.svc.cluster.local; sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
May 29 17:15:00.156: INFO: DNS probes using dns-test-85af534c-5fe4-40d1-bfc3-18ad6d7b516f succeeded

[1mSTEP[0m: deleting the pod
[1mSTEP[0m: changing the externalName to bar.example.com
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5269.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-5269.svc.cluster.local; sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5269.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-5269.svc.cluster.local; sleep 1; done

[1mSTEP[0m: creating a second pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
May 29 17:15:14.615: INFO: DNS probes using dns-test-3a6b50f9-95ef-456d-879b-6299380f723b succeeded

[1mSTEP[0m: deleting the pod
[1mSTEP[0m: changing the service to type=ClusterIP
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5269.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-5269.svc.cluster.local; sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-5269.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-5269.svc.cluster.local; sleep 1; done

[1mSTEP[0m: creating a third pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
May 29 17:15:31.176: INFO: File jessie_udp@dns-test-service-3.dns-5269.svc.cluster.local from pod  dns-5269/dns-test-72a136c3-d3b3-4d5f-aca8-8c67a8c3625d contains '' instead of '10.0.154.191'
May 29 17:15:31.176: INFO: Lookups using dns-5269/dns-test-72a136c3-d3b3-4d5f-aca8-8c67a8c3625d failed for: [jessie_udp@dns-test-service-3.dns-5269.svc.cluster.local]

May 29 17:15:36.263: INFO: DNS probes using dns-test-72a136c3-d3b3-4d5f-aca8-8c67a8c3625d succeeded

[1mSTEP[0m: deleting the pod
[1mSTEP[0m: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:15:36.381: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "dns-5269" for this suite.
May 29 17:15:42.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:15:44.144: INFO: namespace dns-5269 deletion completed in 7.720638586s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:15:44.144: INFO: Driver gluster doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:15:44.146: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver gluster doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:15:44.147: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 17:15:44.401: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3" in namespace "projected-6365" to be "success or failure"
May 29 17:15:44.451: INFO: Pod "downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3": Phase="Pending", Reason="", readiness=false. Elapsed: 50.07521ms
May 29 17:15:46.494: INFO: Pod "downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092372052s
May 29 17:15:48.536: INFO: Pod "downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.13443835s
May 29 17:15:50.578: INFO: Pod "downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.176612524s
[1mSTEP[0m: Saw pod success
May 29 17:15:50.578: INFO: Pod "downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3" satisfied condition "success or failure"
May 29 17:15:50.619: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 17:15:50.720: INFO: Waiting for pod downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3 to disappear
May 29 17:15:50.762: INFO: Pod downwardapi-volume-0d1dba4b-1bb4-4968-8b1e-5dec8d6e24f3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:15:50.762: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-6365" for this suite.
May 29 17:15:56.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:15:58.530: INFO: namespace projected-6365 deletion completed in 7.725814844s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:15:58.530: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:15:58.532: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:15:58.533: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename volume
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be mountable
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136
[1mSTEP[0m: creating a test gce pd volume
W0529 17:15:58.742086   96922 gce_instances.go:280] Cloud object does not have informers set, should only happen in E2E binary.
May 29 17:16:01.343: INFO: Successfully created a new PD: "e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b".
May 29 17:16:01.343: INFO: Creating resource for pre-provisioned PV
May 29 17:16:01.343: INFO: Creating PVC and PV
May 29 17:16:01.343: INFO: AccessModes unspecified, default: all modes (RWO, RWX, ROX).
May 29 17:16:01.343: INFO: PV ReclaimPolicy unspecified, default: Retain
[1mSTEP[0m: Creating a PVC followed by a PV
May 29 17:16:01.885: INFO: Waiting for PV gcepd-57cc6 to bind to PVC pvc-hhpsg
May 29 17:16:01.885: INFO: Waiting up to 3m0s for PersistentVolumeClaims [pvc-hhpsg] to have phase Bound
May 29 17:16:01.927: INFO: PersistentVolumeClaim pvc-hhpsg found but phase is Pending instead of Bound.
May 29 17:16:03.968: INFO: PersistentVolumeClaim pvc-hhpsg found but phase is Pending instead of Bound.
May 29 17:16:06.012: INFO: PersistentVolumeClaim pvc-hhpsg found but phase is Pending instead of Bound.
May 29 17:16:08.054: INFO: PersistentVolumeClaim pvc-hhpsg found but phase is Pending instead of Bound.
May 29 17:16:10.096: INFO: PersistentVolumeClaim pvc-hhpsg found but phase is Pending instead of Bound.
May 29 17:16:12.138: INFO: PersistentVolumeClaim pvc-hhpsg found but phase is Pending instead of Bound.
May 29 17:16:14.180: INFO: PersistentVolumeClaim pvc-hhpsg found and phase=Bound (12.295252459s)
May 29 17:16:14.180: INFO: Waiting up to 3m0s for PersistentVolume gcepd-57cc6 to have phase Bound
May 29 17:16:14.222: INFO: PersistentVolume gcepd-57cc6 found and phase=Bound (41.803107ms)
[1mSTEP[0m: starting gcepd injector
May 29 17:16:14.354: INFO: Waiting up to 5m0s for pod "gcepd-injector-vngq" in namespace "volume-5889" to be "success or failure"
May 29 17:16:14.396: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 41.487245ms
May 29 17:16:16.438: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083812616s
May 29 17:16:18.480: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125733976s
May 29 17:16:20.522: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16762086s
May 29 17:16:22.564: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209467584s
May 29 17:16:24.605: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 10.251061631s
May 29 17:16:26.647: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 12.292837362s
May 29 17:16:28.689: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 14.335168893s
May 29 17:16:30.731: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 16.376948481s
May 29 17:16:32.774: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 18.419897087s
May 29 17:16:34.816: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 20.462248107s
May 29 17:16:36.858: INFO: Pod "gcepd-injector-vngq": Phase="Pending", Reason="", readiness=false. Elapsed: 22.504322932s
May 29 17:16:38.901: INFO: Pod "gcepd-injector-vngq": Phase="Running", Reason="", readiness=true. Elapsed: 24.546613636s
May 29 17:16:40.943: INFO: Pod "gcepd-injector-vngq": Phase="Running", Reason="", readiness=true. Elapsed: 26.588655254s
May 29 17:16:42.985: INFO: Pod "gcepd-injector-vngq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.630844411s
[1mSTEP[0m: Saw pod success
May 29 17:16:42.985: INFO: Pod "gcepd-injector-vngq" satisfied condition "success or failure"
[1mSTEP[0m: starting gcepd-client
[1mSTEP[0m: Checking that text file contents are perfect.
May 29 17:16:53.171: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec gcepd-client --namespace=volume-5889 -- powershell /c type /opt/0/index.html'
May 29 17:16:57.140: INFO: stderr: ""
May 29 17:16:57.140: INFO: stdout: "Hello from gcepd from namespace volume-5889\r\n"
[1mSTEP[0m: cleaning the environment after gcepd
May 29 17:16:57.140: INFO: Deleting pod "gcepd-client" in namespace "volume-5889"
May 29 17:16:57.187: INFO: Wait up to 5m0s for pod "gcepd-client" to be fully deleted
[1mSTEP[0m: Deleting pv and pvc
May 29 17:17:01.270: INFO: Deleting PersistentVolumeClaim "pvc-hhpsg"
May 29 17:17:01.316: INFO: Deleting PersistentVolume "gcepd-57cc6"
May 29 17:17:02.309: INFO: error deleting PD "e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 17:17:02.309: INFO: Couldn't delete PD "e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 17:17:08.240: INFO: error deleting PD "e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 17:17:08.240: INFO: Couldn't delete PD "e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 17:17:14.185: INFO: error deleting PD "e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 17:17:14.185: INFO: Couldn't delete PD "e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 17:17:21.514: INFO: Successfully deleted PD "e2e-6c6aaa8c-c0ea-475e-b726-bdc43db0045b".
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:17:21.515: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "volume-5889" for this suite.
May 29 17:17:27.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:17:29.293: INFO: namespace volume-5889 deletion completed in 7.733746564s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:17:29.293: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:17:29.295: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould surface a failure condition on a common issue like exceeded quota [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] ReplicationController
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:17:29.296: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 17:17:29.502: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
[1mSTEP[0m: Creating rc "condition-test" that asks for more than the allowed pod quota
[1mSTEP[0m: Checking rc "condition-test" has the desired failure condition set
[1mSTEP[0m: Scaling down rc "condition-test" to satisfy pod quota
May 29 17:17:30.816: INFO: Updating replication controller "condition-test"
[1mSTEP[0m: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:17:30.857: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "replication-controller-6223" for this suite.
May 29 17:17:37.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:17:38.630: INFO: namespace replication-controller-6223 deletion completed in 7.729742798s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:17:38.630: INFO: Driver aws doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:17:38.632: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver aws doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] HostPath[0m 
  [1mshould support subPath [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:89[0m
[BeforeEach] [sig-storage] HostPath
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:17:38.633: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename hostpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should support subPath [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:89
[1mSTEP[0m: Creating a pod to test hostPath subPath
May 29 17:17:38.854: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8011" to be "success or failure"
May 29 17:17:38.896: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 41.94649ms
May 29 17:17:40.938: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083575959s
May 29 17:17:42.982: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127128259s
May 29 17:17:45.034: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.179923076s
May 29 17:17:47.081: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 8.226474853s
May 29 17:17:49.123: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 10.268550454s
May 29 17:17:51.165: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 12.31040686s
May 29 17:17:53.207: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 14.352167552s
May 29 17:17:55.253: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.3983883s
[1mSTEP[0m: Saw pod success
May 29 17:17:55.253: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 29 17:17:55.295: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-host-path-test container test-container-2: <nil>
[1mSTEP[0m: delete the pod
May 29 17:17:55.405: INFO: Waiting for pod pod-host-path-test to disappear
May 29 17:17:55.446: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:17:55.447: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "hostpath-8011" for this suite.
May 29 17:18:01.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:18:03.265: INFO: namespace hostpath-8011 deletion completed in 7.77630472s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-windows] Windows volume mounts [0m [90mcheck volume mount permissions[0m 
  [1mcontainer should have readOnly permissions on emptyDir[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/volumes.go:64[0m
[BeforeEach] [sig-windows] Windows volume mounts 
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/framework.go:28
[BeforeEach] [sig-windows] Windows volume mounts 
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:18:03.266: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename windows-volumes
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-windows] Windows volume mounts 
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/volumes.go:58
[It] container should have readOnly permissions on emptyDir
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/volumes.go:64
[1mSTEP[0m: creating a container with readOnly permissions on emptyDir volume
May 29 17:18:11.647: INFO: ExecWithOptions {Command:[cmd /c echo windows-volume-test > C:\test-volume\test-file.txt] Namespace:windows-volumes-7372 PodName:pod-728dbd60-2159-496e-a020-33028e78e61f ContainerName:test-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:18:11.647: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: creating two containers, one with readOnly permissions the other with read-write permissions on emptyDir volume
May 29 17:18:20.205: INFO: ExecWithOptions {Command:[cmd /c echo windows-volume-test > C:\test-volume\test-file] Namespace:windows-volumes-7372 PodName:pod-a95a2661-ca38-4cf5-8fb6-80fc724e6339 ContainerName:test-container-rw Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:18:20.205: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:18:20.553: INFO: ExecWithOptions {Command:[cmd /c echo windows-volume-test > C:\test-volume\test-file] Namespace:windows-volumes-7372 PodName:pod-a95a2661-ca38-4cf5-8fb6-80fc724e6339 ContainerName:test-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:18:20.553: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 17:18:20.910: INFO: ExecWithOptions {Command:[cmd /c type C:\test-volume\test-file] Namespace:windows-volumes-7372 PodName:pod-a95a2661-ca38-4cf5-8fb6-80fc724e6339 ContainerName:test-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 17:18:20.910: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[AfterEach] [sig-windows] Windows volume mounts 
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:18:21.259: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "windows-volumes-7372" for this suite.
May 29 17:18:43.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:18:45.032: INFO: namespace windows-volumes-7372 deletion completed in 23.73001997s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:18:45.032: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 17:18:45.283: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f" in namespace "downward-api-7357" to be "success or failure"
May 29 17:18:45.325: INFO: Pod "downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f": Phase="Pending", Reason="", readiness=false. Elapsed: 41.741563ms
May 29 17:18:47.366: INFO: Pod "downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083330498s
May 29 17:18:49.408: INFO: Pod "downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125418982s
May 29 17:18:51.450: INFO: Pod "downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167314198s
May 29 17:18:53.493: INFO: Pod "downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.209936208s
[1mSTEP[0m: Saw pod success
May 29 17:18:53.493: INFO: Pod "downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f" satisfied condition "success or failure"
May 29 17:18:53.535: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 17:18:53.639: INFO: Waiting for pod downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f to disappear
May 29 17:18:53.681: INFO: Pod downwardapi-volume-bcb76f3c-8fe9-40b0-aa83-cd4e1ee8893f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:18:53.681: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-7357" for this suite.
May 29 17:18:59.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:01.457: INFO: namespace downward-api-7357 deletion completed in 7.730323868s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:19:01.457: INFO: Driver csi-hostpath-v0 doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:01.459: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver csi-hostpath-v0 doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:19:01.460: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 17:19:01.707: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a3222e81-4058-458e-857e-30e373085049" in namespace "projected-9759" to be "success or failure"
May 29 17:19:01.749: INFO: Pod "downwardapi-volume-a3222e81-4058-458e-857e-30e373085049": Phase="Pending", Reason="", readiness=false. Elapsed: 41.507231ms
May 29 17:19:03.791: INFO: Pod "downwardapi-volume-a3222e81-4058-458e-857e-30e373085049": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083593794s
May 29 17:19:05.833: INFO: Pod "downwardapi-volume-a3222e81-4058-458e-857e-30e373085049": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125497223s
May 29 17:19:07.875: INFO: Pod "downwardapi-volume-a3222e81-4058-458e-857e-30e373085049": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.16737951s
[1mSTEP[0m: Saw pod success
May 29 17:19:07.875: INFO: Pod "downwardapi-volume-a3222e81-4058-458e-857e-30e373085049" satisfied condition "success or failure"
May 29 17:19:07.916: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-a3222e81-4058-458e-857e-30e373085049 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 17:19:08.019: INFO: Waiting for pod downwardapi-volume-a3222e81-4058-458e-857e-30e373085049 to disappear
May 29 17:19:08.060: INFO: Pod downwardapi-volume-a3222e81-4058-458e-857e-30e373085049 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:08.060: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-9759" for this suite.
May 29 17:19:14.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:16.048: INFO: namespace projected-9759 deletion completed in 7.945410323s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Service endpoints latency[0m 
  [1mshould not be very high  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-network] Service endpoints latency
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:19:16.048: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename svc-latency
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating replication controller svc-latency-rc in namespace svc-latency-1433
I0529 17:19:16.271794   96922 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1433, replica count: 1
I0529 17:19:17.322281   96922 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:19:18.322543   96922 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:19:19.322756   96922 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:19:20.322979   96922 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:19:21.323221   96922 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:19:22.323450   96922 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 17:19:23.323669   96922 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 29 17:19:23.483: INFO: Created: latency-svc-f9kct
May 29 17:19:23.491: INFO: Got endpoints: latency-svc-f9kct [67.775876ms]
May 29 17:19:23.546: INFO: Created: latency-svc-gktwz
May 29 17:19:23.553: INFO: Got endpoints: latency-svc-gktwz [62.15105ms]
May 29 17:19:23.558: INFO: Created: latency-svc-5n8gl
May 29 17:19:23.562: INFO: Got endpoints: latency-svc-5n8gl [70.499895ms]
May 29 17:19:23.587: INFO: Created: latency-svc-p6vxj
May 29 17:19:23.595: INFO: Created: latency-svc-dr48f
May 29 17:19:23.601: INFO: Got endpoints: latency-svc-p6vxj [109.458402ms]
May 29 17:19:23.606: INFO: Got endpoints: latency-svc-dr48f [113.964702ms]
May 29 17:19:23.612: INFO: Created: latency-svc-pqtjd
May 29 17:19:23.616: INFO: Got endpoints: latency-svc-pqtjd [125.20759ms]
May 29 17:19:23.620: INFO: Created: latency-svc-9vpvp
May 29 17:19:23.631: INFO: Created: latency-svc-rt9kp
May 29 17:19:23.639: INFO: Got endpoints: latency-svc-9vpvp [147.863148ms]
May 29 17:19:23.645: INFO: Got endpoints: latency-svc-rt9kp [153.811011ms]
May 29 17:19:23.655: INFO: Created: latency-svc-l8vff
May 29 17:19:23.666: INFO: Created: latency-svc-b5n6j
May 29 17:19:23.671: INFO: Got endpoints: latency-svc-l8vff [179.585271ms]
May 29 17:19:23.678: INFO: Got endpoints: latency-svc-b5n6j [186.42217ms]
May 29 17:19:23.690: INFO: Created: latency-svc-5trk8
May 29 17:19:23.700: INFO: Created: latency-svc-47cjj
May 29 17:19:23.703: INFO: Got endpoints: latency-svc-5trk8 [86.271034ms]
May 29 17:19:23.721: INFO: Created: latency-svc-q4hzm
May 29 17:19:23.721: INFO: Got endpoints: latency-svc-47cjj [229.38793ms]
May 29 17:19:23.741: INFO: Got endpoints: latency-svc-q4hzm [249.547548ms]
May 29 17:19:23.743: INFO: Created: latency-svc-5jmcv
May 29 17:19:23.750: INFO: Got endpoints: latency-svc-5jmcv [258.055427ms]
May 29 17:19:23.756: INFO: Created: latency-svc-frtns
May 29 17:19:23.766: INFO: Got endpoints: latency-svc-frtns [274.263546ms]
May 29 17:19:23.772: INFO: Created: latency-svc-9h8pp
May 29 17:19:23.778: INFO: Got endpoints: latency-svc-9h8pp [286.689719ms]
May 29 17:19:23.783: INFO: Created: latency-svc-jfnjf
May 29 17:19:23.794: INFO: Got endpoints: latency-svc-jfnjf [302.743407ms]
May 29 17:19:23.799: INFO: Created: latency-svc-86cxp
May 29 17:19:23.806: INFO: Created: latency-svc-jrh28
May 29 17:19:23.814: INFO: Got endpoints: latency-svc-86cxp [260.062019ms]
May 29 17:19:23.822: INFO: Got endpoints: latency-svc-jrh28 [259.72253ms]
May 29 17:19:23.822: INFO: Created: latency-svc-fb89t
May 29 17:19:23.829: INFO: Got endpoints: latency-svc-fb89t [228.306288ms]
May 29 17:19:23.836: INFO: Created: latency-svc-dgpc9
May 29 17:19:23.845: INFO: Created: latency-svc-5whqn
May 29 17:19:23.849: INFO: Got endpoints: latency-svc-dgpc9 [243.14298ms]
May 29 17:19:23.852: INFO: Got endpoints: latency-svc-5whqn [212.422272ms]
May 29 17:19:23.859: INFO: Created: latency-svc-n768w
May 29 17:19:23.870: INFO: Created: latency-svc-kwzxj
May 29 17:19:23.874: INFO: Got endpoints: latency-svc-n768w [228.397315ms]
May 29 17:19:23.883: INFO: Created: latency-svc-28hg8
May 29 17:19:23.887: INFO: Got endpoints: latency-svc-kwzxj [215.685541ms]
May 29 17:19:23.891: INFO: Got endpoints: latency-svc-28hg8 [213.044801ms]
May 29 17:19:23.903: INFO: Created: latency-svc-ssjzh
May 29 17:19:23.908: INFO: Created: latency-svc-ncx7w
May 29 17:19:23.914: INFO: Got endpoints: latency-svc-ssjzh [211.438901ms]
May 29 17:19:23.922: INFO: Created: latency-svc-k7n69
May 29 17:19:23.924: INFO: Got endpoints: latency-svc-ncx7w [203.272368ms]
May 29 17:19:23.931: INFO: Created: latency-svc-prz2j
May 29 17:19:23.940: INFO: Got endpoints: latency-svc-prz2j [190.426248ms]
May 29 17:19:23.940: INFO: Got endpoints: latency-svc-k7n69 [198.989932ms]
May 29 17:19:23.943: INFO: Created: latency-svc-8skck
May 29 17:19:23.952: INFO: Got endpoints: latency-svc-8skck [186.300477ms]
May 29 17:19:23.956: INFO: Created: latency-svc-7n889
May 29 17:19:23.971: INFO: Created: latency-svc-tv97n
May 29 17:19:23.981: INFO: Got endpoints: latency-svc-7n889 [202.354456ms]
May 29 17:19:23.981: INFO: Created: latency-svc-vkq7n
May 29 17:19:23.986: INFO: Got endpoints: latency-svc-tv97n [191.606292ms]
May 29 17:19:23.991: INFO: Created: latency-svc-nncb9
May 29 17:19:23.996: INFO: Got endpoints: latency-svc-vkq7n [182.294678ms]
May 29 17:19:24.006: INFO: Created: latency-svc-8n62v
May 29 17:19:24.009: INFO: Got endpoints: latency-svc-nncb9 [187.337464ms]
May 29 17:19:24.019: INFO: Got endpoints: latency-svc-8n62v [189.376491ms]
May 29 17:19:24.021: INFO: Created: latency-svc-gzk8g
May 29 17:19:24.034: INFO: Created: latency-svc-n9ngl
May 29 17:19:24.039: INFO: Got endpoints: latency-svc-gzk8g [189.870276ms]
May 29 17:19:24.044: INFO: Created: latency-svc-zhgzc
May 29 17:19:24.047: INFO: Got endpoints: latency-svc-n9ngl [195.118304ms]
May 29 17:19:24.057: INFO: Got endpoints: latency-svc-zhgzc [183.213262ms]
May 29 17:19:24.066: INFO: Created: latency-svc-r4t7x
May 29 17:19:24.072: INFO: Got endpoints: latency-svc-r4t7x [185.085208ms]
May 29 17:19:24.078: INFO: Created: latency-svc-tw95d
May 29 17:19:24.086: INFO: Created: latency-svc-4sbm2
May 29 17:19:24.091: INFO: Got endpoints: latency-svc-tw95d [199.860612ms]
May 29 17:19:24.096: INFO: Got endpoints: latency-svc-4sbm2 [182.124759ms]
May 29 17:19:24.110: INFO: Created: latency-svc-vrbvn
May 29 17:19:24.121: INFO: Created: latency-svc-4x74x
May 29 17:19:24.126: INFO: Got endpoints: latency-svc-vrbvn [201.751373ms]
May 29 17:19:24.131: INFO: Created: latency-svc-cvhqg
May 29 17:19:24.138: INFO: Created: latency-svc-699f4
May 29 17:19:24.153: INFO: Created: latency-svc-lmbpd
May 29 17:19:24.164: INFO: Got endpoints: latency-svc-4x74x [224.364011ms]
May 29 17:19:24.186: INFO: Created: latency-svc-dnnk5
May 29 17:19:24.207: INFO: Created: latency-svc-xmwgh
May 29 17:19:24.215: INFO: Got endpoints: latency-svc-cvhqg [274.591651ms]
May 29 17:19:24.215: INFO: Created: latency-svc-fcbd6
May 29 17:19:24.228: INFO: Created: latency-svc-65dz7
May 29 17:19:24.228: INFO: Created: latency-svc-fm8ng
May 29 17:19:24.238: INFO: Created: latency-svc-gbnsh
May 29 17:19:24.244: INFO: Created: latency-svc-6gh7q
May 29 17:19:24.253: INFO: Got endpoints: latency-svc-699f4 [300.901847ms]
May 29 17:19:24.260: INFO: Created: latency-svc-qjlwd
May 29 17:19:24.267: INFO: Created: latency-svc-94nsz
May 29 17:19:24.274: INFO: Created: latency-svc-bvds5
May 29 17:19:24.280: INFO: Created: latency-svc-cp95v
May 29 17:19:24.289: INFO: Created: latency-svc-74z5f
May 29 17:19:24.297: INFO: Created: latency-svc-7c7db
May 29 17:19:24.306: INFO: Created: latency-svc-gqc45
May 29 17:19:24.308: INFO: Got endpoints: latency-svc-lmbpd [327.197052ms]
May 29 17:19:24.350: INFO: Got endpoints: latency-svc-dnnk5 [364.16281ms]
May 29 17:19:24.360: INFO: Created: latency-svc-csxsf
May 29 17:19:24.402: INFO: Created: latency-svc-bpxws
May 29 17:19:24.404: INFO: Got endpoints: latency-svc-xmwgh [407.890284ms]
May 29 17:19:24.456: INFO: Got endpoints: latency-svc-fcbd6 [447.059791ms]
May 29 17:19:24.459: INFO: Created: latency-svc-t62rj
May 29 17:19:24.502: INFO: Got endpoints: latency-svc-fm8ng [482.929698ms]
May 29 17:19:24.511: INFO: Created: latency-svc-hp89v
May 29 17:19:24.552: INFO: Got endpoints: latency-svc-65dz7 [513.386599ms]
May 29 17:19:24.557: INFO: Created: latency-svc-m7mlf
May 29 17:19:24.604: INFO: Got endpoints: latency-svc-gbnsh [556.909834ms]
May 29 17:19:24.613: INFO: Created: latency-svc-8s6lv
May 29 17:19:24.668: INFO: Got endpoints: latency-svc-6gh7q [610.37454ms]
May 29 17:19:24.679: INFO: Created: latency-svc-26brd
May 29 17:19:24.701: INFO: Got endpoints: latency-svc-qjlwd [629.296502ms]
May 29 17:19:24.717: INFO: Created: latency-svc-p67nb
May 29 17:19:24.750: INFO: Got endpoints: latency-svc-94nsz [659.288275ms]
May 29 17:19:24.756: INFO: Created: latency-svc-m66gb
May 29 17:19:24.799: INFO: Got endpoints: latency-svc-bvds5 [702.391351ms]
May 29 17:19:24.803: INFO: Created: latency-svc-9tlcb
May 29 17:19:24.852: INFO: Created: latency-svc-rdvlz
May 29 17:19:24.854: INFO: Got endpoints: latency-svc-cp95v [727.708176ms]
May 29 17:19:24.900: INFO: Got endpoints: latency-svc-74z5f [735.316857ms]
May 29 17:19:24.910: INFO: Created: latency-svc-5ck4t
May 29 17:19:24.951: INFO: Created: latency-svc-9sqls
May 29 17:19:24.953: INFO: Got endpoints: latency-svc-7c7db [738.187379ms]
May 29 17:19:25.004: INFO: Got endpoints: latency-svc-gqc45 [750.869599ms]
May 29 17:19:25.008: INFO: Created: latency-svc-fg4ml
May 29 17:19:25.053: INFO: Created: latency-svc-xkgvs
May 29 17:19:25.056: INFO: Got endpoints: latency-svc-csxsf [748.054277ms]
May 29 17:19:25.102: INFO: Got endpoints: latency-svc-bpxws [751.311993ms]
May 29 17:19:25.111: INFO: Created: latency-svc-2wc9k
May 29 17:19:25.152: INFO: Got endpoints: latency-svc-t62rj [748.48646ms]
May 29 17:19:25.157: INFO: Created: latency-svc-thvmc
May 29 17:19:25.200: INFO: Created: latency-svc-hqcwt
May 29 17:19:25.206: INFO: Got endpoints: latency-svc-hp89v [749.925601ms]
May 29 17:19:25.249: INFO: Got endpoints: latency-svc-m7mlf [747.341138ms]
May 29 17:19:25.261: INFO: Created: latency-svc-pfx8z
May 29 17:19:25.301: INFO: Created: latency-svc-z9f59
May 29 17:19:25.304: INFO: Got endpoints: latency-svc-8s6lv [751.721856ms]
May 29 17:19:25.354: INFO: Got endpoints: latency-svc-26brd [750.198312ms]
May 29 17:19:25.358: INFO: Created: latency-svc-jx9sm
May 29 17:19:25.404: INFO: Got endpoints: latency-svc-p67nb [735.952102ms]
May 29 17:19:25.408: INFO: Created: latency-svc-szzn9
May 29 17:19:25.462: INFO: Got endpoints: latency-svc-m66gb [760.727868ms]
May 29 17:19:25.469: INFO: Created: latency-svc-tpdlc
May 29 17:19:25.498: INFO: Got endpoints: latency-svc-9tlcb [747.528398ms]
May 29 17:19:25.513: INFO: Created: latency-svc-85gms
May 29 17:19:25.547: INFO: Created: latency-svc-wtmqc
May 29 17:19:25.554: INFO: Got endpoints: latency-svc-rdvlz [755.196496ms]
May 29 17:19:25.603: INFO: Got endpoints: latency-svc-5ck4t [749.582539ms]
May 29 17:19:25.607: INFO: Created: latency-svc-jc2zq
May 29 17:19:25.653: INFO: Got endpoints: latency-svc-9sqls [753.522793ms]
May 29 17:19:25.657: INFO: Created: latency-svc-cknmd
May 29 17:19:25.706: INFO: Got endpoints: latency-svc-fg4ml [752.690975ms]
May 29 17:19:25.710: INFO: Created: latency-svc-s5jxw
May 29 17:19:25.750: INFO: Got endpoints: latency-svc-xkgvs [746.077788ms]
May 29 17:19:25.762: INFO: Created: latency-svc-qv822
May 29 17:19:25.800: INFO: Created: latency-svc-hxrhb
May 29 17:19:25.802: INFO: Got endpoints: latency-svc-2wc9k [745.831254ms]
May 29 17:19:25.850: INFO: Got endpoints: latency-svc-thvmc [748.339475ms]
May 29 17:19:25.855: INFO: Created: latency-svc-cjpqp
May 29 17:19:25.902: INFO: Created: latency-svc-gvtkc
May 29 17:19:25.904: INFO: Got endpoints: latency-svc-hqcwt [751.773966ms]
May 29 17:19:25.956: INFO: Got endpoints: latency-svc-pfx8z [749.590317ms]
May 29 17:19:25.959: INFO: Created: latency-svc-cl748
May 29 17:19:26.001: INFO: Got endpoints: latency-svc-z9f59 [751.278152ms]
May 29 17:19:26.011: INFO: Created: latency-svc-kqlgx
May 29 17:19:26.051: INFO: Got endpoints: latency-svc-jx9sm [747.142756ms]
May 29 17:19:26.055: INFO: Created: latency-svc-qxxb2
May 29 17:19:26.099: INFO: Created: latency-svc-wtddj
May 29 17:19:26.101: INFO: Got endpoints: latency-svc-szzn9 [747.152709ms]
May 29 17:19:26.159: INFO: Created: latency-svc-dn5vz
May 29 17:19:26.159: INFO: Got endpoints: latency-svc-tpdlc [755.869117ms]
May 29 17:19:26.202: INFO: Got endpoints: latency-svc-85gms [739.894846ms]
May 29 17:19:26.232: INFO: Created: latency-svc-kjd79
May 29 17:19:26.256: INFO: Got endpoints: latency-svc-wtmqc [758.161275ms]
May 29 17:19:26.259: INFO: Created: latency-svc-7v469
May 29 17:19:26.300: INFO: Got endpoints: latency-svc-jc2zq [745.884368ms]
May 29 17:19:26.314: INFO: Created: latency-svc-xd6dg
May 29 17:19:26.348: INFO: Created: latency-svc-9hlm9
May 29 17:19:26.351: INFO: Got endpoints: latency-svc-cknmd [747.95902ms]
May 29 17:19:26.400: INFO: Created: latency-svc-w25b8
May 29 17:19:26.402: INFO: Got endpoints: latency-svc-s5jxw [748.385348ms]
May 29 17:19:26.451: INFO: Created: latency-svc-b98ld
May 29 17:19:26.463: INFO: Got endpoints: latency-svc-qv822 [757.634728ms]
May 29 17:19:26.499: INFO: Got endpoints: latency-svc-hxrhb [748.947327ms]
May 29 17:19:26.513: INFO: Created: latency-svc-h4scc
May 29 17:19:26.552: INFO: Created: latency-svc-7h4zz
May 29 17:19:26.552: INFO: Got endpoints: latency-svc-cjpqp [750.461187ms]
May 29 17:19:26.604: INFO: Got endpoints: latency-svc-gvtkc [753.939456ms]
May 29 17:19:26.605: INFO: Created: latency-svc-fcnpr
May 29 17:19:26.650: INFO: Got endpoints: latency-svc-cl748 [745.398379ms]
May 29 17:19:26.661: INFO: Created: latency-svc-vvpk9
May 29 17:19:26.702: INFO: Created: latency-svc-kbhq8
May 29 17:19:26.707: INFO: Got endpoints: latency-svc-kqlgx [751.471062ms]
May 29 17:19:26.753: INFO: Got endpoints: latency-svc-qxxb2 [752.606168ms]
May 29 17:19:26.759: INFO: Created: latency-svc-p7vrb
May 29 17:19:26.803: INFO: Got endpoints: latency-svc-wtddj [751.572951ms]
May 29 17:19:26.809: INFO: Created: latency-svc-tndmp
May 29 17:19:26.852: INFO: Got endpoints: latency-svc-dn5vz [750.756984ms]
May 29 17:19:26.856: INFO: Created: latency-svc-6rbw4
May 29 17:19:26.907: INFO: Created: latency-svc-2mbnx
May 29 17:19:26.912: INFO: Got endpoints: latency-svc-kjd79 [752.426272ms]
May 29 17:19:26.949: INFO: Got endpoints: latency-svc-7v469 [747.045832ms]
May 29 17:19:26.963: INFO: Created: latency-svc-rcnfn
May 29 17:19:27.002: INFO: Created: latency-svc-9fdkw
May 29 17:19:27.007: INFO: Got endpoints: latency-svc-xd6dg [750.664951ms]
May 29 17:19:27.051: INFO: Got endpoints: latency-svc-9hlm9 [750.922769ms]
May 29 17:19:27.062: INFO: Created: latency-svc-5zxfj
May 29 17:19:27.105: INFO: Created: latency-svc-hwfpq
May 29 17:19:27.128: INFO: Got endpoints: latency-svc-w25b8 [776.716853ms]
May 29 17:19:27.149: INFO: Got endpoints: latency-svc-b98ld [746.944788ms]
May 29 17:19:27.178: INFO: Created: latency-svc-rmwjm
May 29 17:19:27.201: INFO: Created: latency-svc-6x22c
May 29 17:19:27.204: INFO: Got endpoints: latency-svc-h4scc [740.139564ms]
May 29 17:19:27.253: INFO: Got endpoints: latency-svc-7h4zz [753.867145ms]
May 29 17:19:27.257: INFO: Created: latency-svc-b6h6m
May 29 17:19:27.304: INFO: Got endpoints: latency-svc-fcnpr [751.896089ms]
May 29 17:19:27.310: INFO: Created: latency-svc-pxtg8
May 29 17:19:27.354: INFO: Got endpoints: latency-svc-vvpk9 [749.842905ms]
May 29 17:19:27.359: INFO: Created: latency-svc-l92hv
May 29 17:19:27.404: INFO: Got endpoints: latency-svc-kbhq8 [754.72496ms]
May 29 17:19:27.410: INFO: Created: latency-svc-xn699
May 29 17:19:27.450: INFO: Got endpoints: latency-svc-p7vrb [742.988831ms]
May 29 17:19:27.460: INFO: Created: latency-svc-77phm
May 29 17:19:27.500: INFO: Got endpoints: latency-svc-tndmp [746.780824ms]
May 29 17:19:27.503: INFO: Created: latency-svc-dz8mc
May 29 17:19:27.549: INFO: Created: latency-svc-tjnt5
May 29 17:19:27.554: INFO: Got endpoints: latency-svc-6rbw4 [751.257754ms]
May 29 17:19:27.605: INFO: Got endpoints: latency-svc-2mbnx [753.264624ms]
May 29 17:19:27.609: INFO: Created: latency-svc-mrzgm
May 29 17:19:27.652: INFO: Got endpoints: latency-svc-rcnfn [739.699817ms]
May 29 17:19:27.662: INFO: Created: latency-svc-kxlfw
May 29 17:19:27.700: INFO: Got endpoints: latency-svc-9fdkw [751.2024ms]
May 29 17:19:27.705: INFO: Created: latency-svc-zwdtq
May 29 17:19:27.752: INFO: Created: latency-svc-tl8hg
May 29 17:19:27.754: INFO: Got endpoints: latency-svc-5zxfj [747.648008ms]
May 29 17:19:27.813: INFO: Got endpoints: latency-svc-hwfpq [761.835251ms]
May 29 17:19:27.816: INFO: Created: latency-svc-j6bjr
May 29 17:19:27.850: INFO: Got endpoints: latency-svc-rmwjm [721.612228ms]
May 29 17:19:27.865: INFO: Created: latency-svc-fndtb
May 29 17:19:27.901: INFO: Created: latency-svc-nbkzz
May 29 17:19:27.904: INFO: Got endpoints: latency-svc-6x22c [754.852947ms]
May 29 17:19:27.952: INFO: Got endpoints: latency-svc-b6h6m [748.119799ms]
May 29 17:19:27.966: INFO: Created: latency-svc-h9g9b
May 29 17:19:28.001: INFO: Got endpoints: latency-svc-pxtg8 [748.100786ms]
May 29 17:19:28.005: INFO: Created: latency-svc-j4wmb
May 29 17:19:28.051: INFO: Created: latency-svc-qh9mt
May 29 17:19:28.055: INFO: Got endpoints: latency-svc-l92hv [750.865616ms]
May 29 17:19:28.101: INFO: Got endpoints: latency-svc-xn699 [747.209905ms]
May 29 17:19:28.114: INFO: Created: latency-svc-nfglt
May 29 17:19:28.165: INFO: Created: latency-svc-pnc6l
May 29 17:19:28.172: INFO: Got endpoints: latency-svc-77phm [767.269182ms]
May 29 17:19:28.199: INFO: Got endpoints: latency-svc-dz8mc [748.262492ms]
May 29 17:19:28.222: INFO: Created: latency-svc-rndm7
May 29 17:19:28.252: INFO: Created: latency-svc-dcwgv
May 29 17:19:28.253: INFO: Got endpoints: latency-svc-tjnt5 [752.84239ms]
May 29 17:19:28.303: INFO: Got endpoints: latency-svc-mrzgm [748.809626ms]
May 29 17:19:28.308: INFO: Created: latency-svc-vxrtf
May 29 17:19:28.352: INFO: Got endpoints: latency-svc-kxlfw [746.499362ms]
May 29 17:19:28.357: INFO: Created: latency-svc-7r5t4
May 29 17:19:28.402: INFO: Got endpoints: latency-svc-zwdtq [750.505733ms]
May 29 17:19:28.410: INFO: Created: latency-svc-svzs8
May 29 17:19:28.454: INFO: Got endpoints: latency-svc-tl8hg [753.379185ms]
May 29 17:19:28.459: INFO: Created: latency-svc-c257j
May 29 17:19:28.510: INFO: Got endpoints: latency-svc-j6bjr [755.852332ms]
May 29 17:19:28.520: INFO: Created: latency-svc-thf29
May 29 17:19:28.549: INFO: Got endpoints: latency-svc-fndtb [735.550717ms]
May 29 17:19:28.562: INFO: Created: latency-svc-j6gfj
May 29 17:19:28.601: INFO: Created: latency-svc-bj2xj
May 29 17:19:28.604: INFO: Got endpoints: latency-svc-nbkzz [754.003431ms]
May 29 17:19:28.664: INFO: Got endpoints: latency-svc-h9g9b [760.673763ms]
May 29 17:19:28.672: INFO: Created: latency-svc-8d7c4
May 29 17:19:28.715: INFO: Got endpoints: latency-svc-j4wmb [763.65665ms]
May 29 17:19:28.722: INFO: Created: latency-svc-qsp9d
May 29 17:19:28.751: INFO: Got endpoints: latency-svc-qh9mt [750.12902ms]
May 29 17:19:28.766: INFO: Created: latency-svc-ml2x5
May 29 17:19:28.803: INFO: Created: latency-svc-jdgcd
May 29 17:19:28.805: INFO: Got endpoints: latency-svc-nfglt [749.595186ms]
May 29 17:19:28.851: INFO: Got endpoints: latency-svc-pnc6l [749.509888ms]
May 29 17:19:28.858: INFO: Created: latency-svc-vsqqx
May 29 17:19:28.901: INFO: Got endpoints: latency-svc-rndm7 [729.337656ms]
May 29 17:19:28.904: INFO: Created: latency-svc-pkx9d
May 29 17:19:28.952: INFO: Created: latency-svc-49vcc
May 29 17:19:28.955: INFO: Got endpoints: latency-svc-dcwgv [756.129903ms]
May 29 17:19:29.004: INFO: Got endpoints: latency-svc-vxrtf [750.723951ms]
May 29 17:19:29.008: INFO: Created: latency-svc-7tgdt
May 29 17:19:29.050: INFO: Got endpoints: latency-svc-7r5t4 [747.395898ms]
May 29 17:19:29.064: INFO: Created: latency-svc-fx8bf
May 29 17:19:29.102: INFO: Created: latency-svc-bv6p7
May 29 17:19:29.104: INFO: Got endpoints: latency-svc-svzs8 [751.960289ms]
May 29 17:19:29.159: INFO: Got endpoints: latency-svc-c257j [756.872963ms]
May 29 17:19:29.159: INFO: Created: latency-svc-qwlnq
May 29 17:19:29.208: INFO: Got endpoints: latency-svc-thf29 [754.042886ms]
May 29 17:19:29.221: INFO: Created: latency-svc-p2vnt
May 29 17:19:29.257: INFO: Got endpoints: latency-svc-j6gfj [747.086762ms]
May 29 17:19:29.275: INFO: Created: latency-svc-nwsfk
May 29 17:19:29.300: INFO: Got endpoints: latency-svc-bj2xj [751.449884ms]
May 29 17:19:29.312: INFO: Created: latency-svc-9r285
May 29 17:19:29.351: INFO: Created: latency-svc-8g8fw
May 29 17:19:29.353: INFO: Got endpoints: latency-svc-8d7c4 [749.211639ms]
May 29 17:19:29.404: INFO: Got endpoints: latency-svc-qsp9d [739.600359ms]
May 29 17:19:29.409: INFO: Created: latency-svc-fx5lz
May 29 17:19:29.456: INFO: Got endpoints: latency-svc-ml2x5 [740.823051ms]
May 29 17:19:29.460: INFO: Created: latency-svc-h7cdn
May 29 17:19:29.513: INFO: Got endpoints: latency-svc-jdgcd [761.801712ms]
May 29 17:19:29.525: INFO: Created: latency-svc-jz6zs
May 29 17:19:29.550: INFO: Got endpoints: latency-svc-vsqqx [744.747866ms]
May 29 17:19:29.562: INFO: Created: latency-svc-9ndmv
May 29 17:19:29.600: INFO: Created: latency-svc-b8rqs
May 29 17:19:29.602: INFO: Got endpoints: latency-svc-pkx9d [751.364511ms]
May 29 17:19:29.653: INFO: Got endpoints: latency-svc-49vcc [751.481842ms]
May 29 17:19:29.661: INFO: Created: latency-svc-fgfc5
May 29 17:19:29.706: INFO: Got endpoints: latency-svc-7tgdt [751.296862ms]
May 29 17:19:29.716: INFO: Created: latency-svc-7rzkv
May 29 17:19:29.752: INFO: Got endpoints: latency-svc-fx8bf [748.671363ms]
May 29 17:19:29.768: INFO: Created: latency-svc-gvz2j
May 29 17:19:29.802: INFO: Got endpoints: latency-svc-bv6p7 [751.898324ms]
May 29 17:19:29.804: INFO: Created: latency-svc-t2gcc
May 29 17:19:29.864: INFO: Got endpoints: latency-svc-qwlnq [760.070205ms]
May 29 17:19:29.888: INFO: Created: latency-svc-v4xh6
May 29 17:19:29.902: INFO: Got endpoints: latency-svc-p2vnt [743.200428ms]
May 29 17:19:29.915: INFO: Created: latency-svc-rsq4f
May 29 17:19:29.950: INFO: Created: latency-svc-2pvxt
May 29 17:19:29.954: INFO: Got endpoints: latency-svc-nwsfk [746.218476ms]
May 29 17:19:30.002: INFO: Got endpoints: latency-svc-9r285 [744.175774ms]
May 29 17:19:30.010: INFO: Created: latency-svc-gjww8
May 29 17:19:30.059: INFO: Got endpoints: latency-svc-8g8fw [758.54029ms]
May 29 17:19:30.065: INFO: Created: latency-svc-ct4s8
May 29 17:19:30.100: INFO: Got endpoints: latency-svc-fx5lz [746.708238ms]
May 29 17:19:30.113: INFO: Created: latency-svc-xmgkf
May 29 17:19:30.171: INFO: Created: latency-svc-2w2h9
May 29 17:19:30.176: INFO: Got endpoints: latency-svc-h7cdn [771.951697ms]
May 29 17:19:30.200: INFO: Got endpoints: latency-svc-jz6zs [743.741757ms]
May 29 17:19:30.228: INFO: Created: latency-svc-dqslv
May 29 17:19:30.250: INFO: Created: latency-svc-27khn
May 29 17:19:30.254: INFO: Got endpoints: latency-svc-9ndmv [740.991406ms]
May 29 17:19:30.304: INFO: Got endpoints: latency-svc-b8rqs [754.631914ms]
May 29 17:19:30.311: INFO: Created: latency-svc-7txbj
May 29 17:19:30.352: INFO: Created: latency-svc-v9qqh
May 29 17:19:30.356: INFO: Got endpoints: latency-svc-fgfc5 [753.772232ms]
May 29 17:19:30.401: INFO: Got endpoints: latency-svc-7rzkv [747.946011ms]
May 29 17:19:30.410: INFO: Created: latency-svc-2f2fk
May 29 17:19:30.459: INFO: Created: latency-svc-lfbdk
May 29 17:19:30.459: INFO: Got endpoints: latency-svc-gvz2j [753.178497ms]
May 29 17:19:30.499: INFO: Got endpoints: latency-svc-t2gcc [746.239135ms]
May 29 17:19:30.511: INFO: Created: latency-svc-h748z
May 29 17:19:30.554: INFO: Created: latency-svc-4s748
May 29 17:19:30.557: INFO: Got endpoints: latency-svc-v4xh6 [754.68346ms]
May 29 17:19:30.597: INFO: Got endpoints: latency-svc-rsq4f [733.204442ms]
May 29 17:19:30.613: INFO: Created: latency-svc-v8w6n
May 29 17:19:30.648: INFO: Created: latency-svc-98rw4
May 29 17:19:30.652: INFO: Got endpoints: latency-svc-2pvxt [749.874721ms]
May 29 17:19:30.705: INFO: Got endpoints: latency-svc-gjww8 [750.565889ms]
May 29 17:19:30.709: INFO: Created: latency-svc-nfl9c
May 29 17:19:30.754: INFO: Got endpoints: latency-svc-ct4s8 [752.648992ms]
May 29 17:19:30.764: INFO: Created: latency-svc-phfjd
May 29 17:19:30.801: INFO: Got endpoints: latency-svc-xmgkf [742.044024ms]
May 29 17:19:30.808: INFO: Created: latency-svc-2vz8h
May 29 17:19:30.851: INFO: Got endpoints: latency-svc-2w2h9 [750.937569ms]
May 29 17:19:30.855: INFO: Created: latency-svc-wcmns
May 29 17:19:30.901: INFO: Created: latency-svc-75tt5
May 29 17:19:30.904: INFO: Got endpoints: latency-svc-dqslv [728.069236ms]
May 29 17:19:30.951: INFO: Got endpoints: latency-svc-27khn [751.06987ms]
May 29 17:19:30.960: INFO: Created: latency-svc-cgrb2
May 29 17:19:31.000: INFO: Created: latency-svc-kk8zp
May 29 17:19:31.004: INFO: Got endpoints: latency-svc-7txbj [749.518006ms]
May 29 17:19:31.052: INFO: Got endpoints: latency-svc-v9qqh [747.552026ms]
May 29 17:19:31.059: INFO: Created: latency-svc-2dqtt
May 29 17:19:31.103: INFO: Got endpoints: latency-svc-2f2fk [747.025456ms]
May 29 17:19:31.107: INFO: Created: latency-svc-8jl58
May 29 17:19:31.155: INFO: Got endpoints: latency-svc-lfbdk [754.300348ms]
May 29 17:19:31.159: INFO: Created: latency-svc-fmw8t
May 29 17:19:31.206: INFO: Got endpoints: latency-svc-h748z [746.922214ms]
May 29 17:19:31.210: INFO: Created: latency-svc-dddsm
May 29 17:19:31.253: INFO: Got endpoints: latency-svc-4s748 [753.938949ms]
May 29 17:19:31.259: INFO: Created: latency-svc-qgdvr
May 29 17:19:31.306: INFO: Got endpoints: latency-svc-v8w6n [748.73502ms]
May 29 17:19:31.310: INFO: Created: latency-svc-98n5b
May 29 17:19:31.351: INFO: Got endpoints: latency-svc-98rw4 [753.580882ms]
May 29 17:19:31.363: INFO: Created: latency-svc-k7wwx
May 29 17:19:31.399: INFO: Got endpoints: latency-svc-nfl9c [747.048269ms]
May 29 17:19:31.449: INFO: Got endpoints: latency-svc-phfjd [744.594877ms]
May 29 17:19:31.499: INFO: Got endpoints: latency-svc-2vz8h [744.378151ms]
May 29 17:19:31.555: INFO: Got endpoints: latency-svc-wcmns [753.712976ms]
May 29 17:19:31.599: INFO: Got endpoints: latency-svc-75tt5 [748.201095ms]
May 29 17:19:31.649: INFO: Got endpoints: latency-svc-cgrb2 [744.612546ms]
May 29 17:19:31.700: INFO: Got endpoints: latency-svc-kk8zp [748.979546ms]
May 29 17:19:31.749: INFO: Got endpoints: latency-svc-2dqtt [745.102084ms]
May 29 17:19:31.798: INFO: Got endpoints: latency-svc-8jl58 [746.213521ms]
May 29 17:19:31.849: INFO: Got endpoints: latency-svc-fmw8t [746.429598ms]
May 29 17:19:31.899: INFO: Got endpoints: latency-svc-dddsm [744.098693ms]
May 29 17:19:31.949: INFO: Got endpoints: latency-svc-qgdvr [742.294257ms]
May 29 17:19:31.999: INFO: Got endpoints: latency-svc-98n5b [745.85787ms]
May 29 17:19:32.050: INFO: Got endpoints: latency-svc-k7wwx [743.768256ms]
May 29 17:19:32.050: INFO: Latencies: [62.15105ms 70.499895ms 86.271034ms 109.458402ms 113.964702ms 125.20759ms 147.863148ms 153.811011ms 179.585271ms 182.124759ms 182.294678ms 183.213262ms 185.085208ms 186.300477ms 186.42217ms 187.337464ms 189.376491ms 189.870276ms 190.426248ms 191.606292ms 195.118304ms 198.989932ms 199.860612ms 201.751373ms 202.354456ms 203.272368ms 211.438901ms 212.422272ms 213.044801ms 215.685541ms 224.364011ms 228.306288ms 228.397315ms 229.38793ms 243.14298ms 249.547548ms 258.055427ms 259.72253ms 260.062019ms 274.263546ms 274.591651ms 286.689719ms 300.901847ms 302.743407ms 327.197052ms 364.16281ms 407.890284ms 447.059791ms 482.929698ms 513.386599ms 556.909834ms 610.37454ms 629.296502ms 659.288275ms 702.391351ms 721.612228ms 727.708176ms 728.069236ms 729.337656ms 733.204442ms 735.316857ms 735.550717ms 735.952102ms 738.187379ms 739.600359ms 739.699817ms 739.894846ms 740.139564ms 740.823051ms 740.991406ms 742.044024ms 742.294257ms 742.988831ms 743.200428ms 743.741757ms 743.768256ms 744.098693ms 744.175774ms 744.378151ms 744.594877ms 744.612546ms 744.747866ms 745.102084ms 745.398379ms 745.831254ms 745.85787ms 745.884368ms 746.077788ms 746.213521ms 746.218476ms 746.239135ms 746.429598ms 746.499362ms 746.708238ms 746.780824ms 746.922214ms 746.944788ms 747.025456ms 747.045832ms 747.048269ms 747.086762ms 747.142756ms 747.152709ms 747.209905ms 747.341138ms 747.395898ms 747.528398ms 747.552026ms 747.648008ms 747.946011ms 747.95902ms 748.054277ms 748.100786ms 748.119799ms 748.201095ms 748.262492ms 748.339475ms 748.385348ms 748.48646ms 748.671363ms 748.73502ms 748.809626ms 748.947327ms 748.979546ms 749.211639ms 749.509888ms 749.518006ms 749.582539ms 749.590317ms 749.595186ms 749.842905ms 749.874721ms 749.925601ms 750.12902ms 750.198312ms 750.461187ms 750.505733ms 750.565889ms 750.664951ms 750.723951ms 750.756984ms 750.865616ms 750.869599ms 750.922769ms 750.937569ms 751.06987ms 751.2024ms 751.257754ms 751.278152ms 751.296862ms 751.311993ms 751.364511ms 751.449884ms 751.471062ms 751.481842ms 751.572951ms 751.721856ms 751.773966ms 751.896089ms 751.898324ms 751.960289ms 752.426272ms 752.606168ms 752.648992ms 752.690975ms 752.84239ms 753.178497ms 753.264624ms 753.379185ms 753.522793ms 753.580882ms 753.712976ms 753.772232ms 753.867145ms 753.938949ms 753.939456ms 754.003431ms 754.042886ms 754.300348ms 754.631914ms 754.68346ms 754.72496ms 754.852947ms 755.196496ms 755.852332ms 755.869117ms 756.129903ms 756.872963ms 757.634728ms 758.161275ms 758.54029ms 760.070205ms 760.673763ms 760.727868ms 761.801712ms 761.835251ms 763.65665ms 767.269182ms 771.951697ms 776.716853ms]
May 29 17:19:32.050: INFO: 50 %ile: 747.086762ms
May 29 17:19:32.050: INFO: 90 %ile: 754.68346ms
May 29 17:19:32.050: INFO: 99 %ile: 771.951697ms
May 29 17:19:32.050: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:32.050: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "svc-latency-1433" for this suite.
May 29 17:19:48.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:49.813: INFO: namespace svc-latency-1433 deletion completed in 17.720187771s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] CustomResourceDefinition resources[0m [90mSimple CustomResourceDefinition[0m 
  [1mcreating/deleting custom resource definition objects works  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:19:49.813: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename custom-resource-definition
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 17:19:50.056: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:50.414: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "custom-resource-definition-407" for this suite.
May 29 17:19:56.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:19:58.229: INFO: namespace custom-resource-definition-407 deletion completed in 7.773125547s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:19:58.230: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:19:58.231: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve multiport endpoints from pods  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:19:58.232: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should serve multiport endpoints from pods  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating service multi-endpoint-test in namespace services-9045
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-9045 to expose endpoints map[]
May 29 17:19:58.539: INFO: successfully validated that service multi-endpoint-test in namespace services-9045 exposes endpoints map[] (42.409103ms elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace services-9045
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-9045 to expose endpoints map[pod1:[100]]
May 29 17:20:03.011: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.421170434s elapsed, will retry)
May 29 17:20:05.178: INFO: successfully validated that service multi-endpoint-test in namespace services-9045 exposes endpoints map[pod1:[100]] (6.588337221s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace services-9045
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-9045 to expose endpoints map[pod1:[100] pod2:[101]]
May 29 17:20:09.857: INFO: Unexpected endpoints: found map[ac8a6e20-ea63-4ea2-a62a-a36a169bcf19:[100]], expected map[pod1:[100] pod2:[101]] (4.632316061s elapsed, will retry)
May 29 17:20:10.982: INFO: successfully validated that service multi-endpoint-test in namespace services-9045 exposes endpoints map[pod1:[100] pod2:[101]] (5.756851525s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace services-9045
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-9045 to expose endpoints map[pod2:[101]]
May 29 17:20:11.112: INFO: successfully validated that service multi-endpoint-test in namespace services-9045 exposes endpoints map[pod2:[101]] (84.155788ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace services-9045
[1mSTEP[0m: waiting up to 3m0s for service multi-endpoint-test in namespace services-9045 to expose endpoints map[]
May 29 17:20:11.200: INFO: successfully validated that service multi-endpoint-test in namespace services-9045 exposes endpoints map[] (41.303803ms elapsed)
[AfterEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:20:11.269: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "services-9045" for this suite.
May 29 17:20:49.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:20:51.039: INFO: namespace services-9045 deletion completed in 39.726915091s
[AfterEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable from pods in env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:20:51.040: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating secret with name secret-test-5cbf4d7e-f2c8-4eee-bdaf-fdf3bb41cdd4
[1mSTEP[0m: Creating a pod to test consume secrets
May 29 17:20:51.337: INFO: Waiting up to 5m0s for pod "pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f" in namespace "secrets-1696" to be "success or failure"
May 29 17:20:51.379: INFO: Pod "pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f": Phase="Pending", Reason="", readiness=false. Elapsed: 41.452984ms
May 29 17:20:53.420: INFO: Pod "pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082478997s
May 29 17:20:55.461: INFO: Pod "pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.123536557s
May 29 17:20:57.504: INFO: Pod "pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.166871371s
May 29 17:20:59.546: INFO: Pod "pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.208937088s
[1mSTEP[0m: Saw pod success
May 29 17:20:59.546: INFO: Pod "pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f" satisfied condition "success or failure"
May 29 17:20:59.589: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f container secret-env-test: <nil>
[1mSTEP[0m: delete the pod
May 29 17:20:59.695: INFO: Waiting for pod pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f to disappear
May 29 17:20:59.737: INFO: Pod pod-secrets-44d74f6f-24bb-4110-826c-87a757a03b3f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:20:59.737: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-1696" for this suite.
May 29 17:21:05.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:21:07.508: INFO: namespace secrets-1696 deletion completed in 7.726651819s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:21:07.508: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-map-284bd3b9-acaf-4ca3-9bc8-717abe97def5
[1mSTEP[0m: Creating a pod to test consume secrets
May 29 17:21:07.774: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb" in namespace "projected-3835" to be "success or failure"
May 29 17:21:07.816: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Pending", Reason="", readiness=false. Elapsed: 41.795325ms
May 29 17:21:09.857: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083338637s
May 29 17:21:11.899: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125224268s
May 29 17:21:13.941: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167077819s
May 29 17:21:15.984: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209824152s
May 29 17:21:18.028: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Running", Reason="", readiness=true. Elapsed: 10.253623176s
May 29 17:21:20.070: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Running", Reason="", readiness=true. Elapsed: 12.296034766s
May 29 17:21:22.119: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Running", Reason="", readiness=true. Elapsed: 14.345220505s
May 29 17:21:24.161: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.386919876s
[1mSTEP[0m: Saw pod success
May 29 17:21:24.161: INFO: Pod "pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb" satisfied condition "success or failure"
May 29 17:21:24.203: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 17:21:24.306: INFO: Waiting for pod pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb to disappear
May 29 17:21:24.347: INFO: Pod pod-projected-secrets-72c7df68-3f4b-430e-99ec-a26deef242fb no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:21:24.347: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-3835" for this suite.
May 29 17:21:30.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:21:32.122: INFO: namespace projected-3835 deletion completed in 7.725651298s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:21:32.123: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:21:32.125: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.003 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:21:32.127: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:21:32.129: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.003 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run --rm job[0m 
  [1mshould create a job from an image, then delete the job  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:21:32.131: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create a job from an image, then delete the job  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: executing a command with run --rm and attach with stdin
May 29 17:21:32.334: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config --namespace=kubectl-6774 run e2e-test-rm-busybox-job --image=e2eteam/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 29 17:21:42.398: INFO: stderr: "If you don't see a command prompt, try pressing enter.\n"
May 29 17:21:42.399: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
[1mSTEP[0m: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:21:44.481: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-6774" for this suite.
May 29 17:21:50.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:21:52.249: INFO: namespace kubectl-6774 deletion completed in 7.725187576s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:21:52.249: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:21:52.251: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:21:52.252: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating secret with name s-test-opt-del-e4eb0218-8bd9-45ed-a520-89e0b412f50b
[1mSTEP[0m: Creating secret with name s-test-opt-upd-7383b43f-e8bb-46fc-ae95-8a826af7bb78
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-e4eb0218-8bd9-45ed-a520-89e0b412f50b
[1mSTEP[0m: Updating secret s-test-opt-upd-7383b43f-e8bb-46fc-ae95-8a826af7bb78
[1mSTEP[0m: Creating secret with name s-test-opt-create-e036451e-2ba4-4d5f-b899-05d37c9abf69
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:23:23.111: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-2494" for this suite.
May 29 17:24:29.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:24:30.877: INFO: namespace projected-2494 deletion completed in 1m7.724336445s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:24:30.878: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:24:30.879: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:24:30.879: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:24:30.880: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:24:30.881: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:24:30.881: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl describe[0m 
  [1mshould check if kubectl describe prints relevant information for rc and pods  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:24:30.882: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 17:24:31.084: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config version --client'
May 29 17:24:31.163: INFO: stderr: ""
May 29 17:24:31.163: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 29 17:24:31.204: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-9754'
May 29 17:24:33.639: INFO: stderr: ""
May 29 17:24:33.639: INFO: stdout: "replicationcontroller/redis-master created\n"
May 29 17:24:33.639: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-9754'
May 29 17:24:34.069: INFO: stderr: ""
May 29 17:24:34.069: INFO: stdout: "service/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
May 29 17:24:35.112: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:24:35.112: INFO: Found 0 / 1
May 29 17:24:36.111: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:24:36.112: INFO: Found 0 / 1
May 29 17:24:37.111: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:24:37.111: INFO: Found 0 / 1
May 29 17:24:38.111: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:24:38.111: INFO: Found 0 / 1
May 29 17:24:39.112: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:24:39.112: INFO: Found 0 / 1
May 29 17:24:40.112: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:24:40.112: INFO: Found 0 / 1
May 29 17:24:41.112: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:24:41.112: INFO: Found 1 / 1
May 29 17:24:41.112: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 29 17:24:41.154: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:24:41.154: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 17:24:41.154: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe pod redis-master-ndgtz --namespace=kubectl-9754'
May 29 17:24:41.511: INFO: stderr: ""
May 29 17:24:41.511: INFO: stdout: "Name:               redis-master-ndgtz\nNamespace:          kubectl-9754\nPriority:           0\nPriorityClassName:  <none>\nNode:               e2e-test-peterhornyack-windows-node-group-1vjk/10.40.0.5\nStart Time:         Wed, 29 May 2019 17:24:33 -0700\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.64.2.16\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://3752f4270a60e7fb22c6587f2d60d3499614085024b293dd9eb72f65f98db336\n    Image:          e2eteam/redis:1.0\n    Image ID:       docker-pullable://e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 29 May 2019 17:24:38 -0700\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-c8q2v (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-c8q2v:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-c8q2v\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                     Message\n  ----    ------     ----  ----                                                     -------\n  Normal  Scheduled  8s    default-scheduler                                        Successfully assigned kubectl-9754/redis-master-ndgtz to e2e-test-peterhornyack-windows-node-group-1vjk\n  Normal  Pulled     5s    kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Container image \"e2eteam/redis:1.0\" already present on machine\n  Normal  Created    5s    kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Created container redis-master\n  Normal  Started    3s    kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Started container redis-master\n"
May 29 17:24:41.511: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe rc redis-master --namespace=kubectl-9754'
May 29 17:24:41.924: INFO: stderr: ""
May 29 17:24:41.924: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9754\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        e2eteam/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  8s    replication-controller  Created pod: redis-master-ndgtz\n"
May 29 17:24:41.924: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe service redis-master --namespace=kubectl-9754'
May 29 17:24:42.297: INFO: stderr: ""
May 29 17:24:42.297: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9754\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.193.198\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.64.2.16:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 29 17:24:42.339: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe node e2e-test-peterhornyack-master'
May 29 17:24:42.769: INFO: stderr: ""
May 29 17:24:42.769: INFO: stdout: "Name:               e2e-test-peterhornyack-master\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-standard-1\n                    beta.kubernetes.io/metadata-proxy-ready=true\n                    beta.kubernetes.io/os=linux\n                    cloud.google.com/metadata-proxy-ready=true\n                    failure-domain.beta.kubernetes.io/region=us-central1\n                    failure-domain.beta.kubernetes.io/zone=us-central1-b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=e2e-test-peterhornyack-master\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl=0\n                    volumes.kubernetes.io/controller-managed-attach-detach=true\nCreationTimestamp:  Wed, 29 May 2019 16:02:04 -0700\nTaints:             node-under-test=false:NoSchedule\n                    node.kubernetes.io/unschedulable:NoSchedule\nUnschedulable:      true\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 29 May 2019 16:02:04 -0700   Wed, 29 May 2019 16:02:04 -0700   RouteCreated                 NodeController create implicit route\n  MemoryPressure       False   Wed, 29 May 2019 17:23:58 -0700   Wed, 29 May 2019 16:02:04 -0700   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 29 May 2019 17:23:58 -0700   Wed, 29 May 2019 16:02:04 -0700   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 29 May 2019 17:23:58 -0700   Wed, 29 May 2019 16:02:04 -0700   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 29 May 2019 17:23:58 -0700   Wed, 29 May 2019 16:02:04 -0700   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.40.0.2\n  ExternalIP:   146.148.105.213\n  InternalDNS:  e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal\n  Hostname:     e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal\nCapacity:\n attachable-volumes-gce-pd:  32\n cpu:                        1\n ephemeral-storage:          16293736Ki\n hugepages-2Mi:              0\n memory:                     3787520Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  32\n cpu:                        1\n ephemeral-storage:          15016307073\n hugepages-2Mi:              0\n memory:                     3531520Ki\n pods:                       110\nSystem Info:\n Machine ID:                 804d0c88641256f447b18f4e6b74052c\n System UUID:                804D0C88-6412-56F4-47B1-8F4E6B74052C\n Boot ID:                    435bd611-79d4-413f-84f2-66457dad30cc\n Kernel Version:             4.14.94+\n OS Image:                   Container-Optimized OS from Google\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.3\n Kubelet Version:            v1.15.0-alpha.0.1887+bae0630ef897d6-dirty\n Kube-Proxy Version:         v1.15.0-alpha.0.1887+bae0630ef897d6-dirty\nPodCIDR:                     10.64.0.0/24\nProviderID:                  gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                     CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                     ------------  ----------  ---------------  -------------\n  kube-system                etcd-empty-dir-cleanup-e2e-test-peterhornyack-master     0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                etcd-server-e2e-test-peterhornyack-master                200m (20%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                etcd-server-events-e2e-test-peterhornyack-master         100m (10%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                fluentd-gcp-v3.2.0-r5s9z                                 100m (10%)    1 (100%)    200Mi (5%)       500Mi (14%)\n  kube-system                kube-addon-manager-e2e-test-peterhornyack-master         5m (0%)       0 (0%)      50Mi (1%)        0 (0%)\n  kube-system                kube-apiserver-e2e-test-peterhornyack-master             250m (25%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-e2e-test-peterhornyack-master    200m (20%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-e2e-test-peterhornyack-master             75m (7%)      0 (0%)      0 (0%)           0 (0%)\n  kube-system                l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master    10m (1%)      0 (0%)      50Mi (1%)        0 (0%)\n  kube-system                metadata-proxy-v0.1-w99mm                                32m (3%)      32m (3%)    45Mi (1%)        45Mi (1%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests     Limits\n  --------                   --------     ------\n  cpu                        972m (97%)   1032m (103%)\n  memory                     345Mi (10%)  545Mi (15%)\n  attachable-volumes-gce-pd  0            0\nEvents:                      <none>\n"
May 29 17:24:42.769: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe namespace kubectl-9754'
May 29 17:24:43.161: INFO: stderr: ""
May 29 17:24:43.161: INFO: stdout: "Name:         kubectl-9754\nLabels:       e2e-framework=kubectl\n              e2e-run=c50d661b-b0c4-4fe0-8418-3f1e3df24e9d\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:24:43.161: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-9754" for this suite.
May 29 17:25:05.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:25:07.014: INFO: namespace kubectl-9754 deletion completed in 23.80993584s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl api-versions[0m 
  [1mshould check if v1 is in available api versions  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:25:07.015: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if v1 is in available api versions  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: validating api versions
May 29 17:25:07.189: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config api-versions'
May 29 17:25:07.500: INFO: stderr: ""
May 29 17:25:07.500: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscalingpolicy.kope.io/v1alpha1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:25:07.500: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-2900" for this suite.
May 29 17:25:13.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:25:15.455: INFO: namespace kubectl-2900 deletion completed in 7.911315617s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir wrapper volumes[0m 
  [1mshould not conflict [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:25:15.455: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir-wrapper
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Cleaning up the secret
[1mSTEP[0m: Cleaning up the configmap
[1mSTEP[0m: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:25:22.057: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-wrapper-3531" for this suite.
May 29 17:25:28.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:25:29.832: INFO: namespace emptydir-wrapper-3531 deletion completed in 7.724288619s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:25:29.832: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating pod liveness-exec in namespace container-probe-4175
May 29 17:25:38.151: INFO: Started pod liveness-exec in namespace container-probe-4175
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 29 17:25:38.193: INFO: Initial restart count of pod liveness-exec is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:29:39.249: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-4175" for this suite.
May 29 17:29:45.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:29:47.025: INFO: namespace container-probe-4175 deletion completed in 7.733340861s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:29:47.025: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:29:47.027: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:29:47.028: INFO: Driver csi-hostpath doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:29:47.029: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver csi-hostpath doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:29:47.030: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name configmap-test-volume-fe1dbcf8-26bd-41a8-b9be-b60c886e39e6
[1mSTEP[0m: Creating a pod to test consume configMaps
May 29 17:29:47.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73" in namespace "configmap-9718" to be "success or failure"
May 29 17:29:47.379: INFO: Pod "pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73": Phase="Pending", Reason="", readiness=false. Elapsed: 41.479978ms
May 29 17:29:49.421: INFO: Pod "pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08342088s
May 29 17:29:51.463: INFO: Pod "pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125642524s
May 29 17:29:53.505: INFO: Pod "pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167482523s
May 29 17:29:55.547: INFO: Pod "pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.209430539s
[1mSTEP[0m: Saw pod success
May 29 17:29:55.547: INFO: Pod "pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73" satisfied condition "success or failure"
May 29 17:29:55.589: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 17:29:55.691: INFO: Waiting for pod pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73 to disappear
May 29 17:29:55.733: INFO: Pod pod-configmaps-29cd4f9e-9699-487a-bd9d-ac0159d99d73 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:29:55.733: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-9718" for this suite.
May 29 17:30:01.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:30:03.515: INFO: namespace configmap-9718 deletion completed in 7.738808611s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute prestop exec hook properly [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:30:03.516: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: delete the pod with lifecycle hook
May 29 17:30:18.112: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 17:30:18.154: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 17:30:20.154: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 17:30:20.197: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 17:30:22.154: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 17:30:22.195: INFO: Pod pod-with-prestop-exec-hook still exists
May 29 17:30:24.154: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 29 17:30:24.196: INFO: Pod pod-with-prestop-exec-hook no longer exists
[1mSTEP[0m: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:30:24.248: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-lifecycle-hook-9470" for this suite.
May 29 17:30:46.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:30:48.015: INFO: namespace container-lifecycle-hook-9470 deletion completed in 23.723282646s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:30:48.015: INFO: Driver csi-hostpath doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:30:48.016: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver csi-hostpath doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:30:48.017: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 17:30:48.290: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634" in namespace "downward-api-6276" to be "success or failure"
May 29 17:30:48.331: INFO: Pod "downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634": Phase="Pending", Reason="", readiness=false. Elapsed: 41.305873ms
May 29 17:30:50.373: INFO: Pod "downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083743603s
May 29 17:30:52.416: INFO: Pod "downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125926936s
May 29 17:30:54.458: INFO: Pod "downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.167946019s
[1mSTEP[0m: Saw pod success
May 29 17:30:54.458: INFO: Pod "downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634" satisfied condition "success or failure"
May 29 17:30:54.499: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 17:30:54.599: INFO: Waiting for pod downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634 to disappear
May 29 17:30:54.641: INFO: Pod downwardapi-volume-39858914-a01d-4e8f-bd3a-615baf24b634 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:30:54.641: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-6276" for this suite.
May 29 17:31:00.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:31:02.441: INFO: namespace downward-api-6276 deletion completed in 7.757781236s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen running a container with a new image[0m 
  [1mshould be able to pull image from docker hub [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:380[0m
[BeforeEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:31:02.442: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to pull image from docker hub [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:380
[1mSTEP[0m: create the container
[1mSTEP[0m: check the container status
[1mSTEP[0m: delete the container
[AfterEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:31:11.175: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-runtime-1047" for this suite.
May 29 17:31:17.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:31:18.953: INFO: namespace container-runtime-1047 deletion completed in 7.735226402s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould allow opting out of API token automount  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:31:18.953: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename svcaccounts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: getting the auto-created API token
May 29 17:31:19.844: INFO: created pod pod-service-account-defaultsa
May 29 17:31:19.844: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 29 17:31:19.889: INFO: created pod pod-service-account-mountsa
May 29 17:31:19.889: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 29 17:31:19.933: INFO: created pod pod-service-account-nomountsa
May 29 17:31:19.933: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 29 17:31:19.978: INFO: created pod pod-service-account-defaultsa-mountspec
May 29 17:31:19.978: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 29 17:31:20.023: INFO: created pod pod-service-account-mountsa-mountspec
May 29 17:31:20.023: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 29 17:31:20.069: INFO: created pod pod-service-account-nomountsa-mountspec
May 29 17:31:20.069: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 29 17:31:20.113: INFO: created pod pod-service-account-defaultsa-nomountspec
May 29 17:31:20.113: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 29 17:31:20.159: INFO: created pod pod-service-account-mountsa-nomountspec
May 29 17:31:20.159: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 29 17:31:20.209: INFO: created pod pod-service-account-nomountsa-nomountspec
May 29 17:31:20.209: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:31:20.209: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "svcaccounts-4028" for this suite.
May 29 17:31:42.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:31:43.993: INFO: namespace svcaccounts-4028 deletion completed in 23.740866547s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:31:43.993: INFO: Driver gluster doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:31:43.995: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver gluster doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Docker Containers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:31:43.996: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test override command
May 29 17:31:44.264: INFO: Waiting up to 5m0s for pod "client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc" in namespace "containers-3042" to be "success or failure"
May 29 17:31:44.305: INFO: Pod "client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc": Phase="Pending", Reason="", readiness=false. Elapsed: 41.598775ms
May 29 17:31:46.348: INFO: Pod "client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083740207s
May 29 17:31:48.389: INFO: Pod "client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125657257s
May 29 17:31:50.431: INFO: Pod "client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16762734s
May 29 17:31:52.474: INFO: Pod "client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209749193s
May 29 17:31:54.515: INFO: Pod "client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.251318133s
[1mSTEP[0m: Saw pod success
May 29 17:31:54.515: INFO: Pod "client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc" satisfied condition "success or failure"
May 29 17:31:54.557: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc container test-container: <nil>
[1mSTEP[0m: delete the pod
May 29 17:31:54.659: INFO: Waiting for pod client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc to disappear
May 29 17:31:54.700: INFO: Pod client-containers-69c2f39b-4028-4e88-a838-fb99ad5cdccc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:31:54.700: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "containers-3042" for this suite.
May 29 17:32:00.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:32:02.461: INFO: namespace containers-3042 deletion completed in 7.717871965s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:02.462: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:02.464: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:02.465: INFO: Driver gluster doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:02.466: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver gluster doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:02.467: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:02.468: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen running a container with a new image[0m 
  [1mshould not be able to pull from private registry without secret [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:387[0m
[BeforeEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:32:02.470: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be able to pull from private registry without secret [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:387
[1mSTEP[0m: create the container
[1mSTEP[0m: check the container status
[1mSTEP[0m: delete the container
[AfterEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:07.027: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-runtime-5584" for this suite.
May 29 17:32:13.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:32:14.807: INFO: namespace container-runtime-5584 deletion completed in 7.737092828s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:14.807: INFO: Driver hostPathSymlink doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:14.809: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver hostPathSymlink doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:14.810: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:14.811: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:14.812: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:14.813: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:14.813: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:14.814: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl patch[0m 
  [1mshould add annotations for pods in rc  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:32:14.814: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should add annotations for pods in rc  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating Redis RC
May 29 17:32:15.046: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-800'
May 29 17:32:15.469: INFO: stderr: ""
May 29 17:32:15.469: INFO: stdout: "replicationcontroller/redis-master created\n"
[1mSTEP[0m: Waiting for Redis master to start.
May 29 17:32:16.511: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:16.512: INFO: Found 0 / 1
May 29 17:32:17.512: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:17.512: INFO: Found 0 / 1
May 29 17:32:18.512: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:18.512: INFO: Found 0 / 1
May 29 17:32:19.511: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:19.511: INFO: Found 0 / 1
May 29 17:32:20.512: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:20.512: INFO: Found 0 / 1
May 29 17:32:21.512: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:21.512: INFO: Found 0 / 1
May 29 17:32:22.511: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:22.512: INFO: Found 1 / 1
May 29 17:32:22.512: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
[1mSTEP[0m: patching all pods
May 29 17:32:22.554: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:22.554: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 29 17:32:22.554: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config patch pod redis-master-r7gsh --namespace=kubectl-800 -p {"metadata":{"annotations":{"x":"y"}}}'
May 29 17:32:22.867: INFO: stderr: ""
May 29 17:32:22.867: INFO: stdout: "pod/redis-master-r7gsh patched\n"
[1mSTEP[0m: checking annotations
May 29 17:32:22.909: INFO: Selector matched 1 pods for map[app:redis]
May 29 17:32:22.909: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:22.909: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-800" for this suite.
May 29 17:32:45.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:32:46.667: INFO: namespace kubectl-800 deletion completed in 23.714920779s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:46.668: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:46.669: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:46.670: INFO: Driver hostPath doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:46.672: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver hostPath doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:32:46.673: INFO: Driver hostPath doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:32:46.674: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver hostPath doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Job[0m 
  [1mshould delete a job [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] Job
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:32:46.675: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename job
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a job
[1mSTEP[0m: Ensuring active pods == parallelism
[1mSTEP[0m: delete a job
[1mSTEP[0m: deleting Job.batch foo in namespace job-407, will wait for the garbage collector to delete the pods
May 29 17:32:55.117: INFO: Deleting Job.batch foo took: 44.284943ms
May 29 17:32:55.718: INFO: Terminating Job.batch foo pods took: 600.332791ms
[1mSTEP[0m: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:33:36.960: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "job-407" for this suite.
May 29 17:33:43.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:33:44.745: INFO: namespace job-407 deletion completed in 7.742227404s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:33:44.745: INFO: Driver csi-hostpath-v0 doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:33:44.747: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver csi-hostpath-v0 doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:33:44.748: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename volume
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow exec of files on the volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167
May 29 17:33:44.918: INFO: Creating resource for dynamic PV
[1mSTEP[0m: creating a StorageClass volume-9245-gcepd-scpdkk7
[1mSTEP[0m: creating a claim
May 29 17:33:45.050: INFO: generated pod command echo "ls -n /vol1" > /vol1/test-gcepd-dynamicpv-dn2s.ps1; .\/vol1/test-gcepd-dynamicpv-dn2s.ps1
[1mSTEP[0m: Creating pod exec-volume-test-gcepd-dynamicpv-dn2s
[1mSTEP[0m: Creating a pod to test exec-volume-test
May 29 17:33:45.097: INFO: Waiting up to 5m0s for pod "exec-volume-test-gcepd-dynamicpv-dn2s" in namespace "volume-9245" to be "success or failure"
May 29 17:33:45.139: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 41.555954ms
May 29 17:33:47.181: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083465768s
May 29 17:33:49.224: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126606189s
May 29 17:33:51.266: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168385257s
May 29 17:33:53.308: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210324001s
May 29 17:33:55.350: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 10.252237323s
May 29 17:33:57.391: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 12.294027032s
May 29 17:33:59.433: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 14.335905015s
May 29 17:34:01.486: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 16.388137936s
May 29 17:34:03.528: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 18.430108291s
May 29 17:34:05.569: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 20.47182478s
May 29 17:34:07.611: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 22.513831539s
May 29 17:34:09.653: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 24.555989978s
May 29 17:34:11.695: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 26.597828557s
May 29 17:34:13.737: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 28.639522391s
May 29 17:34:15.783: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 30.68559895s
May 29 17:34:17.825: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Pending", Reason="", readiness=false. Elapsed: 32.727328142s
May 29 17:34:19.867: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Running", Reason="", readiness=true. Elapsed: 34.769134868s
May 29 17:34:21.909: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Running", Reason="", readiness=true. Elapsed: 36.811515637s
May 29 17:34:23.951: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Running", Reason="", readiness=true. Elapsed: 38.853349729s
May 29 17:34:25.993: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 40.895378047s
[1mSTEP[0m: Saw pod success
May 29 17:34:25.993: INFO: Pod "exec-volume-test-gcepd-dynamicpv-dn2s" satisfied condition "success or failure"
May 29 17:34:26.034: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod exec-volume-test-gcepd-dynamicpv-dn2s container exec-container-gcepd-dynamicpv-dn2s: <nil>
[1mSTEP[0m: delete the pod
May 29 17:34:26.135: INFO: Waiting for pod exec-volume-test-gcepd-dynamicpv-dn2s to disappear
May 29 17:34:26.176: INFO: Pod exec-volume-test-gcepd-dynamicpv-dn2s no longer exists
[1mSTEP[0m: Deleting pod exec-volume-test-gcepd-dynamicpv-dn2s
May 29 17:34:26.176: INFO: Deleting pod "exec-volume-test-gcepd-dynamicpv-dn2s" in namespace "volume-9245"
[1mSTEP[0m: Deleting pvc
May 29 17:34:26.217: INFO: Deleting PersistentVolumeClaim "pvc-h6lpb"
[1mSTEP[0m: Deleting sc
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:34:26.306: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "volume-9245" for this suite.
May 29 17:34:32.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:34:34.086: INFO: namespace volume-9245 deletion completed in 7.738006172s
[32m•[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:34:34.087: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:34:34.088: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:34:34.089: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:34:34.090: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:34:34.091: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename volume
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be mountable
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136
May 29 17:34:34.292: INFO: Creating resource for dynamic PV
[1mSTEP[0m: creating a StorageClass volume-4600-gcepd-sccnqzg
[1mSTEP[0m: creating a claim
[1mSTEP[0m: starting gcepd injector
May 29 17:34:34.480: INFO: Waiting up to 5m0s for pod "gcepd-injector-49qx" in namespace "volume-4600" to be "success or failure"
May 29 17:34:34.522: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 41.710836ms
May 29 17:34:36.566: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086187242s
May 29 17:34:38.608: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127710615s
May 29 17:34:40.651: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.17066413s
May 29 17:34:42.692: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.212612709s
May 29 17:34:44.735: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 10.255002998s
May 29 17:34:46.777: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 12.297048852s
May 29 17:34:48.819: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 14.338832174s
May 29 17:34:50.861: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 16.381273052s
May 29 17:34:52.903: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 18.423255153s
May 29 17:34:54.945: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 20.465568857s
May 29 17:34:56.987: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 22.507509956s
May 29 17:34:59.030: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 24.550463993s
May 29 17:35:01.074: INFO: Pod "gcepd-injector-49qx": Phase="Pending", Reason="", readiness=false. Elapsed: 26.593825629s
May 29 17:35:03.116: INFO: Pod "gcepd-injector-49qx": Phase="Running", Reason="", readiness=true. Elapsed: 28.635837976s
May 29 17:35:05.158: INFO: Pod "gcepd-injector-49qx": Phase="Running", Reason="", readiness=true. Elapsed: 30.677958367s
May 29 17:35:07.200: INFO: Pod "gcepd-injector-49qx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.719990373s
[1mSTEP[0m: Saw pod success
May 29 17:35:07.200: INFO: Pod "gcepd-injector-49qx" satisfied condition "success or failure"
[1mSTEP[0m: starting gcepd-client
[1mSTEP[0m: Checking that text file contents are perfect.
May 29 17:35:27.396: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec gcepd-client --namespace=volume-4600 -- powershell /c type /opt/0/index.html'
May 29 17:35:32.479: INFO: stderr: ""
May 29 17:35:32.479: INFO: stdout: "Hello from gcepd from namespace volume-4600\r\n"
[1mSTEP[0m: cleaning the environment after gcepd
May 29 17:35:32.479: INFO: Deleting pod "gcepd-client" in namespace "volume-4600"
May 29 17:35:32.527: INFO: Wait up to 5m0s for pod "gcepd-client" to be fully deleted
[1mSTEP[0m: Deleting pvc
May 29 17:35:36.611: INFO: Deleting PersistentVolumeClaim "pvc-8cfcb"
[1mSTEP[0m: Deleting sc
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:35:36.701: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "volume-4600" for this suite.
May 29 17:35:42.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:35:44.474: INFO: namespace volume-4600 deletion completed in 7.730355761s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:35:44.474: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:35:44.476: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node with explicit kubelet port using proxy subresource  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] version v1
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:35:44.477: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 17:35:44.776: INFO: (0) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 48.023487ms)
May 29 17:35:44.820: INFO: (1) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.838191ms)
May 29 17:35:44.864: INFO: (2) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.65112ms)
May 29 17:35:44.907: INFO: (3) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.410741ms)
May 29 17:35:44.952: INFO: (4) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.609762ms)
May 29 17:35:44.996: INFO: (5) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.353904ms)
May 29 17:35:45.039: INFO: (6) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.823375ms)
May 29 17:35:45.083: INFO: (7) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.841658ms)
May 29 17:35:45.128: INFO: (8) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.198846ms)
May 29 17:35:45.171: INFO: (9) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.481518ms)
May 29 17:35:45.215: INFO: (10) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.376815ms)
May 29 17:35:45.260: INFO: (11) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 45.63261ms)
May 29 17:35:45.304: INFO: (12) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.10106ms)
May 29 17:35:45.348: INFO: (13) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.679266ms)
May 29 17:35:45.393: INFO: (14) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.575193ms)
May 29 17:35:45.437: INFO: (15) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.747084ms)
May 29 17:35:45.481: INFO: (16) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.304378ms)
May 29 17:35:45.525: INFO: (17) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.743217ms)
May 29 17:35:45.576: INFO: (18) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 51.137622ms)
May 29 17:35:45.619: INFO: (19) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.354942ms)
[AfterEach] version v1
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:35:45.619: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "proxy-5778" for this suite.
May 29 17:35:51.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:35:53.381: INFO: namespace proxy-5778 deletion completed in 7.717633224s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:35:53.381: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:35:53.381: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould do a rolling update of a replication controller  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:35:53.382: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should do a rolling update of a replication controller  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the initial replication controller
May 29 17:35:53.584: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-96'
May 29 17:35:55.986: INFO: stderr: ""
May 29 17:35:55.986: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 29 17:35:55.986: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:35:56.255: INFO: stderr: ""
May 29 17:35:56.255: INFO: stdout: "update-demo-nautilus-2xkq6 update-demo-nautilus-swf8k "
May 29 17:35:56.255: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-2xkq6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:35:56.501: INFO: stderr: ""
May 29 17:35:56.501: INFO: stdout: ""
May 29 17:35:56.501: INFO: update-demo-nautilus-2xkq6 is created but not running
May 29 17:36:01.502: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:36:01.759: INFO: stderr: ""
May 29 17:36:01.759: INFO: stdout: "update-demo-nautilus-2xkq6 update-demo-nautilus-swf8k "
May 29 17:36:01.759: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-2xkq6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:36:02.011: INFO: stderr: ""
May 29 17:36:02.011: INFO: stdout: ""
May 29 17:36:02.011: INFO: update-demo-nautilus-2xkq6 is created but not running
May 29 17:36:07.011: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:36:07.276: INFO: stderr: ""
May 29 17:36:07.276: INFO: stdout: "update-demo-nautilus-2xkq6 update-demo-nautilus-swf8k "
May 29 17:36:07.276: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-2xkq6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:36:07.527: INFO: stderr: ""
May 29 17:36:07.527: INFO: stdout: "true"
May 29 17:36:07.527: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-2xkq6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:36:07.794: INFO: stderr: ""
May 29 17:36:07.794: INFO: stdout: "e2eteam/nautilus:1.0"
May 29 17:36:07.794: INFO: validating pod update-demo-nautilus-2xkq6
May 29 17:36:07.974: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:36:07.975: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:36:07.975: INFO: update-demo-nautilus-2xkq6 is verified up and running
May 29 17:36:07.975: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-swf8k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:36:08.225: INFO: stderr: ""
May 29 17:36:08.225: INFO: stdout: "true"
May 29 17:36:08.226: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-swf8k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:36:08.484: INFO: stderr: ""
May 29 17:36:08.485: INFO: stdout: "e2eteam/nautilus:1.0"
May 29 17:36:08.485: INFO: validating pod update-demo-nautilus-swf8k
May 29 17:36:08.724: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 17:36:08.724: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 17:36:08.724: INFO: update-demo-nautilus-swf8k is verified up and running
[1mSTEP[0m: rolling-update to new replication controller
May 29 17:36:08.948: INFO: scanned /usr/local/google/home/peterhornyack for discovery docs: <nil>
May 29 17:36:08.948: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-96'
May 29 17:37:01.109: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 29 17:37:01.109: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 29 17:37:01.110: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:01.421: INFO: stderr: ""
May 29 17:37:01.421: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-2xkq6 update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=4
May 29 17:37:06.421: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:06.721: INFO: stderr: ""
May 29 17:37:06.721: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-2xkq6 update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=4
May 29 17:37:11.724: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:12.021: INFO: stderr: ""
May 29 17:37:12.021: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-2xkq6 update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=4
May 29 17:37:17.021: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:17.312: INFO: stderr: ""
May 29 17:37:17.312: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-2xkq6 update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=4
May 29 17:37:22.312: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:22.607: INFO: stderr: ""
May 29 17:37:22.607: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=3
May 29 17:37:27.607: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:27.910: INFO: stderr: ""
May 29 17:37:27.910: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=3
May 29 17:37:32.911: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:33.202: INFO: stderr: ""
May 29 17:37:33.202: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=3
May 29 17:37:38.203: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:38.503: INFO: stderr: ""
May 29 17:37:38.503: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=3
May 29 17:37:43.504: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:43.803: INFO: stderr: ""
May 29 17:37:43.803: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=3
May 29 17:37:48.803: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:49.095: INFO: stderr: ""
May 29 17:37:49.095: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f update-demo-nautilus-swf8k "
[1mSTEP[0m: Replicas for name=update-demo: expected=2 actual=3
May 29 17:37:54.095: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-96'
May 29 17:37:54.348: INFO: stderr: ""
May 29 17:37:54.348: INFO: stdout: "update-demo-kitten-cqmbt update-demo-kitten-pmx2f "
May 29 17:37:54.348: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-kitten-cqmbt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:37:54.602: INFO: stderr: ""
May 29 17:37:54.602: INFO: stdout: "true"
May 29 17:37:54.602: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-kitten-cqmbt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:37:54.861: INFO: stderr: ""
May 29 17:37:54.861: INFO: stdout: "e2eteam/kitten:1.0"
May 29 17:37:54.861: INFO: validating pod update-demo-kitten-cqmbt
May 29 17:37:54.994: INFO: got data: {
  "image": "kitten.jpg"
}

May 29 17:37:54.994: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 29 17:37:54.995: INFO: update-demo-kitten-cqmbt is verified up and running
May 29 17:37:54.995: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-kitten-pmx2f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:37:55.253: INFO: stderr: ""
May 29 17:37:55.253: INFO: stdout: "true"
May 29 17:37:55.253: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-kitten-pmx2f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-96'
May 29 17:37:55.513: INFO: stderr: ""
May 29 17:37:55.513: INFO: stdout: "e2eteam/kitten:1.0"
May 29 17:37:55.513: INFO: validating pod update-demo-kitten-pmx2f
May 29 17:37:55.809: INFO: got data: {
  "image": "kitten.jpg"
}

May 29 17:37:55.809: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 29 17:37:55.809: INFO: update-demo-kitten-pmx2f is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:37:55.809: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-96" for this suite.
May 29 17:38:39.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:38:41.590: INFO: namespace kubectl-96 deletion completed in 45.738969933s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould invoke init containers on a RestartAlways pod [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:38:41.591: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
May 29 17:38:41.761: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:38:56.729: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "init-container-9244" for this suite.
May 29 17:39:58.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:00.497: INFO: namespace init-container-9244 deletion completed in 1m3.725106687s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mRollingUpdateDeployment should delete old pods and create new ones [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:40:00.497: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 17:40:00.673: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 29 17:40:00.782: INFO: Pod name sample-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
May 29 17:40:08.873: INFO: Creating deployment "test-rolling-update-deployment"
May 29 17:40:08.919: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 29 17:40:09.041: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 29 17:40:09.083: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-7fcdf5fb94\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:40:11.125: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-7fcdf5fb94\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:40:13.125: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-7fcdf5fb94\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:40:15.127: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773615, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694773608, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-7fcdf5fb94\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 17:40:17.125: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:60
May 29 17:40:17.250: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-3127,SelfLink:/apis/apps/v1/namespaces/deployment-3127/deployments/test-rolling-update-deployment,UID:88fc7957-d249-4628-82cb-a5b1d96da10a,ResourceVersion:17104,Generation:1,CreationTimestamp:2019-05-29 17:40:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-29 17:40:08 -0700 PDT 2019-05-29 17:40:08 -0700 PDT MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-29 17:40:15 -0700 PDT 2019-05-29 17:40:08 -0700 PDT NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-7fcdf5fb94" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 29 17:40:17.293: INFO: New ReplicaSet "test-rolling-update-deployment-7fcdf5fb94" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-7fcdf5fb94,GenerateName:,Namespace:deployment-3127,SelfLink:/apis/apps/v1/namespaces/deployment-3127/replicasets/test-rolling-update-deployment-7fcdf5fb94,UID:a3e52f07-d2c5-42aa-93fc-425dc66025a9,ResourceVersion:17097,Generation:1,CreationTimestamp:2019-05-29 17:40:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 7fcdf5fb94,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 88fc7957-d249-4628-82cb-a5b1d96da10a 0xc002415b57 0xc002415b58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 7fcdf5fb94,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 7fcdf5fb94,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 29 17:40:17.293: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 29 17:40:17.293: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-3127,SelfLink:/apis/apps/v1/namespaces/deployment-3127/replicasets/test-rolling-update-controller,UID:e4549eb8-7ddd-4ab2-8e78-8b37573a8d7a,ResourceVersion:17103,Generation:2,CreationTimestamp:2019-05-29 17:40:00 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 88fc7957-d249-4628-82cb-a5b1d96da10a 0xc0024158a7 0xc0024158a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 17:40:17.336: INFO: Pod "test-rolling-update-deployment-7fcdf5fb94-nvrbg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-7fcdf5fb94-nvrbg,GenerateName:test-rolling-update-deployment-7fcdf5fb94-,Namespace:deployment-3127,SelfLink:/api/v1/namespaces/deployment-3127/pods/test-rolling-update-deployment-7fcdf5fb94-nvrbg,UID:aca54677-6aec-43cb-9146-5f125f5c7c68,ResourceVersion:17096,Generation:0,CreationTimestamp:2019-05-29 17:40:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 7fcdf5fb94,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-7fcdf5fb94 a3e52f07-d2c5-42aa-93fc-425dc66025a9 0xc002bc42f7 0xc002bc42f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p8md6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p8md6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-p8md6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bc4360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bc4380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:40:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:40:15 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:40:15 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 17:40:08 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:10.64.2.23,StartTime:2019-05-29 17:40:08 -0700 PDT,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-29 17:40:13 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/redis:1.0 docker-pullable://e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 docker://2c2183bb70f8a74c9a8691f20108a82c1dfc6ba3cc012e35077a266d0f1d2801}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:17.336: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-3127" for this suite.
May 29 17:40:23.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:25.109: INFO: namespace deployment-3127 deletion completed in 7.73019622s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:40:25.110: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:25.111: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould release no longer matching pods [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] ReplicationController
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:40:25.112: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Given a ReplicationController is created
[1mSTEP[0m: When the matched label of one of its pods change
May 29 17:40:25.408: INFO: Pod name pod-release: Found 1 pods out of 1
[1mSTEP[0m: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:25.547: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "replication-controller-5736" for this suite.
May 29 17:40:31.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:33.321: INFO: namespace replication-controller-5736 deletion completed in 7.730688805s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Docker Containers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:40:33.322: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test override arguments
May 29 17:40:33.540: INFO: Waiting up to 5m0s for pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3" in namespace "containers-6631" to be "success or failure"
May 29 17:40:33.582: INFO: Pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 42.11353ms
May 29 17:40:35.625: INFO: Pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085267446s
May 29 17:40:37.667: INFO: Pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126982831s
May 29 17:40:39.709: INFO: Pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3": Phase="Running", Reason="", readiness=true. Elapsed: 6.169241267s
May 29 17:40:41.751: INFO: Pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3": Phase="Running", Reason="", readiness=true. Elapsed: 8.211258565s
May 29 17:40:43.793: INFO: Pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3": Phase="Running", Reason="", readiness=true. Elapsed: 10.253351679s
May 29 17:40:45.835: INFO: Pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.295356402s
[1mSTEP[0m: Saw pod success
May 29 17:40:45.836: INFO: Pod "client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3" satisfied condition "success or failure"
May 29 17:40:45.877: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 29 17:40:45.992: INFO: Waiting for pod client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3 to disappear
May 29 17:40:46.033: INFO: Pod client-containers-16c35d6b-cf31-4c7f-b584-a0095313a0f3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:40:46.033: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "containers-6631" for this suite.
May 29 17:40:52.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:40:53.889: INFO: namespace containers-6631 deletion completed in 7.813035768s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Pods Extended[0m [90m[k8s.io] Delete Grace Period[0m 
  [1mshould be submitted and removed [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:40:53.889: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
[1mSTEP[0m: setting up selector
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
May 29 17:41:02.345: INFO: Asynchronously running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config proxy -p 0'
[1mSTEP[0m: deleting the pod gracefully
[1mSTEP[0m: verifying the kubelet observed the termination notice
May 29 17:41:12.642: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:41:12.683: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-8092" for this suite.
May 29 17:41:18.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:41:20.469: INFO: namespace pods-8092 deletion completed in 7.743761125s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] HostPath[0m 
  [1mshould support r/w [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:65[0m
[BeforeEach] [sig-storage] HostPath
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:41:20.470: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename hostpath
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should support r/w [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:65
[1mSTEP[0m: Creating a pod to test hostPath r/w
May 29 17:41:20.723: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9047" to be "success or failure"
May 29 17:41:20.765: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 42.346408ms
May 29 17:41:22.807: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08454416s
May 29 17:41:24.849: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126469614s
May 29 17:41:26.891: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16833299s
May 29 17:41:28.933: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.21080347s
May 29 17:41:30.976: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 10.252961771s
May 29 17:41:33.018: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 12.29505265s
May 29 17:41:35.059: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 14.336878631s
May 29 17:41:37.101: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.378695903s
[1mSTEP[0m: Saw pod success
May 29 17:41:37.101: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 29 17:41:37.143: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-host-path-test container test-container-2: <nil>
[1mSTEP[0m: delete the pod
May 29 17:41:37.246: INFO: Waiting for pod pod-host-path-test to disappear
May 29 17:41:37.288: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:41:37.288: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "hostpath-9047" for this suite.
May 29 17:41:43.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:41:45.186: INFO: namespace hostpath-9047 deletion completed in 7.85571722s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl version[0m 
  [1mshould check is all data is printed  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:41:45.186: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check is all data is printed  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 17:41:45.392: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config version'
May 29 17:41:45.643: INFO: stderr: ""
May 29 17:41:45.643: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.3\", GitCommit:\"a4529464e4629c21224b3d52edfe0ea91b072862\", GitTreeState:\"clean\", BuildDate:\"2018-09-09T18:02:47Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15+\", GitVersion:\"v1.15.0-alpha.0.1887+bae0630ef897d6-dirty\", GitCommit:\"bae0630ef897d6c560b75628d7003964640c22d2\", GitTreeState:\"dirty\", BuildDate:\"2019-04-05T18:40:20Z\", GoVersion:\"go1.12.1\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:41:45.643: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-7840" for this suite.
May 29 17:41:51.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 17:41:53.405: INFO: namespace kubectl-7840 deletion completed in 7.718035754s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 17:41:53.405: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 17:41:53.406: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould cap back-off at MaxContainerBackOff [Slow][NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:691[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 17:41:53.407: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should cap back-off at MaxContainerBackOff [Slow][NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:691
[1mSTEP[0m: getting restart delay when capped
May 29 17:53:51.229: INFO: getRestartDelay: restartCount = 7, finishedAt=2019-05-29 17:48:37 -0700 PDT restartedAt=2019-05-29 17:53:43 -0700 PDT (5m6s)
May 29 17:59:05.006: INFO: getRestartDelay: restartCount = 8, finishedAt=2019-05-29 17:53:48 -0700 PDT restartedAt=2019-05-29 17:58:57 -0700 PDT (5m9s)
May 29 18:04:22.874: INFO: getRestartDelay: restartCount = 9, finishedAt=2019-05-29 17:59:02 -0700 PDT restartedAt=2019-05-29 18:04:15 -0700 PDT (5m13s)
[1mSTEP[0m: getting restart delay after a capped delay
May 29 18:09:33.479: INFO: getRestartDelay: restartCount = 10, finishedAt=2019-05-29 18:04:20 -0700 PDT restartedAt=2019-05-29 18:09:26 -0700 PDT (5m6s)
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:09:33.479: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-5171" for this suite.
May 29 18:09:55.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:09:57.309: INFO: namespace pods-5171 deletion completed in 23.787710592s

[32m• [SLOW TEST:1683.902 seconds][0m
[k8s.io] Pods
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  should cap back-off at MaxContainerBackOff [Slow][NodeConformance]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:691[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen starting a container that exits[0m 
  [1mshould run with the expected status [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:09:57.309: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpa': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpof': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'Phase'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
[1mSTEP[0m: Container 'terminate-cmd-rpn': should get the expected 'State'
[1mSTEP[0m: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:10:56.951: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-runtime-9301" for this suite.
May 29 18:11:03.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:11:04.709: INFO: namespace container-runtime-9301 deletion completed in 7.714804883s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:11:04.709: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:04.711: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:11:04.711: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:04.712: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:11:04.713: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:04.714: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:11:04.715: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:04.716: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl label[0m 
  [1mshould update the label on a resource  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:11:04.716: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl label
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1124
[1mSTEP[0m: creating the pod
May 29 18:11:04.914: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-1090'
May 29 18:11:07.325: INFO: stderr: ""
May 29 18:11:07.325: INFO: stdout: "pod/pause created\n"
May 29 18:11:07.326: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 29 18:11:07.326: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1090" to be "running and ready"
May 29 18:11:07.367: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 41.718124ms
May 29 18:11:09.409: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083715851s
May 29 18:11:11.451: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125639703s
May 29 18:11:13.493: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167687763s
May 29 18:11:15.535: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 8.20940935s
May 29 18:11:15.535: INFO: Pod "pause" satisfied condition "running and ready"
May 29 18:11:15.535: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: adding the label testing-label with value testing-label-value to a pod
May 29 18:11:15.535: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config label pods pause testing-label=testing-label-value --namespace=kubectl-1090'
May 29 18:11:15.838: INFO: stderr: ""
May 29 18:11:15.838: INFO: stdout: "pod/pause labeled\n"
[1mSTEP[0m: verifying the pod has the label testing-label with the value testing-label-value
May 29 18:11:15.839: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pod pause -L testing-label --namespace=kubectl-1090'
May 29 18:11:16.083: INFO: stderr: ""
May 29 18:11:16.083: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          9s        testing-label-value\n"
[1mSTEP[0m: removing the label testing-label of a pod
May 29 18:11:16.083: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config label pods pause testing-label- --namespace=kubectl-1090'
May 29 18:11:16.387: INFO: stderr: ""
May 29 18:11:16.387: INFO: stdout: "pod/pause labeled\n"
[1mSTEP[0m: verifying the pod doesn't have the label testing-label
May 29 18:11:16.387: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pod pause -L testing-label --namespace=kubectl-1090'
May 29 18:11:16.660: INFO: stderr: ""
May 29 18:11:16.661: INFO: stdout: "NAME      READY     STATUS    RESTARTS   AGE       TESTING-LABEL\npause     1/1       Running   0          9s        \n"
[AfterEach] [k8s.io] Kubectl label
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1131
[1mSTEP[0m: using delete to clean up resources
May 29 18:11:16.661: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-1090'
May 29 18:11:16.954: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 18:11:16.954: INFO: stdout: "pod \"pause\" force deleted\n"
May 29 18:11:16.954: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get rc,svc -l name=pause --no-headers --namespace=kubectl-1090'
May 29 18:11:17.255: INFO: stderr: "No resources found.\n"
May 29 18:11:17.255: INFO: stdout: ""
May 29 18:11:17.256: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -l name=pause --namespace=kubectl-1090 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 18:11:17.512: INFO: stderr: ""
May 29 18:11:17.512: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:17.512: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-1090" for this suite.
May 29 18:11:23.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:11:25.274: INFO: namespace kubectl-1090 deletion completed in 7.719576884s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:11:25.274: INFO: Driver csi-hostpath-v0 doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:25.276: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver csi-hostpath-v0 doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:11:25.276: INFO: Driver csi-hostpath-v0 doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:25.278: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver csi-hostpath-v0 doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:11:25.279: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:25.280: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:11:25.281: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:25.282: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicaSet[0m 
  [1mshould adopt matching pods on creation and release no longer matching pods [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] ReplicaSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:11:25.283: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename replicaset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Given a Pod with a 'name' label pod-adoption-release is created
[1mSTEP[0m: When a replicaset with a matching selector is created
[1mSTEP[0m: Then the orphan pod is adopted
[1mSTEP[0m: When the matched label of one of its pods change
May 29 18:11:33.762: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
[1mSTEP[0m: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:11:33.902: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "replicaset-2637" for this suite.
May 29 18:12:58.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:12:59.670: INFO: namespace replicaset-2637 deletion completed in 1m25.724899868s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould have their auto-restart back-off timer reset on image update [Slow][NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:650[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:12:59.670: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should have their auto-restart back-off timer reset on image update [Slow][NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:650
[1mSTEP[0m: getting restart delay-0
May 29 18:15:02.241: INFO: getRestartDelay: restartCount = 4, finishedAt=2019-05-29 18:14:09 -0700 PDT restartedAt=2019-05-29 18:14:54 -0700 PDT (45s)
[1mSTEP[0m: getting restart delay-1
May 29 18:16:32.911: INFO: getRestartDelay: restartCount = 5, finishedAt=2019-05-29 18:14:59 -0700 PDT restartedAt=2019-05-29 18:16:25 -0700 PDT (1m26s)
[1mSTEP[0m: getting restart delay-2
May 29 18:19:21.774: INFO: getRestartDelay: restartCount = 6, finishedAt=2019-05-29 18:16:30 -0700 PDT restartedAt=2019-05-29 18:19:14 -0700 PDT (2m44s)
[1mSTEP[0m: updating the image
May 29 18:19:22.363: INFO: Successfully updated pod "pod-back-off-image"
[1mSTEP[0m: get restart delay after image update
May 29 18:19:53.246: INFO: getRestartDelay: restartCount = 8, finishedAt=2019-05-29 18:19:29 -0700 PDT restartedAt=2019-05-29 18:19:45 -0700 PDT (16s)
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:19:53.246: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-4814" for this suite.
May 29 18:20:15.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:20:17.043: INFO: namespace pods-4814 deletion completed in 23.754414332s

[32m• [SLOW TEST:437.373 seconds][0m
[k8s.io] Pods
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  should have their auto-restart back-off timer reset on image update [Slow][NodeConformance]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:650[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:20:17.044: INFO: Driver gluster doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:20:17.045: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver gluster doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:20:17.047: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:20:17.049: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:20:17.050: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating secret with name secret-test-4e08b7d9-3553-465e-a94a-45072458a8c4
[1mSTEP[0m: Creating a pod to test consume secrets
May 29 18:20:17.551: INFO: Waiting up to 5m0s for pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe" in namespace "secrets-3084" to be "success or failure"
May 29 18:20:17.593: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe": Phase="Pending", Reason="", readiness=false. Elapsed: 41.779888ms
May 29 18:20:19.635: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083845963s
May 29 18:20:21.679: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12734351s
May 29 18:20:23.720: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168733774s
May 29 18:20:25.762: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210839127s
May 29 18:20:27.804: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe": Phase="Running", Reason="", readiness=true. Elapsed: 10.252583002s
May 29 18:20:29.846: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe": Phase="Running", Reason="", readiness=true. Elapsed: 12.294485063s
May 29 18:20:31.888: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.33673084s
[1mSTEP[0m: Saw pod success
May 29 18:20:31.888: INFO: Pod "pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe" satisfied condition "success or failure"
May 29 18:20:31.930: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 18:20:32.033: INFO: Waiting for pod pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe to disappear
May 29 18:20:32.075: INFO: Pod pod-secrets-d9630e5f-4ca6-44eb-807f-61b06b0beffe no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:20:32.075: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-3084" for this suite.
May 29 18:20:38.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:20:39.843: INFO: namespace secrets-3084 deletion completed in 7.724826086s
[1mSTEP[0m: Destroying namespace "secret-namespace-3290" for this suite.
May 29 18:20:45.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:20:47.584: INFO: namespace secret-namespace-3290 deletion completed in 7.740738541s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:20:47.584: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 18:20:47.801: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314" in namespace "downward-api-411" to be "success or failure"
May 29 18:20:47.844: INFO: Pod "downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314": Phase="Pending", Reason="", readiness=false. Elapsed: 43.499787ms
May 29 18:20:49.886: INFO: Pod "downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085336304s
May 29 18:20:51.928: INFO: Pod "downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127444918s
May 29 18:20:53.971: INFO: Pod "downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.169532021s
[1mSTEP[0m: Saw pod success
May 29 18:20:53.971: INFO: Pod "downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314" satisfied condition "success or failure"
May 29 18:20:54.012: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 18:20:54.118: INFO: Waiting for pod downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314 to disappear
May 29 18:20:54.160: INFO: Pod downwardapi-volume-d9236ad3-8a05-48c6-a3ea-1e3a2e894314 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:20:54.160: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-411" for this suite.
May 29 18:21:00.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:21:01.997: INFO: namespace downward-api-411 deletion completed in 7.795020212s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:21:01.997: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:21:01.999: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould be able to override the image's default command and arguments [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Docker Containers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:21:02.000: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test override all
May 29 18:21:02.219: INFO: Waiting up to 5m0s for pod "client-containers-754d037c-2a27-4639-ac6e-5d7015f40286" in namespace "containers-4955" to be "success or failure"
May 29 18:21:02.263: INFO: Pod "client-containers-754d037c-2a27-4639-ac6e-5d7015f40286": Phase="Pending", Reason="", readiness=false. Elapsed: 44.219751ms
May 29 18:21:04.305: INFO: Pod "client-containers-754d037c-2a27-4639-ac6e-5d7015f40286": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086278726s
May 29 18:21:06.348: INFO: Pod "client-containers-754d037c-2a27-4639-ac6e-5d7015f40286": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128879429s
May 29 18:21:08.390: INFO: Pod "client-containers-754d037c-2a27-4639-ac6e-5d7015f40286": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.17093566s
[1mSTEP[0m: Saw pod success
May 29 18:21:08.390: INFO: Pod "client-containers-754d037c-2a27-4639-ac6e-5d7015f40286" satisfied condition "success or failure"
May 29 18:21:08.432: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod client-containers-754d037c-2a27-4639-ac6e-5d7015f40286 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 29 18:21:08.531: INFO: Waiting for pod client-containers-754d037c-2a27-4639-ac6e-5d7015f40286 to disappear
May 29 18:21:08.572: INFO: Pod client-containers-754d037c-2a27-4639-ac6e-5d7015f40286 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:21:08.572: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "containers-4955" for this suite.
May 29 18:21:14.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:21:16.401: INFO: namespace containers-4955 deletion completed in 7.785583374s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould support retrieving logs from the container over websockets [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:21:16.401: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 18:21:16.601: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:21:24.954: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-2264" for this suite.
May 29 18:21:47.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:21:48.731: INFO: namespace pods-2264 deletion completed in 23.734130739s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:21:48.731: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-0555f4f9-b078-4338-af55-0224aa8d1749
[1mSTEP[0m: Creating a pod to test consume configMaps
May 29 18:21:48.993: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3" in namespace "projected-925" to be "success or failure"
May 29 18:21:49.035: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3": Phase="Pending", Reason="", readiness=false. Elapsed: 41.748267ms
May 29 18:21:51.077: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083386606s
May 29 18:21:53.119: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125115033s
May 29 18:21:55.160: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.166799635s
May 29 18:21:57.202: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.208663618s
May 29 18:21:59.244: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3": Phase="Running", Reason="", readiness=true. Elapsed: 10.250800245s
May 29 18:22:01.286: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3": Phase="Running", Reason="", readiness=true. Elapsed: 12.292890592s
May 29 18:22:03.328: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.33476925s
[1mSTEP[0m: Saw pod success
May 29 18:22:03.328: INFO: Pod "pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3" satisfied condition "success or failure"
May 29 18:22:03.370: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 18:22:03.469: INFO: Waiting for pod pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3 to disappear
May 29 18:22:03.510: INFO: Pod pod-projected-configmaps-8c97c3ac-47cf-4720-8735-0fa1b142a4a3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:03.510: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-925" for this suite.
May 29 18:22:09.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:22:11.285: INFO: namespace projected-925 deletion completed in 7.73249358s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:22:11.286: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:11.287: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] PreStop[0m 
  [1mshould call prestop when killing a pod  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] [sig-node] PreStop
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:22:11.288: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename prestop
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating server pod server in namespace prestop-6646
[1mSTEP[0m: Waiting for pods to come up.
[1mSTEP[0m: Creating tester pod tester in namespace prestop-6646
[1mSTEP[0m: Deleting pre-stop pod
May 29 18:22:32.898: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
[1mSTEP[0m: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:32.946: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "prestop-6646" for this suite.
May 29 18:22:39.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:22:40.705: INFO: namespace prestop-6646 deletion completed in 7.716340229s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:22:40.705: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:40.706: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:22:40.707: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:40.708: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:22:40.709: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:40.710: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:22:40.711: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:40.712: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:22:40.712: INFO: Driver hostPathSymlink doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:40.713: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver hostPathSymlink doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-node] ConfigMap[0m 
  [1mshould fail to create ConfigMap with empty key [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-node] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:22:40.713: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap that has name configmap-test-emptyKey-4bddcfb3-d014-48b9-8c4a-645785a5a7af
[AfterEach] [sig-node] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:22:40.952: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-4971" for this suite.
May 29 18:22:47.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:22:48.760: INFO: namespace configmap-4971 deletion completed in 7.765241889s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mbinary data should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:22:48.760: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name configmap-test-upd-71b28198-5861-49f3-94c8-aa1bdd256098
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Waiting for pod with text data
[1mSTEP[0m: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:23:01.325: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-8999" for this suite.
May 29 18:24:07.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:24:09.094: INFO: namespace configmap-8999 deletion completed in 1m7.72603791s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:24:09.094: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:24:09.095: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:24:09.096: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:24:09.098: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] ConfigMap[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-node] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:24:09.099: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap configmap-8050/configmap-test-7721e4f0-e849-4acd-a024-cbde76e7d6c3
[1mSTEP[0m: Creating a pod to test consume configMaps
May 29 18:24:09.359: INFO: Waiting up to 5m0s for pod "pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685" in namespace "configmap-8050" to be "success or failure"
May 29 18:24:09.401: INFO: Pod "pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685": Phase="Pending", Reason="", readiness=false. Elapsed: 41.578729ms
May 29 18:24:11.443: INFO: Pod "pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083685834s
May 29 18:24:13.485: INFO: Pod "pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125833084s
May 29 18:24:15.527: INFO: Pod "pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.168159398s
[1mSTEP[0m: Saw pod success
May 29 18:24:15.528: INFO: Pod "pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685" satisfied condition "success or failure"
May 29 18:24:15.569: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685 container env-test: <nil>
[1mSTEP[0m: delete the pod
May 29 18:24:15.671: INFO: Waiting for pod pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685 to disappear
May 29 18:24:15.716: INFO: Pod pod-configmaps-bb2d7920-afa9-48ff-916f-e8b0db6bf685 no longer exists
[AfterEach] [sig-node] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:24:15.716: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-8050" for this suite.
May 29 18:24:21.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:24:23.494: INFO: namespace configmap-8050 deletion completed in 7.736791017s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable in multiple volumes in the same pod [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:24:23.495: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-4ee78868-1b66-42a9-90a2-8a676c9dc3aa
[1mSTEP[0m: Creating a pod to test consume configMaps
May 29 18:24:23.782: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9" in namespace "projected-6253" to be "success or failure"
May 29 18:24:23.823: INFO: Pod "pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9": Phase="Pending", Reason="", readiness=false. Elapsed: 41.518453ms
May 29 18:24:25.866: INFO: Pod "pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083764776s
May 29 18:24:27.907: INFO: Pod "pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125447606s
May 29 18:24:29.950: INFO: Pod "pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.168113944s
[1mSTEP[0m: Saw pod success
May 29 18:24:29.950: INFO: Pod "pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9" satisfied condition "success or failure"
May 29 18:24:29.991: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 18:24:30.096: INFO: Waiting for pod pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9 to disappear
May 29 18:24:30.138: INFO: Pod pod-projected-configmaps-d6e2178e-f908-47f7-ab7b-f10cb53b60f9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:24:30.138: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-6253" for this suite.
May 29 18:24:36.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:24:37.911: INFO: namespace projected-6253 deletion completed in 7.730330043s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Security Context[0m [90mWhen creating a pod with readOnlyRootFilesystem[0m 
  [1mshould run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:147[0m
[BeforeEach] [k8s.io] Security Context
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:24:37.911: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename security-context-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:35
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:147
May 29 18:24:38.162: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-0ef2ff97-4141-42fd-a34f-47d6fd8f7d5f" in namespace "security-context-test-1480" to be "success or failure"
May 29 18:24:38.204: INFO: Pod "busybox-readonly-false-0ef2ff97-4141-42fd-a34f-47d6fd8f7d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 42.02046ms
May 29 18:24:40.246: INFO: Pod "busybox-readonly-false-0ef2ff97-4141-42fd-a34f-47d6fd8f7d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083765491s
May 29 18:24:42.288: INFO: Pod "busybox-readonly-false-0ef2ff97-4141-42fd-a34f-47d6fd8f7d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125911847s
May 29 18:24:44.330: INFO: Pod "busybox-readonly-false-0ef2ff97-4141-42fd-a34f-47d6fd8f7d5f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167893912s
May 29 18:24:46.372: INFO: Pod "busybox-readonly-false-0ef2ff97-4141-42fd-a34f-47d6fd8f7d5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.209847335s
May 29 18:24:46.372: INFO: Pod "busybox-readonly-false-0ef2ff97-4141-42fd-a34f-47d6fd8f7d5f" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:24:46.372: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "security-context-test-1480" for this suite.
May 29 18:24:52.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:24:54.151: INFO: namespace security-context-test-1480 deletion completed in 7.7357446s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl cluster-info[0m 
  [1mshould check if Kubernetes master services is included in cluster-info  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:24:54.151: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: validating cluster-info
May 29 18:24:54.351: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config cluster-info'
May 29 18:24:55.114: INFO: stderr: ""
May 29 18:24:55.114: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://146.148.105.213\x1b[0m\n\x1b[0;32mGLBCDefaultBackend\x1b[0m is running at \x1b[0;33mhttps://146.148.105.213/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://146.148.105.213/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://146.148.105.213/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://146.148.105.213/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://146.148.105.213/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:24:55.114: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-3868" for this suite.
May 29 18:25:01.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:25:02.899: INFO: namespace kubectl-3868 deletion completed in 7.741364577s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command that always fails in a pod[0m 
  [1mshould be possible to delete [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:25:02.899: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[AfterEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:25:03.197: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubelet-test-9136" for this suite.
May 29 18:25:09.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:25:11.094: INFO: namespace kubelet-test-9136 deletion completed in 7.854553735s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:25:11.094: INFO: Driver emptydir doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:25:11.096: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver emptydir doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:25:11.097: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating secret with name secret-test-d5d568e7-0ab3-4f23-83e7-3bb96bce3722
[1mSTEP[0m: Creating a pod to test consume secrets
May 29 18:25:11.357: INFO: Waiting up to 5m0s for pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db" in namespace "secrets-208" to be "success or failure"
May 29 18:25:11.398: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db": Phase="Pending", Reason="", readiness=false. Elapsed: 41.354815ms
May 29 18:25:13.440: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083042287s
May 29 18:25:15.482: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125210405s
May 29 18:25:17.524: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167096569s
May 29 18:25:19.566: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db": Phase="Pending", Reason="", readiness=false. Elapsed: 8.20928414s
May 29 18:25:21.608: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db": Phase="Running", Reason="", readiness=true. Elapsed: 10.251033597s
May 29 18:25:23.650: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db": Phase="Running", Reason="", readiness=true. Elapsed: 12.292793892s
May 29 18:25:25.691: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.334443204s
[1mSTEP[0m: Saw pod success
May 29 18:25:25.691: INFO: Pod "pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db" satisfied condition "success or failure"
May 29 18:25:25.733: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 18:25:25.867: INFO: Waiting for pod pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db to disappear
May 29 18:25:25.908: INFO: Pod pod-secrets-d2128228-862a-4e52-8183-1c1b39efa9db no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:25:25.909: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-208" for this suite.
May 29 18:25:32.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:25:33.670: INFO: namespace secrets-208 deletion completed in 7.716953154s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:25:33.671: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:25:33.671: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:25:33.672: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:25:33.673: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:25:33.673: INFO: Driver aws doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:25:33.674: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver aws doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:25:33.674: INFO: Driver aws doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:25:33.675: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver aws doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:25:33.676: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 18:25:33.892: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27" in namespace "downward-api-5777" to be "success or failure"
May 29 18:25:33.933: INFO: Pod "downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27": Phase="Pending", Reason="", readiness=false. Elapsed: 41.549829ms
May 29 18:25:35.978: INFO: Pod "downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086014878s
May 29 18:25:38.020: INFO: Pod "downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128733603s
May 29 18:25:40.062: INFO: Pod "downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.170606329s
[1mSTEP[0m: Saw pod success
May 29 18:25:40.062: INFO: Pod "downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27" satisfied condition "success or failure"
May 29 18:25:40.104: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 18:25:40.208: INFO: Waiting for pod downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27 to disappear
May 29 18:25:40.249: INFO: Pod downwardapi-volume-53e02ba5-fbab-484a-b6fb-3dd006a6ff27 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:25:40.249: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-5777" for this suite.
May 29 18:25:46.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:25:48.012: INFO: namespace downward-api-5777 deletion completed in 7.720986939s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for the cluster  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-network] DNS
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:25:48.013: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;check="$$(dig +notcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/wheezy_udp@google.com;check="$$(dig +tcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@google.com;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7660.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;check="$$(dig +notcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/jessie_udp@google.com;check="$$(dig +tcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/jessie_tcp@google.com;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7660.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
May 29 18:26:00.651: INFO: Unable to read wheezy_tcp@google.com from pod dns-7660/dns-test-a2d867b5-2d07-41c3-89db-b5776fd04ad2: the server could not find the requested resource (get pods dns-test-a2d867b5-2d07-41c3-89db-b5776fd04ad2)
May 29 18:26:01.056: INFO: Lookups using dns-7660/dns-test-a2d867b5-2d07-41c3-89db-b5776fd04ad2 failed for: [wheezy_tcp@google.com]

May 29 18:26:06.620: INFO: DNS probes using dns-7660/dns-test-a2d867b5-2d07-41c3-89db-b5776fd04ad2 succeeded

[1mSTEP[0m: deleting the pod
[AfterEach] [sig-network] DNS
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:06.675: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "dns-7660" for this suite.
May 29 18:26:12.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:26:14.453: INFO: namespace dns-7660 deletion completed in 7.734389317s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:26:14.454: INFO: Driver hostPathSymlink doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:14.454: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver hostPathSymlink doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:26:14.455: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:14.456: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:26:14.457: INFO: Driver csi-hostpath-v0 doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:14.458: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver csi-hostpath-v0 doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:26:14.459: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:14.460: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:26:14.460: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:14.461: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:26:14.461: INFO: Driver aws doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:14.462: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver aws doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:26:14.462: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:14.463: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow composing env vars into new env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Variable Expansion
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:26:14.464: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test env composition
May 29 18:26:14.715: INFO: Waiting up to 5m0s for pod "var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3" in namespace "var-expansion-6944" to be "success or failure"
May 29 18:26:14.757: INFO: Pod "var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3": Phase="Pending", Reason="", readiness=false. Elapsed: 42.159893ms
May 29 18:26:16.799: INFO: Pod "var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083963103s
May 29 18:26:18.841: INFO: Pod "var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125848122s
May 29 18:26:20.883: INFO: Pod "var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.167675846s
[1mSTEP[0m: Saw pod success
May 29 18:26:20.883: INFO: Pod "var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3" satisfied condition "success or failure"
May 29 18:26:20.924: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-1vjk pod var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3 container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 29 18:26:21.034: INFO: Waiting for pod var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3 to disappear
May 29 18:26:21.076: INFO: Pod var-expansion-9b778d94-283b-495c-ae9e-784c9bed6ba3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:26:21.076: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "var-expansion-6944" for this suite.
May 29 18:26:27.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:26:28.892: INFO: namespace var-expansion-6944 deletion completed in 7.774075871s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould be consumable via the environment [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:26:28.892: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating secret secrets-7539/secret-test-0eeb754a-8acb-4665-b3d2-fe9991ca1501
[1mSTEP[0m: Creating a pod to test consume secrets
May 29 18:26:29.153: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9" in namespace "secrets-7539" to be "success or failure"
May 29 18:26:29.195: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 41.621797ms
May 29 18:26:31.237: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083525594s
May 29 18:26:33.279: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126024805s
May 29 18:26:35.322: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168178264s
May 29 18:26:37.364: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210120655s
May 29 18:26:39.406: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.252266674s
May 29 18:26:41.448: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.294193815s
May 29 18:26:43.490: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.336106603s
May 29 18:26:45.531: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.377786334s
May 29 18:26:47.574: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.420196944s
May 29 18:26:49.616: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.462464586s
May 29 18:26:51.658: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.504430645s
May 29 18:26:53.700: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.546549143s
May 29 18:26:55.742: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.588380381s
May 29 18:26:57.784: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.630100939s
May 29 18:26:59.825: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 30.671709988s
May 29 18:27:01.867: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 32.713554613s
May 29 18:27:03.909: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 34.755249897s
May 29 18:27:05.951: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 36.797061972s
May 29 18:27:07.993: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 38.839530814s
May 29 18:27:10.035: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 40.881494771s
May 29 18:27:12.077: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 42.923137426s
May 29 18:27:14.119: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 44.965491809s
May 29 18:27:16.161: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 47.007369063s
May 29 18:27:18.202: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 49.048931372s
May 29 18:27:20.244: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 51.090776915s
May 29 18:27:22.286: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 53.132953s
May 29 18:27:24.328: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 55.174616516s
May 29 18:27:26.370: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 57.216197037s
May 29 18:27:28.412: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 59.258327305s
May 29 18:27:30.454: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.300373216s
May 29 18:27:32.496: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.342502455s
May 29 18:27:34.538: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.384370016s
May 29 18:27:36.580: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.426768601s
May 29 18:27:38.623: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.469360928s
May 29 18:27:40.665: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.511074546s
May 29 18:27:42.706: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.552817547s
May 29 18:27:44.748: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.59487771s
May 29 18:27:46.792: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.638566283s
May 29 18:27:48.841: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.687872731s
May 29 18:27:50.883: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.729761894s
May 29 18:27:52.926: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.772521782s
May 29 18:27:54.969: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.815325364s
May 29 18:27:57.011: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.857798512s
May 29 18:27:59.053: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.899571919s
May 29 18:28:01.095: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.941562143s
May 29 18:28:03.137: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.983677438s
May 29 18:28:05.179: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.025726149s
May 29 18:28:07.221: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.067326931s
May 29 18:28:09.263: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.109366341s
May 29 18:28:11.305: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.151554213s
May 29 18:28:13.347: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.193338308s
May 29 18:28:15.389: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.235346878s
May 29 18:28:17.431: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.277170167s
May 29 18:28:19.473: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.31921121s
May 29 18:28:21.515: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.361181525s
May 29 18:28:23.557: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.403783488s
May 29 18:28:25.600: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.446112536s
May 29 18:28:27.642: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.488113419s
May 29 18:28:29.685: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.531149425s
May 29 18:28:31.727: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.573256211s
May 29 18:28:33.769: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.615637176s
May 29 18:28:35.811: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.657312017s
May 29 18:28:37.868: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.714475752s
May 29 18:28:39.911: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.757122787s
May 29 18:28:41.953: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.799043723s
May 29 18:28:43.994: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.840861453s
May 29 18:28:46.036: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.882990295s
May 29 18:28:48.078: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.924672664s
May 29 18:28:50.120: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.966411348s
May 29 18:28:52.161: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m23.007836747s
May 29 18:28:54.203: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.049730197s
May 29 18:28:56.245: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.091894109s
May 29 18:28:58.287: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.133977135s
May 29 18:29:00.330: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.176046069s
May 29 18:29:02.372: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.218287976s
May 29 18:29:04.414: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.260047748s
May 29 18:29:06.456: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.302090745s
May 29 18:29:08.501: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.347078572s
May 29 18:29:10.544: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.390354883s
May 29 18:29:12.587: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.433586695s
May 29 18:29:14.629: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.475660146s
May 29 18:29:16.671: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.517336142s
May 29 18:29:18.716: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.562675485s
May 29 18:29:20.758: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.60449557s
May 29 18:29:22.800: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.646352978s
May 29 18:29:24.844: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.690619238s
May 29 18:29:26.887: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.733457135s
May 29 18:29:28.932: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.778947026s
May 29 18:29:30.974: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.820721852s
May 29 18:29:33.016: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.862417789s
May 29 18:29:35.057: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.903408555s
May 29 18:29:37.099: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.945353057s
May 29 18:29:39.144: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.990485595s
May 29 18:29:41.186: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.03236799s
May 29 18:29:43.228: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.074197779s
May 29 18:29:45.269: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.115826802s
May 29 18:29:47.312: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.158556844s
May 29 18:29:49.354: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.200664267s
May 29 18:29:51.396: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.242674121s
May 29 18:29:53.438: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.284632973s
May 29 18:29:55.480: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.326685312s
May 29 18:29:57.522: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.368958846s
May 29 18:29:59.565: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.411429862s
May 29 18:30:01.607: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.453635578s
May 29 18:30:03.649: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.495394703s
May 29 18:30:05.691: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.537604055s
May 29 18:30:07.733: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.579416476s
May 29 18:30:09.775: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 3m40.621196318s
[1mSTEP[0m: Saw pod success
May 29 18:30:09.775: INFO: Pod "pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9" satisfied condition "success or failure"
May 29 18:30:09.817: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9 container env-test: <nil>
[1mSTEP[0m: delete the pod
May 29 18:30:09.921: INFO: Waiting for pod pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9 to disappear
May 29 18:30:09.962: INFO: Pod pod-configmaps-ab9c535a-b17f-4aaf-a9b4-290055144bc9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:30:09.963: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-7539" for this suite.
May 29 18:30:16.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:30:17.728: INFO: namespace secrets-7539 deletion completed in 7.723169634s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be updated [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:30:17.729: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
May 29 18:30:26.727: INFO: Successfully updated pod "pod-update-82c8f952-8b60-4daa-bb7a-62973920d456"
[1mSTEP[0m: verifying the updated pod is in kubernetes
May 29 18:30:26.810: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:30:26.810: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-8527" for this suite.
May 29 18:31:28.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:31:30.571: INFO: namespace pods-8527 deletion completed in 1m3.717915274s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:31:30.572: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-4a6e87aa-8964-4b75-b610-4087f4f1823d
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-45abb2dc-a14d-4146-8ece-b2f7ecf4ec25
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-4a6e87aa-8964-4b75-b610-4087f4f1823d
[1mSTEP[0m: Updating configmap cm-test-opt-upd-45abb2dc-a14d-4146-8ece-b2f7ecf4ec25
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-b5a7a2e8-f8ee-4827-a450-f80b5a838315
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:32:59.415: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-3076" for this suite.
May 29 18:33:21.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:33:23.213: INFO: namespace configmap-3076 deletion completed in 23.755197686s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould adopt matching pods on creation [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] ReplicationController
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:33:23.213: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Given a Pod with a 'name' label pod-adoption is created
[1mSTEP[0m: When a replication controller with a matching selector is created
[1mSTEP[0m: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:36:13.646: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 18:36:13.689: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 18:35:18 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 18:35:20 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "replication-controller-217" for this suite.
May 29 18:46:13.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:46:14.287: INFO: namespace: replication-controller-217, resource: pods, items remaining: 1
May 29 18:46:15.497: INFO: namespace: replication-controller-217, DeletionTimetamp: 2019-05-29 18:36:13 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 29 18:46:15.538: INFO: namespace: replication-controller-217, total namespaces: 5, active: 4, terminating: 1
May 29 18:46:15.580: INFO: POD           NODE                                            PHASE    GRACE  CONDITIONS
May 29 18:46:15.580: INFO: pod-adoption  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:33:23 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:36:11 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:36:11 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:33:23 -0700 PDT  }]
May 29 18:46:15.580: INFO: 
May 29 18:46:15.580: INFO: Couldn't delete ns: "replication-controller-217": namespace replication-controller-217 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace replication-controller-217 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})

[91m[1m• Failure in Spec Teardown (AfterEach) [772.368 seconds][0m
[sig-apps] ReplicationController
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [91m[1mshould adopt matching pods on creation [Conformance] [AfterEach][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mMay 29 18:46:15.580: Couldn't delete ns: "replication-controller-217": namespace replication-controller-217 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace replication-controller-217 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:46:15.582: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward api env vars
May 29 18:46:15.806: INFO: Waiting up to 5m0s for pod "downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a" in namespace "downward-api-1603" to be "success or failure"
May 29 18:46:15.848: INFO: Pod "downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a": Phase="Pending", Reason="", readiness=false. Elapsed: 41.733391ms
May 29 18:46:17.890: INFO: Pod "downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083803967s
May 29 18:46:19.931: INFO: Pod "downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125324859s
May 29 18:46:21.973: INFO: Pod "downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.166989479s
May 29 18:46:24.015: INFO: Pod "downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.208984163s
[1mSTEP[0m: Saw pod success
May 29 18:46:24.015: INFO: Pod "downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a" satisfied condition "success or failure"
May 29 18:46:24.057: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 29 18:46:24.170: INFO: Waiting for pod downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a to disappear
May 29 18:46:24.212: INFO: Pod downward-api-6535621f-5cf4-4ed9-84aa-56dcaad1764a no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:46:24.212: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-1603" for this suite.
May 29 18:46:30.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:46:31.967: INFO: namespace downward-api-1603 deletion completed in 7.711260375s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:46:31.967: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:46:31.968: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should support proportional scaling [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:46:31.969: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
[It] deployment should support proportional scaling [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 18:46:32.166: INFO: Creating deployment "nginx-deployment"
May 29 18:46:32.212: INFO: Waiting for observed generation 1
May 29 18:46:32.273: INFO: Waiting for all required pods to come up
May 29 18:46:32.343: INFO: Pod name nginx: Found 10 pods out of 10
[1mSTEP[0m: ensuring each pod is running
May 29 18:50:16.489: INFO: Waiting for deployment "nginx-deployment" to complete
May 29 18:50:16.572: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 29 18:50:16.659: INFO: Updating deployment nginx-deployment
May 29 18:50:16.659: INFO: Waiting for observed generation 2
May 29 18:50:18.771: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 29 18:50:18.812: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 29 18:50:18.854: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 29 18:50:18.981: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 29 18:50:18.981: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 29 18:50:19.022: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 29 18:50:19.106: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 29 18:50:19.106: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 29 18:50:19.192: INFO: Updating deployment nginx-deployment
May 29 18:50:19.192: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 29 18:50:19.408: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 29 18:50:19.527: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:60
May 29 18:50:19.679: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8098,SelfLink:/apis/apps/v1/namespaces/deployment-8098/deployments/nginx-deployment,UID:faf9c5f5-af8d-4765-936f-249bfc515663,ResourceVersion:27780,Generation:3,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-29 18:50:19 -0700 PDT 2019-05-29 18:50:19 -0700 PDT MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-29 18:50:19 -0700 PDT 2019-05-29 18:46:32 -0700 PDT ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 29 18:50:19.749: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-8098,SelfLink:/apis/apps/v1/namespaces/deployment-8098/replicasets/nginx-deployment-5f9595f595,UID:b11d3d7c-754b-4483-829d-79e13af353bb,ResourceVersion:27777,Generation:3,CreationTimestamp:2019-05-29 18:50:16 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment faf9c5f5-af8d-4765-936f-249bfc515663 0xc002d24a17 0xc002d24a18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 18:50:19.749: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 29 18:50:19.749: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f,GenerateName:,Namespace:deployment-8098,SelfLink:/apis/apps/v1/namespaces/deployment-8098/replicasets/nginx-deployment-56d49d846f,UID:4ae537a1-8507-4ab7-8edd-bb00240a7dbe,ResourceVersion:27770,Generation:3,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment faf9c5f5-af8d-4765-936f-249bfc515663 0xc002d24947 0xc002d24948}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 29 18:50:19.805: INFO: Pod "nginx-deployment-56d49d846f-478tn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-478tn,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-478tn,UID:c01610b1-63eb-49c6-b4cf-b693db74367d,ResourceVersion:27769,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e4e27 0xc0027e4e28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e4e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e4eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.806: INFO: Pod "nginx-deployment-56d49d846f-6wqpl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-6wqpl,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-6wqpl,UID:a1f7a87f-81f8-44a6-92ff-0deba40e7430,ResourceVersion:27388,Generation:0,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e4f30 0xc0027e4f31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e4f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e4fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:48:16 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:48:16 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:10.64.1.73,StartTime:2019-05-29 18:46:32 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 18:46:39 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/nginx:1.14-alpine docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 docker://91367311d7c4ed595116b998f84e5e1befb9120c767b88a45bca4c35ec9f8e1d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.806: INFO: Pod "nginx-deployment-56d49d846f-7r6nf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-7r6nf,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-7r6nf,UID:c2c8f25a-bfaf-4f14-9315-3dec1e797e05,ResourceVersion:27788,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5080 0xc0027e5081}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e50e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.806: INFO: Pod "nginx-deployment-56d49d846f-c9bfj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-c9bfj,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-c9bfj,UID:acce8aac-d43c-4d18-9093-40c2a94b5676,ResourceVersion:27149,Generation:0,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e51c0 0xc0027e51c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:42 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:42 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:10.64.3.64,StartTime:2019-05-29 18:46:32 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 18:46:39 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/nginx:1.14-alpine docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 docker://64a934e3a8361d08b48b269e4fc00b0fd241ad22d7ae3c3f4d3bebe20402bcaa}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.806: INFO: Pod "nginx-deployment-56d49d846f-cr4g7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-cr4g7,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-cr4g7,UID:eff1d11d-3f38-4fc9-bbf2-d8529588e540,ResourceVersion:27768,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5330 0xc0027e5331}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e53a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e53d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.806: INFO: Pod "nginx-deployment-56d49d846f-gdvgw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-gdvgw,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-gdvgw,UID:5013f608-da1b-43bf-a960-642deb85c44a,ResourceVersion:27789,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5480 0xc0027e5481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e54f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.807: INFO: Pod "nginx-deployment-56d49d846f-hmthd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-hmthd,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-hmthd,UID:022154b8-6d19-4e8b-9ba5-172b49a5241d,ResourceVersion:27173,Generation:0,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e55e0 0xc0027e55e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:10.64.2.33,StartTime:2019-05-29 18:46:32 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 18:46:42 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/nginx:1.14-alpine docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 docker://f76ca6d6a0dbaa0274aa4f92058f288bdb571281ae0df6a16d863f8c01c4e98c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.807: INFO: Pod "nginx-deployment-56d49d846f-jb85c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-jb85c,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-jb85c,UID:f87a678e-f099-458d-a912-6b111d0e688a,ResourceVersion:27786,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5740 0xc0027e5741}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e57a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e57d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.807: INFO: Pod "nginx-deployment-56d49d846f-jntv7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-jntv7,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-jntv7,UID:86cb66bf-4312-40e1-8c1b-29b5dbac1b5c,ResourceVersion:27167,Generation:0,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e58a0 0xc0027e58a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:46 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:46 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:10.64.2.30,StartTime:2019-05-29 18:46:32 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 18:46:42 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/nginx:1.14-alpine docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 docker://e880b88d157e06fef112385e309673d46ddf0d8b217be217dd2308a32e02f5f4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.807: INFO: Pod "nginx-deployment-56d49d846f-mv9sq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-mv9sq,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-mv9sq,UID:ad9905e0-df39-43ba-8f78-bad7ca199b30,ResourceVersion:27163,Generation:0,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5a20 0xc0027e5a21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:46 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:46 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:10.64.2.31,StartTime:2019-05-29 18:46:32 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 18:46:42 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/nginx:1.14-alpine docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 docker://b6f9736a071f416213966f6c81395d2dcdc06d43f8a7d420b9d204b4869b4b02}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.807: INFO: Pod "nginx-deployment-56d49d846f-nbjw6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-nbjw6,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-nbjw6,UID:f8d7218b-277e-49de-92ec-9ecf5013bb2e,ResourceVersion:27782,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5ba0 0xc0027e5ba1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.808: INFO: Pod "nginx-deployment-56d49d846f-nbwf5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-nbwf5,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-nbwf5,UID:3b4bfce6-a0c2-477e-95a3-2e920cc7baaf,ResourceVersion:27153,Generation:0,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5cf0 0xc0027e5cf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:43 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:43 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:10.64.3.66,StartTime:2019-05-29 18:46:32 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 18:46:39 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/nginx:1.14-alpine docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 docker://9c85aa99e327eee54e662d3e1248c481ffd74d4f7a2d99ce09855cdb17c3fecb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.808: INFO: Pod "nginx-deployment-56d49d846f-ng7qv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-ng7qv,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-ng7qv,UID:47e6fef7-84bd-4bad-8aae-43f98ec4ad9c,ResourceVersion:27764,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5e40 0xc0027e5e41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027e5ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.808: INFO: Pod "nginx-deployment-56d49d846f-nnnwr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-nnnwr,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-nnnwr,UID:821b1dff-cb1b-4853-ab74-bb861cb36bb3,ResourceVersion:27778,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0027e5f80 0xc0027e5f81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027e5fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dc000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.808: INFO: Pod "nginx-deployment-56d49d846f-qgzps" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-qgzps,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-qgzps,UID:2c1c80a3-5ea0-44d5-9b04-b68b87572f18,ResourceVersion:27145,Generation:0,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0021dc0c0 0xc0021dc0c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dc120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dc140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:42 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:42 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:10.64.3.65,StartTime:2019-05-29 18:46:32 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 18:46:39 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/nginx:1.14-alpine docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 docker://c357cd722259ca5fe52291b3cdab0a5ab7d1c785ae2fe5a7e4f542a86d159fa3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.809: INFO: Pod "nginx-deployment-56d49d846f-rbz8x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-rbz8x,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-rbz8x,UID:bb0e786d-4000-48a1-8894-486186f8cf8a,ResourceVersion:27779,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0021dc230 0xc0021dc231}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dc290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dc2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.809: INFO: Pod "nginx-deployment-56d49d846f-rk69f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-rk69f,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-rk69f,UID:5f2bb5c4-0077-4f0c-8ea6-568c40ba6057,ResourceVersion:27743,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0021dc390 0xc0021dc391}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dc410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dc430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.809: INFO: Pod "nginx-deployment-56d49d846f-rsjpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-rsjpt,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-rsjpt,UID:133b7a9c-9f5b-4292-b8a5-13022882d1d5,ResourceVersion:27177,Generation:0,CreationTimestamp:2019-05-29 18:46:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0021dc510 0xc0021dc511}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dc580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dc5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:48 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:48 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:46:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:10.64.2.32,StartTime:2019-05-29 18:46:32 -0700 PDT,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-29 18:46:42 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/nginx:1.14-alpine docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 docker://200d6967ec35c3236c00700187bd1caaaaec348ae190857b1688095c3d785776}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.809: INFO: Pod "nginx-deployment-56d49d846f-vpckk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-vpckk,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-vpckk,UID:d7816905-df7b-43da-8dd5-3018a34d1690,ResourceVersion:27772,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0021dc670 0xc0021dc671}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dc6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dc700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.809: INFO: Pod "nginx-deployment-56d49d846f-wxrtq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-56d49d846f-wxrtq,GenerateName:nginx-deployment-56d49d846f-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-56d49d846f-wxrtq,UID:7f21b488-ae4c-4cc5-9ae8-ef8d5d9ff2a8,ResourceVersion:27783,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 56d49d846f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-56d49d846f 4ae537a1-8507-4ab7-8edd-bb00240a7dbe 0xc0021dc7e0 0xc0021dc7e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dc850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dc880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.810: INFO: Pod "nginx-deployment-5f9595f595-7sb27" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-7sb27,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-7sb27,UID:8f8490ec-f609-4bc5-8a01-0de2881995f8,ResourceVersion:27773,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dc960 0xc0021dc961}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dc9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dca10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.810: INFO: Pod "nginx-deployment-5f9595f595-7vch4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-7vch4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-7vch4,UID:7d5d54c8-32d9-4ed6-b4aa-41d58570eaa4,ResourceVersion:27785,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dcaa0 0xc0021dcaa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dcb10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dcb30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.810: INFO: Pod "nginx-deployment-5f9595f595-85hs7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-85hs7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-85hs7,UID:d267e7ad-d920-4cbf-8e47-5f0cac5d7767,ResourceVersion:27787,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dcc10 0xc0021dcc11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dcc80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dcca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.810: INFO: Pod "nginx-deployment-5f9595f595-88xwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-88xwg,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-88xwg,UID:227455bc-9a56-4381-9f63-98e732d7fa82,ResourceVersion:27699,Generation:0,CreationTimestamp:2019-05-29 18:50:16 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dcda0 0xc0021dcda1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dce30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dce50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:,StartTime:2019-05-29 18:50:16 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.810: INFO: Pod "nginx-deployment-5f9595f595-bvgkr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-bvgkr,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-bvgkr,UID:cba8a095-f7dd-423e-9f2d-8bff1657851d,ResourceVersion:27713,Generation:0,CreationTimestamp:2019-05-29 18:50:16 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dcf40 0xc0021dcf41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dcfb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dcfd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:,StartTime:2019-05-29 18:50:16 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.811: INFO: Pod "nginx-deployment-5f9595f595-jg62p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-jg62p,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-jg62p,UID:1cce260b-b7b4-4b0b-92b7-0dc8df7e1e04,ResourceVersion:27781,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dd0a0 0xc0021dd0a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dd120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dd150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.811: INFO: Pod "nginx-deployment-5f9595f595-nrg2l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-nrg2l,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-nrg2l,UID:1781da23-32f0-43f3-bab8-63c2e6435322,ResourceVersion:27790,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dd230 0xc0021dd231}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dd2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dd2f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.811: INFO: Pod "nginx-deployment-5f9595f595-p58q7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-p58q7,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-p58q7,UID:067d9d49-647b-47b4-865b-cb67cfe53a88,ResourceVersion:27776,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dd400 0xc0021dd401}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dd470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dd490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.811: INFO: Pod "nginx-deployment-5f9595f595-qs4tw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-qs4tw,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-qs4tw,UID:a4b5c0d3-bc50-498d-81fa-323017c0678e,ResourceVersion:27692,Generation:0,CreationTimestamp:2019-05-29 18:50:16 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dd560 0xc0021dd561}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dd5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dd5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:,StartTime:2019-05-29 18:50:16 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.812: INFO: Pod "nginx-deployment-5f9595f595-rqzfh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-rqzfh,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-rqzfh,UID:610009bb-7a44-4a67-9e20-65b9fd6ee995,ResourceVersion:27698,Generation:0,CreationTimestamp:2019-05-29 18:50:16 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dd6e0 0xc0021dd6e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dd750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dd770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:,StartTime:2019-05-29 18:50:16 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.812: INFO: Pod "nginx-deployment-5f9595f595-rzdlx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-rzdlx,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-rzdlx,UID:7437f570-2fa0-493b-aa3f-c8eeb56cbcae,ResourceVersion:27774,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dd870 0xc0021dd871}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-9q9v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dd8f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dd910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.4,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.812: INFO: Pod "nginx-deployment-5f9595f595-s22bz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-s22bz,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-s22bz,UID:28f37c9d-d341-40e0-a524-9fa259bc58d3,ResourceVersion:27711,Generation:0,CreationTimestamp:2019-05-29 18:50:16 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021dd9f0 0xc0021dd9f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021dda60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021dda80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:16 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:,StartTime:2019-05-29 18:50:16 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 29 18:50:19.813: INFO: Pod "nginx-deployment-5f9595f595-svtp8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-svtp8,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8098,SelfLink:/api/v1/namespaces/deployment-8098/pods/nginx-deployment-5f9595f595-svtp8,UID:2529dc4a-cf9c-442d-9405-4d521031d7f0,ResourceVersion:27784,Generation:0,CreationTimestamp:2019-05-29 18:50:19 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 b11d3d7c-754b-4483-829d-79e13af353bb 0xc0021ddb50 0xc0021ddb51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9jn52 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9jn52,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9jn52 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021ddbc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021ddbe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:50:19 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:,StartTime:2019-05-29 18:50:19 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:50:19.813: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-8098" for this suite.
May 29 18:50:27.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:50:29.628: INFO: namespace deployment-8098 deletion completed in 9.763345539s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl replace[0m 
  [1mshould update a single-container pod's image  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:50:29.628: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl replace
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1635
[It] should update a single-container pod's image  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: running the image e2eteam/nginx:1.14-alpine
May 29 18:50:29.802: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config run e2e-test-nginx-pod --generator=run-pod/v1 --image=e2eteam/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-876'
May 29 18:50:32.054: INFO: stderr: ""
May 29 18:50:32.055: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod is running
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod was created
May 29 18:50:42.105: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pod e2e-test-nginx-pod --namespace=kubectl-876 -o json'
May 29 18:50:42.353: INFO: stderr: ""
May 29 18:50:42.353: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-30T01:50:32Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-876\",\n        \"resourceVersion\": \"27950\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-876/pods/e2e-test-nginx-pod\",\n        \"uid\": \"b5112993-0c8d-41b9-a7fd-b631353a8874\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"e2eteam/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-lv74w\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"e2e-test-peterhornyack-windows-node-group-9q9v\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-lv74w\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-lv74w\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-30T01:50:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-30T01:50:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-30T01:50:39Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-30T01:50:32Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://65458ed017eed0ff83e4567a74227e148acff3305dd9f51ac627bdbb7e1c6244\",\n                \"image\": \"e2eteam/nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-30T01:50:37Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.40.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.64.3.79\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-30T01:50:31Z\"\n    }\n}\n"
[1mSTEP[0m: replace the image in the pod
May 29 18:50:42.354: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config replace -f - --namespace=kubectl-876'
May 29 18:50:42.769: INFO: stderr: ""
May 29 18:50:42.769: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
[1mSTEP[0m: verifying the pod e2e-test-nginx-pod has the right image e2eteam/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1640
May 29 18:50:42.811: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete pods e2e-test-nginx-pod --namespace=kubectl-876'
May 29 18:50:53.469: INFO: stderr: ""
May 29 18:50:53.469: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:50:53.469: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-876" for this suite.
May 29 18:50:59.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:51:01.261: INFO: namespace kubectl-876 deletion completed in 7.748257026s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu request [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:51:01.261: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 18:51:01.532: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae" in namespace "downward-api-9185" to be "success or failure"
May 29 18:51:01.639: INFO: Pod "downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae": Phase="Pending", Reason="", readiness=false. Elapsed: 107.090179ms
May 29 18:51:03.682: INFO: Pod "downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.150008906s
May 29 18:51:05.725: INFO: Pod "downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.192463341s
May 29 18:51:07.767: INFO: Pod "downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae": Phase="Running", Reason="", readiness=true. Elapsed: 6.23459745s
May 29 18:51:09.810: INFO: Pod "downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae": Phase="Running", Reason="", readiness=true. Elapsed: 8.277972346s
May 29 18:51:11.852: INFO: Pod "downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.320193201s
[1mSTEP[0m: Saw pod success
May 29 18:51:11.852: INFO: Pod "downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae" satisfied condition "success or failure"
May 29 18:51:11.894: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 18:51:11.994: INFO: Waiting for pod downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae to disappear
May 29 18:51:12.035: INFO: Pod downwardapi-volume-a9992912-b313-4e58-81da-e7a2c0f5ecae no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:51:12.036: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-9185" for this suite.
May 29 18:51:18.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:51:19.801: INFO: namespace downward-api-9185 deletion completed in 7.718237702s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:51:19.802: INFO: Driver gluster doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:51:19.802: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver gluster doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen running a container with a new image[0m 
  [1mshould be able to pull image from gcr.io [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:369[0m
[BeforeEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:51:19.803: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to pull image from gcr.io [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:369
[1mSTEP[0m: create the container
[1mSTEP[0m: check the container status
[1mSTEP[0m: delete the container
[AfterEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:56:19.300: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 18:56:19.344: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 18:55:20 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 18:55:25 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "container-runtime-127" for this suite.
May 29 18:56:25.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:56:27.062: INFO: namespace container-runtime-127 deletion completed in 7.717895877s

[32m• [SLOW TEST:307.259 seconds][0m
[k8s.io] Container Runtime
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  blackbox test
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37[0m
    when running a container with a new image
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:248[0m
      should be able to pull image from gcr.io [NodeConformance]
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:369[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:56:27.062: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:56:27.063: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould invoke init containers on a RestartNever pod [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:56:27.065: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
May 29 18:56:27.264: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:56:39.711: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "init-container-1524" for this suite.
May 29 18:56:45.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:56:47.468: INFO: namespace init-container-1524 deletion completed in 7.715052767s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy logs on node using proxy subresource  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] version v1
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:56:47.468: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 18:56:47.762: INFO: (0) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 48.61461ms)
May 29 18:56:47.806: INFO: (1) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.156816ms)
May 29 18:56:47.850: INFO: (2) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.275544ms)
May 29 18:56:47.895: INFO: (3) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.742161ms)
May 29 18:56:47.939: INFO: (4) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.480171ms)
May 29 18:56:47.984: INFO: (5) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 45.409956ms)
May 29 18:56:48.029: INFO: (6) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.697488ms)
May 29 18:56:48.073: INFO: (7) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.65955ms)
May 29 18:56:48.117: INFO: (8) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.129099ms)
May 29 18:56:48.161: INFO: (9) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.129247ms)
May 29 18:56:48.205: INFO: (10) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.013175ms)
May 29 18:56:48.248: INFO: (11) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.344076ms)
May 29 18:56:48.292: INFO: (12) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.922433ms)
May 29 18:56:48.336: INFO: (13) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.494504ms)
May 29 18:56:48.380: INFO: (14) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.368516ms)
May 29 18:56:48.425: INFO: (15) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.583155ms)
May 29 18:56:48.469: INFO: (16) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.647221ms)
May 29 18:56:48.513: INFO: (17) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 43.752722ms)
May 29 18:56:48.565: INFO: (18) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 52.822169ms)
May 29 18:56:48.610: INFO: (19) /api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="fluentd-buffers/">fluentd-buffers/</a>
<a hr... (200; 44.546225ms)
[AfterEach] version v1
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:56:48.610: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "proxy-867" for this suite.
May 29 18:56:54.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:56:56.379: INFO: namespace proxy-867 deletion completed in 7.727214723s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:56:56.380: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:56:56.381: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen running a container with a new image[0m 
  [1mshould be able to pull from private registry with secret [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:397[0m
[BeforeEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:56:56.382: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to pull from private registry with secret [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:397
[1mSTEP[0m: create image pull secret
[1mSTEP[0m: create the container
[1mSTEP[0m: check the container status
[1mSTEP[0m: delete the container
[AfterEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:57:03.106: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-runtime-4946" for this suite.
May 29 18:57:09.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:57:10.879: INFO: namespace container-runtime-4946 deletion completed in 7.730872164s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:57:10.880: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:57:10.881: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:57:10.882: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:57:10.883: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:57:10.884: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:58:11.141: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-1431" for this suite.
May 29 18:58:33.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 18:58:34.913: INFO: namespace container-probe-1431 deletion completed in 23.728857947s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:58:34.913: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:58:34.915: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:58:34.917: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:58:34.918: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 18:58:34.919: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 18:58:34.920: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 18:58:34.920: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating the pod
May 29 19:00:21.983: INFO: Successfully updated pod "annotationupdateb44af120-cf01-497b-88f1-4589a4971d27"
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "downward-api-7812".
[1mSTEP[0m: Found 5 events.
May 29 19:03:22.027: INFO: At 2019-05-29 18:58:35 -0700 PDT - event for annotationupdateb44af120-cf01-497b-88f1-4589a4971d27: {default-scheduler } Scheduled: Successfully assigned downward-api-7812/annotationupdateb44af120-cf01-497b-88f1-4589a4971d27 to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:03:22.027: INFO: At 2019-05-29 18:58:37 -0700 PDT - event for annotationupdateb44af120-cf01-497b-88f1-4589a4971d27: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 29 19:03:22.027: INFO: At 2019-05-29 18:58:37 -0700 PDT - event for annotationupdateb44af120-cf01-497b-88f1-4589a4971d27: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container client-container
May 29 19:03:22.027: INFO: At 2019-05-29 18:58:39 -0700 PDT - event for annotationupdateb44af120-cf01-497b-88f1-4589a4971d27: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container client-container
May 29 19:03:22.027: INFO: At 2019-05-29 19:00:25 -0700 PDT - event for annotationupdateb44af120-cf01-497b-88f1-4589a4971d27: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod downward-api-7812/annotationupdateb44af120-cf01-497b-88f1-4589a4971d27
May 29 19:03:22.115: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 29 19:03:22.115: INFO: annotationupdateb44af120-cf01-497b-88f1-4589a4971d27   e2e-test-peterhornyack-windows-node-group-jpxd  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:58:35 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:00:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:00:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 18:58:35 -0700 PDT  }]
May 29 19:03:22.115: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:03:22.115: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 19:03:22.115: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:03:22.115: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:03:22.115: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:03:22.115: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:03:22.115: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:03:22.115: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 19:03:22.115: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 19:03:22.115: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 19:03:22.115: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 19:03:22.115: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:03:22.115: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 19:03:22.115: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 19:03:22.115: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:03:22.115: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 19:03:22.115: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 19:03:22.115: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:03:22.115: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:03:22.115: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:03:22.115: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:03:22.116: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:03:22.116: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:03:22.116: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 19:03:22.116: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 19:03:22.116: INFO: 
May 29 19:03:22.158: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 19:03:22.200: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:29866,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:03:18 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:03:18 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:03:18 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:03:18 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 19:03:22.200: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 19:03:22.242: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 19:03:22.294: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.294: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.294: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.294: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 19:03:22.294: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:03:22.295: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.295: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.295: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.295: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 19:03:22.295: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:03:22.295: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.295: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.295: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.295: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.444: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 19:03:22.444: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 19:03:22.486: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:29808,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{KernelDeadlock False 2019-05-29 19:02:47 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 19:02:47 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 19:02:47 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 19:02:47 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 19:02:47 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 19:02:47 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 19:02:47 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:02:53 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:02:53 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:02:53 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:02:53 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 19:03:22.486: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 19:03:22.527: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 19:03:22.587: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:03:22.587: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 19:03:22.587: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.587: INFO: 	Container event-exporter ready: true, restart count 0
May 29 19:03:22.587: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:03:22.587: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:03:22.587: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 19:03:22.587: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.587: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 19:03:22.587: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:03:22.587: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.587: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:03:22.587: INFO: 	Container coredns ready: true, restart count 0
May 29 19:03:22.587: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:03:22.588: INFO: 	Container autoscaler ready: true, restart count 0
May 29 19:03:22.588: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:03:22.588: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 19:03:22.588: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.588: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 19:03:22.588: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:03:22.738: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 19:03:22.738: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 19:03:22.779: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:29789,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentKubeletRestart False 2019-05-29 19:02:45 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 19:02:45 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 19:02:45 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 19:02:45 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 19:02:45 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 19:02:45 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 19:02:45 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:02:24 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:02:24 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:02:24 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:02:24 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 19:03:22.780: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 19:03:22.821: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 19:03:22.879: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.879: INFO: 	Container heapster ready: true, restart count 0
May 29 19:03:22.879: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 19:03:22.879: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 19:03:22.879: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.879: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 19:03:22.879: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:03:22.879: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.879: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 19:03:22.879: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:03:22.879: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 19:03:22.879: INFO: 	Container coredns ready: true, restart count 0
May 29 19:03:22.879: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 19:03:22.879: INFO: 	Container metrics-server ready: true, restart count 0
May 29 19:03:22.879: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 19:03:23.045: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 19:03:23.045: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 19:03:23.086: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:29848,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:03:10 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:03:10 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:03:10 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:03:10 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 19:03:23.087: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 19:03:23.128: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 19:03:23.334: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 19:03:23.334: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 19:03:23.376: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:29754,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:02:30 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:02:30 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:02:30 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:02:30 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 19:03:23.376: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 19:03:23.417: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 19:03:23.622: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 19:03:23.622: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:03:23.664: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:29878,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 19:03:21 -0700 PDT}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:03:21 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:03:21 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:03:21 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready False 2019-05-29 19:03:21 -0700 PDT 2019-05-29 19:03:21 -0700 PDT KubeletNotReady PLEG is not healthy: pleg was last seen active 3m2.5161199s ago; threshold is 3m0s.}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 19:03:23.665: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:03:23.706: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:03:23.750: INFO: annotationupdateb44af120-cf01-497b-88f1-4589a4971d27 started at 2019-05-29 18:58:35 -0700 PDT (0+1 container statuses recorded)
May 29 19:03:23.750: INFO: 	Container client-container ready: true, restart count 0
May 29 19:03:23.957: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:03:23.957: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 19:03:24.000: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false instead of true. Reason: KubeletNotReady, message: PLEG is not healthy: pleg was last seen active 3m2.5161199s ago; threshold is 3m0s.
[1mSTEP[0m: Destroying namespace "downward-api-7812" for this suite.
May 29 19:13:24.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 19:13:25.775: INFO: Couldn't delete ns: "downward-api-7812": namespace downward-api-7812 was not deleted with limit: timed out waiting for the condition, namespace is empty but is not yet removed (&errors.errorString{s:"namespace downward-api-7812 was not deleted with limit: timed out waiting for the condition, namespace is empty but is not yet removed"})

[91m[1m• Failure [890.856 seconds][0m
[sig-storage] Downward API volume
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34[0m
  [91m[1mshould update annotations on modification [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mTimed out after 180.001s.
  Expected
      <string>: content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T01:58:35.0388835Z"
      kubernetes.io/config.source="api"
      
  to contain substring
      <string>: builder="foo"
      [0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:181
[90m------------------------------[0m
[0m[k8s.io] Docker Containers[0m 
  [1mshould use the image defaults if command and args are blank [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Docker Containers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 19:13:25.777: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename containers
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test use defaults
May 29 19:13:26.028: INFO: Waiting up to 5m0s for pod "client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0" in namespace "containers-4264" to be "success or failure"
May 29 19:13:26.070: INFO: Pod "client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0": Phase="Pending", Reason="", readiness=false. Elapsed: 41.542423ms
May 29 19:13:28.112: INFO: Pod "client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083219159s
May 29 19:13:30.153: INFO: Pod "client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.124902368s
May 29 19:13:32.195: INFO: Pod "client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.166747425s
May 29 19:13:34.237: INFO: Pod "client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.208910554s
[1mSTEP[0m: Saw pod success
May 29 19:13:34.238: INFO: Pod "client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0" satisfied condition "success or failure"
May 29 19:13:34.279: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0 container test-container: <nil>
[1mSTEP[0m: delete the pod
May 29 19:13:34.382: INFO: Waiting for pod client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0 to disappear
May 29 19:13:34.423: INFO: Pod client-containers-afa55fd3-dfb5-41ee-9051-5b7851cee9a0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:13:34.423: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "containers-4264" for this suite.
May 29 19:13:40.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 19:13:42.178: INFO: namespace containers-4264 deletion completed in 7.713002539s
[32m•[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:13:42.178: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:13:42.179: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:13:42.179: INFO: Driver emptydir doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:13:42.180: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver emptydir doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:13:42.180: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:13:42.181: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:13:42.181: INFO: Driver csi-hostpath doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:13:42.181: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver csi-hostpath doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:13:42.182: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:13:42.182: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute poststart exec hook properly [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 19:13:42.182: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: check poststart hook
[1mSTEP[0m: delete the pod with lifecycle hook
May 29 19:22:26.824: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:26.866: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:28.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:28.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:30.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:30.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:32.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:32.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:34.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:34.913: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:36.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:36.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:38.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:38.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:40.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:40.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:42.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:42.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:44.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:44.909: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:46.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:46.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:48.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:48.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:50.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:50.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:52.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:52.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:54.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:54.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:56.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:56.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:22:58.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:22:58.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:00.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:00.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:02.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:02.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:04.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:04.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:06.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:06.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:08.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:08.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:10.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:10.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:12.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:12.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:14.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:14.911: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:16.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:16.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:18.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:18.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:20.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:20.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:22.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:22.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:24.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:24.913: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:26.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:26.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:28.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:28.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:30.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:30.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:32.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:32.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:34.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:34.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:36.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:36.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:38.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:38.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:40.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:40.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:42.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:42.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:44.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:44.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:46.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:46.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:48.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:48.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:50.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:50.913: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:52.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:52.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:54.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:54.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:56.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:56.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:23:58.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:23:58.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:00.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:00.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:02.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:02.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:04.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:04.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:06.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:06.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:08.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:08.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:10.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:10.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:12.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:12.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:14.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:14.913: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:16.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:16.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:18.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:18.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:20.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:20.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:22.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:22.909: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:24.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:24.909: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:26.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:26.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:28.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:28.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:30.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:30.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:32.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:32.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:34.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:34.910: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:36.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:36.909: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:38.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:38.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:40.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:40.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:42.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:42.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:44.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:44.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:46.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:46.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:48.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:48.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:50.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:50.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:52.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:52.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:54.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:54.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:56.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:56.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:24:58.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:24:58.909: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:00.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:00.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:02.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:02.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:04.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:04.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:06.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:06.907: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:08.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:08.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:10.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:10.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:12.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:12.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:14.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:14.912: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:16.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:16.915: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:18.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:18.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:20.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:20.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:22.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:22.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:24.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:24.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:26.866: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:26.908: INFO: Pod pod-with-poststart-exec-hook still exists
May 29 19:25:26.908: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 29 19:25:26.950: INFO: Pod pod-with-poststart-exec-hook still exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "container-lifecycle-hook-9969".
[1mSTEP[0m: Found 10 events.
May 29 19:25:26.993: INFO: At 2019-05-29 19:13:42 -0700 PDT - event for pod-handle-http-request: {default-scheduler } Scheduled: Successfully assigned container-lifecycle-hook-9969/pod-handle-http-request to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:25:26.993: INFO: At 2019-05-29 19:13:44 -0700 PDT - event for pod-handle-http-request: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/netexec:1.1" already present on machine
May 29 19:25:26.993: INFO: At 2019-05-29 19:13:44 -0700 PDT - event for pod-handle-http-request: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container pod-handle-http-request
May 29 19:25:26.993: INFO: At 2019-05-29 19:13:47 -0700 PDT - event for pod-handle-http-request: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container pod-handle-http-request
May 29 19:25:26.993: INFO: At 2019-05-29 19:16:35 -0700 PDT - event for pod-handle-http-request: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod container-lifecycle-hook-9969/pod-handle-http-request
May 29 19:25:26.993: INFO: At 2019-05-29 19:18:24 -0700 PDT - event for pod-with-poststart-exec-hook: {default-scheduler } Scheduled: Successfully assigned container-lifecycle-hook-9969/pod-with-poststart-exec-hook to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:25:26.993: INFO: At 2019-05-29 19:18:26 -0700 PDT - event for pod-with-poststart-exec-hook: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/hostexec:1.1" already present on machine
May 29 19:25:26.994: INFO: At 2019-05-29 19:18:26 -0700 PDT - event for pod-with-poststart-exec-hook: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container pod-with-poststart-exec-hook
May 29 19:25:26.994: INFO: At 2019-05-29 19:18:28 -0700 PDT - event for pod-with-poststart-exec-hook: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container pod-with-poststart-exec-hook
May 29 19:25:26.994: INFO: At 2019-05-29 19:20:35 -0700 PDT - event for pod-with-poststart-exec-hook: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod container-lifecycle-hook-9969/pod-with-poststart-exec-hook
May 29 19:25:27.082: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 29 19:25:27.082: INFO: pod-handle-http-request                                e2e-test-peterhornyack-windows-node-group-jpxd  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:13:42 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:18:24 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:18:24 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:13:42 -0700 PDT  }]
May 29 19:25:27.082: INFO: pod-with-poststart-exec-hook                           e2e-test-peterhornyack-windows-node-group-jpxd  Running  15s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:18:24 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:22:25 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:22:25 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:18:24 -0700 PDT  }]
May 29 19:25:27.082: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:25:27.082: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 19:25:27.082: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:25:27.082: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:25:27.082: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:25:27.082: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:25:27.082: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:25:27.082: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 19:25:27.082: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 19:25:27.082: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 19:25:27.082: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 19:25:27.082: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:25:27.082: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 19:25:27.082: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 19:25:27.083: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:25:27.083: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 19:25:27.083: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 19:25:27.083: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:25:27.083: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:25:27.083: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:25:27.083: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 19:25:27.083: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:25:27.083: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 19:25:27.083: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 19:25:27.083: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 19:25:27.083: INFO: 
May 29 19:25:27.125: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 19:25:27.173: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:33046,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:25:22 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:25:22 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:25:22 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:25:22 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 19:25:27.173: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 19:25:27.214: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 19:25:27.261: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.261: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.261: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 19:25:27.261: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:25:27.261: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.261: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.261: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.261: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.261: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.261: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.261: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.261: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 19:25:27.261: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:25:27.261: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.409: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 19:25:27.409: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 19:25:27.455: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:32999,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentDockerRestart False 2019-05-29 19:25:01 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 19:25:01 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 19:25:01 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 19:25:01 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 19:25:01 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 19:25:01 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 19:25:01 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:24:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:24:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:24:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:24:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 19:25:27.455: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 19:25:27.497: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 19:25:27.547: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:25:27.547: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 19:25:27.547: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.547: INFO: 	Container event-exporter ready: true, restart count 0
May 29 19:25:27.547: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:25:27.547: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:25:27.547: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 19:25:27.547: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.547: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 19:25:27.547: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:25:27.547: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.547: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:25:27.547: INFO: 	Container coredns ready: true, restart count 0
May 29 19:25:27.547: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:25:27.547: INFO: 	Container autoscaler ready: true, restart count 0
May 29 19:25:27.547: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 19:25:27.547: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 19:25:27.547: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.547: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 19:25:27.548: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:25:27.698: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 19:25:27.698: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 19:25:27.740: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:33056,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{ReadonlyFilesystem False 2019-05-29 19:24:58 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 19:24:58 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 19:24:58 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 19:24:58 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 19:24:58 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 19:24:58 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 19:24:58 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:25:27 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:25:27 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:25:27 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:25:27 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 19:25:27.740: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 19:25:27.782: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 19:25:27.832: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.832: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 19:25:27.832: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:25:27.832: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 19:25:27.832: INFO: 	Container coredns ready: true, restart count 0
May 29 19:25:27.832: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.832: INFO: 	Container metrics-server ready: true, restart count 0
May 29 19:25:27.832: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 19:25:27.832: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.832: INFO: 	Container heapster ready: true, restart count 0
May 29 19:25:27.832: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 19:25:27.832: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 19:25:27.832: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 19:25:27.832: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 19:25:27.832: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 19:25:27.991: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 19:25:27.991: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 19:25:28.033: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:33022,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:25:12 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:25:12 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:25:12 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:25:12 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 19:25:28.033: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 19:25:28.074: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 19:25:28.278: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 19:25:28.278: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 19:25:28.319: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:32927,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:24:31 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:24:31 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:24:31 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:24:31 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 19:25:28.320: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 19:25:28.361: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 19:25:28.568: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 19:25:28.568: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:25:28.610: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:32937,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 19:24:33 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 19:24:33 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 19:24:33 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 19:24:33 -0700 PDT 2019-05-29 19:24:33 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 19:25:28.610: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:25:28.651: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:25:28.700: INFO: pod-handle-http-request started at 2019-05-29 19:13:42 -0700 PDT (0+1 container statuses recorded)
May 29 19:25:28.700: INFO: 	Container pod-handle-http-request ready: true, restart count 0
May 29 19:25:28.700: INFO: pod-with-poststart-exec-hook started at 2019-05-29 19:18:24 -0700 PDT (0+1 container statuses recorded)
May 29 19:25:28.700: INFO: 	Container pod-with-poststart-exec-hook ready: true, restart count 0
May 29 19:25:32.784: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 19:25:32.784: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-lifecycle-hook-9969" for this suite.
May 29 19:35:32.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 19:35:34.382: INFO: namespace: container-lifecycle-hook-9969, resource: pods, items remaining: 2
May 29 19:35:34.632: INFO: namespace: container-lifecycle-hook-9969, DeletionTimetamp: 2019-05-29 19:25:32 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 29 19:35:34.673: INFO: namespace: container-lifecycle-hook-9969, total namespaces: 5, active: 4, terminating: 1
May 29 19:35:34.717: INFO: POD                           NODE                                            PHASE    GRACE  CONDITIONS
May 29 19:35:34.717: INFO: pod-handle-http-request       e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:13:42 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:34:28 -0700 PDT ContainersNotReady containers with unready status: [pod-handle-http-request]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:34:28 -0700 PDT ContainersNotReady containers with unready status: [pod-handle-http-request]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:13:42 -0700 PDT  }]
May 29 19:35:34.717: INFO: pod-with-poststart-exec-hook  e2e-test-peterhornyack-windows-node-group-jpxd  Running  15s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:18:24 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:22:25 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:22:25 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 19:18:24 -0700 PDT  }]
May 29 19:35:34.717: INFO: 
May 29 19:35:34.717: INFO: Couldn't delete ns: "container-lifecycle-hook-9969": namespace container-lifecycle-hook-9969 was not deleted with limit: timed out waiting for the condition, pods remaining: 2 (&errors.errorString{s:"namespace container-lifecycle-hook-9969 was not deleted with limit: timed out waiting for the condition, pods remaining: 2"})

[91m[1m• Failure [1312.536 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  when create a pod with lifecycle hook
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    [91m[1mshould execute poststart exec hook properly [NodeConformance] [Conformance] [It][0m
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mwait for pod "pod-with-poststart-exec-hook" to disappear
    Expected success, but got an error:
        <*errors.errorString | 0xc0002b5440>: {
            s: "timed out waiting for the condition",
        }
        timed out waiting for the condition[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:177
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:35:34.718: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:35:34.719: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:35:34.720: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:35:34.721: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:35:34.722: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:35:34.722: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 19:35:34.723: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name projected-configmap-test-volume-map-083b13a6-682f-421b-9d74-bc31c4e25349
[1mSTEP[0m: Creating a pod to test consume configMaps
May 29 19:35:34.981: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40" in namespace "projected-1207" to be "success or failure"
May 29 19:35:35.023: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40": Phase="Pending", Reason="", readiness=false. Elapsed: 41.995465ms
May 29 19:35:37.065: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083758673s
May 29 19:35:39.107: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125876291s
May 29 19:35:41.149: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168097603s
May 29 19:35:43.191: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40": Phase="Running", Reason="", readiness=true. Elapsed: 8.210271181s
May 29 19:35:45.239: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40": Phase="Running", Reason="", readiness=true. Elapsed: 10.258357622s
May 29 19:35:47.292: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40": Phase="Running", Reason="", readiness=true. Elapsed: 12.311390062s
May 29 19:35:49.337: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.356467004s
[1mSTEP[0m: Saw pod success
May 29 19:35:49.337: INFO: Pod "pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40" satisfied condition "success or failure"
May 29 19:35:49.379: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40 container projected-configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 19:35:49.484: INFO: Waiting for pod pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40 to disappear
May 29 19:35:49.525: INFO: Pod pod-projected-configmaps-2c6d0556-2cc4-4920-b02d-9bcec46a9d40 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:35:49.525: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 19:35:49.568: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 19:35:35 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 19:35:35 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "projected-1207" for this suite.
May 29 19:35:55.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 19:35:57.278: INFO: namespace projected-1207 deletion completed in 7.709505513s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 19:35:57.278: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating the pod
May 29 19:36:06.291: INFO: Successfully updated pod "labelsupdate00558040-9f55-48a3-8504-53ae2df8cbad"
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:36:08.392: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 19:36:08.435: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 19:35:35 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 19:35:35 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "downward-api-2368" for this suite.
May 29 19:36:28.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 19:36:30.145: INFO: namespace downward-api-2368 deletion completed in 21.709961426s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:36:30.146: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:36:30.147: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:36:30.148: INFO: Driver emptydir doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:36:30.150: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver emptydir doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 19:36:30.151: INFO: Driver csi-hostpath doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:36:30.153: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver csi-hostpath doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:89[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 19:36:30.153: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:89
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-953cfdc5-840d-465b-99df-77472eb71b15
[1mSTEP[0m: Creating a pod to test consume secrets
May 29 19:36:30.620: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae" in namespace "projected-2571" to be "success or failure"
May 29 19:36:30.662: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae": Phase="Pending", Reason="", readiness=false. Elapsed: 41.479249ms
May 29 19:36:32.703: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083330189s
May 29 19:36:34.745: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12513133s
May 29 19:36:36.787: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae": Phase="Pending", Reason="", readiness=false. Elapsed: 6.166688731s
May 29 19:36:38.829: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae": Phase="Pending", Reason="", readiness=false. Elapsed: 8.208652848s
May 29 19:36:40.871: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae": Phase="Running", Reason="", readiness=true. Elapsed: 10.25069615s
May 29 19:36:42.913: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae": Phase="Running", Reason="", readiness=true. Elapsed: 12.292715327s
May 29 19:36:44.955: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.334628033s
[1mSTEP[0m: Saw pod success
May 29 19:36:44.955: INFO: Pod "pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae" satisfied condition "success or failure"
May 29 19:36:44.996: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 19:36:45.096: INFO: Waiting for pod pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae to disappear
May 29 19:36:45.138: INFO: Pod pod-projected-secrets-d72d3bdb-b190-400d-b7c6-e962618352ae no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 19:36:45.138: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-2571" for this suite.
May 29 19:36:51.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 19:36:52.895: INFO: namespace projected-2571 deletion completed in 7.714163425s
[1mSTEP[0m: Destroying namespace "secret-namespace-6494" for this suite.
May 29 19:36:59.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 19:37:00.622: INFO: namespace secret-namespace-6494 deletion completed in 7.726705674s
[32m•[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mScaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 19:37:00.622: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-5035
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Initializing watcher for selector baz=blah,foo=bar
[1mSTEP[0m: Creating stateful set ss in namespace statefulset-5035
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace statefulset-5035
May 29 19:37:01.001: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May 29 19:37:11.044: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 29 19:37:11.086: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-5035 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 19:37:11.744: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 19:37:11.744: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 19:37:11.744: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 19:37:11.786: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 29 19:37:21.829: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 19:37:21.829: INFO: Waiting for statefulset status.replicas updated to 0
May 29 19:37:22.001: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999549s
May 29 19:37:23.043: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.957605525s
May 29 19:37:24.086: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.915175158s
May 29 19:37:25.128: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.872687013s
May 29 19:37:26.170: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.83052385s
May 29 19:37:27.212: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.78862854s
May 29 19:37:28.254: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.746647667s
May 29 19:37:29.296: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.704379514s
May 29 19:37:30.338: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.662292055s
May 29 19:37:31.380: INFO: Verifying statefulset ss doesn't scale past 1 for another 620.325607ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5035
May 29 19:37:32.423: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-5035 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 19:37:33.099: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 19:37:33.099: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 19:37:33.099: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 19:37:33.141: INFO: Found 1 stateful pods, waiting for 3
May 29 19:37:43.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:37:53.183: INFO: Found 2 stateful pods, waiting for 3
May 29 19:38:03.183: INFO: Found 2 stateful pods, waiting for 3
May 29 19:38:13.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:38:23.183: INFO: Found 2 stateful pods, waiting for 3
May 29 19:38:33.183: INFO: Found 2 stateful pods, waiting for 3
May 29 19:38:43.191: INFO: Found 2 stateful pods, waiting for 3
May 29 19:38:53.187: INFO: Found 2 stateful pods, waiting for 3
May 29 19:39:03.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:39:13.191: INFO: Found 2 stateful pods, waiting for 3
May 29 19:39:23.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:39:33.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:39:43.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:39:53.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:40:03.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:40:13.184: INFO: Found 2 stateful pods, waiting for 3
May 29 19:40:23.185: INFO: Found 2 stateful pods, waiting for 3
May 29 19:40:33.184: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 19:40:33.184: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 19:40:33.184: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
May 29 19:40:43.183: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 19:40:43.183: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 19:40:43.183: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Verifying that stateful set ss was scaled up in order
[1mSTEP[0m: Scale down will halt with unhealthy stateful pod
May 29 19:40:43.266: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-5035 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 19:40:43.930: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 19:40:43.930: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 19:40:43.930: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 19:40:43.930: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-5035 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 19:40:44.569: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 19:40:44.569: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 19:40:44.569: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 19:40:44.570: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-5035 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 19:40:45.221: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 19:40:45.221: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 19:40:45.221: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 19:40:45.221: INFO: Waiting for statefulset status.replicas updated to 0
May 29 19:40:45.264: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 29 19:40:55.349: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 19:40:55.349: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 29 19:40:55.349: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 29 19:40:55.479: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999566s
May 29 19:40:56.522: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.957889865s
May 29 19:40:57.565: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.91530123s
May 29 19:40:58.608: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.872173526s
May 29 19:40:59.651: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.828770879s
May 29 19:41:00.693: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.786478537s
May 29 19:41:01.735: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.744424661s
May 29 19:41:02.778: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.702089458s
May 29 19:41:03.820: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.659387595s
May 29 19:41:04.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 616.77917ms
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5035
May 29 19:41:05.907: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-5035 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 19:41:06.567: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 19:41:06.567: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 19:41:06.567: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 19:41:06.567: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-5035 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 19:41:07.202: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 19:41:07.202: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 19:41:07.202: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 19:41:07.202: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-5035 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 19:41:07.845: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 19:41:07.845: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 19:41:07.845: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 19:41:07.846: INFO: Scaling statefulset ss to 0
[1mSTEP[0m: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 19:51:08.196: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe po ss-0 --namespace=statefulset-5035'
May 29 19:51:09.054: INFO: stderr: ""
May 29 19:51:09.054: INFO: stdout: "Name:               ss-0\nNamespace:          statefulset-5035\nPriority:           0\nPriorityClassName:  <none>\nNode:               e2e-test-peterhornyack-windows-node-group-1vjk/10.40.0.5\nStart Time:         Wed, 29 May 2019 19:37:00 -0700\nLabels:             baz=blah\n                    controller-revision-hash=ss-577b4dc465\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss-0\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.64.2.43\nControlled By:      StatefulSet/ss\nContainers:\n  nginx:\n    Container ID:   docker://07f4a1011da28ed59d9d89edf9bf2855c53966a75fb8366337007b424a1a3a60\n    Image:          e2eteam/nginx:1.14-alpine\n    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Wed, 29 May 2019 19:37:06 -0700\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-46t4t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-46t4t:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-46t4t\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type     Reason     Age                 From                                                     Message\n  ----     ------     ----                ----                                                     -------\n  Normal   Scheduled  14m                 default-scheduler                                        Successfully assigned statefulset-5035/ss-0 to e2e-test-peterhornyack-windows-node-group-1vjk\n  Normal   Pulled     14m                 kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Container image \"e2eteam/nginx:1.14-alpine\" already present on machine\n  Normal   Created    14m                 kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Created container nginx\n  Normal   Started    14m                 kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Started container nginx\n  Warning  Unhealthy  10m (x22 over 13m)  kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Readiness probe failed: HTTP probe failed with statuscode: 404\n"
May 29 19:51:09.054: INFO: 
Output of kubectl describe ss-0:
Name:               ss-0
Namespace:          statefulset-5035
Priority:           0
PriorityClassName:  <none>
Node:               e2e-test-peterhornyack-windows-node-group-1vjk/10.40.0.5
Start Time:         Wed, 29 May 2019 19:37:00 -0700
Labels:             baz=blah
                    controller-revision-hash=ss-577b4dc465
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss-0
Annotations:        <none>
Status:             Running
IP:                 10.64.2.43
Controlled By:      StatefulSet/ss
Containers:
  nginx:
    Container ID:   docker://07f4a1011da28ed59d9d89edf9bf2855c53966a75fb8366337007b424a1a3a60
    Image:          e2eteam/nginx:1.14-alpine
    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 29 May 2019 19:37:06 -0700
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-46t4t (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-46t4t:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-46t4t
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason     Age                 From                                                     Message
  ----     ------     ----                ----                                                     -------
  Normal   Scheduled  14m                 default-scheduler                                        Successfully assigned statefulset-5035/ss-0 to e2e-test-peterhornyack-windows-node-group-1vjk
  Normal   Pulled     14m                 kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Container image "e2eteam/nginx:1.14-alpine" already present on machine
  Normal   Created    14m                 kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Created container nginx
  Normal   Started    14m                 kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Started container nginx
  Warning  Unhealthy  10m (x22 over 13m)  kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Readiness probe failed: HTTP probe failed with statuscode: 404

May 29 19:51:09.055: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs ss-0 --namespace=statefulset-5035 --tail=100'
May 29 19:51:09.372: INFO: stderr: ""
May 29 19:51:09.372: INFO: stdout: ""
May 29 19:51:09.372: INFO: 
Last 100 log lines of ss-0:

May 29 19:51:09.372: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe po ss-1 --namespace=statefulset-5035'
May 29 19:51:09.728: INFO: stderr: ""
May 29 19:51:09.729: INFO: stdout: "Name:                      ss-1\nNamespace:                 statefulset-5035\nPriority:                  0\nPriorityClassName:         <none>\nNode:                      e2e-test-peterhornyack-windows-node-group-jpxd/10.40.0.3\nStart Time:                Wed, 29 May 2019 19:37:33 -0700\nLabels:                    baz=blah\n                           controller-revision-hash=ss-577b4dc465\n                           foo=bar\n                           statefulset.kubernetes.io/pod-name=ss-1\nAnnotations:               <none>\nStatus:                    Terminating (lasts 9m)\nTermination Grace Period:  30s\nIP:                        10.64.1.95\nControlled By:             StatefulSet/ss\nContainers:\n  nginx:\n    Container ID:   docker://fd4b03627891108f265d046e4993cc4ed93d96ee3ce06d2c438b8d9a50f362de\n    Image:          e2eteam/nginx:1.14-alpine\n    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Wed, 29 May 2019 19:37:38 -0700\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-46t4t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-46t4t:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-46t4t\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type     Reason     Age                 From                                                     Message\n  ----     ------     ----                ----                                                     -------\n  Normal   Scheduled  13m                 default-scheduler                                        Successfully assigned statefulset-5035/ss-1 to e2e-test-peterhornyack-windows-node-group-jpxd\n  Normal   Pulled     13m                 kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Container image \"e2eteam/nginx:1.14-alpine\" already present on machine\n  Normal   Created    13m                 kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Created container nginx\n  Normal   Started    13m                 kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Started container nginx\n  Warning  Unhealthy  10m (x22 over 10m)  kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Readiness probe failed: HTTP probe failed with statuscode: 404\n"
May 29 19:51:09.729: INFO: 
Output of kubectl describe ss-1:
Name:                      ss-1
Namespace:                 statefulset-5035
Priority:                  0
PriorityClassName:         <none>
Node:                      e2e-test-peterhornyack-windows-node-group-jpxd/10.40.0.3
Start Time:                Wed, 29 May 2019 19:37:33 -0700
Labels:                    baz=blah
                           controller-revision-hash=ss-577b4dc465
                           foo=bar
                           statefulset.kubernetes.io/pod-name=ss-1
Annotations:               <none>
Status:                    Terminating (lasts 9m)
Termination Grace Period:  30s
IP:                        10.64.1.95
Controlled By:             StatefulSet/ss
Containers:
  nginx:
    Container ID:   docker://fd4b03627891108f265d046e4993cc4ed93d96ee3ce06d2c438b8d9a50f362de
    Image:          e2eteam/nginx:1.14-alpine
    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 29 May 2019 19:37:38 -0700
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-46t4t (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-46t4t:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-46t4t
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason     Age                 From                                                     Message
  ----     ------     ----                ----                                                     -------
  Normal   Scheduled  13m                 default-scheduler                                        Successfully assigned statefulset-5035/ss-1 to e2e-test-peterhornyack-windows-node-group-jpxd
  Normal   Pulled     13m                 kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Container image "e2eteam/nginx:1.14-alpine" already present on machine
  Normal   Created    13m                 kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Created container nginx
  Normal   Started    13m                 kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Started container nginx
  Warning  Unhealthy  10m (x22 over 10m)  kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Readiness probe failed: HTTP probe failed with statuscode: 404

May 29 19:51:09.729: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs ss-1 --namespace=statefulset-5035 --tail=100'
May 29 19:51:10.031: INFO: stderr: ""
May 29 19:51:10.031: INFO: stdout: ""
May 29 19:51:10.031: INFO: 
Last 100 log lines of ss-1:

May 29 19:51:10.031: INFO: Deleting all statefulset in ns statefulset-5035
May 29 19:51:10.072: INFO: Scaling statefulset ss to 0
May 29 20:01:10.286: INFO: Waiting for statefulset status.replicas updated to 0
May 29 20:01:10.328: INFO: Waiting for stateful set status.replicas to become 0, currently 1
May 29 20:01:20.370: INFO: Waiting for stateful set status.replicas to become 0, currently 1
May 29 20:01:30.371: INFO: Waiting for stateful set status.replicas to become 0, currently 1
May 29 20:01:40.370: INFO: Deleting statefulset ss
May 29 20:01:40.506: INFO: Unexpected error occurred: Failed to scale statefulset to 0 in 10m0s. Remaining pods:
[ss-0: deletion 2019-05-29 20:01:07 -0700 PDT, phase Running, readiness false]
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "statefulset-5035".
[1mSTEP[0m: Found 24 events.
May 29 20:01:40.554: INFO: At 2019-05-29 19:37:00 -0700 PDT - event for ss: {statefulset-controller } SuccessfulCreate: create Pod ss-0 in StatefulSet ss successful
May 29 20:01:40.554: INFO: At 2019-05-29 19:37:00 -0700 PDT - event for ss-0: {default-scheduler } Scheduled: Successfully assigned statefulset-5035/ss-0 to e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:01:40.554: INFO: At 2019-05-29 19:37:03 -0700 PDT - event for ss-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 20:01:40.554: INFO: At 2019-05-29 19:37:03 -0700 PDT - event for ss-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Created: Created container nginx
May 29 20:01:40.555: INFO: At 2019-05-29 19:37:06 -0700 PDT - event for ss-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Started: Started container nginx
May 29 20:01:40.555: INFO: At 2019-05-29 19:37:12 -0700 PDT - event for ss-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Unhealthy: Readiness probe failed: HTTP probe failed with statuscode: 404
May 29 20:01:40.555: INFO: At 2019-05-29 19:37:33 -0700 PDT - event for ss: {statefulset-controller } SuccessfulCreate: create Pod ss-1 in StatefulSet ss successful
May 29 20:01:40.555: INFO: At 2019-05-29 19:37:33 -0700 PDT - event for ss-1: {default-scheduler } Scheduled: Successfully assigned statefulset-5035/ss-1 to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:01:40.555: INFO: At 2019-05-29 19:37:35 -0700 PDT - event for ss-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container nginx
May 29 20:01:40.555: INFO: At 2019-05-29 19:37:35 -0700 PDT - event for ss-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 20:01:40.555: INFO: At 2019-05-29 19:37:38 -0700 PDT - event for ss-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container nginx
May 29 20:01:40.555: INFO: At 2019-05-29 19:40:31 -0700 PDT - event for ss: {statefulset-controller } SuccessfulCreate: create Pod ss-2 in StatefulSet ss successful
May 29 20:01:40.555: INFO: At 2019-05-29 19:40:31 -0700 PDT - event for ss-2: {default-scheduler } Scheduled: Successfully assigned statefulset-5035/ss-2 to e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:01:40.555: INFO: At 2019-05-29 19:40:34 -0700 PDT - event for ss-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container nginx
May 29 20:01:40.555: INFO: At 2019-05-29 19:40:34 -0700 PDT - event for ss-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 20:01:40.555: INFO: At 2019-05-29 19:40:35 -0700 PDT - event for ss-1: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod statefulset-5035/ss-1
May 29 20:01:40.555: INFO: At 2019-05-29 19:40:37 -0700 PDT - event for ss-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container nginx
May 29 20:01:40.555: INFO: At 2019-05-29 19:40:44 -0700 PDT - event for ss-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Unhealthy: Readiness probe failed: HTTP probe failed with statuscode: 404
May 29 20:01:40.555: INFO: At 2019-05-29 19:40:46 -0700 PDT - event for ss-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Unhealthy: Readiness probe failed: HTTP probe failed with statuscode: 404
May 29 20:01:40.555: INFO: At 2019-05-29 19:41:07 -0700 PDT - event for ss: {statefulset-controller } SuccessfulDelete: delete Pod ss-2 in StatefulSet ss successful
May 29 20:01:40.555: INFO: At 2019-05-29 19:41:16 -0700 PDT - event for ss: {statefulset-controller } SuccessfulDelete: delete Pod ss-1 in StatefulSet ss successful
May 29 20:01:40.555: INFO: At 2019-05-29 19:52:33 -0700 PDT - event for ss-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Killing: Stopping container nginx
May 29 20:01:40.555: INFO: At 2019-05-29 20:00:37 -0700 PDT - event for ss: {statefulset-controller } SuccessfulDelete: delete Pod ss-0 in StatefulSet ss successful
May 29 20:01:40.555: INFO: At 2019-05-29 20:00:37 -0700 PDT - event for ss-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Killing: Stopping container nginx
May 29 20:01:40.643: INFO: POD                                                    NODE                                      PHASE    GRACE  CONDITIONS
May 29 20:01:40.643: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:01:40.643: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 20:01:40.643: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:01:40.643: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:01:40.643: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:01:40.643: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:01:40.643: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:01:40.643: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 20:01:40.643: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 20:01:40.643: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 20:01:40.643: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 20:01:40.643: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:01:40.644: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 20:01:40.644: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 20:01:40.644: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:01:40.644: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 20:01:40.644: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 20:01:40.644: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:01:40.644: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:01:40.644: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:01:40.644: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:01:40.644: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:01:40.644: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:01:40.644: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 20:01:40.644: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 20:01:40.644: INFO: 
May 29 20:01:40.687: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 20:01:40.728: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:38333,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:01:29 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:01:29 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:01:29 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:01:29 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:01:40.728: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 20:01:40.769: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 20:01:40.816: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:01:40.816: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:01:40.816: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:40.816: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:01:40.816: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:01:40.816: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:01:40.816: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:01:40.816: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:01:40.816: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:01:40.816: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:01:40.816: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:01:40.816: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:40.816: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:01:40.816: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:01:40.975: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 20:01:40.975: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:01:41.017: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:38325,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{KernelDeadlock False 2019-05-29 20:01:24 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 20:01:24 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 20:01:24 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 20:01:24 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 20:01:24 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 20:01:24 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 20:01:24 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:00:59 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:00:59 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:00:59 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:00:59 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:01:41.017: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:01:41.059: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:01:41.108: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 20:01:41.108: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:01:41.108: INFO: 	Container coredns ready: true, restart count 0
May 29 20:01:41.108: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:01:41.108: INFO: 	Container autoscaler ready: true, restart count 0
May 29 20:01:41.108: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:01:41.108: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 20:01:41.108: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:41.108: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:01:41.108: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:01:41.108: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:01:41.108: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 20:01:41.108: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:41.108: INFO: 	Container event-exporter ready: true, restart count 0
May 29 20:01:41.108: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:01:41.108: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:01:41.108: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 20:01:41.108: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:41.108: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:01:41.108: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:01:41.260: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:01:41.260: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:01:41.301: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:38338,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentDockerRestart False 2019-05-29 20:01:17 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 20:01:17 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 20:01:17 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 20:01:17 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 20:01:17 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 20:01:17 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 20:01:17 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:01:31 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:01:31 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:01:31 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:01:31 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:01:41.302: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:01:41.343: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:01:41.393: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:41.393: INFO: 	Container metrics-server ready: true, restart count 0
May 29 20:01:41.393: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 20:01:41.393: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:41.393: INFO: 	Container heapster ready: true, restart count 0
May 29 20:01:41.393: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 20:01:41.393: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 20:01:41.393: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:41.393: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:01:41.393: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:01:41.393: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 20:01:41.393: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:01:41.393: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:01:41.393: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 20:01:41.393: INFO: 	Container coredns ready: true, restart count 0
May 29 20:01:41.553: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:01:41.553: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:01:41.596: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:38303,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:01:15 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:01:15 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:01:15 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:01:15 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:01:41.596: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:01:41.638: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:01:41.841: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:01:41.841: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:01:41.883: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:38350,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:01:35 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:01:35 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:01:35 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:01:35 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:01:41.883: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:01:41.925: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:01:42.132: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:01:42.132: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:01:42.174: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:38357,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:01:37 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:01:37 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:01:37 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:01:37 -0700 PDT 2019-05-29 20:00:37 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:01:42.174: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:01:42.215: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:01:42.440: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:01:42.440: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-5035" for this suite.
May 29 20:01:48.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:01:50.206: INFO: namespace statefulset-5035 deletion completed in 7.723440297s

[91m[1m• Failure [1489.585 seconds][0m
[sig-apps] StatefulSet
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
    [91m[1mScaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance] [It][0m
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mUnexpected error:
        <*errors.errorString | 0xc0002b5ba0>: {
            s: "watch closed before UntilWithoutRetry timeout",
        }
        watch closed before UntilWithoutRetry timeout
    occurred[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:650
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:01:50.207: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename volume
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow exec of files on the volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167
[1mSTEP[0m: creating a test gce pd volume
W0529 20:01:50.406056   96922 gce_instances.go:280] Cloud object does not have informers set, should only happen in E2E binary.
May 29 20:01:53.070: INFO: Successfully created a new PD: "e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20".
May 29 20:01:53.070: INFO: Creating resource for inline volume
May 29 20:01:53.071: INFO: generated pod command echo "ls -n /vol1" > /vol1/test-gcepd-l7jb.ps1; .\/vol1/test-gcepd-l7jb.ps1
[1mSTEP[0m: Creating pod exec-volume-test-gcepd-l7jb
[1mSTEP[0m: Creating a pod to test exec-volume-test
May 29 20:01:53.118: INFO: Waiting up to 5m0s for pod "exec-volume-test-gcepd-l7jb" in namespace "volume-4561" to be "success or failure"
May 29 20:01:53.162: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 43.116792ms
May 29 20:01:55.203: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08464195s
May 29 20:01:57.245: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126708819s
May 29 20:01:59.291: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.172536897s
May 29 20:02:01.333: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.214316533s
May 29 20:02:03.375: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.256256917s
May 29 20:02:05.417: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.298354895s
May 29 20:02:07.459: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.340365789s
May 29 20:02:09.501: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.382371385s
May 29 20:02:11.543: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 18.424337778s
May 29 20:02:13.585: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 20.466076743s
May 29 20:02:15.627: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 22.508304768s
May 29 20:02:17.669: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.550730818s
May 29 20:02:19.713: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 26.594250532s
May 29 20:02:21.755: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 28.636358327s
May 29 20:02:23.797: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 30.678031746s
May 29 20:02:25.838: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 32.719811422s
May 29 20:02:27.881: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 34.762084036s
May 29 20:02:29.922: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 36.803338046s
May 29 20:02:31.964: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 38.845531086s
May 29 20:02:34.006: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 40.887546508s
May 29 20:02:36.048: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 42.929466196s
May 29 20:02:38.090: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 44.971172375s
May 29 20:02:40.132: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 47.013089271s
May 29 20:02:42.174: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 49.055069975s
May 29 20:02:44.216: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 51.097241076s
May 29 20:02:46.258: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 53.139309432s
May 29 20:02:48.300: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 55.181084349s
May 29 20:02:50.341: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 57.222894514s
May 29 20:02:52.383: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 59.264413596s
May 29 20:02:54.425: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.306807638s
May 29 20:02:56.467: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.34878785s
May 29 20:02:58.509: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.390988634s
May 29 20:03:00.551: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.432648602s
May 29 20:03:02.593: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.474693419s
May 29 20:03:04.641: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.522432603s
May 29 20:03:06.682: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.563724046s
May 29 20:03:08.724: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.605904082s
May 29 20:03:10.768: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.649280146s
May 29 20:03:12.811: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.692941851s
May 29 20:03:14.857: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.738809118s
May 29 20:03:16.899: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.780665088s
May 29 20:03:18.941: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.822830781s
May 29 20:03:20.983: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.864901184s
May 29 20:03:23.025: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.906798947s
May 29 20:03:25.067: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.948728983s
May 29 20:03:27.113: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.994178633s
May 29 20:03:29.159: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.040132687s
May 29 20:03:31.201: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.0822371s
May 29 20:03:33.243: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.124009688s
May 29 20:03:35.285: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.166174021s
May 29 20:03:37.327: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.208194467s
May 29 20:03:39.369: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.250506856s
May 29 20:03:41.411: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.29211818s
May 29 20:03:43.453: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.333996291s
May 29 20:03:45.495: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.376041939s
May 29 20:03:47.537: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.418421917s
May 29 20:03:49.581: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.462760336s
May 29 20:03:51.629: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.510464249s
May 29 20:03:53.671: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.552302836s
May 29 20:03:55.716: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.597534354s
May 29 20:03:57.758: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.63956338s
May 29 20:03:59.800: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.681599536s
May 29 20:04:01.842: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.723648308s
May 29 20:04:03.884: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.765380715s
May 29 20:04:05.928: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.80978815s
May 29 20:04:07.970: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.851820863s
May 29 20:04:10.012: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.893968205s
May 29 20:04:12.054: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.93566956s
May 29 20:04:14.096: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.9775965s
May 29 20:04:16.143: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m23.024962343s
May 29 20:04:18.186: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.067067398s
May 29 20:04:20.227: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.108728742s
May 29 20:04:22.269: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.150282152s
May 29 20:04:24.311: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.192188396s
May 29 20:04:26.353: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.23414893s
May 29 20:04:28.403: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.284637686s
May 29 20:04:30.445: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.326728358s
May 29 20:04:32.487: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.368220548s
May 29 20:04:34.529: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.410187649s
May 29 20:04:36.571: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.451998584s
May 29 20:04:38.613: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.494059846s
May 29 20:04:40.657: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.53878386s
May 29 20:04:42.699: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.580930511s
May 29 20:04:44.741: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.62268821s
May 29 20:04:46.783: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.664438057s
May 29 20:04:48.825: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.70638531s
May 29 20:04:50.867: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.748564355s
May 29 20:04:52.909: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.790710018s
May 29 20:04:54.950: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.831981512s
May 29 20:04:56.992: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.873786325s
May 29 20:04:59.033: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.91493734s
May 29 20:05:01.075: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.956835562s
May 29 20:05:03.117: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.998645343s
May 29 20:05:05.164: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.045536335s
May 29 20:05:07.206: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.087321908s
May 29 20:05:09.248: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.129536511s
May 29 20:05:11.291: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.172119977s
May 29 20:05:13.333: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.214325883s
May 29 20:05:15.375: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.256458835s
May 29 20:05:17.418: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.299083365s
May 29 20:05:19.460: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.341413739s
May 29 20:05:21.503: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.384122601s
May 29 20:05:23.545: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.426687564s
May 29 20:05:25.587: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.468896955s
May 29 20:05:27.630: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.511733602s
May 29 20:05:29.674: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.555616779s
May 29 20:05:31.724: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.605321566s
May 29 20:05:33.770: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.651570594s
May 29 20:05:35.812: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.693373631s
May 29 20:05:37.854: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.73544211s
May 29 20:05:39.896: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.777700654s
May 29 20:05:41.938: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.819648028s
May 29 20:05:43.980: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.861726329s
May 29 20:05:46.022: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.90380462s
May 29 20:05:48.064: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.945593455s
May 29 20:05:50.106: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.987777315s
May 29 20:05:52.148: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 3m59.02979085s
May 29 20:05:54.190: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m1.071656878s
May 29 20:05:56.232: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m3.113594547s
May 29 20:05:58.274: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m5.155213518s
May 29 20:06:00.316: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m7.197219138s
May 29 20:06:02.358: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m9.239302821s
May 29 20:06:04.400: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m11.281683964s
May 29 20:06:06.443: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m13.324272641s
May 29 20:06:08.485: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m15.366487042s
May 29 20:06:10.527: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m17.408846038s
May 29 20:06:12.570: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m19.451271159s
May 29 20:06:14.612: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m21.493383341s
May 29 20:06:16.654: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m23.535610765s
May 29 20:06:18.696: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m25.577600992s
May 29 20:06:20.738: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m27.619665953s
May 29 20:06:22.780: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m29.661683386s
May 29 20:06:24.822: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m31.703438025s
May 29 20:06:26.865: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m33.746780031s
May 29 20:06:28.907: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m35.788721075s
May 29 20:06:30.949: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m37.830626917s
May 29 20:06:32.991: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m39.872567876s
May 29 20:06:35.033: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m41.914707022s
May 29 20:06:37.075: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Pending", Reason="", readiness=false. Elapsed: 4m43.956583498s
May 29 20:06:39.117: INFO: Pod "exec-volume-test-gcepd-l7jb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4m45.998826625s
[1mSTEP[0m: Saw pod success
May 29 20:06:39.117: INFO: Pod "exec-volume-test-gcepd-l7jb" satisfied condition "success or failure"
May 29 20:06:39.159: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod exec-volume-test-gcepd-l7jb container exec-container-gcepd-l7jb: <nil>
[1mSTEP[0m: delete the pod
May 29 20:06:39.262: INFO: Waiting for pod exec-volume-test-gcepd-l7jb to disappear
May 29 20:06:39.306: INFO: Pod exec-volume-test-gcepd-l7jb no longer exists
[1mSTEP[0m: Deleting pod exec-volume-test-gcepd-l7jb
May 29 20:06:39.306: INFO: Deleting pod "exec-volume-test-gcepd-l7jb" in namespace "volume-4561"
May 29 20:06:40.431: INFO: error deleting PD "e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:06:40.431: INFO: Couldn't delete PD "e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:06:46.365: INFO: error deleting PD "e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:06:46.366: INFO: Couldn't delete PD "e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:06:52.281: INFO: error deleting PD "e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:06:52.281: INFO: Couldn't delete PD "e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:06:59.675: INFO: Successfully deleted PD "e2e-b6d8738a-b6e5-4fb9-a1db-811579ea2e20".
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:06:59.675: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "volume-4561" for this suite.
May 29 20:07:05.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:07:07.444: INFO: namespace volume-4561 deletion completed in 7.723980525s

[32m• [SLOW TEST:317.237 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gcepd]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      should allow exec of files on the volume
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 20:07:07.444: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:07:07.445: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 20:07:07.446: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:07:07.447: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 20:07:07.448: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:07:07.450: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:07:07.451: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename volume
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow exec of files on the volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167
[1mSTEP[0m: creating a test gce pd volume
W0529 20:07:07.621684   96922 gce_instances.go:280] Cloud object does not have informers set, should only happen in E2E binary.
May 29 20:07:10.163: INFO: Successfully created a new PD: "e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7".
May 29 20:07:10.163: INFO: Creating resource for pre-provisioned PV
May 29 20:07:10.163: INFO: Creating PVC and PV
May 29 20:07:10.163: INFO: AccessModes unspecified, default: all modes (RWO, RWX, ROX).
May 29 20:07:10.163: INFO: PV ReclaimPolicy unspecified, default: Retain
[1mSTEP[0m: Creating a PVC followed by a PV
May 29 20:07:10.651: INFO: Waiting for PV gcepd-l5hbj to bind to PVC pvc-s5j6l
May 29 20:07:10.651: INFO: Waiting up to 3m0s for PersistentVolumeClaims [pvc-s5j6l] to have phase Bound
May 29 20:07:10.696: INFO: PersistentVolumeClaim pvc-s5j6l found but phase is Pending instead of Bound.
May 29 20:07:12.738: INFO: PersistentVolumeClaim pvc-s5j6l found but phase is Pending instead of Bound.
May 29 20:07:14.780: INFO: PersistentVolumeClaim pvc-s5j6l found and phase=Bound (4.128727819s)
May 29 20:07:14.780: INFO: Waiting up to 3m0s for PersistentVolume gcepd-l5hbj to have phase Bound
May 29 20:07:14.826: INFO: PersistentVolume gcepd-l5hbj found and phase=Bound (45.372787ms)
May 29 20:07:14.908: INFO: generated pod command echo "ls -n /vol1" > /vol1/test-gcepd-preprovisionedpv-6bx5.ps1; .\/vol1/test-gcepd-preprovisionedpv-6bx5.ps1
[1mSTEP[0m: Creating pod exec-volume-test-gcepd-preprovisionedpv-6bx5
[1mSTEP[0m: Creating a pod to test exec-volume-test
May 29 20:07:14.959: INFO: Waiting up to 5m0s for pod "exec-volume-test-gcepd-preprovisionedpv-6bx5" in namespace "volume-1445" to be "success or failure"
May 29 20:07:15.020: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 60.997817ms
May 29 20:07:17.062: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.102893948s
May 29 20:07:19.104: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.14500013s
May 29 20:07:21.146: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.186610951s
May 29 20:07:23.188: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.228450515s
May 29 20:07:25.230: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.270589379s
May 29 20:07:27.272: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.312599022s
May 29 20:07:29.314: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.354304451s
May 29 20:07:31.356: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.39621482s
May 29 20:07:33.398: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.438288936s
May 29 20:07:35.442: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.482974574s
May 29 20:07:37.485: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.525456428s
May 29 20:07:39.527: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.567537946s
May 29 20:07:41.569: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.609458466s
May 29 20:07:43.611: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.651608546s
May 29 20:07:45.653: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.693671147s
May 29 20:07:47.696: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.736289624s
May 29 20:07:49.738: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.778532749s
May 29 20:07:51.781: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.82111442s
May 29 20:07:53.823: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.863273988s
May 29 20:07:55.864: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.905017044s
May 29 20:07:57.906: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.946440865s
May 29 20:07:59.948: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.988440971s
May 29 20:08:01.990: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 47.030604315s
May 29 20:08:04.032: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 49.072730866s
May 29 20:08:06.074: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 51.114626659s
May 29 20:08:08.117: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 53.157042089s
May 29 20:08:10.158: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 55.199023488s
May 29 20:08:12.201: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 57.241357446s
May 29 20:08:14.243: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 59.283462221s
May 29 20:08:16.285: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.325161906s
May 29 20:08:18.327: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.367200281s
May 29 20:08:20.369: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.409231198s
May 29 20:08:22.411: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.451179971s
May 29 20:08:24.453: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.493351122s
May 29 20:08:26.495: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.535703539s
May 29 20:08:28.537: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.577884527s
May 29 20:08:30.579: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.619722451s
May 29 20:08:32.623: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.663768937s
May 29 20:08:34.666: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.706476207s
May 29 20:08:36.708: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.748878028s
May 29 20:08:38.750: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.790811162s
May 29 20:08:40.793: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 1m25.833522428s
[1mSTEP[0m: Saw pod success
May 29 20:08:40.793: INFO: Pod "exec-volume-test-gcepd-preprovisionedpv-6bx5" satisfied condition "success or failure"
May 29 20:08:40.835: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod exec-volume-test-gcepd-preprovisionedpv-6bx5 container exec-container-gcepd-preprovisionedpv-6bx5: <nil>
[1mSTEP[0m: delete the pod
May 29 20:08:40.942: INFO: Waiting for pod exec-volume-test-gcepd-preprovisionedpv-6bx5 to disappear
May 29 20:08:40.983: INFO: Pod exec-volume-test-gcepd-preprovisionedpv-6bx5 no longer exists
[1mSTEP[0m: Deleting pod exec-volume-test-gcepd-preprovisionedpv-6bx5
May 29 20:08:40.984: INFO: Deleting pod "exec-volume-test-gcepd-preprovisionedpv-6bx5" in namespace "volume-1445"
[1mSTEP[0m: Deleting pv and pvc
May 29 20:08:41.025: INFO: Deleting PersistentVolumeClaim "pvc-s5j6l"
May 29 20:08:41.069: INFO: Deleting PersistentVolume "gcepd-l5hbj"
May 29 20:08:42.167: INFO: error deleting PD "e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:08:42.167: INFO: Couldn't delete PD "e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:08:48.132: INFO: error deleting PD "e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:08:48.133: INFO: Couldn't delete PD "e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:08:54.072: INFO: error deleting PD "e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:08:54.072: INFO: Couldn't delete PD "e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 29 20:09:01.650: INFO: Successfully deleted PD "e2e-12d178d0-c0c6-44ab-b15e-25093c104fd7".
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:09:01.650: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "volume-1445" for this suite.
May 29 20:09:07.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:09:09.410: INFO: namespace volume-1445 deletion completed in 7.715528612s
[32m•[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:09:09.410: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating secret with name secret-test-2ab88ccb-0494-4676-afac-def35452bead
[1mSTEP[0m: Creating a pod to test consume secrets
May 29 20:09:09.709: INFO: Waiting up to 5m0s for pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30" in namespace "secrets-5024" to be "success or failure"
May 29 20:09:09.751: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 41.77451ms
May 29 20:09:11.793: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083585919s
May 29 20:09:13.835: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126126908s
May 29 20:09:15.877: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168128819s
May 29 20:09:17.919: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210208675s
May 29 20:09:19.961: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 10.251861614s
May 29 20:09:22.003: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 12.294029025s
May 29 20:09:24.045: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 14.335984126s
May 29 20:09:26.087: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 16.377734252s
May 29 20:09:28.133: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 18.423523234s
May 29 20:09:30.174: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 20.465279786s
May 29 20:09:32.217: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 22.507292841s
May 29 20:09:34.259: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 24.549400315s
May 29 20:09:36.301: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 26.5918187s
May 29 20:09:38.343: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 28.634100575s
May 29 20:09:40.385: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 30.676149506s
May 29 20:09:42.427: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 32.718206561s
May 29 20:09:44.470: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 34.760428432s
May 29 20:09:46.511: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 36.802185053s
May 29 20:09:48.553: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 38.844015568s
May 29 20:09:50.595: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 40.886203686s
May 29 20:09:52.639: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 42.929343648s
May 29 20:09:54.698: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 44.98853899s
May 29 20:09:56.740: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 47.030700851s
May 29 20:09:58.782: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 49.072585528s
May 29 20:10:00.824: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 51.114721836s
May 29 20:10:02.866: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 53.156799472s
May 29 20:10:04.908: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 55.198936519s
May 29 20:10:06.951: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 57.241350857s
May 29 20:10:08.992: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 59.283272492s
May 29 20:10:11.035: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.325298248s
May 29 20:10:13.076: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.367052135s
May 29 20:10:15.118: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.408971929s
May 29 20:10:17.160: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.45059022s
May 29 20:10:19.201: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.492119813s
May 29 20:10:21.243: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.533694632s
May 29 20:10:23.285: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.575903461s
May 29 20:10:25.328: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.618657537s
May 29 20:10:27.370: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.661027465s
May 29 20:10:29.412: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.703042779s
May 29 20:10:31.454: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.745227028s
May 29 20:10:33.497: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.787374454s
May 29 20:10:35.538: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.829241497s
May 29 20:10:37.581: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.871751555s
May 29 20:10:39.623: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.913860265s
May 29 20:10:41.665: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.955707033s
May 29 20:10:43.707: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.997901415s
May 29 20:10:45.749: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.040108372s
May 29 20:10:47.791: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.081838607s
May 29 20:10:49.833: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.123816562s
May 29 20:10:51.875: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.165905711s
May 29 20:10:53.917: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.207676081s
May 29 20:10:55.958: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.249276819s
May 29 20:10:58.001: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.291395103s
May 29 20:11:00.043: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.333720062s
May 29 20:11:02.086: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.376567521s
May 29 20:11:04.128: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.41873872s
May 29 20:11:06.176: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.466362667s
May 29 20:11:08.221: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.51198842s
May 29 20:11:10.263: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.55331963s
May 29 20:11:12.304: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.594861383s
May 29 20:11:14.346: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.637111488s
May 29 20:11:16.398: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.688963897s
May 29 20:11:18.440: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.731237745s
May 29 20:11:20.483: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.773311502s
May 29 20:11:22.525: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.815300332s
May 29 20:11:24.568: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.859189962s
May 29 20:11:26.610: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.901130716s
May 29 20:11:28.652: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.94290417s
May 29 20:11:30.694: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.985263589s
May 29 20:11:32.740: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m23.030467486s
May 29 20:11:34.781: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.072095163s
May 29 20:11:36.823: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.113987071s
May 29 20:11:38.865: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.155857212s
May 29 20:11:40.907: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.1977835s
May 29 20:11:42.953: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.244066758s
May 29 20:11:44.995: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.285906655s
May 29 20:11:47.037: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.327778961s
May 29 20:11:49.079: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.36965149s
May 29 20:11:51.122: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.41252778s
May 29 20:11:53.164: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.454311933s
May 29 20:11:55.205: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.49627189s
May 29 20:11:57.248: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.538706782s
May 29 20:11:59.290: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.580802147s
May 29 20:12:01.337: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.628010265s
May 29 20:12:03.380: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.670582149s
May 29 20:12:05.422: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.71247858s
May 29 20:12:07.464: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.754554883s
May 29 20:12:09.505: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.796027768s
May 29 20:12:11.547: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.837981184s
May 29 20:12:13.589: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.880156283s
May 29 20:12:15.632: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.922451779s
May 29 20:12:17.674: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.964914693s
May 29 20:12:19.717: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.008087587s
May 29 20:12:21.759: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.049627988s
May 29 20:12:23.806: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.096571813s
May 29 20:12:25.850: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.140478885s
May 29 20:12:27.891: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.182072949s
May 29 20:12:29.933: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.224137121s
May 29 20:12:31.975: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.265651737s
May 29 20:12:34.017: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.30802623s
May 29 20:12:36.059: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.349844106s
May 29 20:12:38.101: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.391938594s
May 29 20:12:40.146: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.436628495s
May 29 20:12:42.188: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.478727468s
May 29 20:12:44.230: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.520865886s
May 29 20:12:46.273: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.56363506s
May 29 20:12:48.315: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.605312684s
May 29 20:12:50.356: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.647059891s
May 29 20:12:52.398: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.68881519s
May 29 20:12:54.444: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.734650923s
May 29 20:12:56.486: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.776507457s
May 29 20:12:58.528: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.818455012s
May 29 20:13:00.576: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.867096406s
May 29 20:13:02.624: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.914763259s
May 29 20:13:04.666: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.957059282s
May 29 20:13:06.708: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.998829246s
May 29 20:13:08.750: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 3m59.040831691s
May 29 20:13:10.792: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m1.082773946s
May 29 20:13:12.834: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m3.124832694s
May 29 20:13:14.876: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m5.166877494s
May 29 20:13:16.918: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m7.208420028s
May 29 20:13:18.960: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m9.250340809s
May 29 20:13:21.001: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m11.292164394s
May 29 20:13:23.043: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m13.334171128s
May 29 20:13:25.085: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m15.376216495s
May 29 20:13:27.129: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m17.420151667s
May 29 20:13:29.172: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m19.463102751s
May 29 20:13:31.216: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m21.506580949s
May 29 20:13:33.258: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m23.548726036s
May 29 20:13:35.300: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m25.590668271s
May 29 20:13:37.342: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m27.632508967s
May 29 20:13:39.384: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m29.674945505s
May 29 20:13:41.428: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m31.718694402s
May 29 20:13:43.470: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m33.760581291s
May 29 20:13:45.511: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m35.802182265s
May 29 20:13:47.554: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m37.844468598s
May 29 20:13:49.596: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m39.88654508s
May 29 20:13:51.638: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m41.928426256s
May 29 20:13:53.680: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m43.970680633s
May 29 20:13:55.722: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.012373334s
May 29 20:13:57.763: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.054099545s
May 29 20:13:59.805: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.095783496s
May 29 20:14:01.847: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.137734033s
May 29 20:14:03.889: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.179392982s
May 29 20:14:05.931: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.221430088s
May 29 20:14:07.972: INFO: Pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.262987015s
May 29 20:14:10.062: INFO: Failed to get logs from node "e2e-test-peterhornyack-windows-node-group-jpxd" pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30" container "secret-volume-test": the server rejected our request for an unknown reason (get pods pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30)
[1mSTEP[0m: delete the pod
May 29 20:14:10.109: INFO: Waiting for pod pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 to disappear
May 29 20:14:10.150: INFO: Pod pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 still exists
May 29 20:14:12.151: INFO: Waiting for pod pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 to disappear
May 29 20:14:12.192: INFO: Pod pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 still exists
May 29 20:14:14.151: INFO: Waiting for pod pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 to disappear
May 29 20:14:14.192: INFO: Pod pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 still exists
May 29 20:14:16.151: INFO: Waiting for pod pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 to disappear
May 29 20:14:16.192: INFO: Pod pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 no longer exists
May 29 20:14:16.192: INFO: Unexpected error occurred: expected pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30" success: Gave up after waiting 5m0s for pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30" to be "success or failure"
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "secrets-5024".
[1mSTEP[0m: Found 5 events.
May 29 20:14:16.235: INFO: At 2019-05-29 20:09:09 -0700 PDT - event for pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30: {default-scheduler } Scheduled: Successfully assigned secrets-5024/pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30 to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:14:16.235: INFO: At 2019-05-29 20:09:11 -0700 PDT - event for pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 29 20:14:16.235: INFO: At 2019-05-29 20:09:11 -0700 PDT - event for pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container secret-volume-test
May 29 20:14:16.235: INFO: At 2019-05-29 20:09:14 -0700 PDT - event for pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container secret-volume-test
May 29 20:14:16.235: INFO: At 2019-05-29 20:12:51 -0700 PDT - event for pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod secrets-5024/pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30
May 29 20:14:16.323: INFO: POD                                                    NODE                                      PHASE    GRACE  CONDITIONS
May 29 20:14:16.323: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:14:16.323: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 20:14:16.323: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:14:16.323: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:14:16.323: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:14:16.323: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:14:16.323: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:14:16.323: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 20:14:16.323: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 20:14:16.323: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 20:14:16.323: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 20:14:16.324: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:14:16.324: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 20:14:16.324: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 20:14:16.324: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:14:16.324: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 20:14:16.324: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 20:14:16.324: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:14:16.324: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:14:16.324: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:14:16.324: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:14:16.324: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:14:16.324: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:14:16.324: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 20:14:16.324: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 20:14:16.324: INFO: 
May 29 20:14:16.367: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 20:14:16.408: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:40117,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:13:31 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:13:31 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:13:31 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:13:31 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:14:16.409: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 20:14:16.450: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 20:14:16.495: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:16.495: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:14:16.495: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:14:16.495: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.495: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.495: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.495: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.496: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.496: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.496: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.496: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.496: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:16.496: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:14:16.496: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:14:16.684: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 20:14:16.684: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:14:16.725: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:40184,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentDockerRestart False 2019-05-29 20:13:29 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 20:13:29 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 20:13:29 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 20:13:29 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 20:13:29 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 20:13:29 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 20:13:29 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:14:00 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:14:00 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:14:00 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:14:00 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:14:16.726: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:14:16.767: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:14:16.822: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 20:14:16.822: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:14:16.822: INFO: 	Container coredns ready: true, restart count 0
May 29 20:14:16.822: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:14:16.822: INFO: 	Container autoscaler ready: true, restart count 0
May 29 20:14:16.822: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:14:16.822: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 20:14:16.822: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:16.822: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:14:16.822: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:14:16.822: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:14:16.822: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 20:14:16.822: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:16.822: INFO: 	Container event-exporter ready: true, restart count 0
May 29 20:14:16.822: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:14:16.822: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:14:16.822: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 20:14:16.822: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:16.822: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:14:16.822: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:14:16.981: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:14:16.981: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:14:17.023: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:40119,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentUnregisterNetDevice False 2019-05-29 20:13:22 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 20:13:22 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 20:13:22 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 20:13:22 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 20:13:22 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 20:13:22 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 20:13:22 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:13:32 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:13:32 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:13:32 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:13:32 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:14:17.024: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:14:17.065: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:14:17.121: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:17.121: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:14:17.121: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:14:17.121: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 20:14:17.121: INFO: 	Container coredns ready: true, restart count 0
May 29 20:14:17.122: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:17.122: INFO: 	Container metrics-server ready: true, restart count 0
May 29 20:14:17.122: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 20:14:17.122: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:17.122: INFO: 	Container heapster ready: true, restart count 0
May 29 20:14:17.122: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 20:14:17.122: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 20:14:17.122: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 20:14:17.122: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:14:17.122: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:14:17.289: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:14:17.289: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:14:17.331: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:40227,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:14:16 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:14:16 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:14:16 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:14:16 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:14:17.331: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:14:17.372: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:14:17.576: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:14:17.576: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:14:17.619: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:40132,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:13:36 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:13:36 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:13:36 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:13:36 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:14:17.620: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:14:17.662: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:14:17.872: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:14:17.872: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:14:17.914: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:40160,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:13:49 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:13:49 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:13:49 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:13:49 -0700 PDT 2019-05-29 20:12:49 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:14:17.914: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:14:17.955: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:14:18.199: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:14:18.199: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-5024" for this suite.
May 29 20:14:24.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:14:25.968: INFO: namespace secrets-5024 deletion completed in 7.726772937s

[91m[1m• Failure [316.558 seconds][0m
[sig-storage] Secrets
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  [91m[1mshould be consumable from pods in volume [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mUnexpected error:
      <*errors.errorString | 0xc0005e7fe0>: {
          s: "expected pod \"pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30\" success: Gave up after waiting 5m0s for pod \"pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30\" to be \"success or failure\"",
      }
      expected pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30" success: Gave up after waiting 5m0s for pod "pod-secrets-b0d9ec09-3ba0-4730-95e1-0e797f720e30" to be "success or failure"
  occurred[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:2285
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform canary updates and phased rolling updates of template modifications [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:14:25.969: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-1120
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a new StatefulSet
May 29 20:14:26.312: INFO: Found 1 stateful pods, waiting for 3
May 29 20:14:36.355: INFO: Found 2 stateful pods, waiting for 3
May 29 20:14:46.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:14:56.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:15:06.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:15:16.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:15:26.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:15:36.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:15:46.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:15:56.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:16:06.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:16:16.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:16:26.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:16:36.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:16:46.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:16:56.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:17:06.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:17:16.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:17:26.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:17:36.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:17:46.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:17:56.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:18:06.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:18:16.357: INFO: Found 2 stateful pods, waiting for 3
May 29 20:18:26.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:18:36.356: INFO: Found 2 stateful pods, waiting for 3
May 29 20:18:46.356: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:18:46.356: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:18:46.356: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 29 20:18:56.359: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:18:56.359: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:18:56.359: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Updating stateful set template: update image from e2eteam/nginx:1.14-alpine to e2eteam/nginx:1.15-alpine
May 29 20:18:56.582: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Not applying an update when the partition is greater than the number of replicas
[1mSTEP[0m: Performing a canary update
May 29 20:18:56.763: INFO: Updating stateful set ss2
May 29 20:18:56.847: INFO: Waiting for Pod statefulset-1120/ss2-2 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
[1mSTEP[0m: Restoring Pods to the correct revision when they are deleted
May 29 20:19:07.106: INFO: Found 2 stateful pods, waiting for 3
May 29 20:19:17.158: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:19:17.158: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:19:17.158: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 29 20:19:27.153: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:19:27.153: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:19:27.153: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Performing a phased rolling update
May 29 20:19:27.338: INFO: Updating stateful set ss2
May 29 20:19:27.421: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:19:37.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:19:47.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:19:57.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:20:07.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:20:17.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:20:27.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:20:37.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:20:47.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:20:57.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:21:07.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:21:17.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:21:27.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:21:37.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:21:47.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:21:57.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:22:07.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:22:17.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:22:27.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:22:37.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:22:47.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:22:57.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:23:07.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:23:17.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:23:27.508: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:23:37.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:23:47.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:23:57.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:24:07.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:24:17.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:24:27.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:24:37.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:24:47.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:24:57.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:25:07.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:25:17.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:25:27.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:25:37.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:25:47.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:25:57.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:26:07.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:26:17.508: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:26:27.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:26:37.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:26:47.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:26:57.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:27:07.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:27:17.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:27:27.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:27:37.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:27:47.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:27:57.514: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:28:07.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:28:17.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:28:27.508: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:28:37.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:28:47.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:28:57.506: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:29:07.505: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:29:17.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:29:27.507: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:29:27.591: INFO: Waiting for Pod statefulset-1120/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 20:29:27.591: INFO: Failed waiting for state update: timed out waiting for the condition
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 20:29:27.635: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe po ss2-0 --namespace=statefulset-1120'
May 29 20:29:28.527: INFO: stderr: ""
May 29 20:29:28.527: INFO: stdout: "Name:               ss2-0\nNamespace:          statefulset-1120\nPriority:           0\nPriorityClassName:  <none>\nNode:               e2e-test-peterhornyack-windows-node-group-1vjk/10.40.0.5\nStart Time:         Wed, 29 May 2019 20:19:06 -0700\nLabels:             baz=blah\n                    controller-revision-hash=ss2-577b4dc465\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-0\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.64.2.45\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   docker://9b3e1bc1a33f74d860769df75b6a38869ab9d28879d1a1c77decf54571972054\n    Image:          e2eteam/nginx:1.14-alpine\n    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Wed, 29 May 2019 20:19:11 -0700\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-plsvz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-plsvz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-plsvz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                     Message\n  ----    ------     ----  ----                                                     -------\n  Normal  Scheduled  10m   default-scheduler                                        Successfully assigned statefulset-1120/ss2-0 to e2e-test-peterhornyack-windows-node-group-1vjk\n  Normal  Pulled     10m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Container image \"e2eteam/nginx:1.14-alpine\" already present on machine\n  Normal  Created    10m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Created container nginx\n  Normal  Started    10m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Started container nginx\n"
May 29 20:29:28.527: INFO: 
Output of kubectl describe ss2-0:
Name:               ss2-0
Namespace:          statefulset-1120
Priority:           0
PriorityClassName:  <none>
Node:               e2e-test-peterhornyack-windows-node-group-1vjk/10.40.0.5
Start Time:         Wed, 29 May 2019 20:19:06 -0700
Labels:             baz=blah
                    controller-revision-hash=ss2-577b4dc465
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-0
Annotations:        <none>
Status:             Running
IP:                 10.64.2.45
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   docker://9b3e1bc1a33f74d860769df75b6a38869ab9d28879d1a1c77decf54571972054
    Image:          e2eteam/nginx:1.14-alpine
    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 29 May 2019 20:19:11 -0700
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-plsvz (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-plsvz:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-plsvz
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From                                                     Message
  ----    ------     ----  ----                                                     -------
  Normal  Scheduled  10m   default-scheduler                                        Successfully assigned statefulset-1120/ss2-0 to e2e-test-peterhornyack-windows-node-group-1vjk
  Normal  Pulled     10m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Container image "e2eteam/nginx:1.14-alpine" already present on machine
  Normal  Created    10m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Created container nginx
  Normal  Started    10m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Started container nginx

May 29 20:29:28.528: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs ss2-0 --namespace=statefulset-1120 --tail=100'
May 29 20:29:28.845: INFO: stderr: ""
May 29 20:29:28.845: INFO: stdout: ""
May 29 20:29:28.845: INFO: 
Last 100 log lines of ss2-0:

May 29 20:29:28.846: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe po ss2-1 --namespace=statefulset-1120'
May 29 20:29:29.205: INFO: stderr: ""
May 29 20:29:29.205: INFO: stdout: "Name:                      ss2-1\nNamespace:                 statefulset-1120\nPriority:                  0\nPriorityClassName:         <none>\nNode:                      e2e-test-peterhornyack-windows-node-group-jpxd/10.40.0.3\nStart Time:                Wed, 29 May 2019 20:14:33 -0700\nLabels:                    baz=blah\n                           controller-revision-hash=ss2-577b4dc465\n                           foo=bar\n                           statefulset.kubernetes.io/pod-name=ss2-1\nAnnotations:               <none>\nStatus:                    Terminating (lasts 9m)\nTermination Grace Period:  30s\nIP:                        10.64.1.99\nControlled By:             StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   docker://8c163ab4408ba06e77c51e42d8cf9682a4af7d429066a23699f607007aec188b\n    Image:          e2eteam/nginx:1.14-alpine\n    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Wed, 29 May 2019 20:14:37 -0700\n    Ready:          False\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-plsvz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  default-token-plsvz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-plsvz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                     Message\n  ----    ------     ----  ----                                                     -------\n  Normal  Scheduled  14m   default-scheduler                                        Successfully assigned statefulset-1120/ss2-1 to e2e-test-peterhornyack-windows-node-group-jpxd\n  Normal  Pulled     14m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Container image \"e2eteam/nginx:1.14-alpine\" already present on machine\n  Normal  Created    14m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Created container nginx\n  Normal  Started    14m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Started container nginx\n  Normal  Killing    46s   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Stopping container nginx\n"
May 29 20:29:29.205: INFO: 
Output of kubectl describe ss2-1:
Name:                      ss2-1
Namespace:                 statefulset-1120
Priority:                  0
PriorityClassName:         <none>
Node:                      e2e-test-peterhornyack-windows-node-group-jpxd/10.40.0.3
Start Time:                Wed, 29 May 2019 20:14:33 -0700
Labels:                    baz=blah
                           controller-revision-hash=ss2-577b4dc465
                           foo=bar
                           statefulset.kubernetes.io/pod-name=ss2-1
Annotations:               <none>
Status:                    Terminating (lasts 9m)
Termination Grace Period:  30s
IP:                        10.64.1.99
Controlled By:             StatefulSet/ss2
Containers:
  nginx:
    Container ID:   docker://8c163ab4408ba06e77c51e42d8cf9682a4af7d429066a23699f607007aec188b
    Image:          e2eteam/nginx:1.14-alpine
    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 29 May 2019 20:14:37 -0700
    Ready:          False
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-plsvz (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  default-token-plsvz:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-plsvz
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From                                                     Message
  ----    ------     ----  ----                                                     -------
  Normal  Scheduled  14m   default-scheduler                                        Successfully assigned statefulset-1120/ss2-1 to e2e-test-peterhornyack-windows-node-group-jpxd
  Normal  Pulled     14m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Container image "e2eteam/nginx:1.14-alpine" already present on machine
  Normal  Created    14m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Created container nginx
  Normal  Started    14m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Started container nginx
  Normal  Killing    46s   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Stopping container nginx

May 29 20:29:29.205: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs ss2-1 --namespace=statefulset-1120 --tail=100'
May 29 20:29:29.514: INFO: stderr: ""
May 29 20:29:29.514: INFO: stdout: ""
May 29 20:29:29.514: INFO: 
Last 100 log lines of ss2-1:

May 29 20:29:29.514: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe po ss2-2 --namespace=statefulset-1120'
May 29 20:29:29.879: INFO: stderr: ""
May 29 20:29:29.879: INFO: stdout: "Name:               ss2-2\nNamespace:          statefulset-1120\nPriority:           0\nPriorityClassName:  <none>\nNode:               e2e-test-peterhornyack-windows-node-group-9q9v/10.40.0.4\nStart Time:         Wed, 29 May 2019 20:19:13 -0700\nLabels:             baz=blah\n                    controller-revision-hash=ss2-5f4db4b9f4\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-2\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.64.3.89\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   docker://0a08bf525c3128473face83deaa8dbb81ced7290b062a35b59e10b0996962d53\n    Image:          e2eteam/nginx:1.15-alpine\n    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Wed, 29 May 2019 20:19:16 -0700\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-plsvz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-plsvz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-plsvz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                     Message\n  ----    ------     ----  ----                                                     -------\n  Normal  Scheduled  10m   default-scheduler                                        Successfully assigned statefulset-1120/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v\n  Normal  Pulled     10m   kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Container image \"e2eteam/nginx:1.15-alpine\" already present on machine\n  Normal  Created    10m   kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Created container nginx\n  Normal  Started    10m   kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Started container nginx\n"
May 29 20:29:29.879: INFO: 
Output of kubectl describe ss2-2:
Name:               ss2-2
Namespace:          statefulset-1120
Priority:           0
PriorityClassName:  <none>
Node:               e2e-test-peterhornyack-windows-node-group-9q9v/10.40.0.4
Start Time:         Wed, 29 May 2019 20:19:13 -0700
Labels:             baz=blah
                    controller-revision-hash=ss2-5f4db4b9f4
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-2
Annotations:        <none>
Status:             Running
IP:                 10.64.3.89
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   docker://0a08bf525c3128473face83deaa8dbb81ced7290b062a35b59e10b0996962d53
    Image:          e2eteam/nginx:1.15-alpine
    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 29 May 2019 20:19:16 -0700
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-plsvz (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-plsvz:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-plsvz
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From                                                     Message
  ----    ------     ----  ----                                                     -------
  Normal  Scheduled  10m   default-scheduler                                        Successfully assigned statefulset-1120/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v
  Normal  Pulled     10m   kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Container image "e2eteam/nginx:1.15-alpine" already present on machine
  Normal  Created    10m   kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Created container nginx
  Normal  Started    10m   kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Started container nginx

May 29 20:29:29.880: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs ss2-2 --namespace=statefulset-1120 --tail=100'
May 29 20:29:30.190: INFO: stderr: ""
May 29 20:29:30.190: INFO: stdout: ""
May 29 20:29:30.190: INFO: 
Last 100 log lines of ss2-2:

May 29 20:29:30.190: INFO: Deleting all statefulset in ns statefulset-1120
May 29 20:29:30.232: INFO: Scaling statefulset ss2 to 0
May 29 20:37:50.410: INFO: Waiting for statefulset status.replicas updated to 0
May 29 20:37:50.452: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "statefulset-1120".
[1mSTEP[0m: Found 37 events.
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:26 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-0 in StatefulSet ss2 successful
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:26 -0700 PDT - event for ss2-0: {default-scheduler } Scheduled: Successfully assigned statefulset-1120/ss2-0 to e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:28 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Created: Created container nginx
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:28 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:30 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Started: Started container nginx
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:33 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-1 in StatefulSet ss2 successful
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:33 -0700 PDT - event for ss2-1: {default-scheduler } Scheduled: Successfully assigned statefulset-1120/ss2-1 to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:35 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container nginx
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:35 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 20:37:50.623: INFO: At 2019-05-29 20:14:37 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container nginx
May 29 20:37:50.623: INFO: At 2019-05-29 20:16:51 -0700 PDT - event for ss2-1: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod statefulset-1120/ss2-1
May 29 20:37:50.623: INFO: At 2019-05-29 20:18:42 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-2 in StatefulSet ss2 successful
May 29 20:37:50.623: INFO: At 2019-05-29 20:18:42 -0700 PDT - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned statefulset-1120/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:37:50.623: INFO: At 2019-05-29 20:18:44 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 20:37:50.623: INFO: At 2019-05-29 20:18:44 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container nginx
May 29 20:37:50.623: INFO: At 2019-05-29 20:18:46 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container nginx
May 29 20:37:50.623: INFO: At 2019-05-29 20:18:56 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-2 in StatefulSet ss2 successful
May 29 20:37:50.624: INFO: At 2019-05-29 20:18:56 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Killing: Stopping container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:04 -0700 PDT - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned statefulset-1120/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:06 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Killing: Stopping container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:06 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Successfully pulled image "e2eteam/nginx:1.15-alpine"
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:06 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulling: Pulling image "e2eteam/nginx:1.15-alpine"
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:06 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:07 -0700 PDT - event for ss2-0: {default-scheduler } Scheduled: Successfully assigned statefulset-1120/ss2-0 to e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:08 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:08 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:09 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Created: Created container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:11 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Started: Started container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:13 -0700 PDT - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned statefulset-1120/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:15 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Container image "e2eteam/nginx:1.15-alpine" already present on machine
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:15 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:17 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:19:27 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-1 in StatefulSet ss2 successful
May 29 20:37:50.624: INFO: At 2019-05-29 20:28:43 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Killing: Stopping container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:29:30 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Killing: Stopping container nginx
May 29 20:37:50.624: INFO: At 2019-05-29 20:36:54 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-0 in StatefulSet ss2 successful
May 29 20:37:50.624: INFO: At 2019-05-29 20:36:54 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Killing: Stopping container nginx
May 29 20:37:50.718: INFO: POD                                                    NODE                                      PHASE    GRACE  CONDITIONS
May 29 20:37:50.718: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:37:50.718: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 20:37:50.718: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:37:50.719: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:37:50.719: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:37:50.719: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:37:50.719: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:37:50.719: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 20:37:50.719: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 20:37:50.719: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 20:37:50.719: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 20:37:50.719: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:37:50.719: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 20:37:50.719: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 20:37:50.719: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:37:50.719: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 20:37:50.719: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 20:37:50.719: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:37:50.719: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:37:50.719: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:37:50.719: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 20:37:50.719: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:37:50.719: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 20:37:50.719: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 20:37:50.719: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 20:37:50.719: INFO: 
May 29 20:37:50.762: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 20:37:50.805: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:43646,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:37:36 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:37:36 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:37:36 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:37:36 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:37:50.805: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 20:37:50.847: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 20:37:50.894: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:37:50.894: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:37:50.894: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:37:50.894: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:37:50.894: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:37:50.894: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:50.894: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:37:50.894: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:37:50.894: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:37:50.894: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:37:50.894: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:50.894: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:37:50.894: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:37:50.894: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 20:37:51.042: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 20:37:51.042: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:37:51.084: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:43673,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{CorruptDockerOverlay2 False 2019-05-29 20:37:45 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 20:37:45 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 20:37:45 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 20:37:45 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 20:37:45 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 20:37:45 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 20:37:45 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:37:02 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:37:02 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:37:02 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:37:02 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:37:51.084: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:37:51.127: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:37:51.177: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 20:37:51.177: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:37:51.177: INFO: 	Container coredns ready: true, restart count 0
May 29 20:37:51.177: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:37:51.177: INFO: 	Container autoscaler ready: true, restart count 0
May 29 20:37:51.177: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:37:51.177: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 20:37:51.177: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:51.177: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:37:51.177: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:37:51.177: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:37:51.177: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 20:37:51.177: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:51.177: INFO: 	Container event-exporter ready: true, restart count 0
May 29 20:37:51.177: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:37:51.177: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 20:37:51.177: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 20:37:51.177: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:51.177: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:37:51.177: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:37:51.336: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 20:37:51.336: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:37:51.378: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:43654,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentKubeletRestart False 2019-05-29 20:37:37 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 20:37:37 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 20:37:37 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 20:37:37 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 20:37:37 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 20:37:37 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 20:37:37 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:37:33 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:37:33 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:37:33 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:37:33 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 20:37:51.378: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:37:51.420: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:37:51.469: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:51.469: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 20:37:51.469: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:37:51.469: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:51.469: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 20:37:51.469: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 20:37:51.469: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 20:37:51.469: INFO: 	Container coredns ready: true, restart count 0
May 29 20:37:51.469: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:51.469: INFO: 	Container metrics-server ready: true, restart count 0
May 29 20:37:51.469: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 20:37:51.469: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 20:37:51.469: INFO: 	Container heapster ready: true, restart count 0
May 29 20:37:51.469: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 20:37:51.469: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 20:37:51.628: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 20:37:51.628: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:37:51.670: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:43607,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:37:18 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:37:18 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:37:18 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:37:18 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:37:51.671: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:37:51.713: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:37:51.913: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 20:37:51.913: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:37:51.955: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:43629,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:37:28 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:37:28 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:37:28 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:37:28 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:37:51.955: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:37:51.996: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:37:52.195: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 20:37:52.195: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:37:52.237: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:43689,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 20:37:51 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 20:37:51 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 20:37:51 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 20:37:51 -0700 PDT 2019-05-29 20:36:51 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 20:37:52.237: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:37:52.278: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:37:52.506: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 20:37:52.506: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-1120" for this suite.
May 29 20:37:58.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:38:00.259: INFO: namespace statefulset-1120 deletion completed in 7.710745729s

[91m[1m• Failure [1414.290 seconds][0m
[sig-apps] StatefulSet
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
    [91m[1mshould perform canary updates and phased rolling updates of template modifications [Conformance] [It][0m
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mMay 29 20:29:27.591: Failed waiting for state update: timed out waiting for the condition[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/statefulset_utils.go:337
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 20:38:00.260: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:38:00.261: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:99
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:38:00.262: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename provisioning
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provision storage with mount options
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157
May 29 20:38:00.431: INFO: In creating storage class object and pvc object for driver - sc: &StorageClass{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:provisioning-427-gcepd-sck2gqp,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Provisioner:kubernetes.io/gce-pd,Parameters:map[string]string{fsType: ntfs,},ReclaimPolicy:nil,MountOptions:[],AllowVolumeExpansion:nil,VolumeBindingMode:*WaitForFirstConsumer,AllowedTopologies:[],}, pvc: &PersistentVolumeClaim{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:pvc-,Namespace:provisioning-427,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PersistentVolumeClaimSpec{AccessModes:[ReadWriteOnce],Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{storage: {{5368709120 0} {<nil>} 5Gi BinarySI},},},VolumeName:,Selector:nil,StorageClassName:*provisioning-427-gcepd-sck2gqp,VolumeMode:nil,DataSource:nil,},Status:PersistentVolumeClaimStatus{Phase:,AccessModes:[],Capacity:ResourceList{},Conditions:[],},}
[1mSTEP[0m: creating a StorageClass provisioning-427-gcepd-sck2gqp
[1mSTEP[0m: creating a claim
[1mSTEP[0m: checking the created volume is writable on node {Name: Selector:map[] Affinity:nil}
May 29 20:38:00.613: INFO: Waiting up to 15m0s for pod "pvc-volume-tester-writer-dk95k" in namespace "provisioning-427" to be "success or failure"
May 29 20:38:00.656: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 42.52532ms
May 29 20:38:02.698: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084519946s
May 29 20:38:04.740: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126977499s
May 29 20:38:06.782: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16928717s
May 29 20:38:08.824: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.211238468s
May 29 20:38:10.866: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 10.253269996s
May 29 20:38:12.908: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 12.295407266s
May 29 20:38:14.953: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 14.339662001s
May 29 20:38:16.995: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 16.381624498s
May 29 20:38:19.043: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 18.430005469s
May 29 20:38:21.085: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 20.472225329s
May 29 20:38:23.127: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 22.514183768s
May 29 20:38:25.169: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 24.556173726s
May 29 20:38:27.211: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 26.598211025s
May 29 20:38:29.253: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 28.640446805s
May 29 20:38:31.296: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 30.682506915s
May 29 20:38:33.337: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 32.72438535s
May 29 20:38:35.380: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 34.766816568s
May 29 20:38:37.422: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 36.808891657s
May 29 20:38:39.464: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 38.850582782s
May 29 20:38:41.505: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 40.891873699s
May 29 20:38:43.547: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 42.933656554s
May 29 20:38:45.589: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 44.975510758s
May 29 20:38:47.630: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 47.017421066s
May 29 20:38:49.672: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 49.059164687s
May 29 20:38:51.718: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 51.104975449s
May 29 20:38:53.760: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 53.146890591s
May 29 20:38:55.802: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 55.18866591s
May 29 20:38:57.843: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 57.230381598s
May 29 20:38:59.886: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 59.272518139s
May 29 20:39:01.928: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.315051583s
May 29 20:39:03.970: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.357290033s
May 29 20:39:06.012: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.399071713s
May 29 20:39:08.054: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.441089369s
May 29 20:39:10.096: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.483153339s
May 29 20:39:12.143: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.529533382s
May 29 20:39:14.184: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.57103881s
May 29 20:39:16.226: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.612660819s
May 29 20:39:18.267: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.654455686s
May 29 20:39:20.309: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.696390086s
May 29 20:39:22.352: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.738791355s
May 29 20:39:24.394: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.781311722s
May 29 20:39:26.436: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.823448428s
May 29 20:39:28.479: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.865749606s
May 29 20:39:30.521: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.907639923s
May 29 20:39:32.567: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.953641284s
May 29 20:39:34.609: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.995761431s
May 29 20:39:36.657: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.043729649s
May 29 20:39:38.698: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.085324774s
May 29 20:39:40.741: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.127819546s
May 29 20:39:42.783: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.169934424s
May 29 20:39:44.825: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.212243526s
May 29 20:39:46.874: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.260751285s
May 29 20:39:48.916: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.302980346s
May 29 20:39:50.958: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.344657455s
May 29 20:39:53.000: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.386659508s
May 29 20:39:55.042: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.429019943s
May 29 20:39:57.084: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.470725063s
May 29 20:39:59.126: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.513193825s
May 29 20:40:01.168: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.554861639s
May 29 20:40:03.210: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.597131146s
May 29 20:40:05.252: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.639234424s
May 29 20:40:07.294: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.681122099s
May 29 20:40:09.336: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.723354234s
May 29 20:40:11.378: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.765107171s
May 29 20:40:13.420: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.806993941s
May 29 20:40:15.462: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.849230567s
May 29 20:40:17.506: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.893318044s
May 29 20:40:19.548: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.935059484s
May 29 20:40:21.590: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.977176674s
May 29 20:40:23.632: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m23.018992092s
May 29 20:40:25.674: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.060962299s
May 29 20:40:27.718: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.104498832s
May 29 20:40:29.760: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.146520817s
May 29 20:40:31.802: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.188823873s
May 29 20:40:33.844: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.230668085s
May 29 20:40:35.886: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.272583791s
May 29 20:40:37.927: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.314145804s
May 29 20:40:39.969: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.35627283s
May 29 20:40:42.011: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.397978127s
May 29 20:40:44.054: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.440854788s
May 29 20:40:46.096: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.482731231s
May 29 20:40:48.142: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.529451749s
May 29 20:40:50.184: INFO: Pod "pvc-volume-tester-writer-dk95k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2m49.571152804s
[1mSTEP[0m: Saw pod success
May 29 20:40:50.184: INFO: Pod "pvc-volume-tester-writer-dk95k" satisfied condition "success or failure"
May 29 20:40:50.275: INFO: Pod pvc-volume-tester-writer-dk95k has the following logs: 
[1mSTEP[0m: Deleting pod pvc-volume-tester-writer-dk95k in namespace provisioning-427
[1mSTEP[0m: checking the created volume has the correct mount options, is readable and retains data on the same node "e2e-test-peterhornyack-windows-node-group-jpxd"
May 29 20:40:50.463: INFO: Waiting up to 15m0s for pod "pvc-volume-tester-reader-zkdls" in namespace "provisioning-427" to be "success or failure"
May 29 20:40:50.505: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 41.645411ms
May 29 20:40:52.547: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083509979s
May 29 20:40:54.589: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125397337s
May 29 20:40:56.631: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167201309s
May 29 20:40:58.674: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210281647s
May 29 20:41:00.718: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 10.25479837s
May 29 20:41:02.765: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 12.301823675s
May 29 20:41:04.806: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 14.343009294s
May 29 20:41:06.849: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 16.385696089s
May 29 20:41:08.891: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 18.427871426s
May 29 20:41:10.934: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 20.470500071s
May 29 20:41:12.976: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 22.51263696s
May 29 20:41:15.018: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 24.554270407s
May 29 20:41:17.060: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 26.597036239s
May 29 20:41:19.102: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 28.638639026s
May 29 20:41:21.144: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 30.680433106s
May 29 20:41:23.186: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 32.722453104s
May 29 20:41:25.228: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 34.765046842s
May 29 20:41:27.275: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 36.811819019s
May 29 20:41:29.317: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 38.853878713s
May 29 20:41:31.359: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 40.89549453s
May 29 20:41:33.401: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 42.938045184s
May 29 20:41:35.444: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 44.980084403s
May 29 20:41:37.485: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 47.021763977s
May 29 20:41:39.527: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 49.063748089s
May 29 20:41:41.569: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 51.105734001s
May 29 20:41:43.611: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 53.147502508s
May 29 20:41:45.653: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 55.189667607s
May 29 20:41:47.695: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 57.231798372s
May 29 20:41:49.737: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 59.273870602s
May 29 20:41:51.780: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.316540779s
May 29 20:41:53.822: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.358332622s
May 29 20:41:55.864: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.400121001s
May 29 20:41:57.906: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.442116485s
May 29 20:41:59.948: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.48490953s
May 29 20:42:01.990: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.52636952s
May 29 20:42:04.032: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.568569701s
May 29 20:42:06.074: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.610490904s
May 29 20:42:08.116: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.652570837s
May 29 20:42:10.158: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.694322624s
May 29 20:42:12.199: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.735954605s
May 29 20:42:14.241: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.777881782s
May 29 20:42:16.285: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.821547349s
May 29 20:42:18.327: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.863726849s
May 29 20:42:20.369: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.905720124s
May 29 20:42:22.411: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.947659944s
May 29 20:42:24.453: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.98984977s
May 29 20:42:26.496: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.032249924s
May 29 20:42:28.538: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.074268659s
May 29 20:42:30.581: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.117266624s
May 29 20:42:32.623: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.159305803s
May 29 20:42:34.667: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.203099188s
May 29 20:42:36.708: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.245061035s
May 29 20:42:38.752: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.288777549s
May 29 20:42:40.795: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.331185437s
May 29 20:42:42.836: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.372779709s
May 29 20:42:44.878: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.414793186s
May 29 20:42:46.920: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.456987983s
May 29 20:42:48.963: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.499076734s
May 29 20:42:51.006: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.542764505s
May 29 20:42:53.048: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.584820771s
May 29 20:42:55.090: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.626825371s
May 29 20:42:57.132: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.668819254s
May 29 20:42:59.179: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.715204355s
May 29 20:43:01.221: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.757624445s
May 29 20:43:03.263: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.799215376s
May 29 20:43:05.306: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.842314023s
May 29 20:43:07.348: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.884366364s
May 29 20:43:09.389: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.925890178s
May 29 20:43:11.431: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.967696565s
May 29 20:43:13.473: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m23.009723471s
May 29 20:43:15.519: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.055803316s
May 29 20:43:17.574: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.110503764s
May 29 20:43:19.619: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.155873538s
May 29 20:43:21.662: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.198252445s
May 29 20:43:23.704: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.240302712s
May 29 20:43:25.746: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.282141962s
May 29 20:43:27.787: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.323637856s
May 29 20:43:29.829: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.365778775s
May 29 20:43:31.871: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.407391343s
May 29 20:43:33.912: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.448918154s
May 29 20:43:35.954: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.490783786s
May 29 20:43:37.996: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.532493921s
May 29 20:43:40.038: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.574506319s
May 29 20:43:42.080: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.616509797s
May 29 20:43:44.122: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.658113854s
May 29 20:43:46.163: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.699930464s
May 29 20:43:48.205: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.741449699s
May 29 20:43:50.247: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.783554927s
May 29 20:43:52.289: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.825532315s
May 29 20:43:54.331: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.867856524s
May 29 20:43:56.373: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.909744117s
May 29 20:43:58.415: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.951897719s
May 29 20:44:00.458: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.994104791s
May 29 20:44:02.499: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.036033447s
May 29 20:44:04.541: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.077986974s
May 29 20:44:06.583: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.119830745s
May 29 20:44:08.627: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.163382038s
May 29 20:44:10.669: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.205878023s
May 29 20:44:12.713: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.24980906s
May 29 20:44:14.757: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.293341305s
May 29 20:44:16.798: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.334912687s
May 29 20:44:18.840: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.376735835s
May 29 20:44:20.882: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.41864672s
May 29 20:44:22.924: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.460777457s
May 29 20:44:24.966: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.502448252s
May 29 20:44:27.007: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.543909538s
May 29 20:44:29.049: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.585753997s
May 29 20:44:31.091: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.627607399s
May 29 20:44:33.133: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.669887202s
May 29 20:44:35.175: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.711791033s
May 29 20:44:37.217: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.753746243s
May 29 20:44:39.259: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.796061998s
May 29 20:44:41.301: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.837822114s
May 29 20:44:43.343: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.879951552s
May 29 20:44:45.386: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.922504351s
May 29 20:44:47.428: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.964602973s
May 29 20:44:49.470: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 3m59.006208293s
May 29 20:44:51.512: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m1.048241546s
May 29 20:44:53.553: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m3.089494068s
May 29 20:44:55.595: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m5.131358621s
May 29 20:44:57.637: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m7.173168916s
May 29 20:44:59.679: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m9.215122285s
May 29 20:45:01.720: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m11.256911353s
May 29 20:45:03.763: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m13.299123441s
May 29 20:45:05.804: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m15.340940515s
May 29 20:45:07.846: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m17.382429718s
May 29 20:45:09.888: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m19.425015185s
May 29 20:45:11.931: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m21.467162353s
May 29 20:45:13.975: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m23.511543665s
May 29 20:45:16.017: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m25.553323365s
May 29 20:45:18.059: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m27.595105351s
May 29 20:45:20.101: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m29.637162823s
May 29 20:45:22.148: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m31.684969473s
May 29 20:45:24.191: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m33.727155406s
May 29 20:45:26.233: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m35.769506737s
May 29 20:45:28.276: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m37.812615101s
May 29 20:45:30.318: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m39.85454022s
May 29 20:45:32.360: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m41.896280859s
May 29 20:45:34.402: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m43.938419835s
May 29 20:45:36.445: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m45.981152691s
May 29 20:45:38.487: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.023123261s
May 29 20:45:40.529: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.065232413s
May 29 20:45:42.570: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.106999754s
May 29 20:45:44.613: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.149082477s
May 29 20:45:46.655: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.191437974s
May 29 20:45:48.697: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.233076717s
May 29 20:45:50.739: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.275959138s
May 29 20:45:52.781: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m2.317794938s
May 29 20:45:54.823: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m4.359665202s
May 29 20:45:56.869: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m6.405412793s
May 29 20:45:58.911: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m8.447749939s
May 29 20:46:00.954: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m10.490408223s
May 29 20:46:02.999: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m12.53535632s
May 29 20:46:05.043: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m14.579896274s
May 29 20:46:07.085: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m16.621686465s
May 29 20:46:09.130: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m18.666607611s
May 29 20:46:11.172: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m20.708645946s
May 29 20:46:13.214: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m22.750828096s
May 29 20:46:15.256: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m24.792962238s
May 29 20:46:17.298: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m26.834955872s
May 29 20:46:19.341: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m28.877169022s
May 29 20:46:21.383: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m30.919522602s
May 29 20:46:23.425: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m32.961357465s
May 29 20:46:25.467: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m35.003292179s
May 29 20:46:27.508: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m37.044704565s
May 29 20:46:29.551: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m39.087425796s
May 29 20:46:31.593: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m41.129235385s
May 29 20:46:33.634: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m43.171024873s
May 29 20:46:35.677: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m45.213110101s
May 29 20:46:37.718: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m47.254749577s
May 29 20:46:39.760: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m49.296797653s
May 29 20:46:41.802: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m51.338566671s
May 29 20:46:43.844: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m53.380281441s
May 29 20:46:45.886: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m55.422625739s
May 29 20:46:47.928: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Pending", Reason="", readiness=false. Elapsed: 5m57.464572141s
May 29 20:46:49.970: INFO: Pod "pvc-volume-tester-reader-zkdls": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5m59.506492837s
[1mSTEP[0m: Saw pod success
May 29 20:46:49.970: INFO: Pod "pvc-volume-tester-reader-zkdls" satisfied condition "success or failure"
May 29 20:46:50.022: INFO: Pod pvc-volume-tester-reader-zkdls has the following logs: 
mnt\test\data:1:hello world



[1mSTEP[0m: Deleting pod pvc-volume-tester-reader-zkdls in namespace provisioning-427
May 29 20:46:50.073: INFO: Waiting up to 5m0s for PersistentVolumeClaims [pvc-qqlcq] to have phase Bound
May 29 20:46:50.114: INFO: PersistentVolumeClaim pvc-qqlcq found and phase=Bound (41.322851ms)
[1mSTEP[0m: checking the claim
[1mSTEP[0m: checking the PV
[1mSTEP[0m: deleting claim "provisioning-427"/"pvc-qqlcq"
[1mSTEP[0m: deleting the claim's PV "pvc-f56efec8-50ae-4af5-9da8-ac72696ce6ed"
May 29 20:46:50.244: INFO: Waiting up to 20m0s for PersistentVolume pvc-f56efec8-50ae-4af5-9da8-ac72696ce6ed to get deleted
May 29 20:46:50.285: INFO: PersistentVolume pvc-f56efec8-50ae-4af5-9da8-ac72696ce6ed found and phase=Released (41.561096ms)
May 29 20:46:55.327: INFO: PersistentVolume pvc-f56efec8-50ae-4af5-9da8-ac72696ce6ed found and phase=Released (5.083243833s)
May 29 20:47:00.370: INFO: PersistentVolume pvc-f56efec8-50ae-4af5-9da8-ac72696ce6ed found and phase=Released (10.12613259s)
May 29 20:47:05.412: INFO: PersistentVolume pvc-f56efec8-50ae-4af5-9da8-ac72696ce6ed was removed
May 29 20:47:05.412: INFO: deleting claim "provisioning-427"/"pvc-qqlcq"
May 29 20:47:05.453: INFO: deleting storage class provisioning-427-gcepd-sck2gqp
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:47:05.498: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "provisioning-427" for this suite.
May 29 20:47:11.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:47:13.277: INFO: namespace provisioning-427 deletion completed in 7.736714971s

[32m• [SLOW TEST:553.015 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gcepd]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      should provision storage with mount options
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 20:47:13.278: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:47:13.279: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicaSet[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] ReplicaSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:47:13.280: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename replicaset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 20:47:13.451: INFO: Creating ReplicaSet my-hostname-basic-856d4ba0-d339-4fb9-ae24-e0447c7a6f62
May 29 20:47:13.560: INFO: Pod name my-hostname-basic-856d4ba0-d339-4fb9-ae24-e0447c7a6f62: Found 1 pods out of 1
May 29 20:47:13.560: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-856d4ba0-d339-4fb9-ae24-e0447c7a6f62" is running
May 29 20:50:51.643: INFO: Pod "my-hostname-basic-856d4ba0-d339-4fb9-ae24-e0447c7a6f62-zv7vv" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 20:47:13 -0700 PDT Reason: Message:}])
May 29 20:50:51.643: INFO: Trying to dial the pod
May 29 20:50:56.965: INFO: Controller my-hostname-basic-856d4ba0-d339-4fb9-ae24-e0447c7a6f62: Got expected result from replica 1 [my-hostname-basic-856d4ba0-d339-4fb9-ae24-e0447c7a6f62-zv7vv]: "my-hostname-basic-856d4ba0-d339-4fb9-ae24-e0447c7a6f62-zv7vv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:50:56.965: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "replicaset-5192" for this suite.
May 29 20:51:03.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:51:04.738: INFO: namespace replicaset-5192 deletion completed in 7.730177533s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 20:51:04.738: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:51:04.739: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould receive events on concurrent watches in same order [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:51:04.741: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: starting a background goroutine to produce watch events
[1mSTEP[0m: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:51:12.267: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "watch-5173" for this suite.
May 29 20:51:18.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:51:20.085: INFO: namespace watch-5173 deletion completed in 7.735197437s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 20:51:20.086: INFO: Driver aws doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:51:20.087: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver aws doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:51:20.088: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating pod liveness-http in namespace container-probe-7475
May 29 20:51:28.433: INFO: Started pod liveness-http in namespace container-probe-7475
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 29 20:51:28.480: INFO: Initial restart count of pod liveness-http is 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 20:55:29.547: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-7475" for this suite.
May 29 20:55:35.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 20:55:37.307: INFO: namespace container-probe-7475 deletion completed in 7.717776404s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mBurst scaling should run to completion even with unhealthy pods [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 20:55:37.308: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-8949
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating stateful set ss in namespace statefulset-8949
[1mSTEP[0m: Waiting until all stateful set ss replicas will be running in namespace statefulset-8949
May 29 20:55:37.655: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May 29 20:55:47.698: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 29 20:55:47.740: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 20:55:48.403: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 20:55:48.403: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 20:55:48.403: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 20:55:48.446: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 29 20:55:58.488: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 20:55:58.488: INFO: Waiting for statefulset status.replicas updated to 0
May 29 20:55:58.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999549s
May 29 20:55:59.721: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.939366104s
May 29 20:56:00.763: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.897103156s
May 29 20:56:01.805: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.855080159s
May 29 20:56:02.848: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.812648421s
May 29 20:56:03.890: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.770246663s
May 29 20:56:04.933: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.727795513s
May 29 20:56:05.975: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.685363278s
May 29 20:56:07.017: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.643418598s
May 29 20:56:08.060: INFO: Verifying statefulset ss doesn't scale past 3 for another 600.983742ms
[1mSTEP[0m: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8949
May 29 20:56:09.102: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:56:09.756: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 20:56:09.757: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 20:56:09.757: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 20:56:09.757: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:56:10.401: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 29 20:56:10.401: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 20:56:10.401: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 20:56:10.402: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:56:11.096: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 29 20:56:11.096: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 20:56:11.096: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 20:56:11.138: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:56:11.139: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 20:56:11.139: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
[1mSTEP[0m: Scale down will not halt with unhealthy stateful pod
May 29 20:56:11.182: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 20:56:11.832: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 20:56:11.832: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 20:56:11.832: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 20:56:11.832: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 20:56:12.492: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 20:56:12.492: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 20:56:12.492: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 20:56:12.492: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 20:56:13.123: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 20:56:13.123: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 20:56:13.123: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 29 20:56:13.123: INFO: Waiting for statefulset status.replicas updated to 0
May 29 20:56:13.164: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 29 20:56:23.249: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 29 20:56:23.249: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 29 20:56:23.249: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 29 20:56:23.391: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:23.391: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:23.391: INFO: ss-1  e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:23.391: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:23.391: INFO: 
May 29 20:56:23.391: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 20:56:24.434: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:24.434: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:24.434: INFO: ss-1  e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:24.434: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:24.434: INFO: 
May 29 20:56:24.434: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 20:56:25.477: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:25.477: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:25.477: INFO: ss-1  e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:25.477: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:25.477: INFO: 
May 29 20:56:25.477: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 20:56:26.520: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:26.520: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:26.520: INFO: ss-1  e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:26.520: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:26.520: INFO: 
May 29 20:56:26.520: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 20:56:27.563: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:27.563: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:27.563: INFO: ss-1  e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:27.563: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:27.563: INFO: 
May 29 20:56:27.563: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 20:56:28.605: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:28.606: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:28.606: INFO: ss-1  e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:28.606: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:28.606: INFO: 
May 29 20:56:28.606: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 20:56:29.649: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:29.649: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:29.649: INFO: ss-1  e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:29.649: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:29.649: INFO: 
May 29 20:56:29.649: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 20:56:30.693: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:30.693: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:30.693: INFO: ss-1  e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:30.693: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:30.693: INFO: 
May 29 20:56:30.693: INFO: StatefulSet ss has not reached scale 0, at 3
May 29 20:56:31.735: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:31.735: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:31.735: INFO: ss-2  e2e-test-peterhornyack-windows-node-group-1vjk  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:13 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:58 -0700 PDT  }]
May 29 20:56:31.735: INFO: 
May 29 20:56:31.735: INFO: StatefulSet ss has not reached scale 0, at 2
May 29 20:56:32.778: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 29 20:56:32.778: INFO: ss-0  e2e-test-peterhornyack-windows-node-group-1vjk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:56:11 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 20:55:37 -0700 PDT  }]
May 29 20:56:32.778: INFO: 
May 29 20:56:32.778: INFO: StatefulSet ss has not reached scale 0, at 1
[1mSTEP[0m: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8949
May 29 20:56:33.821: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:56:34.270: INFO: rc: 1
May 29 20:56:34.270: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc002759b00 exit status 1 <nil> <nil> true [0xc00019e958 0xc00019e9a0 0xc00019e9c8] [0xc00019e958 0xc00019e9a0 0xc00019e9c8] [0xc00019e980 0xc00019e9c0] [0x9bb530 0x9bb530] 0xc002081a40 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

May 29 20:56:44.270: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:56:44.510: INFO: rc: 1
May 29 20:56:44.511: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002850d80 exit status 1 <nil> <nil> true [0xc001ffa6d0 0xc001ffa6e8 0xc001ffa700] [0xc001ffa6d0 0xc001ffa6e8 0xc001ffa700] [0xc001ffa6e0 0xc001ffa6f8] [0x9bb530 0x9bb530] 0xc003996060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:56:54.511: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:56:54.761: INFO: rc: 1
May 29 20:56:54.761: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028510e0 exit status 1 <nil> <nil> true [0xc001ffa708 0xc001ffa720 0xc001ffa738] [0xc001ffa708 0xc001ffa720 0xc001ffa738] [0xc001ffa718 0xc001ffa730] [0x9bb530 0x9bb530] 0xc003996360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:57:04.761: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:57:05.012: INFO: rc: 1
May 29 20:57:05.012: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002ad5170 exit status 1 <nil> <nil> true [0xc0018c28d0 0xc0018c28e8 0xc0018c2900] [0xc0018c28d0 0xc0018c28e8 0xc0018c2900] [0xc0018c28e0 0xc0018c28f8] [0x9bb530 0x9bb530] 0xc002d78720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:57:15.012: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:57:15.252: INFO: rc: 1
May 29 20:57:15.252: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0028513e0 exit status 1 <nil> <nil> true [0xc001ffa740 0xc001ffa758 0xc001ffa770] [0xc001ffa740 0xc001ffa758 0xc001ffa770] [0xc001ffa750 0xc001ffa768] [0x9bb530 0x9bb530] 0xc003996660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:57:25.252: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:57:25.499: INFO: rc: 1
May 29 20:57:25.499: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003851f50 exit status 1 <nil> <nil> true [0xc0005fd7b0 0xc0005fd800 0xc0005fd848] [0xc0005fd7b0 0xc0005fd800 0xc0005fd848] [0xc0005fd7f0 0xc0005fd838] [0x9bb530 0x9bb530] 0xc003284840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:57:35.500: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:57:35.748: INFO: rc: 1
May 29 20:57:35.748: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033d02a0 exit status 1 <nil> <nil> true [0xc0000e9b20 0xc0000e9c38 0xc00057c0a0] [0xc0000e9b20 0xc0000e9c38 0xc00057c0a0] [0xc0000e9bf8 0xc00057c088] [0x9bb530 0x9bb530] 0xc002780720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:57:45.748: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:57:45.984: INFO: rc: 1
May 29 20:57:45.984: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033d05a0 exit status 1 <nil> <nil> true [0xc00057c0d0 0xc00019e008 0xc00019e330] [0xc00057c0d0 0xc00019e008 0xc00019e330] [0xc00057c1c0 0xc00019e328] [0x9bb530 0x9bb530] 0xc002780d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:57:55.992: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:57:56.252: INFO: rc: 1
May 29 20:57:56.252: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002152330 exit status 1 <nil> <nil> true [0xc001ffa000 0xc001ffa018 0xc001ffa030] [0xc001ffa000 0xc001ffa018 0xc001ffa030] [0xc001ffa010 0xc001ffa028] [0x9bb530 0x9bb530] 0xc001d6a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:58:06.252: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:58:06.495: INFO: rc: 1
May 29 20:58:06.495: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b0e360 exit status 1 <nil> <nil> true [0xc0005fc0c8 0xc0005fc168 0xc0005fc220] [0xc0005fc0c8 0xc0005fc168 0xc0005fc220] [0xc0005fc158 0xc0005fc208] [0x9bb530 0x9bb530] 0xc0028fd740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:58:16.496: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:58:16.750: INFO: rc: 1
May 29 20:58:16.750: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033d08a0 exit status 1 <nil> <nil> true [0xc00019e338 0xc00019e368 0xc00019e5c0] [0xc00019e338 0xc00019e368 0xc00019e5c0] [0xc00019e358 0xc00019e5b8] [0x9bb530 0x9bb530] 0xc0027813e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:58:26.750: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:58:26.998: INFO: rc: 1
May 29 20:58:26.998: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002152600 exit status 1 <nil> <nil> true [0xc001ffa038 0xc001ffa050 0xc001ffa068] [0xc001ffa038 0xc001ffa050 0xc001ffa068] [0xc001ffa048 0xc001ffa060] [0x9bb530 0x9bb530] 0xc001d6ac60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:58:36.999: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:58:37.285: INFO: rc: 1
May 29 20:58:37.285: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002152900 exit status 1 <nil> <nil> true [0xc001ffa070 0xc001ffa088 0xc001ffa0a0] [0xc001ffa070 0xc001ffa088 0xc001ffa0a0] [0xc001ffa080 0xc001ffa098] [0x9bb530 0x9bb530] 0xc001d6b440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:58:47.286: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:58:47.524: INFO: rc: 1
May 29 20:58:47.524: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00276e2a0 exit status 1 <nil> <nil> true [0xc002846000 0xc002846058 0xc0028460a8] [0xc002846000 0xc002846058 0xc0028460a8] [0xc002846048 0xc002846090] [0x9bb530 0x9bb530] 0xc0017962a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:58:57.524: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:58:57.769: INFO: rc: 1
May 29 20:58:57.769: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002152c00 exit status 1 <nil> <nil> true [0xc001ffa0a8 0xc001ffa0c0 0xc001ffa0d8] [0xc001ffa0a8 0xc001ffa0c0 0xc001ffa0d8] [0xc001ffa0b8 0xc001ffa0d0] [0x9bb530 0x9bb530] 0xc001d6bc20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:59:07.769: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:59:08.026: INFO: rc: 1
May 29 20:59:08.026: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002152f30 exit status 1 <nil> <nil> true [0xc001ffa0e0 0xc001ffa0f8 0xc001ffa110] [0xc001ffa0e0 0xc001ffa0f8 0xc001ffa110] [0xc001ffa0f0 0xc001ffa108] [0x9bb530 0x9bb530] 0xc002ffb020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:59:18.026: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:59:18.274: INFO: rc: 1
May 29 20:59:18.274: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b0e6c0 exit status 1 <nil> <nil> true [0xc0005fc360 0xc0005fc520 0xc0005fc688] [0xc0005fc360 0xc0005fc520 0xc0005fc688] [0xc0005fc4f8 0xc0005fc638] [0x9bb530 0x9bb530] 0xc001da5da0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:59:28.275: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:59:28.516: INFO: rc: 1
May 29 20:59:28.516: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b0e9c0 exit status 1 <nil> <nil> true [0xc0005fc718 0xc0005fc780 0xc0005fc7c8] [0xc0005fc718 0xc0005fc780 0xc0005fc7c8] [0xc0005fc760 0xc0005fc7a0] [0x9bb530 0x9bb530] 0xc0016055c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:59:38.516: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:59:38.754: INFO: rc: 1
May 29 20:59:38.755: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00276e2d0 exit status 1 <nil> <nil> true [0xc00057c0a0 0xc00057c1c0 0xc0000e9bc0] [0xc00057c0a0 0xc00057c1c0 0xc0000e9bc0] [0xc00057c180 0xc0000e9b20] [0x9bb530 0x9bb530] 0xc001ac2960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:59:48.755: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:59:49.013: INFO: rc: 1
May 29 20:59:49.013: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00276e5d0 exit status 1 <nil> <nil> true [0xc0000e9bf8 0xc002846000 0xc002846058] [0xc0000e9bf8 0xc002846000 0xc002846058] [0xc0000e9cc8 0xc002846048] [0x9bb530 0x9bb530] 0xc0028fd620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 20:59:59.014: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 20:59:59.258: INFO: rc: 1
May 29 20:59:59.258: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b0e330 exit status 1 <nil> <nil> true [0xc00019e008 0xc00019e330 0xc00019e358] [0xc00019e008 0xc00019e330 0xc00019e358] [0xc00019e328 0xc00019e348] [0x9bb530 0x9bb530] 0xc001d6a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:00:09.258: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:00:09.501: INFO: rc: 1
May 29 21:00:09.501: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b0e660 exit status 1 <nil> <nil> true [0xc00019e368 0xc00019e5c0 0xc00019e5d8] [0xc00019e368 0xc00019e5c0 0xc00019e5d8] [0xc00019e5b8 0xc00019e5d0] [0x9bb530 0x9bb530] 0xc001d6ac60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:00:19.501: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:00:19.759: INFO: rc: 1
May 29 21:00:19.759: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033d0330 exit status 1 <nil> <nil> true [0xc0005fc0c8 0xc0005fc168 0xc0005fc220] [0xc0005fc0c8 0xc0005fc168 0xc0005fc220] [0xc0005fc158 0xc0005fc208] [0x9bb530 0x9bb530] 0xc0017962a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:00:29.759: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:00:30.009: INFO: rc: 1
May 29 21:00:30.009: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0033d0690 exit status 1 <nil> <nil> true [0xc0005fc360 0xc0005fc520 0xc0005fc688] [0xc0005fc360 0xc0005fc520 0xc0005fc688] [0xc0005fc4f8 0xc0005fc638] [0x9bb530 0x9bb530] 0xc0017965a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:00:40.010: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:00:40.275: INFO: rc: 1
May 29 21:00:40.275: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00276e8d0 exit status 1 <nil> <nil> true [0xc002846068 0xc0028460f0 0xc002846118] [0xc002846068 0xc0028460f0 0xc002846118] [0xc0028460a8 0xc002846110] [0x9bb530 0x9bb530] 0xc0027803c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:00:50.275: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:00:50.506: INFO: rc: 1
May 29 21:00:50.506: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002152360 exit status 1 <nil> <nil> true [0xc001ffa000 0xc001ffa018 0xc001ffa030] [0xc001ffa000 0xc001ffa018 0xc001ffa030] [0xc001ffa010 0xc001ffa028] [0x9bb530 0x9bb530] 0xc002ffb020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:01:00.507: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:01:00.762: INFO: rc: 1
May 29 21:01:00.762: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002152660 exit status 1 <nil> <nil> true [0xc001ffa038 0xc001ffa050 0xc001ffa068] [0xc001ffa038 0xc001ffa050 0xc001ffa068] [0xc001ffa048 0xc001ffa060] [0x9bb530 0x9bb530] 0xc002ffb320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:01:10.763: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:01:11.013: INFO: rc: 1
May 29 21:01:11.013: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001b0e9f0 exit status 1 <nil> <nil> true [0xc00019e5e0 0xc00019e5f8 0xc00019e610] [0xc00019e5e0 0xc00019e5f8 0xc00019e610] [0xc00019e5f0 0xc00019e608] [0x9bb530 0x9bb530] 0xc001d6b440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:01:21.013: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:01:21.253: INFO: rc: 1
May 29 21:01:21.253: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00276ebd0 exit status 1 <nil> <nil> true [0xc002846120 0xc002846138 0xc002846150] [0xc002846120 0xc002846138 0xc002846150] [0xc002846130 0xc002846148] [0x9bb530 0x9bb530] 0xc0027807e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:01:31.253: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:01:31.529: INFO: rc: 1
May 29 21:01:31.529: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl [kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00276eea0 exit status 1 <nil> <nil> true [0xc002846158 0xc002846170 0xc002846188] [0xc002846158 0xc002846170 0xc002846188] [0xc002846168 0xc002846180] [0x9bb530 0x9bb530] 0xc002780f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

May 29 21:01:41.530: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-8949 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:01:41.775: INFO: rc: 1
May 29 21:01:41.775: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
May 29 21:01:41.775: INFO: Scaling statefulset ss to 0
May 29 21:01:41.902: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 21:01:41.944: INFO: Deleting all statefulset in ns statefulset-8949
May 29 21:01:41.985: INFO: Scaling statefulset ss to 0
May 29 21:01:42.113: INFO: Waiting for statefulset status.replicas updated to 0
May 29 21:01:42.154: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:01:42.283: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-8949" for this suite.
May 29 21:01:48.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:01:50.116: INFO: namespace statefulset-8949 deletion completed in 7.790619587s

[32m• [SLOW TEST:372.809 seconds][0m
[sig-apps] StatefulSet
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mshould perform rolling updates and roll backs of template modifications [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:01:50.117: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-9070
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a new StatefulSet
May 29 21:01:50.454: INFO: Found 1 stateful pods, waiting for 3
May 29 21:02:00.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:02:10.498: INFO: Found 2 stateful pods, waiting for 3
May 29 21:02:20.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:02:30.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:02:40.501: INFO: Found 2 stateful pods, waiting for 3
May 29 21:02:50.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:03:00.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:03:10.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:03:20.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:03:30.496: INFO: Found 2 stateful pods, waiting for 3
May 29 21:03:40.499: INFO: Found 2 stateful pods, waiting for 3
May 29 21:03:50.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:04:00.498: INFO: Found 2 stateful pods, waiting for 3
May 29 21:04:10.504: INFO: Found 2 stateful pods, waiting for 3
May 29 21:04:20.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:04:30.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:04:40.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:04:50.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:05:00.498: INFO: Found 2 stateful pods, waiting for 3
May 29 21:05:10.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:05:20.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:05:30.498: INFO: Found 2 stateful pods, waiting for 3
May 29 21:05:40.498: INFO: Found 2 stateful pods, waiting for 3
May 29 21:05:50.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:06:00.498: INFO: Found 2 stateful pods, waiting for 3
May 29 21:06:10.498: INFO: Found 2 stateful pods, waiting for 3
May 29 21:06:20.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:06:30.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:06:40.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:06:50.497: INFO: Found 2 stateful pods, waiting for 3
May 29 21:07:00.497: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 21:07:00.497: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 21:07:00.497: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
May 29 21:07:10.497: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 29 21:07:10.497: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 29 21:07:10.497: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 29 21:07:10.626: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-9070 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 29 21:07:11.288: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
May 29 21:07:11.288: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 29 21:07:11.288: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

[1mSTEP[0m: Updating StatefulSet template: update image from e2eteam/nginx:1.14-alpine to e2eteam/nginx:1.15-alpine
May 29 21:07:11.471: INFO: Updating stateful set ss2
[1mSTEP[0m: Creating a new revision
[1mSTEP[0m: Updating Pods in reverse ordinal order
May 29 21:07:11.598: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec --namespace=statefulset-9070 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 29 21:07:12.241: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
May 29 21:07:12.241: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 29 21:07:12.241: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 29 21:07:12.422: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:07:12.422: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:12.422: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:12.422: INFO: Waiting for Pod statefulset-9070/ss2-2 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:22.508: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:07:22.508: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:22.508: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:32.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:07:32.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:32.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:42.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:07:42.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:42.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:52.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:07:52.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:07:52.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:02.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:08:02.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:02.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:12.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:08:12.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:12.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:22.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:08:22.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:22.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:32.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:08:32.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:32.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:42.509: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:08:42.509: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:42.509: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:52.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:08:52.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:08:52.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:02.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:09:02.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:02.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:12.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:09:12.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:12.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:22.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:09:22.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:22.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:32.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:09:32.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:32.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:42.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:09:42.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:42.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:52.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:09:52.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:09:52.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:02.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:10:02.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:02.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:12.515: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:10:12.516: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:12.516: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:22.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:10:22.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:22.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:32.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:10:32.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:32.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:42.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:10:42.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:42.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:52.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:10:52.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:10:52.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:02.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:11:02.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:02.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:12.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:11:12.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:12.508: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:22.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:11:22.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:22.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:32.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:11:32.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:32.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:42.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:11:42.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:42.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:52.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:11:52.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:11:52.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:02.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:12:02.508: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:02.508: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:12.508: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:12:12.508: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:12.508: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:22.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:12:22.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:22.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:32.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:12:32.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:32.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:42.523: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:12:42.523: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:42.524: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:52.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:12:52.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:12:52.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:02.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:13:02.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:02.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:12.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:13:12.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:12.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:22.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:13:22.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:22.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:32.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:13:32.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:32.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:42.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:13:42.508: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:42.508: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:52.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:13:52.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:13:52.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:02.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:14:02.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:02.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:12.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:14:12.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:12.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:22.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:14:22.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:22.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:32.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:14:32.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:32.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:42.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:14:42.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:42.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:52.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:14:52.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:14:52.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:02.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:15:02.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:02.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:12.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:15:12.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:12.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:22.511: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:15:22.511: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:22.511: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:32.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:15:32.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:32.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:42.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:15:42.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:42.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:52.514: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:15:52.514: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:15:52.514: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:02.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:16:02.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:02.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:12.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:16:12.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:12.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:22.512: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:16:22.512: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:22.512: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:32.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:16:32.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:32.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:42.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:16:42.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:42.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:52.507: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:16:52.507: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:16:52.507: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:17:02.508: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:17:02.508: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:17:02.508: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:17:12.506: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:17:12.506: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:17:12.506: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:17:12.590: INFO: Waiting for StatefulSet statefulset-9070/ss2 to complete update
May 29 21:17:12.590: INFO: Waiting for Pod statefulset-9070/ss2-0 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:17:12.590: INFO: Waiting for Pod statefulset-9070/ss2-1 to have revision ss2-5f4db4b9f4 update revision ss2-577b4dc465
May 29 21:17:12.590: INFO: Failed waiting for state update: timed out waiting for the condition
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 21:17:12.632: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe po ss2-0 --namespace=statefulset-9070'
May 29 21:17:13.473: INFO: stderr: ""
May 29 21:17:13.473: INFO: stdout: "Name:               ss2-0\nNamespace:          statefulset-9070\nPriority:           0\nPriorityClassName:  <none>\nNode:               e2e-test-peterhornyack-windows-node-group-1vjk/10.40.0.5\nStart Time:         Wed, 29 May 2019 21:01:50 -0700\nLabels:             baz=blah\n                    controller-revision-hash=ss2-577b4dc465\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-0\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.64.2.48\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   docker://0d865ab018b0c54f0ae25129ad12aca1b28b72176acfadb1e59a9886551984bd\n    Image:          e2eteam/nginx:1.14-alpine\n    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Wed, 29 May 2019 21:01:54 -0700\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7bfwg (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7bfwg:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7bfwg\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                     Message\n  ----    ------     ----  ----                                                     -------\n  Normal  Scheduled  15m   default-scheduler                                        Successfully assigned statefulset-9070/ss2-0 to e2e-test-peterhornyack-windows-node-group-1vjk\n  Normal  Pulled     15m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Container image \"e2eteam/nginx:1.14-alpine\" already present on machine\n  Normal  Created    15m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Created container nginx\n  Normal  Started    15m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Started container nginx\n"
May 29 21:17:13.473: INFO: 
Output of kubectl describe ss2-0:
Name:               ss2-0
Namespace:          statefulset-9070
Priority:           0
PriorityClassName:  <none>
Node:               e2e-test-peterhornyack-windows-node-group-1vjk/10.40.0.5
Start Time:         Wed, 29 May 2019 21:01:50 -0700
Labels:             baz=blah
                    controller-revision-hash=ss2-577b4dc465
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-0
Annotations:        <none>
Status:             Running
IP:                 10.64.2.48
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   docker://0d865ab018b0c54f0ae25129ad12aca1b28b72176acfadb1e59a9886551984bd
    Image:          e2eteam/nginx:1.14-alpine
    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 29 May 2019 21:01:54 -0700
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7bfwg (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-7bfwg:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-7bfwg
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From                                                     Message
  ----    ------     ----  ----                                                     -------
  Normal  Scheduled  15m   default-scheduler                                        Successfully assigned statefulset-9070/ss2-0 to e2e-test-peterhornyack-windows-node-group-1vjk
  Normal  Pulled     15m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Container image "e2eteam/nginx:1.14-alpine" already present on machine
  Normal  Created    15m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Created container nginx
  Normal  Started    15m   kubelet, e2e-test-peterhornyack-windows-node-group-1vjk  Started container nginx

May 29 21:17:13.473: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs ss2-0 --namespace=statefulset-9070 --tail=100'
May 29 21:17:13.787: INFO: stderr: ""
May 29 21:17:13.787: INFO: stdout: ""
May 29 21:17:13.787: INFO: 
Last 100 log lines of ss2-0:

May 29 21:17:13.787: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe po ss2-1 --namespace=statefulset-9070'
May 29 21:17:14.136: INFO: stderr: ""
May 29 21:17:14.136: INFO: stdout: "Name:                      ss2-1\nNamespace:                 statefulset-9070\nPriority:                  0\nPriorityClassName:         <none>\nNode:                      e2e-test-peterhornyack-windows-node-group-jpxd/10.40.0.3\nStart Time:                Wed, 29 May 2019 21:01:57 -0700\nLabels:                    baz=blah\n                           controller-revision-hash=ss2-577b4dc465\n                           foo=bar\n                           statefulset.kubernetes.io/pod-name=ss2-1\nAnnotations:               <none>\nStatus:                    Terminating (lasts 9m)\nTermination Grace Period:  30s\nIP:                        10.64.1.103\nControlled By:             StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   docker://7000d7494890994ea1d31ace85e2384a3441fc8b496ec408d86396931c42f3fd\n    Image:          e2eteam/nginx:1.14-alpine\n    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Wed, 29 May 2019 21:02:02 -0700\n    Ready:          False\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7bfwg (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  default-token-7bfwg:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7bfwg\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type     Reason     Age   From                                                     Message\n  ----     ------     ----  ----                                                     -------\n  Normal   Scheduled  15m   default-scheduler                                        Successfully assigned statefulset-9070/ss2-1 to e2e-test-peterhornyack-windows-node-group-jpxd\n  Normal   Pulled     15m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Container image \"e2eteam/nginx:1.14-alpine\" already present on machine\n  Normal   Created    15m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Created container nginx\n  Normal   Started    15m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Started container nginx\n  Warning  Unhealthy  10m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Readiness probe failed: HTTP probe failed with statuscode: 404\n  Normal   Killing    17s   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Stopping container nginx\n"
May 29 21:17:14.137: INFO: 
Output of kubectl describe ss2-1:
Name:                      ss2-1
Namespace:                 statefulset-9070
Priority:                  0
PriorityClassName:         <none>
Node:                      e2e-test-peterhornyack-windows-node-group-jpxd/10.40.0.3
Start Time:                Wed, 29 May 2019 21:01:57 -0700
Labels:                    baz=blah
                           controller-revision-hash=ss2-577b4dc465
                           foo=bar
                           statefulset.kubernetes.io/pod-name=ss2-1
Annotations:               <none>
Status:                    Terminating (lasts 9m)
Termination Grace Period:  30s
IP:                        10.64.1.103
Controlled By:             StatefulSet/ss2
Containers:
  nginx:
    Container ID:   docker://7000d7494890994ea1d31ace85e2384a3441fc8b496ec408d86396931c42f3fd
    Image:          e2eteam/nginx:1.14-alpine
    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 29 May 2019 21:02:02 -0700
    Ready:          False
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7bfwg (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  default-token-7bfwg:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-7bfwg
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason     Age   From                                                     Message
  ----     ------     ----  ----                                                     -------
  Normal   Scheduled  15m   default-scheduler                                        Successfully assigned statefulset-9070/ss2-1 to e2e-test-peterhornyack-windows-node-group-jpxd
  Normal   Pulled     15m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Container image "e2eteam/nginx:1.14-alpine" already present on machine
  Normal   Created    15m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Created container nginx
  Normal   Started    15m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Started container nginx
  Warning  Unhealthy  10m   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Readiness probe failed: HTTP probe failed with statuscode: 404
  Normal   Killing    17s   kubelet, e2e-test-peterhornyack-windows-node-group-jpxd  Stopping container nginx

May 29 21:17:14.137: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs ss2-1 --namespace=statefulset-9070 --tail=100'
May 29 21:17:14.452: INFO: stderr: ""
May 29 21:17:14.452: INFO: stdout: ""
May 29 21:17:14.452: INFO: 
Last 100 log lines of ss2-1:

May 29 21:17:14.453: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config describe po ss2-2 --namespace=statefulset-9070'
May 29 21:17:14.806: INFO: stderr: ""
May 29 21:17:14.806: INFO: stdout: "Name:               ss2-2\nNamespace:          statefulset-9070\nPriority:           0\nPriorityClassName:  <none>\nNode:               e2e-test-peterhornyack-windows-node-group-9q9v/10.40.0.4\nStart Time:         Wed, 29 May 2019 21:07:20 -0700\nLabels:             baz=blah\n                    controller-revision-hash=ss2-5f4db4b9f4\n                    foo=bar\n                    statefulset.kubernetes.io/pod-name=ss2-2\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.64.3.93\nControlled By:      StatefulSet/ss2\nContainers:\n  nginx:\n    Container ID:   docker://c826d5396d4c19de105fe225411218284f0f5eb7c9ab9fc0917cfb2c2ce0dd62\n    Image:          e2eteam/nginx:1.15-alpine\n    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Wed, 29 May 2019 21:07:25 -0700\n    Ready:          True\n    Restart Count:  0\n    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7bfwg (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7bfwg:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7bfwg\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                     Message\n  ----    ------     ----  ----                                                     -------\n  Normal  Scheduled  9m    default-scheduler                                        Successfully assigned statefulset-9070/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v\n  Normal  Pulled     9m    kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Container image \"e2eteam/nginx:1.15-alpine\" already present on machine\n  Normal  Created    9m    kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Created container nginx\n  Normal  Started    9m    kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Started container nginx\n"
May 29 21:17:14.806: INFO: 
Output of kubectl describe ss2-2:
Name:               ss2-2
Namespace:          statefulset-9070
Priority:           0
PriorityClassName:  <none>
Node:               e2e-test-peterhornyack-windows-node-group-9q9v/10.40.0.4
Start Time:         Wed, 29 May 2019 21:07:20 -0700
Labels:             baz=blah
                    controller-revision-hash=ss2-5f4db4b9f4
                    foo=bar
                    statefulset.kubernetes.io/pod-name=ss2-2
Annotations:        <none>
Status:             Running
IP:                 10.64.3.93
Controlled By:      StatefulSet/ss2
Containers:
  nginx:
    Container ID:   docker://c826d5396d4c19de105fe225411218284f0f5eb7c9ab9fc0917cfb2c2ce0dd62
    Image:          e2eteam/nginx:1.15-alpine
    Image ID:       docker-pullable://e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Wed, 29 May 2019 21:07:25 -0700
    Ready:          True
    Restart Count:  0
    Readiness:      http-get http://:80/index.html delay=0s timeout=1s period=1s #success=1 #failure=1
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7bfwg (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  default-token-7bfwg:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-7bfwg
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From                                                     Message
  ----    ------     ----  ----                                                     -------
  Normal  Scheduled  9m    default-scheduler                                        Successfully assigned statefulset-9070/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v
  Normal  Pulled     9m    kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Container image "e2eteam/nginx:1.15-alpine" already present on machine
  Normal  Created    9m    kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Created container nginx
  Normal  Started    9m    kubelet, e2e-test-peterhornyack-windows-node-group-9q9v  Started container nginx

May 29 21:17:14.806: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config logs ss2-2 --namespace=statefulset-9070 --tail=100'
May 29 21:17:15.127: INFO: stderr: ""
May 29 21:17:15.127: INFO: stdout: ""
May 29 21:17:15.127: INFO: 
Last 100 log lines of ss2-2:

May 29 21:17:15.127: INFO: Deleting all statefulset in ns statefulset-9070
May 29 21:17:15.169: INFO: Scaling statefulset ss2 to 0
May 29 21:27:15.383: INFO: Waiting for statefulset status.replicas updated to 0
May 29 21:27:15.426: INFO: Waiting for stateful set status.replicas to become 0, currently 1
May 29 21:27:25.468: INFO: Waiting for stateful set status.replicas to become 0, currently 1
May 29 21:27:35.468: INFO: Waiting for stateful set status.replicas to become 0, currently 1
May 29 21:27:45.468: INFO: Deleting statefulset ss2
May 29 21:27:45.596: INFO: Unexpected error occurred: Failed to scale statefulset to 0 in 10m0s. Remaining pods:
[ss2-0: deletion 2019-05-29 21:27:34 -0700 PDT, phase Running, readiness false]
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "statefulset-9070".
[1mSTEP[0m: Found 28 events.
May 29 21:27:45.639: INFO: At 2019-05-29 21:01:50 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-0 in StatefulSet ss2 successful
May 29 21:27:45.639: INFO: At 2019-05-29 21:01:50 -0700 PDT - event for ss2-0: {default-scheduler } Scheduled: Successfully assigned statefulset-9070/ss2-0 to e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:27:45.639: INFO: At 2019-05-29 21:01:52 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Created: Created container nginx
May 29 21:27:45.639: INFO: At 2019-05-29 21:01:52 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 21:27:45.639: INFO: At 2019-05-29 21:01:55 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Started: Started container nginx
May 29 21:27:45.639: INFO: At 2019-05-29 21:01:57 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-1 in StatefulSet ss2 successful
May 29 21:27:45.639: INFO: At 2019-05-29 21:01:57 -0700 PDT - event for ss2-1: {default-scheduler } Scheduled: Successfully assigned statefulset-9070/ss2-1 to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:27:45.639: INFO: At 2019-05-29 21:01:59 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 21:27:45.640: INFO: At 2019-05-29 21:01:59 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:02:02 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:05:06 -0700 PDT - event for ss2-1: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod statefulset-9070/ss2-1
May 29 21:27:45.640: INFO: At 2019-05-29 21:06:55 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulCreate: create Pod ss2-2 in StatefulSet ss2 successful
May 29 21:27:45.640: INFO: At 2019-05-29 21:06:55 -0700 PDT - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned statefulset-9070/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:27:45.640: INFO: At 2019-05-29 21:06:57 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Container image "e2eteam/nginx:1.14-alpine" already present on machine
May 29 21:27:45.640: INFO: At 2019-05-29 21:06:57 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:00 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:11 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Unhealthy: Readiness probe failed: HTTP probe failed with statuscode: 404
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:12 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-2 in StatefulSet ss2 successful
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:12 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Killing: Stopping container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:21 -0700 PDT - event for ss2-2: {default-scheduler } Scheduled: Successfully assigned statefulset-9070/ss2-2 to e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:23 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Container image "e2eteam/nginx:1.15-alpine" already present on machine
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:23 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:26 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:07:29 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-1 in StatefulSet ss2 successful
May 29 21:27:45.640: INFO: At 2019-05-29 21:16:57 -0700 PDT - event for ss2-1: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Killing: Stopping container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:17:15 -0700 PDT - event for ss2-2: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Killing: Stopping container nginx
May 29 21:27:45.640: INFO: At 2019-05-29 21:27:04 -0700 PDT - event for ss2: {statefulset-controller } SuccessfulDelete: delete Pod ss2-0 in StatefulSet ss2 successful
May 29 21:27:45.640: INFO: At 2019-05-29 21:27:04 -0700 PDT - event for ss2-0: {kubelet e2e-test-peterhornyack-windows-node-group-1vjk} Killing: Stopping container nginx
May 29 21:27:45.727: INFO: POD                                                    NODE                                      PHASE    GRACE  CONDITIONS
May 29 21:27:45.728: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:27:45.728: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 21:27:45.728: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:27:45.728: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:27:45.728: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:27:45.728: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:27:45.728: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:27:45.728: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 21:27:45.728: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 21:27:45.728: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 21:27:45.728: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 21:27:45.728: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:27:45.728: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 21:27:45.728: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 21:27:45.728: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:27:45.728: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 21:27:45.728: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 21:27:45.728: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:27:45.728: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:27:45.728: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:27:45.728: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:27:45.728: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:27:45.728: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:27:45.728: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 21:27:45.729: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 21:27:45.729: INFO: 
May 29 21:27:45.772: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 21:27:45.814: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:50986,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:26:46 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:26:46 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:26:46 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:26:46 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 21:27:45.814: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 21:27:45.855: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 21:27:45.901: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:27:45.901: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:27:45.901: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:27:45.901: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:27:45.901: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:27:45.901: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:27:45.901: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:45.901: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 21:27:45.901: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:27:45.901: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:27:45.901: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:27:45.901: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:45.901: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 21:27:45.901: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:27:46.064: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 21:27:46.064: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 21:27:46.106: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:51056,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentKubeletRestart False 2019-05-29 21:27:11 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 21:27:11 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 21:27:11 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 21:27:11 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 21:27:11 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 21:27:11 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 21:27:11 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:27:06 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:27:06 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:27:06 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:27:06 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 21:27:46.106: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 21:27:46.147: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 21:27:46.195: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:46.195: INFO: 	Container event-exporter ready: true, restart count 0
May 29 21:27:46.195: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:27:46.195: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:27:46.195: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 21:27:46.195: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:46.195: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 21:27:46.195: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:27:46.195: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:27:46.195: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 21:27:46.195: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:27:46.195: INFO: 	Container coredns ready: true, restart count 0
May 29 21:27:46.195: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:27:46.195: INFO: 	Container autoscaler ready: true, restart count 0
May 29 21:27:46.195: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:27:46.195: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 21:27:46.195: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:46.195: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 21:27:46.195: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:27:46.195: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 21:27:46.356: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 21:27:46.356: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 21:27:46.397: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:51112,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{ReadonlyFilesystem False 2019-05-29 21:27:02 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 21:27:02 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 21:27:02 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 21:27:02 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 21:27:02 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 21:27:02 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 21:27:02 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:27:37 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:27:37 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:27:37 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:27:37 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 21:27:46.398: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 21:27:46.440: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 21:27:46.488: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:46.488: INFO: 	Container heapster ready: true, restart count 0
May 29 21:27:46.488: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 21:27:46.488: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 21:27:46.488: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:46.488: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 21:27:46.488: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:27:46.488: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:46.488: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 21:27:46.488: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:27:46.488: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 21:27:46.488: INFO: 	Container coredns ready: true, restart count 0
May 29 21:27:46.488: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 21:27:46.488: INFO: 	Container metrics-server ready: true, restart count 0
May 29 21:27:46.488: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 21:27:46.662: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 21:27:46.662: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:27:46.704: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:51081,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:27:23 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:27:23 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:27:23 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:27:23 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 21:27:46.705: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:27:46.746: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:27:46.951: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:27:46.951: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:27:46.993: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:51104,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:27:33 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:27:33 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:27:33 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:27:33 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 21:27:46.994: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:27:47.035: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:27:47.234: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:27:47.234: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:27:47.276: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:51038,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:27:06 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:27:06 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:27:06 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:27:06 -0700 PDT 2019-05-29 21:25:06 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 21:27:47.276: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:27:47.318: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:27:47.545: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:27:47.545: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-9070" for this suite.
May 29 21:27:53.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:27:55.323: INFO: namespace statefulset-9070 deletion completed in 7.735341641s

[91m[1m• Failure [1565.206 seconds][0m
[sig-apps] StatefulSet
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22[0m
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
    [91m[1mshould perform rolling updates and roll backs of template modifications [Conformance] [It][0m
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mMay 29 21:17:12.590: Failed waiting for state update: timed out waiting for the condition[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/statefulset_utils.go:337
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:27:55.323: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name configmap-test-volume-eda379b8-7e0b-485a-9edb-886f7d285f1d
[1mSTEP[0m: Creating a pod to test consume configMaps
May 29 21:27:55.582: INFO: Waiting up to 5m0s for pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201" in namespace "configmap-6879" to be "success or failure"
May 29 21:27:55.624: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Pending", Reason="", readiness=false. Elapsed: 41.732409ms
May 29 21:27:57.666: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08389935s
May 29 21:27:59.708: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125538948s
May 29 21:28:01.749: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Pending", Reason="", readiness=false. Elapsed: 6.166771047s
May 29 21:28:03.791: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Pending", Reason="", readiness=false. Elapsed: 8.208746575s
May 29 21:28:05.834: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Running", Reason="", readiness=true. Elapsed: 10.251077385s
May 29 21:28:07.875: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Running", Reason="", readiness=true. Elapsed: 12.29285694s
May 29 21:28:09.918: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Running", Reason="", readiness=true. Elapsed: 14.335879752s
May 29 21:28:11.960: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.377983026s
[1mSTEP[0m: Saw pod success
May 29 21:28:11.960: INFO: Pod "pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201" satisfied condition "success or failure"
May 29 21:28:12.002: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 21:28:12.102: INFO: Waiting for pod pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201 to disappear
May 29 21:28:12.145: INFO: Pod pod-configmaps-694b38ed-2e1d-4ec8-8fc7-11ac02443201 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:28:12.145: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 21:28:12.188: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 21:28:06 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 21:28:06 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "configmap-6879" for this suite.
May 29 21:28:18.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:28:19.903: INFO: namespace configmap-6879 deletion completed in 7.715392742s
[32m•[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 21:28:19.904: INFO: Driver hostPath doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:28:19.905: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver hostPath doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould create and stop a replication controller  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:28:19.906: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should create and stop a replication controller  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating a replication controller
May 29 21:28:20.104: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-5407'
May 29 21:28:22.567: INFO: stderr: ""
May 29 21:28:22.567: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 29 21:28:22.567: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5407'
May 29 21:28:22.827: INFO: stderr: ""
May 29 21:28:22.827: INFO: stdout: "update-demo-nautilus-pqn5m update-demo-nautilus-xrg54 "
May 29 21:28:22.827: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-pqn5m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5407'
May 29 21:28:23.083: INFO: stderr: ""
May 29 21:28:23.083: INFO: stdout: ""
May 29 21:28:23.083: INFO: update-demo-nautilus-pqn5m is created but not running
May 29 21:28:28.083: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5407'
May 29 21:28:28.341: INFO: stderr: ""
May 29 21:28:28.341: INFO: stdout: "update-demo-nautilus-pqn5m update-demo-nautilus-xrg54 "
May 29 21:28:28.341: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-pqn5m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5407'
May 29 21:28:28.590: INFO: stderr: ""
May 29 21:28:28.590: INFO: stdout: ""
May 29 21:28:28.590: INFO: update-demo-nautilus-pqn5m is created but not running
May 29 21:28:33.590: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5407'
May 29 21:28:33.844: INFO: stderr: ""
May 29 21:28:33.844: INFO: stdout: "update-demo-nautilus-pqn5m update-demo-nautilus-xrg54 "
May 29 21:28:33.844: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-pqn5m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5407'
May 29 21:28:34.100: INFO: stderr: ""
May 29 21:28:34.100: INFO: stdout: "true"
May 29 21:28:34.100: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-pqn5m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5407'
May 29 21:28:34.347: INFO: stderr: ""
May 29 21:28:34.347: INFO: stdout: "e2eteam/nautilus:1.0"
May 29 21:28:34.347: INFO: validating pod update-demo-nautilus-pqn5m
May 29 21:28:34.463: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 21:28:34.463: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 21:28:34.463: INFO: update-demo-nautilus-pqn5m is verified up and running
May 29 21:28:34.464: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-xrg54 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5407'
May 29 21:28:34.755: INFO: stderr: ""
May 29 21:28:34.756: INFO: stdout: "true"
May 29 21:28:34.756: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-xrg54 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5407'
May 29 21:28:35.009: INFO: stderr: ""
May 29 21:28:35.010: INFO: stdout: "e2eteam/nautilus:1.0"
May 29 21:28:35.010: INFO: validating pod update-demo-nautilus-xrg54
May 29 21:28:35.126: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 21:28:35.126: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 21:28:35.126: INFO: update-demo-nautilus-xrg54 is verified up and running
[1mSTEP[0m: using delete to clean up resources
May 29 21:28:35.126: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-5407'
May 29 21:28:35.430: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 21:28:35.430: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 29 21:28:35.431: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5407'
May 29 21:28:35.753: INFO: stderr: "No resources found.\n"
May 29 21:28:35.753: INFO: stdout: ""
May 29 21:28:35.753: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -l name=update-demo --namespace=kubectl-5407 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 21:28:36.010: INFO: stderr: ""
May 29 21:28:36.010: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:28:36.010: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 21:28:36.053: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 21:28:06 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 21:28:06 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "kubectl-5407" for this suite.
May 29 21:29:28.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:29:29.815: INFO: namespace kubectl-5407 deletion completed in 53.762327206s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide pod UID as env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:29:29.815: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward api env vars
May 29 21:29:30.075: INFO: Waiting up to 5m0s for pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed" in namespace "downward-api-9571" to be "success or failure"
May 29 21:29:30.117: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 41.850993ms
May 29 21:29:32.158: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08344657s
May 29 21:29:34.200: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125349911s
May 29 21:29:36.242: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167216856s
May 29 21:29:38.283: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 8.208687099s
May 29 21:29:40.325: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.250678832s
May 29 21:29:42.367: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 12.292407202s
May 29 21:29:44.409: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 14.333981802s
May 29 21:29:46.450: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 16.375450143s
May 29 21:29:48.492: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 18.417365664s
May 29 21:29:50.534: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 20.459309097s
May 29 21:29:52.578: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 22.502930402s
May 29 21:29:54.620: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 24.545680017s
May 29 21:29:56.666: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 26.591708672s
May 29 21:29:58.708: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 28.633601165s
May 29 21:30:00.751: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 30.676718384s
May 29 21:30:02.793: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 32.718602093s
May 29 21:30:04.835: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 34.760343617s
May 29 21:30:06.877: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 36.802062582s
May 29 21:30:08.919: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 38.843934791s
May 29 21:30:10.960: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 40.885507045s
May 29 21:30:13.002: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 42.927622122s
May 29 21:30:15.044: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 44.969516065s
May 29 21:30:17.086: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 47.011221857s
May 29 21:30:19.128: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 49.053175215s
May 29 21:30:21.169: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 51.094840997s
May 29 21:30:23.211: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 53.136437045s
May 29 21:30:25.253: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 55.178458705s
May 29 21:30:27.295: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 57.220523671s
May 29 21:30:29.337: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 59.262498478s
May 29 21:30:31.379: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.3046671s
May 29 21:30:33.421: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.346434259s
May 29 21:30:35.463: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.38851417s
May 29 21:30:37.505: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.430476786s
May 29 21:30:39.547: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.472323799s
May 29 21:30:41.588: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.51384005s
May 29 21:30:43.630: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.555753139s
May 29 21:30:45.672: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.59712529s
May 29 21:30:47.716: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.641225981s
May 29 21:30:49.757: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.682760257s
May 29 21:30:51.800: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.724858485s
May 29 21:30:53.842: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.76776756s
May 29 21:30:55.884: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.809225143s
May 29 21:30:57.925: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.850828502s
May 29 21:30:59.967: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.892474309s
May 29 21:31:02.009: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.934592109s
May 29 21:31:04.052: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.977078451s
May 29 21:31:06.094: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.019091589s
May 29 21:31:08.135: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.06068364s
May 29 21:31:10.177: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.102586643s
May 29 21:31:12.219: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.144572262s
May 29 21:31:14.261: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.186758574s
May 29 21:31:16.306: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.231452015s
May 29 21:31:18.348: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.273460039s
May 29 21:31:20.390: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.315167979s
May 29 21:31:22.432: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.357420735s
May 29 21:31:24.474: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.399511203s
May 29 21:31:26.516: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.441417729s
May 29 21:31:28.560: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.485239442s
May 29 21:31:30.602: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.527494154s
May 29 21:31:32.644: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.569422483s
May 29 21:31:34.686: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.611421517s
May 29 21:31:36.732: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.657270289s
May 29 21:31:38.775: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.70055019s
May 29 21:31:40.818: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.743241034s
May 29 21:31:42.860: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.785110341s
May 29 21:31:44.902: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.827238779s
May 29 21:31:46.944: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.869401177s
May 29 21:31:48.991: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.916123134s
May 29 21:31:51.033: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.958116238s
May 29 21:31:53.074: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.999776804s
May 29 21:31:55.116: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.041756611s
May 29 21:31:57.158: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.083813874s
May 29 21:31:59.201: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.125866807s
May 29 21:32:01.242: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.167815025s
May 29 21:32:03.286: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.21098685s
May 29 21:32:05.328: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.252862738s
May 29 21:32:07.369: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.294808496s
May 29 21:32:09.412: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.336877343s
May 29 21:32:11.454: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.37892311s
May 29 21:32:13.496: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.421826293s
May 29 21:32:15.539: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.463913596s
May 29 21:32:17.581: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.506839341s
May 29 21:32:19.624: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.549257438s
May 29 21:32:21.667: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.592126612s
May 29 21:32:23.708: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.633845234s
May 29 21:32:25.751: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.676051188s
May 29 21:32:27.793: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.717863941s
May 29 21:32:29.834: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.759465471s
May 29 21:32:31.876: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.801321636s
May 29 21:32:33.918: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.84325523s
May 29 21:32:35.960: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.885166167s
May 29 21:32:38.002: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.927028665s
May 29 21:32:40.044: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.969072973s
May 29 21:32:42.085: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.010725359s
May 29 21:32:44.127: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.052787887s
May 29 21:32:46.170: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.09490216s
May 29 21:32:48.211: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.136610489s
May 29 21:32:50.253: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.178410359s
May 29 21:32:52.295: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.220538723s
May 29 21:32:54.337: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.262358914s
May 29 21:32:56.379: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.304444228s
May 29 21:32:58.421: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.346105746s
May 29 21:33:00.462: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.387450689s
May 29 21:33:02.504: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.429570753s
May 29 21:33:04.546: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 3m34.471585368s
[1mSTEP[0m: Saw pod success
May 29 21:33:04.546: INFO: Pod "downward-api-4d3cd168-b507-4b7d-801b-442016565eed" satisfied condition "success or failure"
May 29 21:33:04.588: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod downward-api-4d3cd168-b507-4b7d-801b-442016565eed container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 29 21:33:04.694: INFO: Waiting for pod downward-api-4d3cd168-b507-4b7d-801b-442016565eed to disappear
May 29 21:33:04.735: INFO: Pod downward-api-4d3cd168-b507-4b7d-801b-442016565eed no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:33:04.735: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 21:33:04.777: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 21:32:06 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 21:32:06 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "downward-api-9571" for this suite.
May 29 21:33:10.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:33:12.492: INFO: namespace downward-api-9571 deletion completed in 7.71479886s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 21:33:12.492: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:33:12.494: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 21:33:12.495: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:33:12.496: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Variable Expansion[0m 
  [1mshould allow substituting values in a container's command [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Variable Expansion
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:33:12.497: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename var-expansion
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test substitution in container's command
May 29 21:33:12.750: INFO: Waiting up to 5m0s for pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c" in namespace "var-expansion-4054" to be "success or failure"
May 29 21:33:12.793: INFO: Pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c": Phase="Pending", Reason="", readiness=false. Elapsed: 42.680259ms
May 29 21:33:14.834: INFO: Pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.08430958s
May 29 21:33:16.876: INFO: Pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126112807s
May 29 21:33:18.918: INFO: Pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168011944s
May 29 21:33:20.960: INFO: Pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c": Phase="Running", Reason="", readiness=true. Elapsed: 8.209608871s
May 29 21:33:23.001: INFO: Pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c": Phase="Running", Reason="", readiness=true. Elapsed: 10.251083147s
May 29 21:33:25.043: INFO: Pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.293388611s
[1mSTEP[0m: Saw pod success
May 29 21:33:25.044: INFO: Pod "var-expansion-2a53be92-2f80-441b-97b9-0200a221318c" satisfied condition "success or failure"
May 29 21:33:25.086: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod var-expansion-2a53be92-2f80-441b-97b9-0200a221318c container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 29 21:33:25.188: INFO: Waiting for pod var-expansion-2a53be92-2f80-441b-97b9-0200a221318c to disappear
May 29 21:33:25.229: INFO: Pod var-expansion-2a53be92-2f80-441b-97b9-0200a221318c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:33:25.229: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "var-expansion-4054" for this suite.
May 29 21:33:31.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:33:33.007: INFO: namespace var-expansion-4054 deletion completed in 7.735460195s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete pods created by rc when not orphaning [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:33:33.008: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for all pods to be garbage collected
[1mSTEP[0m: Gathering metrics
May 29 21:33:43.538: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 8
	[quantile=0.9] = 353
	[quantile=0.99] = 353
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 504574
	[quantile=0.9] = 537674
	[quantile=0.99] = 537674
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 8
	[quantile=0.99] = 22
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 19
	[quantile=0.9] = 37
	[quantile=0.99] = 64
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 26
	[quantile=0.99] = 32
For namespace_queue_latency_sum:
	[] = 8466
For namespace_queue_latency_count:
	[] = 451
For namespace_retries:
	[] = 464
For namespace_work_duration:
	[quantile=0.5] = 203327
	[quantile=0.9] = 338160
	[quantile=0.99] = 384071
For namespace_work_duration_sum:
	[] = 98586624
For namespace_work_duration_count:
	[] = 451
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:33:43.538: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-7346" for this suite.
May 29 21:33:49.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:33:51.300: INFO: namespace gc-7346 deletion completed in 7.719889271s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 21:33:51.301: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:33:51.302: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 21:33:51.303: INFO: Driver csi-hostpath doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:33:51.305: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver csi-hostpath doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: block][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 21:33:51.305: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:33:51.307: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: block]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute prestop http hook properly [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:33:51.307: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the pod with lifecycle hook
May 29 21:38:59.837: INFO: Unexpected error occurred: timed out waiting for the condition
[AfterEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "container-lifecycle-hook-4466".
[1mSTEP[0m: Found 9 events.
May 29 21:38:59.880: INFO: At 2019-05-29 21:33:51 -0700 PDT - event for pod-handle-http-request: {default-scheduler } Scheduled: Successfully assigned container-lifecycle-hook-4466/pod-handle-http-request to e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:38:59.880: INFO: At 2019-05-29 21:33:54 -0700 PDT - event for pod-handle-http-request: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Container image "e2eteam/netexec:1.1" already present on machine
May 29 21:38:59.880: INFO: At 2019-05-29 21:33:54 -0700 PDT - event for pod-handle-http-request: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container pod-handle-http-request
May 29 21:38:59.880: INFO: At 2019-05-29 21:33:56 -0700 PDT - event for pod-handle-http-request: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container pod-handle-http-request
May 29 21:38:59.880: INFO: At 2019-05-29 21:33:59 -0700 PDT - event for pod-with-prestop-http-hook: {default-scheduler } Scheduled: Successfully assigned container-lifecycle-hook-4466/pod-with-prestop-http-hook to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:38:59.880: INFO: At 2019-05-29 21:34:01 -0700 PDT - event for pod-with-prestop-http-hook: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/pause:3.1" already present on machine
May 29 21:38:59.880: INFO: At 2019-05-29 21:34:01 -0700 PDT - event for pod-with-prestop-http-hook: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container pod-with-prestop-http-hook
May 29 21:38:59.880: INFO: At 2019-05-29 21:34:03 -0700 PDT - event for pod-with-prestop-http-hook: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container pod-with-prestop-http-hook
May 29 21:38:59.880: INFO: At 2019-05-29 21:37:12 -0700 PDT - event for pod-with-prestop-http-hook: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod container-lifecycle-hook-4466/pod-with-prestop-http-hook
May 29 21:38:59.968: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 29 21:38:59.968: INFO: pod-handle-http-request                                e2e-test-peterhornyack-windows-node-group-9q9v  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:51 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:58 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:58 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:51 -0700 PDT  }]
May 29 21:38:59.969: INFO: pod-with-prestop-http-hook                             e2e-test-peterhornyack-windows-node-group-jpxd  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:59 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:59 -0700 PDT ContainersNotReady containers with unready status: [pod-with-prestop-http-hook]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:59 -0700 PDT ContainersNotReady containers with unready status: [pod-with-prestop-http-hook]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:59 -0700 PDT  }]
May 29 21:38:59.969: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:38:59.969: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 21:38:59.969: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:38:59.969: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:38:59.969: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:38:59.969: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:38:59.969: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:38:59.969: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 21:38:59.969: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 21:38:59.969: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 21:38:59.969: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 21:38:59.969: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:38:59.969: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 21:38:59.969: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 21:38:59.969: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:38:59.969: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 21:38:59.969: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 21:38:59.970: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:38:59.970: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:38:59.970: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:38:59.970: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 21:38:59.970: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:38:59.970: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 21:38:59.970: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 21:38:59.970: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 21:38:59.970: INFO: 
May 29 21:39:00.014: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 21:39:00.056: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:52837,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:38:48 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:38:48 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:38:48 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:38:48 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 21:39:00.056: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 21:39:00.097: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 21:39:00.151: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.151: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.151: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.151: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 21:39:00.151: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:39:00.151: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.151: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.151: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 21:39:00.151: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:39:00.151: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.151: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.151: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.151: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.151: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.301: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 21:39:00.301: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 21:39:00.342: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:52765,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentDockerRestart False 2019-05-29 21:38:16 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 21:38:16 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 21:38:16 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 21:38:16 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 21:38:16 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 21:38:16 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 21:38:16 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:38:06 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:38:06 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:38:06 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:38:06 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 21:39:00.342: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 21:39:00.383: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 21:39:00.434: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:39:00.434: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 21:39:00.434: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.434: INFO: 	Container event-exporter ready: true, restart count 0
May 29 21:39:00.434: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:39:00.434: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:39:00.434: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 21:39:00.434: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.434: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 21:39:00.434: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:39:00.434: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:39:00.434: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 21:39:00.434: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.434: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 21:39:00.434: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:39:00.434: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.434: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:39:00.434: INFO: 	Container coredns ready: true, restart count 0
May 29 21:39:00.434: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 21:39:00.434: INFO: 	Container autoscaler ready: true, restart count 0
May 29 21:39:00.585: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 21:39:00.585: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 21:39:00.626: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:52814,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentUnregisterNetDevice False 2019-05-29 21:38:11 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 21:38:11 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 21:38:11 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 21:38:11 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 21:38:11 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 21:38:11 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 21:38:11 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:38:38 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:38:38 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:38:38 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:38:38 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 21:39:00.627: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 21:39:00.668: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 21:39:00.724: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.724: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 21:39:00.724: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:39:00.724: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.724: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 21:39:00.724: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 21:39:00.724: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 21:39:00.724: INFO: 	Container coredns ready: true, restart count 0
May 29 21:39:00.724: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.724: INFO: 	Container metrics-server ready: true, restart count 0
May 29 21:39:00.724: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 21:39:00.724: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 21:39:00.724: INFO: 	Container heapster ready: true, restart count 0
May 29 21:39:00.724: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 21:39:00.724: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 21:39:00.893: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 21:39:00.893: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:39:00.935: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:52783,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:38:24 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:38:24 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:38:24 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:38:24 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 21:39:00.936: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:39:00.977: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:39:01.182: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 21:39:01.183: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:39:01.224: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:52806,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:38:34 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:38:34 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:38:34 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:38:34 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 21:39:01.224: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:39:01.266: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:39:01.314: INFO: pod-handle-http-request started at 2019-05-29 21:33:51 -0700 PDT (0+1 container statuses recorded)
May 29 21:39:01.314: INFO: 	Container pod-handle-http-request ready: true, restart count 0
May 29 21:39:02.786: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 21:39:02.786: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:39:02.828: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:52742,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 21:38:07 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 21:38:07 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 21:38:07 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 21:38:07 -0700 PDT 2019-05-29 21:37:07 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 21:39:02.828: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:39:02.870: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:39:02.918: INFO: pod-with-prestop-http-hook started at 2019-05-29 21:33:59 -0700 PDT (0+1 container statuses recorded)
May 29 21:39:02.918: INFO: 	Container pod-with-prestop-http-hook ready: false, restart count 0
May 29 21:39:05.072: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 21:39:05.072: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-lifecycle-hook-4466" for this suite.
May 29 21:49:05.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:49:06.420: INFO: namespace: container-lifecycle-hook-4466, resource: pods, items remaining: 1
May 29 21:49:06.960: INFO: namespace: container-lifecycle-hook-4466, DeletionTimetamp: 2019-05-29 21:39:05 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 29 21:49:07.002: INFO: namespace: container-lifecycle-hook-4466, total namespaces: 5, active: 4, terminating: 1
May 29 21:49:07.044: INFO: POD                         NODE                                            PHASE    GRACE  CONDITIONS
May 29 21:49:07.044: INFO: pod-with-prestop-http-hook  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:59 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:39:03 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:39:03 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:33:59 -0700 PDT  }]
May 29 21:49:07.044: INFO: 
May 29 21:49:07.044: INFO: Couldn't delete ns: "container-lifecycle-hook-4466": namespace container-lifecycle-hook-4466 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace container-lifecycle-hook-4466 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})

[91m[1m• Failure [915.738 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  when create a pod with lifecycle hook
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    [91m[1mshould execute prestop http hook properly [NodeConformance] [Conformance] [It][0m
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mUnexpected error:
        <*errors.errorString | 0xc0002b5440>: {
            s: "timed out waiting for the condition",
        }
        timed out waiting for the condition
    occurred[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:112
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] ReplicationController[0m 
  [1mshould serve a basic image on each replica with a public image  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] ReplicationController
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:49:07.046: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename replication-controller
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating replication controller my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a
May 29 21:49:07.312: INFO: Pod name my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a: Found 1 pods out of 1
May 29 21:49:07.312: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a" are running
May 29 21:49:17.395: INFO: Pod "my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a-qxs9n" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 21:49:07 -0700 PDT Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 21:49:07 -0700 PDT Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 21:49:07 -0700 PDT Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-29 21:49:07 -0700 PDT Reason: Message:}])
May 29 21:49:17.395: INFO: Trying to dial the pod
May 29 21:49:22.586: INFO: Controller my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a: Got expected result from replica 1 [my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a-qxs9n]: "my-hostname-basic-d698fb1e-183f-492a-9655-21bf1c114c3a-qxs9n", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:49:22.586: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "replication-controller-5359" for this suite.
May 29 21:49:28.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 21:49:30.350: INFO: namespace replication-controller-5359 deletion completed in 7.720005723s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 21:49:30.350: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:49:30.351: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 21:49:30.352: INFO: Driver hostPath doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:49:30.353: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver hostPath doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-windows] Windows volume mounts [0m [90mcheck volume mount permissions[0m 
  [1mcontainer should have readOnly permissions on hostMapPath[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/volumes.go:73[0m
[BeforeEach] [sig-windows] Windows volume mounts 
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/framework.go:28
[BeforeEach] [sig-windows] Windows volume mounts 
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 21:49:30.353: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename windows-volumes
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-windows] Windows volume mounts 
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/volumes.go:58
[It] container should have readOnly permissions on hostMapPath
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/volumes.go:73
[1mSTEP[0m: creating a container with readOnly permissions on hostMap volume
May 29 21:53:08.723: INFO: ExecWithOptions {Command:[cmd /c echo windows-volume-test > C:\tmp\test-file.txt] Namespace:windows-volumes-1832 PodName:pod-3da0c3ef-918e-4a31-9b3e-a46b4f77233d ContainerName:test-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 21:53:08.723: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: creating two containers, one with readOnly permissions the other with read-write permissions on hostMap volume
May 29 21:57:11.243: INFO: ExecWithOptions {Command:[cmd /c echo windows-volume-test > C:\tmp\test-file] Namespace:windows-volumes-1832 PodName:pod-751355a7-ab47-4202-ab51-164f6dc0c639 ContainerName:test-container-rw Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 21:57:11.243: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 21:57:11.600: INFO: ExecWithOptions {Command:[cmd /c echo windows-volume-test > C:\tmp\test-file] Namespace:windows-volumes-1832 PodName:pod-751355a7-ab47-4202-ab51-164f6dc0c639 ContainerName:test-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 21:57:11.600: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 21:57:11.947: INFO: ExecWithOptions {Command:[cmd /c type C:\tmp\test-file] Namespace:windows-volumes-1832 PodName:pod-751355a7-ab47-4202-ab51-164f6dc0c639 ContainerName:test-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 21:57:11.947: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[AfterEach] [sig-windows] Windows volume mounts 
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 21:57:12.288: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 21:57:12.331: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 21:56:09 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 21:56:12 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "windows-volumes-1832" for this suite.
May 29 22:07:12.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:07:13.050: INFO: namespace: windows-volumes-1832, resource: pods, items remaining: 2
May 29 22:07:14.145: INFO: namespace: windows-volumes-1832, DeletionTimetamp: 2019-05-29 21:57:12 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 29 22:07:14.187: INFO: namespace: windows-volumes-1832, total namespaces: 5, active: 4, terminating: 1
May 29 22:07:14.229: INFO: POD                                       NODE                                            PHASE    GRACE  CONDITIONS
May 29 22:07:14.229: INFO: pod-3da0c3ef-918e-4a31-9b3e-a46b4f77233d  e2e-test-peterhornyack-windows-node-group-jpxd  Failed   30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:49:30 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:07:12 -0700 PDT ContainersNotReady containers with unready status: [test-container]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:07:12 -0700 PDT ContainersNotReady containers with unready status: [test-container]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:49:30 -0700 PDT  }]
May 29 22:07:14.229: INFO: pod-751355a7-ab47-4202-ab51-164f6dc0c639  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:53:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:57:09 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:57:09 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:53:09 -0700 PDT  }]
May 29 22:07:14.229: INFO: 
May 29 22:07:14.229: INFO: Couldn't delete ns: "windows-volumes-1832": namespace windows-volumes-1832 was not deleted with limit: timed out waiting for the condition, pods remaining: 2 (&errors.errorString{s:"namespace windows-volumes-1832 was not deleted with limit: timed out waiting for the condition, pods remaining: 2"})

[91m[1m• Failure in Spec Teardown (AfterEach) [1063.877 seconds][0m
[sig-windows] Windows volume mounts 
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/framework.go:27[0m
  [91m[1mcheck volume mount permissions [AfterEach][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/volumes.go:62[0m
    container should have readOnly permissions on hostMapPath
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/volumes.go:73[0m

    [91mMay 29 22:07:14.229: Couldn't delete ns: "windows-volumes-1832": namespace windows-volumes-1832 was not deleted with limit: timed out waiting for the condition, pods remaining: 2 (&errors.errorString{s:"namespace windows-volumes-1832 was not deleted with limit: timed out waiting for the condition, pods remaining: 2"})[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide podname only [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:07:14.231: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 22:07:14.455: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c" in namespace "projected-4195" to be "success or failure"
May 29 22:07:14.496: INFO: Pod "downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c": Phase="Pending", Reason="", readiness=false. Elapsed: 41.539869ms
May 29 22:07:16.538: INFO: Pod "downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083410556s
May 29 22:07:18.581: INFO: Pod "downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125847211s
May 29 22:07:20.623: INFO: Pod "downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168326862s
May 29 22:07:22.665: INFO: Pod "downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.210592855s
[1mSTEP[0m: Saw pod success
May 29 22:07:22.666: INFO: Pod "downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c" satisfied condition "success or failure"
May 29 22:07:22.707: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 22:07:22.811: INFO: Waiting for pod downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c to disappear
May 29 22:07:22.852: INFO: Pod downwardapi-volume-b758aaa1-5df1-4bf1-8368-68b46f04f15c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:07:22.852: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-4195" for this suite.
May 29 22:07:29.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:07:30.613: INFO: namespace projected-4195 deletion completed in 7.718817303s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Runtime[0m [90mblackbox test[0m [0mwhen running a container with a new image[0m 
  [1mshould not be able to pull image from invalid registry [NodeConformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:354[0m
[BeforeEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:07:30.614: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-runtime
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be able to pull image from invalid registry [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:354
[1mSTEP[0m: create the container
[1mSTEP[0m: check the container status
[1mSTEP[0m: delete the container
[AfterEach] [k8s.io] Container Runtime
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:07:34.102: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-runtime-5398" for this suite.
May 29 22:07:40.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:07:41.866: INFO: namespace container-runtime-5398 deletion completed in 7.72089726s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:07:41.866: INFO: Driver csi-hostpath doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:07:41.868: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver csi-hostpath doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:07:41.869: INFO: Driver aws doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:07:41.870: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver aws doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould delete RS created by deployment when not orphaning [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:07:41.871: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the deployment
[1mSTEP[0m: Wait for the Deployment to create new ReplicaSet
[1mSTEP[0m: delete the deployment
[1mSTEP[0m: wait for all rs to be garbage collected
[1mSTEP[0m: expected 0 pods, got 2 pods
[1mSTEP[0m: expected 0 rs, got 1 rs
[1mSTEP[0m: Gathering metrics
May 29 22:07:43.102: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 21
	[quantile=0.99] = 21
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 35393
	[quantile=0.9] = 37141
	[quantile=0.99] = 37141
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 8
	[quantile=0.99] = 24
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 18
	[quantile=0.9] = 36
	[quantile=0.99] = 62
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 19
	[quantile=0.9] = 42
	[quantile=0.99] = 48
For namespace_queue_latency_sum:
	[] = 9830
For namespace_queue_latency_count:
	[] = 502
For namespace_retries:
	[] = 522
For namespace_work_duration:
	[quantile=0.5] = 246098
	[quantile=0.9] = 449543
	[quantile=0.99] = 453411
For namespace_work_duration_sum:
	[] = 110605459
For namespace_work_duration_count:
	[] = 502
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:07:43.102: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-5557" for this suite.
May 29 22:07:49.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:07:50.856: INFO: namespace gc-5557 deletion completed in 7.712244993s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould have monotonically increasing restart count [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:07:50.857: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating pod liveness-http in namespace container-probe-1157
May 29 22:07:57.197: INFO: Started pod liveness-http in namespace container-probe-1157
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 29 22:07:57.239: INFO: Initial restart count of pod liveness-http is 0
May 29 22:08:15.661: INFO: Restart count of pod container-probe-1157/liveness-http is now 1 (18.421793893s elapsed)
May 29 22:08:36.080: INFO: Restart count of pod container-probe-1157/liveness-http is now 2 (38.841324571s elapsed)
May 29 22:08:56.501: INFO: Restart count of pod container-probe-1157/liveness-http is now 3 (59.261693893s elapsed)
May 29 22:09:14.885: INFO: Restart count of pod container-probe-1157/liveness-http is now 4 (1m17.646168257s elapsed)
May 29 22:10:24.314: INFO: Restart count of pod container-probe-1157/liveness-http is now 5 (2m27.075110406s elapsed)
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:10:24.366: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-1157" for this suite.
May 29 22:10:30.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:10:32.145: INFO: namespace container-probe-1157 deletion completed in 7.736570573s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:10:32.145: INFO: Driver emptydir doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:10:32.146: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver emptydir doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:10:32.147: INFO: Driver csi-hostpath doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:10:32.148: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver csi-hostpath doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:10:32.148: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:10:32.149: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Update Demo[0m 
  [1mshould scale a replication controller  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:10:32.150: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Update Demo
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:266
[It] should scale a replication controller  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating a replication controller
May 29 22:10:32.321: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-472'
May 29 22:10:34.651: INFO: stderr: ""
May 29 22:10:34.651: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 29 22:10:34.651: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:10:34.927: INFO: stderr: ""
May 29 22:10:34.927: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:10:34.927: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:10:35.185: INFO: stderr: ""
May 29 22:10:35.185: INFO: stdout: ""
May 29 22:10:35.185: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:10:40.186: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:10:40.456: INFO: stderr: ""
May 29 22:10:40.456: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:10:40.456: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:10:40.721: INFO: stderr: ""
May 29 22:10:40.721: INFO: stdout: ""
May 29 22:10:40.721: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:10:45.722: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:10:45.983: INFO: stderr: ""
May 29 22:10:45.983: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:10:45.983: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:10:46.218: INFO: stderr: ""
May 29 22:10:46.218: INFO: stdout: ""
May 29 22:10:46.218: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:10:51.218: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:10:51.477: INFO: stderr: ""
May 29 22:10:51.477: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:10:51.477: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:10:51.727: INFO: stderr: ""
May 29 22:10:51.727: INFO: stdout: ""
May 29 22:10:51.727: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:10:56.728: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:10:56.986: INFO: stderr: ""
May 29 22:10:56.986: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:10:56.986: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:10:57.237: INFO: stderr: ""
May 29 22:10:57.237: INFO: stdout: ""
May 29 22:10:57.237: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:02.237: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:02.486: INFO: stderr: ""
May 29 22:11:02.486: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:02.486: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:02.737: INFO: stderr: ""
May 29 22:11:02.737: INFO: stdout: ""
May 29 22:11:02.737: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:07.738: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:07.990: INFO: stderr: ""
May 29 22:11:07.990: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:07.990: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:08.229: INFO: stderr: ""
May 29 22:11:08.229: INFO: stdout: ""
May 29 22:11:08.229: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:13.229: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:13.490: INFO: stderr: ""
May 29 22:11:13.490: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:13.491: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:13.741: INFO: stderr: ""
May 29 22:11:13.741: INFO: stdout: ""
May 29 22:11:13.741: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:18.741: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:19.010: INFO: stderr: ""
May 29 22:11:19.010: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:19.010: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:19.255: INFO: stderr: ""
May 29 22:11:19.255: INFO: stdout: ""
May 29 22:11:19.255: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:24.256: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:24.516: INFO: stderr: ""
May 29 22:11:24.516: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:24.516: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:24.766: INFO: stderr: ""
May 29 22:11:24.766: INFO: stdout: ""
May 29 22:11:24.767: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:29.767: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:30.031: INFO: stderr: ""
May 29 22:11:30.031: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:30.031: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:30.260: INFO: stderr: ""
May 29 22:11:30.260: INFO: stdout: ""
May 29 22:11:30.260: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:35.261: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:35.524: INFO: stderr: ""
May 29 22:11:35.524: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:35.525: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:35.781: INFO: stderr: ""
May 29 22:11:35.781: INFO: stdout: ""
May 29 22:11:35.781: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:40.781: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:41.041: INFO: stderr: ""
May 29 22:11:41.041: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:41.041: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:41.277: INFO: stderr: ""
May 29 22:11:41.277: INFO: stdout: ""
May 29 22:11:41.277: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:46.278: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:46.546: INFO: stderr: ""
May 29 22:11:46.546: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:46.547: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:46.810: INFO: stderr: ""
May 29 22:11:46.810: INFO: stdout: ""
May 29 22:11:46.810: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:51.811: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:52.066: INFO: stderr: ""
May 29 22:11:52.066: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:52.067: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:52.319: INFO: stderr: ""
May 29 22:11:52.319: INFO: stdout: ""
May 29 22:11:52.319: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:11:57.320: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:11:57.586: INFO: stderr: ""
May 29 22:11:57.586: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:11:57.586: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:11:57.841: INFO: stderr: ""
May 29 22:11:57.841: INFO: stdout: ""
May 29 22:11:57.841: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:02.841: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:03.096: INFO: stderr: ""
May 29 22:12:03.096: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:03.096: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:03.348: INFO: stderr: ""
May 29 22:12:03.348: INFO: stdout: ""
May 29 22:12:03.348: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:08.348: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:08.618: INFO: stderr: ""
May 29 22:12:08.618: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:08.618: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:08.863: INFO: stderr: ""
May 29 22:12:08.863: INFO: stdout: ""
May 29 22:12:08.863: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:13.863: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:14.121: INFO: stderr: ""
May 29 22:12:14.121: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:14.121: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:14.376: INFO: stderr: ""
May 29 22:12:14.376: INFO: stdout: ""
May 29 22:12:14.376: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:19.377: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:19.641: INFO: stderr: ""
May 29 22:12:19.641: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:19.641: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:19.902: INFO: stderr: ""
May 29 22:12:19.902: INFO: stdout: ""
May 29 22:12:19.902: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:24.902: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:25.168: INFO: stderr: ""
May 29 22:12:25.168: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:25.168: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:25.419: INFO: stderr: ""
May 29 22:12:25.419: INFO: stdout: ""
May 29 22:12:25.419: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:30.419: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:30.687: INFO: stderr: ""
May 29 22:12:30.687: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:30.687: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:30.944: INFO: stderr: ""
May 29 22:12:30.944: INFO: stdout: ""
May 29 22:12:30.944: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:35.944: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:36.211: INFO: stderr: ""
May 29 22:12:36.211: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:36.211: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:36.460: INFO: stderr: ""
May 29 22:12:36.460: INFO: stdout: ""
May 29 22:12:36.460: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:41.461: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:41.717: INFO: stderr: ""
May 29 22:12:41.717: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:41.718: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:41.960: INFO: stderr: ""
May 29 22:12:41.960: INFO: stdout: ""
May 29 22:12:41.960: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:46.960: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:47.221: INFO: stderr: ""
May 29 22:12:47.221: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:47.222: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:47.472: INFO: stderr: ""
May 29 22:12:47.472: INFO: stdout: ""
May 29 22:12:47.472: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:52.473: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:52.740: INFO: stderr: ""
May 29 22:12:52.740: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:52.740: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:53.001: INFO: stderr: ""
May 29 22:12:53.001: INFO: stdout: ""
May 29 22:12:53.001: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:12:58.002: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:12:58.259: INFO: stderr: ""
May 29 22:12:58.259: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:12:58.260: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:12:58.513: INFO: stderr: ""
May 29 22:12:58.513: INFO: stdout: ""
May 29 22:12:58.513: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:13:03.513: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:03.766: INFO: stderr: ""
May 29 22:13:03.766: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:13:03.766: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:13:04.015: INFO: stderr: ""
May 29 22:13:04.015: INFO: stdout: ""
May 29 22:13:04.015: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:13:09.016: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:09.274: INFO: stderr: ""
May 29 22:13:09.274: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:13:09.274: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:13:09.539: INFO: stderr: ""
May 29 22:13:09.540: INFO: stdout: ""
May 29 22:13:09.540: INFO: update-demo-nautilus-5pqcg is created but not running
May 29 22:13:14.540: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:14.806: INFO: stderr: ""
May 29 22:13:14.806: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
May 29 22:13:14.806: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:13:15.059: INFO: stderr: ""
May 29 22:13:15.059: INFO: stdout: "true"
May 29 22:13:15.059: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-5pqcg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:13:15.326: INFO: stderr: ""
May 29 22:13:15.326: INFO: stdout: "e2eteam/nautilus:1.0"
May 29 22:13:15.326: INFO: validating pod update-demo-nautilus-5pqcg
May 29 22:13:15.482: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 22:13:15.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 22:13:15.483: INFO: update-demo-nautilus-5pqcg is verified up and running
May 29 22:13:15.483: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-mfv4h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:13:15.744: INFO: stderr: ""
May 29 22:13:15.744: INFO: stdout: "true"
May 29 22:13:15.745: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods update-demo-nautilus-mfv4h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-472'
May 29 22:13:15.996: INFO: stderr: ""
May 29 22:13:15.996: INFO: stdout: "e2eteam/nautilus:1.0"
May 29 22:13:15.996: INFO: validating pod update-demo-nautilus-mfv4h
May 29 22:13:16.093: INFO: got data: {
  "image": "nautilus.jpg"
}

May 29 22:13:16.093: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 29 22:13:16.093: INFO: update-demo-nautilus-mfv4h is verified up and running
[1mSTEP[0m: scaling down the replication controller
May 29 22:13:16.338: INFO: scanned /usr/local/google/home/peterhornyack for discovery docs: <nil>
May 29 22:13:16.338: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-472'
May 29 22:13:16.751: INFO: stderr: ""
May 29 22:13:16.751: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
[1mSTEP[0m: waiting for all containers in name=update-demo pods to come up.
May 29 22:13:16.751: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:17.015: INFO: stderr: ""
May 29 22:13:17.015: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:13:22.016: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:22.275: INFO: stderr: ""
May 29 22:13:22.275: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:13:27.276: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:27.533: INFO: stderr: ""
May 29 22:13:27.533: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:13:32.533: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:32.794: INFO: stderr: ""
May 29 22:13:32.794: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:13:37.794: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:38.049: INFO: stderr: ""
May 29 22:13:38.049: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:13:43.049: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:43.322: INFO: stderr: ""
May 29 22:13:43.322: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:13:48.323: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:48.579: INFO: stderr: ""
May 29 22:13:48.579: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:13:53.580: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:53.847: INFO: stderr: ""
May 29 22:13:53.847: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:13:58.847: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:13:59.112: INFO: stderr: ""
May 29 22:13:59.112: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:04.112: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:04.393: INFO: stderr: ""
May 29 22:14:04.393: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:09.394: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:09.653: INFO: stderr: ""
May 29 22:14:09.653: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:14.654: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:14.934: INFO: stderr: ""
May 29 22:14:14.935: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:19.935: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:20.193: INFO: stderr: ""
May 29 22:14:20.193: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:25.193: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:25.490: INFO: stderr: ""
May 29 22:14:25.490: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:30.490: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:30.744: INFO: stderr: ""
May 29 22:14:30.744: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:35.745: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:36.007: INFO: stderr: ""
May 29 22:14:36.007: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:41.007: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:41.263: INFO: stderr: ""
May 29 22:14:41.263: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:46.263: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:46.530: INFO: stderr: ""
May 29 22:14:46.530: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:51.531: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:51.795: INFO: stderr: ""
May 29 22:14:51.795: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:14:56.795: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:14:57.061: INFO: stderr: ""
May 29 22:14:57.061: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:02.061: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:02.321: INFO: stderr: ""
May 29 22:15:02.321: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:07.322: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:07.568: INFO: stderr: ""
May 29 22:15:07.568: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:12.569: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:12.825: INFO: stderr: ""
May 29 22:15:12.825: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:17.826: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:18.081: INFO: stderr: ""
May 29 22:15:18.081: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:23.081: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:23.347: INFO: stderr: ""
May 29 22:15:23.347: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:28.348: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:28.591: INFO: stderr: ""
May 29 22:15:28.591: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:33.591: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:33.845: INFO: stderr: ""
May 29 22:15:33.845: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:38.846: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:39.105: INFO: stderr: ""
May 29 22:15:39.105: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:44.105: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:44.368: INFO: stderr: ""
May 29 22:15:44.368: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:49.372: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:49.616: INFO: stderr: ""
May 29 22:15:49.616: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:54.616: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:15:54.874: INFO: stderr: ""
May 29 22:15:54.874: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:15:59.875: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:00.137: INFO: stderr: ""
May 29 22:16:00.137: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:05.138: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:05.391: INFO: stderr: ""
May 29 22:16:05.391: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:10.391: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:10.658: INFO: stderr: ""
May 29 22:16:10.658: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:15.658: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:15.930: INFO: stderr: ""
May 29 22:16:15.930: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:20.931: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:21.212: INFO: stderr: ""
May 29 22:16:21.212: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:26.213: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:26.478: INFO: stderr: ""
May 29 22:16:26.478: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:31.479: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:31.732: INFO: stderr: ""
May 29 22:16:31.732: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:36.733: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:36.995: INFO: stderr: ""
May 29 22:16:36.995: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:41.996: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:42.268: INFO: stderr: ""
May 29 22:16:42.268: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:47.269: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:47.520: INFO: stderr: ""
May 29 22:16:47.520: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:52.521: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:52.775: INFO: stderr: ""
May 29 22:16:52.776: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:16:57.776: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:16:58.035: INFO: stderr: ""
May 29 22:16:58.035: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:03.035: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:03.307: INFO: stderr: ""
May 29 22:17:03.307: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:08.307: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:08.562: INFO: stderr: ""
May 29 22:17:08.562: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:13.562: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:13.827: INFO: stderr: ""
May 29 22:17:13.827: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:18.827: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:19.099: INFO: stderr: ""
May 29 22:17:19.099: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:24.099: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:24.354: INFO: stderr: ""
May 29 22:17:24.354: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:29.355: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:29.617: INFO: stderr: ""
May 29 22:17:29.617: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:34.617: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:34.876: INFO: stderr: ""
May 29 22:17:34.876: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:39.876: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:40.133: INFO: stderr: ""
May 29 22:17:40.133: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:45.134: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:45.396: INFO: stderr: ""
May 29 22:17:45.396: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:50.397: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:50.655: INFO: stderr: ""
May 29 22:17:50.655: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:17:55.655: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:17:55.930: INFO: stderr: ""
May 29 22:17:55.930: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:18:00.930: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:18:01.180: INFO: stderr: ""
May 29 22:18:01.180: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:18:06.181: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:18:06.439: INFO: stderr: ""
May 29 22:18:06.439: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:18:11.439: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:18:11.697: INFO: stderr: ""
May 29 22:18:11.697: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:18:16.697: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-472'
May 29 22:18:16.956: INFO: stderr: ""
May 29 22:18:16.956: INFO: stdout: "update-demo-nautilus-5pqcg update-demo-nautilus-mfv4h "
[1mSTEP[0m: Replicas for name=update-demo: expected=1 actual=2
May 29 22:18:21.956: INFO: Timed out after 300 seconds waiting for name=update-demo pods to reach valid state
[1mSTEP[0m: using delete to clean up resources
May 29 22:18:21.958: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-472'
May 29 22:18:22.265: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 22:18:22.265: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 29 22:18:22.265: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-472'
May 29 22:18:22.564: INFO: stderr: "No resources found.\n"
May 29 22:18:22.564: INFO: stdout: ""
May 29 22:18:22.564: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -l name=update-demo --namespace=kubectl-472 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 29 22:18:22.825: INFO: stderr: ""
May 29 22:18:22.825: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "kubectl-472".
[1mSTEP[0m: Found 13 events.
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:34 -0700 PDT - event for update-demo-nautilus: {replication-controller } SuccessfulCreate: Created pod: update-demo-nautilus-5pqcg
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:34 -0700 PDT - event for update-demo-nautilus: {replication-controller } SuccessfulCreate: Created pod: update-demo-nautilus-mfv4h
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:34 -0700 PDT - event for update-demo-nautilus-5pqcg: {default-scheduler } Scheduled: Successfully assigned kubectl-472/update-demo-nautilus-5pqcg to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:34 -0700 PDT - event for update-demo-nautilus-mfv4h: {default-scheduler } Scheduled: Successfully assigned kubectl-472/update-demo-nautilus-mfv4h to e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:36 -0700 PDT - event for update-demo-nautilus-mfv4h: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container update-demo
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:36 -0700 PDT - event for update-demo-nautilus-mfv4h: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Container image "e2eteam/nautilus:1.0" already present on machine
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:37 -0700 PDT - event for update-demo-nautilus-5pqcg: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container update-demo
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:37 -0700 PDT - event for update-demo-nautilus-5pqcg: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/nautilus:1.0" already present on machine
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:38 -0700 PDT - event for update-demo-nautilus-mfv4h: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container update-demo
May 29 22:18:22.868: INFO: At 2019-05-29 22:10:39 -0700 PDT - event for update-demo-nautilus-5pqcg: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container update-demo
May 29 22:18:22.868: INFO: At 2019-05-29 22:13:16 -0700 PDT - event for update-demo-nautilus: {replication-controller } SuccessfulDelete: Deleted pod: update-demo-nautilus-5pqcg
May 29 22:18:22.868: INFO: At 2019-05-29 22:13:22 -0700 PDT - event for update-demo-nautilus-5pqcg: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod kubectl-472/update-demo-nautilus-5pqcg
May 29 22:18:22.868: INFO: At 2019-05-29 22:18:22 -0700 PDT - event for update-demo-nautilus-mfv4h: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Killing: Stopping container update-demo
May 29 22:18:22.958: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 29 22:18:22.958: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:18:22.958: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 22:18:22.958: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:18:22.958: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:18:22.958: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:18:22.958: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:18:22.958: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:18:22.958: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 22:18:22.958: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 22:18:22.958: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 22:18:22.958: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 22:18:22.958: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:18:22.958: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 22:18:22.958: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 22:18:22.958: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:18:22.958: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 22:18:22.958: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 22:18:22.958: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:18:22.959: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:18:22.959: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:18:22.959: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:18:22.959: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:18:22.959: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:18:22.959: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 22:18:22.959: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 22:18:22.959: INFO: update-demo-nautilus-5pqcg                             e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:34 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:13:14 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:13:14 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:34 -0700 PDT  }]
May 29 22:18:22.959: INFO: update-demo-nautilus-mfv4h                             e2e-test-peterhornyack-windows-node-group-9q9v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:34 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:34 -0700 PDT  }]
May 29 22:18:22.959: INFO: pod-751355a7-ab47-4202-ab51-164f6dc0c639               e2e-test-peterhornyack-windows-node-group-jpxd  Failed   30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:53:09 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:13:14 -0700 PDT ContainersNotReady containers with unready status: [test-container test-container-rw]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:13:14 -0700 PDT ContainersNotReady containers with unready status: [test-container test-container-rw]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 21:53:09 -0700 PDT  }]
May 29 22:18:22.959: INFO: 
May 29 22:18:23.001: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 22:18:23.043: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:58564,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:17:56 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:17:56 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:17:56 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:17:56 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:18:23.044: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 22:18:23.085: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 22:18:23.132: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.132: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.132: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.132: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.132: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.132: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.132: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:23.132: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:18:23.132: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:18:23.132: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.132: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.132: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:23.132: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:18:23.132: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:18:23.302: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 22:18:23.302: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:18:23.344: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:58591,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentContainerdRestart False 2019-05-29 22:17:40 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 22:17:40 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 22:17:40 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 22:17:40 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 22:17:40 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 22:17:40 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 22:17:40 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:18:09 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:18:09 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:18:09 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:18:09 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:18:23.345: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:18:23.386: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:18:23.932: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:18:23.933: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 22:18:23.933: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:23.933: INFO: 	Container event-exporter ready: true, restart count 0
May 29 22:18:23.933: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:18:23.933: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:18:23.933: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 22:18:23.933: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:23.933: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:18:23.933: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:18:23.933: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 22:18:23.933: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:18:23.933: INFO: 	Container coredns ready: true, restart count 0
May 29 22:18:23.933: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:18:23.933: INFO: 	Container autoscaler ready: true, restart count 0
May 29 22:18:23.933: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:18:23.933: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 22:18:23.933: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:23.933: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:18:23.933: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:18:24.081: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:18:24.081: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:18:24.122: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:58528,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{ReadonlyFilesystem False 2019-05-29 22:17:35 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 22:17:35 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 22:17:35 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 22:17:35 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 22:17:35 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 22:17:35 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 22:17:35 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:17:42 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:17:42 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:17:42 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:17:42 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:18:24.122: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:18:24.164: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:18:24.215: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:24.215: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:18:24.215: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:18:24.215: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 22:18:24.215: INFO: 	Container coredns ready: true, restart count 0
May 29 22:18:24.215: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:24.215: INFO: 	Container metrics-server ready: true, restart count 0
May 29 22:18:24.215: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 22:18:24.215: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:24.215: INFO: 	Container heapster ready: true, restart count 0
May 29 22:18:24.215: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 22:18:24.215: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 22:18:24.215: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:24.215: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:18:24.215: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:18:24.381: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:18:24.381: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:18:24.422: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:58610,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:18:17 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:18:17 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:18:17 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:18:17 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:18:24.422: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:18:24.463: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:18:24.666: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:18:24.666: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:18:24.708: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:58519,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:17:37 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:17:37 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:17:37 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:17:37 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:18:24.709: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:18:24.750: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:18:24.796: INFO: update-demo-nautilus-mfv4h started at 2019-05-29 22:10:34 -0700 PDT (0+1 container statuses recorded)
May 29 22:18:24.796: INFO: 	Container update-demo ready: false, restart count 0
May 29 22:18:24.968: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:18:24.968: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:18:25.009: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:58617,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:18:21 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:18:21 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:18:21 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:18:21 -0700 PDT 2019-05-29 22:17:21 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:18:25.009: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:18:25.050: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:18:25.100: INFO: update-demo-nautilus-5pqcg started at 2019-05-29 22:10:34 -0700 PDT (0+1 container statuses recorded)
May 29 22:18:25.100: INFO: 	Container update-demo ready: true, restart count 0
May 29 22:18:25.100: INFO: pod-751355a7-ab47-4202-ab51-164f6dc0c639 started at 2019-05-29 21:53:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:18:25.100: INFO: 	Container test-container ready: false, restart count 0
May 29 22:18:25.100: INFO: 	Container test-container-rw ready: false, restart count 0
May 29 22:18:26.886: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:18:26.886: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-472" for this suite.
May 29 22:28:27.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:28:27.729: INFO: namespace: kubectl-472, resource: pods, items remaining: 1
May 29 22:28:28.729: INFO: namespace: kubectl-472, DeletionTimetamp: 2019-05-29 22:18:26 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 29 22:28:28.770: INFO: namespace: kubectl-472, total namespaces: 5, active: 4, terminating: 1
May 29 22:28:28.811: INFO: POD                         NODE                                            PHASE    GRACE  CONDITIONS
May 29 22:28:28.811: INFO: update-demo-nautilus-5pqcg  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:34 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:13:14 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:13:14 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:34 -0700 PDT  }]
May 29 22:28:28.811: INFO: 
May 29 22:28:28.811: INFO: Couldn't delete ns: "kubectl-472": namespace kubectl-472 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace kubectl-472 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})

[91m[1m• Failure [1076.663 seconds][0m
[sig-cli] Kubectl client
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23[0m
  [k8s.io] Update Demo
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
    [91m[1mshould scale a replication controller  [Conformance] [It][0m
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mMay 29 22:18:21.956: Timed out after 300 seconds waiting for name=update-demo pods to reach valid state[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/rc_util.go:257
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:28:28.813: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 22:28:29.026: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 22:28:22 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 22:28:22 -0700 PDT}]. Failure
[1mSTEP[0m: create the rc1
[1mSTEP[0m: create the rc2
[1mSTEP[0m: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
[1mSTEP[0m: delete the rc simpletest-rc-to-be-deleted
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: Gathering metrics
May 29 22:28:39.721: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 16199
	[quantile=0.9] = 287363
	[quantile=0.99] = 385083
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 533368
	[quantile=0.9] = 777496
	[quantile=0.99] = 819042
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 8
	[quantile=0.99] = 40
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 19
	[quantile=0.9] = 37
	[quantile=0.99] = 61
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 19
	[quantile=0.9] = 27
	[quantile=0.99] = 27
For namespace_queue_latency_sum:
	[] = 10760
For namespace_queue_latency_count:
	[] = 530
For namespace_retries:
	[] = 554
For namespace_work_duration:
	[quantile=0.5] = 167661
	[quantile=0.9] = 348780
	[quantile=0.99] = 348780
For namespace_work_duration_sum:
	[] = 116487607
For namespace_work_duration_count:
	[] = 530
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:28:39.721: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 22:28:39.763: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 22:28:22 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 22:28:22 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "gc-8328" for this suite.
May 29 22:28:45.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:28:47.500: INFO: namespace gc-8328 deletion completed in 7.736449345s
[32m•[0m
[90m------------------------------[0m
[0m[sig-network] DNS[0m 
  [1mshould provide DNS for services  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-network] DNS
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:28:47.500: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename dns
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a test headless service
[1mSTEP[0m: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4877.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4877.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4877.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4877.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4877.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4877.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4877.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4877.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4877.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4877.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4877.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 176.195.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.195.176_udp@PTR;check="$$(dig +tcp +noall +answer +search 176.195.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.195.176_tcp@PTR;sleep 1; done

[1mSTEP[0m: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4877.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4877.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4877.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4877.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4877.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4877.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4877.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4877.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4877.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4877.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4877.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 176.195.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.195.176_udp@PTR;check="$$(dig +tcp +noall +answer +search 176.195.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.195.176_tcp@PTR;sleep 1; done

[1mSTEP[0m: creating a pod to probe DNS
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: retrieving the pod
[1mSTEP[0m: looking for the results for each expected name from probers
May 29 22:29:16.070: INFO: Unable to read wheezy_udp@dns-test-service.dns-4877.svc.cluster.local from pod dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f: the server could not find the requested resource (get pods dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f)
May 29 22:29:16.115: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4877.svc.cluster.local from pod dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f: the server could not find the requested resource (get pods dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f)
May 29 22:29:16.164: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local from pod dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f: the server could not find the requested resource (get pods dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f)
May 29 22:29:16.209: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local from pod dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f: the server could not find the requested resource (get pods dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f)
May 29 22:29:16.571: INFO: Unable to read jessie_udp@dns-test-service.dns-4877.svc.cluster.local from pod dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f: the server could not find the requested resource (get pods dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f)
May 29 22:29:16.615: INFO: Unable to read jessie_tcp@dns-test-service.dns-4877.svc.cluster.local from pod dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f: the server could not find the requested resource (get pods dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f)
May 29 22:29:16.658: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local from pod dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f: the server could not find the requested resource (get pods dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f)
May 29 22:29:16.701: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local from pod dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f: the server could not find the requested resource (get pods dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f)
May 29 22:29:16.959: INFO: Lookups using dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f failed for: [wheezy_udp@dns-test-service.dns-4877.svc.cluster.local wheezy_tcp@dns-test-service.dns-4877.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local jessie_udp@dns-test-service.dns-4877.svc.cluster.local jessie_tcp@dns-test-service.dns-4877.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4877.svc.cluster.local]

May 29 22:29:22.848: INFO: DNS probes using dns-4877/dns-test-f6be0e76-7058-4531-9b21-19e6e1a9b03f succeeded

[1mSTEP[0m: deleting the pod
[1mSTEP[0m: deleting the test service
[1mSTEP[0m: deleting the test headless service
[AfterEach] [sig-network] DNS
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:29:23.062: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "dns-4877" for this suite.
May 29 22:29:29.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:29:30.825: INFO: namespace dns-4877 deletion completed in 7.720265565s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] StatefulSet[0m [90m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic][0m 
  [1mShould recreate evicted statefulset [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:29:30.825: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename statefulset
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
[1mSTEP[0m: Creating service test in namespace statefulset-7687
[It] Should recreate evicted statefulset [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Looking for a node to schedule stateful set and pod
[1mSTEP[0m: Creating pod with conflicting port in namespace statefulset-7687
[1mSTEP[0m: Creating statefulset with conflicting port in namespace statefulset-7687
[1mSTEP[0m: Waiting until pod test-pod will start running in namespace statefulset-7687
[1mSTEP[0m: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7687
May 29 22:29:41.306: INFO: Observed stateful pod in namespace: statefulset-7687, name: ss-0, uid: 16c2cd66-99d6-4569-bfc8-34027763a27f, status phase: Pending. Waiting for statefulset controller to delete.
May 29 22:29:41.748: INFO: Observed stateful pod in namespace: statefulset-7687, name: ss-0, uid: 16c2cd66-99d6-4569-bfc8-34027763a27f, status phase: Failed. Waiting for statefulset controller to delete.
May 29 22:29:41.759: INFO: Observed stateful pod in namespace: statefulset-7687, name: ss-0, uid: 16c2cd66-99d6-4569-bfc8-34027763a27f, status phase: Failed. Waiting for statefulset controller to delete.
May 29 22:29:41.763: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7687
[1mSTEP[0m: Removing pod with conflicting port in namespace statefulset-7687
[1mSTEP[0m: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7687 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 29 22:29:47.984: INFO: Deleting all statefulset in ns statefulset-7687
May 29 22:29:48.026: INFO: Scaling statefulset ss to 0
May 29 22:29:58.199: INFO: Waiting for statefulset status.replicas updated to 0
May 29 22:29:58.240: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:29:58.369: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "statefulset-7687" for this suite.
May 29 22:30:04.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:30:06.132: INFO: namespace statefulset-7687 deletion completed in 7.721066413s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:30:06.134: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:30:06.135: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to restart watching from the last resource version observed by the previous watch [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:30:06.136: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating a watch on configmaps
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: closing the watch once it receives two notifications
May 29 22:30:06.474: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-235,SelfLink:/api/v1/namespaces/watch-235/configmaps/e2e-watch-test-watch-closed,UID:9de3e7ce-0eea-4702-8bc5-d8619b0ddad2,ResourceVersion:60543,Generation:0,CreationTimestamp:2019-05-29 22:30:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 29 22:30:06.474: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-235,SelfLink:/api/v1/namespaces/watch-235/configmaps/e2e-watch-test-watch-closed,UID:9de3e7ce-0eea-4702-8bc5-d8619b0ddad2,ResourceVersion:60545,Generation:0,CreationTimestamp:2019-05-29 22:30:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time, while the watch is closed
[1mSTEP[0m: creating a new watch on configmaps from the last resource version observed by the first watch
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 29 22:30:06.644: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-235,SelfLink:/api/v1/namespaces/watch-235/configmaps/e2e-watch-test-watch-closed,UID:9de3e7ce-0eea-4702-8bc5-d8619b0ddad2,ResourceVersion:60547,Generation:0,CreationTimestamp:2019-05-29 22:30:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 29 22:30:06.644: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-235,SelfLink:/api/v1/namespaces/watch-235/configmaps/e2e-watch-test-watch-closed,UID:9de3e7ce-0eea-4702-8bc5-d8619b0ddad2,ResourceVersion:60548,Generation:0,CreationTimestamp:2019-05-29 22:30:06 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:30:06.645: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "watch-235" for this suite.
May 29 22:30:12.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:30:14.406: INFO: namespace watch-235 deletion completed in 7.718401642s
[32m•[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link-bindmounted][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:30:14.406: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:30:14.408: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:30:14.408: INFO: Driver hostPath doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:30:14.410: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver hostPath doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould support remote command execution over websockets [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:30:14.410: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 22:30:14.611: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
May 29 22:35:14.785: INFO: Unexpected error occurred: timed out waiting for the condition
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "pods-4732".
[1mSTEP[0m: Found 5 events.
May 29 22:35:14.828: INFO: At 2019-05-29 22:30:14 -0700 PDT - event for pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d: {default-scheduler } Scheduled: Successfully assigned pods-4732/pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:35:14.828: INFO: At 2019-05-29 22:30:17 -0700 PDT - event for pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/busybox:1.29" already present on machine
May 29 22:35:14.828: INFO: At 2019-05-29 22:30:17 -0700 PDT - event for pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container main
May 29 22:35:14.828: INFO: At 2019-05-29 22:30:19 -0700 PDT - event for pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container main
May 29 22:35:14.828: INFO: At 2019-05-29 22:33:27 -0700 PDT - event for pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod pods-4732/pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d
May 29 22:35:14.918: INFO: POD                                                      NODE                                            PHASE    GRACE  CONDITIONS
May 29 22:35:14.918: INFO: coredns-5b969f4c88-gsjpw                                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:35:14.919: INFO: coredns-5b969f4c88-mvhtd                                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 22:35:14.919: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master     e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:35:14.919: INFO: etcd-server-e2e-test-peterhornyack-master                e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:35:14.919: INFO: etcd-server-events-e2e-test-peterhornyack-master         e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:35:14.919: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                   e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:35:14.919: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:35:14.919: INFO: fluentd-gcp-v3.2.0-fr5zq                                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 22:35:14.919: INFO: fluentd-gcp-v3.2.0-r5s9z                                 e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 22:35:14.919: INFO: fluentd-gcp-v3.2.0-wp9vf                                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 22:35:14.919: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                  e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 22:35:14.919: INFO: kube-addon-manager-e2e-test-peterhornyack-master         e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:35:14.919: INFO: kube-apiserver-e2e-test-peterhornyack-master             e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 22:35:14.919: INFO: kube-controller-manager-e2e-test-peterhornyack-master    e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 22:35:14.919: INFO: kube-dns-autoscaler-97df449df-7v474                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:35:14.919: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 22:35:14.919: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6      e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 22:35:14.919: INFO: kube-scheduler-e2e-test-peterhornyack-master             e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:35:14.919: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:35:14.919: INFO: l7-default-backend-8f479dd9-hnbtn                        e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:35:14.919: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master    e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:35:14.919: INFO: metadata-proxy-v0.1-8mhrb                                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:35:14.919: INFO: metadata-proxy-v0.1-gqcgn                                e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:35:14.919: INFO: metadata-proxy-v0.1-w99mm                                e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 22:35:14.919: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                   e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 22:35:14.919: INFO: update-demo-nautilus-5pqcg                               e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:34 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:29:19 -0700 PDT ContainersNotReady containers with unready status: [update-demo]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:29:19 -0700 PDT ContainersNotReady containers with unready status: [update-demo]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:10:34 -0700 PDT  }]
May 29 22:35:14.919: INFO: pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d  e2e-test-peterhornyack-windows-node-group-jpxd  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:30:14 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:30:14 -0700 PDT ContainersNotReady containers with unready status: [main]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:30:14 -0700 PDT ContainersNotReady containers with unready status: [main]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:30:14 -0700 PDT  }]
May 29 22:35:14.919: INFO: 
May 29 22:35:14.961: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 22:35:15.003: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:61252,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:34:59 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:34:59 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:34:59 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:34:59 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:35:15.003: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 22:35:15.044: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 22:35:15.091: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.091: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.091: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:35:15.091: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:35:15.091: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.091: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.091: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.091: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.091: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.091: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.091: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.091: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.091: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:35:15.091: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:35:15.252: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 22:35:15.252: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:35:15.293: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:61277,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{KernelDeadlock False 2019-05-29 22:34:48 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 22:34:48 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 22:34:48 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 22:34:48 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 22:34:48 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 22:34:48 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 22:34:48 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:35:11 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:35:11 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:35:11 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:35:11 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:35:15.294: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:35:15.335: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:35:15.387: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:35:15.387: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 22:35:15.387: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.387: INFO: 	Container event-exporter ready: true, restart count 0
May 29 22:35:15.387: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:35:15.387: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:35:15.387: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 22:35:15.387: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.387: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:35:15.387: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:35:15.387: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:35:15.387: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 22:35:15.387: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.387: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:35:15.387: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:35:15.387: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.387: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:35:15.387: INFO: 	Container coredns ready: true, restart count 0
May 29 22:35:15.387: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:35:15.387: INFO: 	Container autoscaler ready: true, restart count 0
May 29 22:35:15.550: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:35:15.550: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:35:15.591: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:61223,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{CorruptDockerOverlay2 False 2019-05-29 22:34:46 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 22:34:46 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 22:34:46 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 22:34:46 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 22:34:46 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 22:34:46 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 22:34:46 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:34:43 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:34:43 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:34:43 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:34:43 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:35:15.592: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:35:15.634: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:35:15.683: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.683: INFO: 	Container metrics-server ready: true, restart count 0
May 29 22:35:15.683: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 22:35:15.683: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.683: INFO: 	Container heapster ready: true, restart count 0
May 29 22:35:15.683: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 22:35:15.683: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 22:35:15.684: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.684: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:35:15.684: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:35:15.684: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 22:35:15.684: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:35:15.684: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:35:15.684: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 22:35:15.684: INFO: 	Container coredns ready: true, restart count 0
May 29 22:35:15.863: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:35:15.864: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:35:15.905: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:61157,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:34:18 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:34:18 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:34:18 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:34:18 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:35:15.906: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:35:15.948: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:35:16.152: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:35:16.152: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:35:16.194: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:61204,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:34:39 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:34:39 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:34:39 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:34:39 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:35:16.194: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:35:16.235: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:35:16.438: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:35:16.438: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:35:16.481: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:61164,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:34:22 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:34:22 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:34:22 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:34:22 -0700 PDT 2019-05-29 22:33:22 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:35:16.481: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:35:16.522: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:35:16.571: INFO: update-demo-nautilus-5pqcg started at 2019-05-29 22:10:34 -0700 PDT (0+1 container statuses recorded)
May 29 22:35:16.571: INFO: 	Container update-demo ready: false, restart count 0
May 29 22:35:16.571: INFO: pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d started at 2019-05-29 22:30:14 -0700 PDT (0+1 container statuses recorded)
May 29 22:35:16.571: INFO: 	Container main ready: false, restart count 0
May 29 22:35:18.795: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:35:18.795: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-4732" for this suite.
May 29 22:45:19.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:45:20.028: INFO: namespace: pods-4732, resource: pods, items remaining: 1
May 29 22:45:20.651: INFO: namespace: pods-4732, DeletionTimetamp: 2019-05-29 22:35:18 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 29 22:45:20.692: INFO: namespace: pods-4732, total namespaces: 5, active: 4, terminating: 1
May 29 22:45:20.740: INFO: POD                                                      NODE                                            PHASE    GRACE  CONDITIONS
May 29 22:45:20.740: INFO: pod-exec-websocket-5ee920d5-eefa-4887-b5e0-09fc5939c69d  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:30:14 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:43:22 -0700 PDT ContainersNotReady containers with unready status: [main]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:43:22 -0700 PDT ContainersNotReady containers with unready status: [main]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:30:14 -0700 PDT  }]
May 29 22:45:20.740: INFO: 
May 29 22:45:20.740: INFO: Couldn't delete ns: "pods-4732": namespace pods-4732 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace pods-4732 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})

[91m[1m• Failure [906.331 seconds][0m
[k8s.io] Pods
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  [91m[1mshould support remote command execution over websockets [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mUnexpected error:
      <*errors.errorString | 0xc0002b5440>: {
          s: "timed out waiting for the condition",
      }
      timed out waiting for the condition
  occurred[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:112
[90m------------------------------[0m
[0m[sig-windows] Hybrid cluster network[0m [90mfor all supported CNIs[0m 
  [1mshould have stable networking for Linux and Windows pods[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/hybrid_network.go:51[0m
[BeforeEach] [sig-windows] Hybrid cluster network
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/framework.go:28
[BeforeEach] [sig-windows] Hybrid cluster network
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:45:20.741: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename hybrid-network
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-windows] Hybrid cluster network
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/hybrid_network.go:45
[It] should have stable networking for Linux and Windows pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/hybrid_network.go:51
[1mSTEP[0m: creating linux and windows pods
[1mSTEP[0m: checking connectivity to 8.8.8.8 53 (google.com) from Linux
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:33.320: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 8.8.8.8 53 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:33.320: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:34.760: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 8.8.8.8 53 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:34.760: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:36.224: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 8.8.8.8 53 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:36.224: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:37.650: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 8.8.8.8 53 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:37.650: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:39.087: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 8.8.8.8 53 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:39.087: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:40.506: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 8.8.8.8 53 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:40.506: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:41.937: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 8.8.8.8 53 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:41.937: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity to www.google.com from Windows
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:45:43.320: INFO: ExecWithOptions {Command:[cmd /c curl.exe www.google.com --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:43.320: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:45:44.905: INFO: ExecWithOptions {Command:[cmd /c curl.exe www.google.com --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:44.905: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:45:46.374: INFO: ExecWithOptions {Command:[cmd /c curl.exe www.google.com --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:46.374: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:45:47.863: INFO: ExecWithOptions {Command:[cmd /c curl.exe www.google.com --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:47.863: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:45:49.344: INFO: ExecWithOptions {Command:[cmd /c curl.exe www.google.com --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:49.344: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:45:50.846: INFO: ExecWithOptions {Command:[cmd /c curl.exe www.google.com --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:50.846: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:45:52.326: INFO: ExecWithOptions {Command:[cmd /c curl.exe www.google.com --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:52.326: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity from Linux to Windows
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:53.320: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 10.64.2.61 80 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:53.320: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:54.748: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 10.64.2.61 80 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:54.748: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:56.183: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 10.64.2.61 80 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:56.183: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:57.618: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 10.64.2.61 80 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:57.618: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:45:59.033: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 10.64.2.61 80 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:45:59.033: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:46:00.481: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 10.64.2.61 80 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:00.481: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of linux-container in pod-c3f4a43c-581a-4d3c-a342-81c264bd6283
May 29 22:46:01.918: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vz 10.64.2.61 80 -w 10] Namespace:hybrid-network-999 PodName:pod-c3f4a43c-581a-4d3c-a342-81c264bd6283 ContainerName:linux-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:01.918: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity from Windows to Linux
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:46:03.320: INFO: ExecWithOptions {Command:[cmd /c curl.exe 10.64.4.9 --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:03.320: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:46:04.693: INFO: ExecWithOptions {Command:[cmd /c curl.exe 10.64.4.9 --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:04.693: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:46:06.075: INFO: ExecWithOptions {Command:[cmd /c curl.exe 10.64.4.9 --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:06.075: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:46:07.436: INFO: ExecWithOptions {Command:[cmd /c curl.exe 10.64.4.9 --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:07.441: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:46:08.829: INFO: ExecWithOptions {Command:[cmd /c curl.exe 10.64.4.9 --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:08.829: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:46:10.192: INFO: ExecWithOptions {Command:[cmd /c curl.exe 10.64.4.9 --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:10.192: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:46:11.563: INFO: ExecWithOptions {Command:[cmd /c curl.exe 10.64.4.9 --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:11.563: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: checking connectivity of windows-container in pod-dc844d89-a10e-47a6-8411-2691f49fc0c8
May 29 22:46:12.938: INFO: ExecWithOptions {Command:[cmd /c curl.exe 10.64.4.9 --connect-timeout 10 --fail] Namespace:hybrid-network-999 PodName:pod-dc844d89-a10e-47a6-8411-2691f49fc0c8 ContainerName:windows-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:46:12.938: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[AfterEach] [sig-windows] Hybrid cluster network
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:46:13.321: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "hybrid-network-999" for this suite.
May 29 22:46:51.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:46:53.083: INFO: namespace hybrid-network-999 deletion completed in 39.716430153s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:46:53.083: INFO: Driver csi-hostpath-v0 doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:46:53.085: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver csi-hostpath-v0 doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:46:53.086: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name configmap-test-upd-4ea55185-f48f-494c-b864-9d9d3d208c55
[1mSTEP[0m: Creating the pod
May 29 22:51:25.472: INFO: Unexpected error occurred: pod ran to completion
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "configmap-7510".
[1mSTEP[0m: Found 5 events.
May 29 22:51:25.515: INFO: At 2019-05-29 22:46:53 -0700 PDT - event for pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e: {default-scheduler } Scheduled: Successfully assigned configmap-7510/pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:51:25.515: INFO: At 2019-05-29 22:46:56 -0700 PDT - event for pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 29 22:51:25.515: INFO: At 2019-05-29 22:46:56 -0700 PDT - event for pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container configmap-volume-test
May 29 22:51:25.515: INFO: At 2019-05-29 22:46:58 -0700 PDT - event for pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container configmap-volume-test
May 29 22:51:25.515: INFO: At 2019-05-29 22:49:37 -0700 PDT - event for pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod configmap-7510/pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e
May 29 22:51:25.605: INFO: POD                                                    NODE                                            PHASE      GRACE  CONDITIONS
May 29 22:51:25.605: INFO: pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e    e2e-test-peterhornyack-windows-node-group-jpxd  Succeeded         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:46:53 -0700 PDT PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:46:53 -0700 PDT PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:46:53 -0700 PDT PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:46:53 -0700 PDT  }]
May 29 22:51:25.605: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:51:25.605: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 22:51:25.605: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:51:25.605: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:51:25.605: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:51:25.605: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:51:25.605: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:51:25.605: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 22:51:25.605: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 22:51:25.606: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 22:51:25.606: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 22:51:25.606: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:51:25.606: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 22:51:25.606: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 22:51:25.606: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:51:25.606: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 22:51:25.606: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 22:51:25.606: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:51:25.606: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:51:25.606: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:51:25.606: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:51:25.606: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:51:25.606: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:51:25.606: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 22:51:25.607: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running           [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 22:51:25.607: INFO: 
May 29 22:51:25.651: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 22:51:25.692: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:63581,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:51:02 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:51:02 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:51:02 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:51:02 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:51:25.693: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 22:51:25.734: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 22:51:25.781: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:25.781: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:51:25.781: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:51:25.781: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:51:25.781: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:51:25.781: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:51:25.781: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:51:25.781: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:51:25.781: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:51:25.781: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:25.781: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:51:25.781: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:51:25.781: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:51:25.781: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:51:25.985: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 22:51:25.985: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:51:26.027: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:63602,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentContainerdRestart False 2019-05-29 22:50:58 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 22:50:58 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 22:50:58 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 22:50:58 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 22:50:58 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 22:50:58 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 22:50:58 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:51:12 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:51:12 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:51:12 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:51:12 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:51:26.028: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:51:26.073: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:51:26.136: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:51:26.136: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 22:51:26.136: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:26.136: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:51:26.136: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:51:26.136: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 22:51:26.136: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:51:26.136: INFO: 	Container coredns ready: true, restart count 0
May 29 22:51:26.136: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:51:26.136: INFO: 	Container autoscaler ready: true, restart count 0
May 29 22:51:26.136: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:51:26.136: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 22:51:26.136: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:26.136: INFO: 	Container event-exporter ready: true, restart count 0
May 29 22:51:26.136: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:51:26.136: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:51:26.136: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 22:51:26.136: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:26.136: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:51:26.136: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:51:26.340: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:51:26.340: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:51:26.394: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:63560,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentDockerRestart False 2019-05-29 22:50:54 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 22:50:54 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 22:50:54 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 22:50:54 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 22:50:54 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 22:50:54 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 22:50:54 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:50:44 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:50:44 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:50:44 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:50:44 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:51:26.394: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:51:26.438: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:51:26.485: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:26.485: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:51:26.485: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:51:26.485: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:26.485: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:51:26.485: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:51:26.486: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 22:51:26.486: INFO: 	Container coredns ready: true, restart count 0
May 29 22:51:26.486: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:26.486: INFO: 	Container metrics-server ready: true, restart count 0
May 29 22:51:26.486: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 22:51:26.486: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 22:51:26.486: INFO: 	Container heapster ready: true, restart count 0
May 29 22:51:26.486: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 22:51:26.486: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 22:51:26.643: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:51:26.643: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:51:26.685: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:63622,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:51:20 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:51:20 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:51:20 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:51:20 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:51:26.686: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:51:26.727: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:51:26.931: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:51:26.931: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:51:26.973: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:63528,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:50:40 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:50:40 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:50:40 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:50:40 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:51:26.973: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:51:27.015: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:51:27.215: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:51:27.215: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:51:27.260: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:63509,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:50:34 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:50:34 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:50:34 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:50:34 -0700 PDT 2019-05-29 22:49:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:51:27.260: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:51:27.301: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:51:27.351: INFO: pod-configmaps-f486795c-b412-42c3-9e6a-59ac7b24ea8e started at 2019-05-29 22:46:53 -0700 PDT (0+1 container statuses recorded)
May 29 22:51:27.351: INFO: 	Container configmap-volume-test ready: false, restart count 0
May 29 22:51:27.585: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:51:27.585: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-7510" for this suite.
May 29 22:51:33.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:51:35.351: INFO: namespace configmap-7510 deletion completed in 7.723739497s

[91m[1m• Failure [282.266 seconds][0m
[sig-storage] ConfigMap
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32[0m
  [91m[1mupdates should be reflected in volume [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mUnexpected error:
      <*errors.errorString | 0xc0005d6080>: {
          s: "pod ran to completion",
      }
      pod ran to completion
  occurred[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:112
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:51:35.352: INFO: Driver emptydir doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:51:35.353: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver emptydir doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:51:35.354: INFO: Driver aws doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:51:35.355: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver aws doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 22:51:35.356: INFO: Driver local doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:51:35.358: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver local doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] [sig-windows] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: udp[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:87[0m
[BeforeEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:51:35.359: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:32
[It] should function for node-pod communication: udp
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:87
[1mSTEP[0m: Performing setup for networking test in namespace pod-network-test-3671
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
May 29 22:51:35.529: INFO: Waiting up to 10m0s for all (but 3) nodes to be schedulable
May 29 22:51:35.570: INFO: Unschedulable nodes:
May 29 22:51:35.571: INFO: -> e2e-test-peterhornyack-minion-group-5wdh Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 22:51:35.571: INFO: -> e2e-test-peterhornyack-minion-group-fzx6 Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 22:51:35.571: INFO: ================================
[1mSTEP[0m: Creating test pods
May 29 22:53:40.444: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.64.1.111 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3671 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:53:40.444: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 22:53:42.142: INFO: Found all expected endpoints: [netserver-0]
May 29 22:53:42.183: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.64.2.62 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3671 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:53:42.183: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 22:53:44.130: INFO: Found all expected endpoints: [netserver-1]
May 29 22:53:44.171: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.64.3.109 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3671 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 29 22:53:44.172: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 29 22:53:46.127: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 22:53:46.127: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pod-network-test-3671" for this suite.
May 29 22:54:10.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 22:54:11.919: INFO: namespace pod-network-test-3671 deletion completed in 25.748975261s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Proxy[0m [90mversion v1[0m 
  [1mshould proxy through a service and a pod  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] version v1
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 22:54:11.920: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename proxy
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: starting an echo server on multiple ports
[1mSTEP[0m: creating replication controller proxy-service-4sk2r in namespace proxy-6895
I0529 22:54:12.225553   96922 runners.go:180] Created replication controller with name: proxy-service-4sk2r, namespace: proxy-6895, replica count: 1
I0529 22:54:13.326137   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:14.326411   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:15.326678   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:16.326863   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:17.327078   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:18.327343   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:19.327584   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:20.327873   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:21.328147   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:22.328369   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:23.328575   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:24.328823   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:25.329005   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:26.329237   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:27.329491   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:28.329781   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:29.329980   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:30.330261   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:31.330482   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:32.330714   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:33.330955   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:34.331162   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:35.331435   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:36.331723   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:37.332008   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:38.332298   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:39.332521   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:40.332781   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:41.333051   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:42.333275   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:43.333536   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:44.333772   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:45.333979   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:46.334218   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:47.334444   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:48.334686   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:49.334931   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:50.335171   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:51.335455   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:52.335723   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:53.335947   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:54.336257   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:55.336470   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:56.336686   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:57.336917   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:58.337113   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:54:59.337293   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:00.337503   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:01.337720   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:02.337912   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:03.338145   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:04.338403   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:05.338724   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:06.338941   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:07.339261   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:08.339460   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:09.339753   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:10.340065   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:11.340354   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:12.340614   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:13.340835   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:14.341047   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:15.341294   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:16.341549   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:17.341757   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:18.342078   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:19.342295   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:20.342498   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:21.342705   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:22.342854   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:23.343007   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:24.343247   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:25.343558   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:26.343724   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:27.343960   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:28.344250   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:29.344458   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:30.344719   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:31.344970   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:32.345201   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:33.345469   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:34.345729   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:35.346003   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:36.346227   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:37.346447   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:38.346688   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:39.347000   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:40.347307   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:41.347581   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:42.347819   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:43.348191   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:44.348433   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:45.348614   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:46.348893   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:47.349148   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:48.349398   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:49.349635   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:50.349909   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:51.350156   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:52.350439   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:53.350691   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:54.350921   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:55.351147   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:56.351377   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:57.351571   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:58.351792   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:55:59.352013   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:00.352261   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:01.352513   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:02.352748   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:03.353001   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:04.353242   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:05.353536   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:06.354336   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:07.354647   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:08.354872   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:09.355140   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:10.355409   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:11.355626   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:12.355873   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:13.356092   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:14.356343   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:15.356609   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:16.356829   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:17.357132   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:18.357361   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:19.357588   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:20.357859   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:21.358085   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:22.358368   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:23.358585   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:24.358801   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:25.359085   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:26.359326   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:27.359548   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:28.359757   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:29.360011   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:30.360297   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:31.360481   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:32.360664   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:33.360880   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:34.361133   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:35.361347   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:36.361597   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:37.361842   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:38.362186   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:39.362424   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:40.362670   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:41.362924   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:42.363158   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:43.363427   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:44.363648   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:45.363897   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:46.364199   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:47.364386   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:48.364622   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:49.364833   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:50.365091   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:51.365345   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:52.365653   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:53.365867   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:54.366053   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:55.366285   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:56.366496   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:57.366724   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:58.366975   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:56:59.367273   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:00.367509   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:01.367762   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:02.368089   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:03.368351   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:04.368584   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:05.368764   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:06.369039   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:07.369292   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:08.369503   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:09.369695   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:10.369945   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:11.370196   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:12.370460   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:13.370740   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:14.370976   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:15.371263   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:16.371554   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:17.371811   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:18.372052   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:19.372278   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:20.372534   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:21.372775   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:22.373110   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:23.373342   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:24.373540   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:25.373745   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:26.374052   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:27.374316   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:28.374588   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:29.374856   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:30.375162   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:31.375338   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:32.375678   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:33.375997   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:34.376228   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:35.376418   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:36.376617   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:37.376863   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:38.377123   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:39.377328   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:40.377623   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:41.377804   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:42.378095   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:43.378302   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:44.378508   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:45.378724   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:46.378933   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:47.379146   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:48.379328   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:49.379526   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:50.379766   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:51.379997   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:52.380232   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:53.380453   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:54.380707   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:55.380908   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:56.381092   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:57.381382   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:58.381655   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:57:59.381861   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:00.382047   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:01.382277   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:02.382474   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:03.382737   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:04.383028   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:05.383294   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:06.383551   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:07.383972   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:08.384240   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:09.384432   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:10.384660   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:11.384930   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:12.385170   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:13.385398   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:14.385565   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:15.385843   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:16.386183   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:17.386357   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:18.386602   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:19.386837   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:20.387127   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:21.387309   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:22.387526   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:23.387764   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:24.388063   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:25.388368   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:26.388573   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:27.388830   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:28.389109   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:29.389404   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:30.389690   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:31.389921   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:32.390149   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:33.390466   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:34.390760   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:35.391073   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:36.391289   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:37.391565   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:38.391810   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:39.392033   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:40.392343   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:41.392597   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:42.392807   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:43.393132   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:44.393433   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:45.393649   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:46.393884   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:47.394104   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:48.394343   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:49.394547   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:50.394796   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:51.395031   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:52.395323   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:53.395547   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:54.395771   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:55.396081   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:56.396360   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:57.396614   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:58.396867   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:58:59.397069   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:00.397390   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:01.397650   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:02.397881   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:03.398186   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:04.398448   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:05.398708   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:06.398933   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:07.399158   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:08.399429   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:09.399634   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:10.399832   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:11.400097   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:12.400350   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:13.400614   96922 runners.go:180] proxy-service-4sk2r Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0529 22:59:13.443548   96922 runners.go:180] Pod proxy-service-4sk2r-fpkgw	e2e-test-peterhornyack-windows-node-group-jpxd	Pending	<nil>
[AfterEach] version v1
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "proxy-6895".
[1mSTEP[0m: Found 7 events.
May 29 22:59:13.486: INFO: At 2019-05-29 22:54:12 -0700 PDT - event for proxy-service-4sk2r: {replication-controller } SuccessfulCreate: Created pod: proxy-service-4sk2r-fpkgw
May 29 22:59:13.487: INFO: At 2019-05-29 22:54:12 -0700 PDT - event for proxy-service-4sk2r-fpkgw: {default-scheduler } Scheduled: Successfully assigned proxy-6895/proxy-service-4sk2r-fpkgw to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:59:13.487: INFO: At 2019-05-29 22:54:14 -0700 PDT - event for proxy-service-4sk2r-fpkgw: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulling: Pulling image "e2eteam/porter:1.0"
May 29 22:59:13.487: INFO: At 2019-05-29 22:54:16 -0700 PDT - event for proxy-service-4sk2r-fpkgw: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Successfully pulled image "e2eteam/porter:1.0"
May 29 22:59:13.487: INFO: At 2019-05-29 22:54:16 -0700 PDT - event for proxy-service-4sk2r-fpkgw: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container proxy-service-4sk2r
May 29 22:59:13.487: INFO: At 2019-05-29 22:54:18 -0700 PDT - event for proxy-service-4sk2r-fpkgw: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container proxy-service-4sk2r
May 29 22:59:13.487: INFO: At 2019-05-29 22:57:37 -0700 PDT - event for proxy-service-4sk2r-fpkgw: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod proxy-6895/proxy-service-4sk2r-fpkgw
May 29 22:59:13.576: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 29 22:59:13.576: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:59:13.576: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 22:59:13.576: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:59:13.576: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:59:13.576: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:59:13.576: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:59:13.576: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:59:13.576: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 22:59:13.576: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 22:59:13.576: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 22:59:13.576: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 22:59:13.577: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:59:13.577: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 22:59:13.577: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 22:59:13.577: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:59:13.577: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 22:59:13.577: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 22:59:13.577: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:59:13.577: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:59:13.577: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:59:13.577: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 22:59:13.577: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:59:13.577: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 22:59:13.577: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 22:59:13.577: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 22:59:13.577: INFO: proxy-service-4sk2r-fpkgw                              e2e-test-peterhornyack-windows-node-group-jpxd  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:54:12 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:54:12 -0700 PDT ContainersNotReady containers with unready status: [proxy-service-4sk2r]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:54:12 -0700 PDT ContainersNotReady containers with unready status: [proxy-service-4sk2r]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 22:54:12 -0700 PDT  }]
May 29 22:59:13.578: INFO: 
May 29 22:59:13.620: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 22:59:13.662: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:64784,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:59:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:59:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:59:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:59:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:59:13.662: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 22:59:13.704: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 22:59:13.750: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:59:13.750: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:59:13.750: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:13.750: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:59:13.750: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:59:13.750: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:59:13.750: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:59:13.750: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:59:13.750: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:59:13.750: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:59:13.750: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 22:59:13.750: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:13.750: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:59:13.750: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:59:13.944: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 22:59:13.944: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:59:13.986: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:64805,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentUnregisterNetDevice False 2019-05-29 22:59:01 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 22:59:01 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 22:59:01 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 22:59:01 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 22:59:01 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 22:59:01 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 22:59:01 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:59:12 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:59:12 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:59:12 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:59:12 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:59:13.986: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:59:14.027: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:59:14.079: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:59:14.079: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 22:59:14.079: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:14.079: INFO: 	Container event-exporter ready: true, restart count 0
May 29 22:59:14.079: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:59:14.079: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:59:14.079: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 22:59:14.079: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:14.079: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:59:14.079: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:59:14.079: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 22:59:14.079: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:59:14.079: INFO: 	Container coredns ready: true, restart count 0
May 29 22:59:14.079: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:59:14.079: INFO: 	Container autoscaler ready: true, restart count 0
May 29 22:59:14.079: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 22:59:14.079: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 22:59:14.079: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:14.079: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:59:14.079: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:59:14.243: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 22:59:14.243: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:59:14.285: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:64770,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentUnregisterNetDevice False 2019-05-29 22:58:57 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 22:58:57 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 22:58:57 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 22:58:57 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 22:58:57 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 22:58:57 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 22:58:57 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:58:45 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:58:45 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:58:45 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:58:45 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 22:59:14.285: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:59:14.326: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:59:14.377: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:14.377: INFO: 	Container heapster ready: true, restart count 0
May 29 22:59:14.377: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 22:59:14.377: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 22:59:14.377: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:14.377: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 22:59:14.377: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:59:14.377: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:14.377: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 22:59:14.377: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 22:59:14.377: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 22:59:14.377: INFO: 	Container coredns ready: true, restart count 0
May 29 22:59:14.377: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 22:59:14.377: INFO: 	Container metrics-server ready: true, restart count 0
May 29 22:59:14.378: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 22:59:14.542: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 22:59:14.542: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:59:14.584: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:64755,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:58:51 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:58:51 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:58:51 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:58:51 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:59:14.584: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:59:14.626: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:59:14.838: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 22:59:14.838: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:59:14.883: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:64731,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:58:41 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:58:41 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:58:41 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:58:41 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:59:14.883: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:59:14.925: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:59:15.124: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 22:59:15.124: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:59:15.166: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:64714,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 22:58:35 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 22:58:35 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 22:58:35 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 22:58:35 -0700 PDT 2019-05-29 22:57:35 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 22:59:15.166: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:59:15.207: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:59:15.260: INFO: proxy-service-4sk2r-fpkgw started at 2019-05-29 22:54:12 -0700 PDT (0+1 container statuses recorded)
May 29 22:59:15.260: INFO: 	Container proxy-service-4sk2r ready: false, restart count 0
May 29 22:59:17.476: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 22:59:17.476: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "proxy-6895" for this suite.
May 29 23:02:11.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:02:13.321: INFO: namespace proxy-6895 deletion completed in 2m55.801625238s

[91m[1m• Failure [481.401 seconds][0m
[sig-network] Proxy
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  version v1
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56[0m
    [91m[1mshould proxy through a service and a pod  [Conformance] [It][0m
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mUnexpected error:
        <*errors.errorString | 0xc0025ec480>: {
            s: "Only 0 pods started out of 1",
        }
        Only 0 pods started out of 1
    occurred[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:161
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:02:13.321: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:02:13.322: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mwith readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:02:13.324: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 23:07:13.751: INFO: Unexpected error occurred: want pod 'test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c' on 'e2e-test-peterhornyack-windows-node-group-jpxd' to be 'Running' but was 'Pending'
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "container-probe-7636".
[1mSTEP[0m: Found 5 events.
May 29 23:07:13.794: INFO: At 2019-05-29 23:02:13 -0700 PDT - event for test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c: {default-scheduler } Scheduled: Successfully assigned container-probe-7636/test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:07:13.794: INFO: At 2019-05-29 23:02:15 -0700 PDT - event for test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/test-webserver:1.0" already present on machine
May 29 23:07:13.794: INFO: At 2019-05-29 23:02:15 -0700 PDT - event for test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container test-webserver
May 29 23:07:13.794: INFO: At 2019-05-29 23:02:17 -0700 PDT - event for test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container test-webserver
May 29 23:07:13.794: INFO: At 2019-05-29 23:05:38 -0700 PDT - event for test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod container-probe-7636/test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c
May 29 23:07:13.882: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 29 23:07:13.882: INFO: test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c    e2e-test-peterhornyack-windows-node-group-jpxd  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:02:13 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:02:13 -0700 PDT ContainersNotReady containers with unready status: [test-webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:02:13 -0700 PDT ContainersNotReady containers with unready status: [test-webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:02:13 -0700 PDT  }]
May 29 23:07:13.882: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:07:13.882: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 23:07:13.882: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:07:13.882: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:07:13.882: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:07:13.882: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:07:13.883: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:07:13.883: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 23:07:13.883: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 23:07:13.883: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 23:07:13.883: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 23:07:13.883: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:07:13.883: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 23:07:13.883: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 23:07:13.883: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:07:13.883: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 23:07:13.883: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 23:07:13.883: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:07:13.883: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:07:13.883: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:07:13.883: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:07:13.883: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:07:13.883: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:07:13.883: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 23:07:13.883: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 23:07:13.883: INFO: 
May 29 23:07:13.927: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 23:07:13.968: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:65950,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:07:06 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:07:06 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:07:06 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:07:06 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 23:07:13.968: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 23:07:14.012: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 23:07:14.061: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.061: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.061: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.061: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.061: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.061: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.061: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 23:07:14.061: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:07:14.061: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.061: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.061: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.061: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 23:07:14.061: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:07:14.061: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.222: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 23:07:14.222: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 23:07:14.263: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:65967,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{ReadonlyFilesystem False 2019-05-29 23:07:04 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 23:07:04 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-29 23:07:04 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 23:07:04 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 23:07:04 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 23:07:04 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 23:07:04 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:07:13 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:07:13 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:07:13 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:07:13 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 23:07:14.264: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 23:07:14.305: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 23:07:14.357: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:07:14.357: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 23:07:14.357: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.357: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 23:07:14.357: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:07:14.357: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.357: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:07:14.357: INFO: 	Container coredns ready: true, restart count 0
May 29 23:07:14.357: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:07:14.357: INFO: 	Container autoscaler ready: true, restart count 0
May 29 23:07:14.357: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:07:14.357: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 23:07:14.357: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.357: INFO: 	Container event-exporter ready: true, restart count 0
May 29 23:07:14.357: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:07:14.357: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:07:14.357: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 23:07:14.357: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.357: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 23:07:14.357: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:07:14.526: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 23:07:14.526: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 23:07:14.568: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:65940,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentContainerdRestart False 2019-05-29 23:07:02 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 23:07:02 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 23:07:02 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 23:07:02 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 23:07:02 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 23:07:02 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 23:07:02 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:06:45 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:06:45 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:06:45 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:06:45 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 23:07:14.568: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 23:07:14.610: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 23:07:14.660: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 23:07:14.660: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.660: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 23:07:14.660: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:07:14.660: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.660: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 23:07:14.660: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:07:14.661: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 23:07:14.661: INFO: 	Container coredns ready: true, restart count 0
May 29 23:07:14.661: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.661: INFO: 	Container metrics-server ready: true, restart count 0
May 29 23:07:14.661: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 23:07:14.661: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 23:07:14.661: INFO: 	Container heapster ready: true, restart count 0
May 29 23:07:14.661: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 23:07:14.832: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 23:07:14.832: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 23:07:14.873: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:65916,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:06:51 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:06:51 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:06:51 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:06:51 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 23:07:14.874: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 23:07:14.920: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 23:07:15.124: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 23:07:15.124: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 23:07:15.166: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:65892,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:06:42 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:06:42 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:06:42 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:06:42 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 23:07:15.166: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 23:07:15.207: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 23:07:15.412: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 23:07:15.412: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:07:15.455: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:65875,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:06:36 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:06:36 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:06:36 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:06:36 -0700 PDT 2019-05-29 23:05:35 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 23:07:15.455: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:07:15.496: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:07:15.545: INFO: test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c started at 2019-05-29 23:02:13 -0700 PDT (0+1 container statuses recorded)
May 29 23:07:15.545: INFO: 	Container test-webserver ready: false, restart count 0
May 29 23:07:17.124: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:07:17.124: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-probe-7636" for this suite.
May 29 23:07:39.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:07:40.911: INFO: namespace container-probe-7636 deletion completed in 23.744313854s

[91m[1m• Failure [327.588 seconds][0m
[k8s.io] Probing container
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  [91m[1mwith readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mUnexpected error:
      <*errors.errorString | 0xc003a4cc10>: {
          s: "want pod 'test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c' on 'e2e-test-peterhornyack-windows-node-group-jpxd' to be 'Running' but was 'Pending'",
      }
      want pod 'test-webserver-6cd89928-8100-45e0-bd58-470476a7e51c' on 'e2e-test-peterhornyack-windows-node-group-jpxd' to be 'Running' but was 'Pending'
  occurred[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:67
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1mupdates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:07:40.912: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating projection with configMap that has name projected-configmap-test-upd-b1350443-e4f2-4e15-81be-4f01d2a528c8
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Updating configmap projected-configmap-test-upd-b1350443-e4f2-4e15-81be-4f01d2a528c8
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:09:19.730: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 23:09:19.774: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 23:08:36 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 23:08:38 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "projected-7870" for this suite.
May 29 23:10:51.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:10:53.620: INFO: namespace projected-7870 deletion completed in 1m33.845850224s
[32m•[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:10:53.620: INFO: Driver emptydir doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:10:53.621: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver emptydir doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:10:53.623: INFO: Driver hostPathSymlink doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:10:53.624: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver hostPathSymlink doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Container Lifecycle Hook[0m [90mwhen create a pod with lifecycle hook[0m 
  [1mshould execute poststart http hook properly [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:10:53.625: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-lifecycle-hook
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
[1mSTEP[0m: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the pod with lifecycle hook
[1mSTEP[0m: check poststart hook
[1mSTEP[0m: delete the pod with lifecycle hook
May 29 23:13:44.251: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 23:13:44.293: INFO: Pod pod-with-poststart-http-hook still exists
May 29 23:13:46.293: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 23:13:46.335: INFO: Pod pod-with-poststart-http-hook still exists
May 29 23:13:48.293: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 29 23:13:48.335: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:13:48.335: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "container-lifecycle-hook-6689" for this suite.
May 29 23:23:48.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:23:49.517: INFO: namespace: container-lifecycle-hook-6689, resource: pods, items remaining: 1
May 29 23:23:50.186: INFO: namespace: container-lifecycle-hook-6689, DeletionTimetamp: 2019-05-29 23:13:48 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 29 23:23:50.228: INFO: namespace: container-lifecycle-hook-6689, total namespaces: 5, active: 4, terminating: 1
May 29 23:23:50.272: INFO: POD                      NODE                                            PHASE    GRACE  CONDITIONS
May 29 23:23:50.272: INFO: pod-handle-http-request  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:10:53 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:13:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:13:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:10:53 -0700 PDT  }]
May 29 23:23:50.272: INFO: 
May 29 23:23:50.272: INFO: Couldn't delete ns: "container-lifecycle-hook-6689": namespace container-lifecycle-hook-6689 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace container-lifecycle-hook-6689 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})

[91m[1m• Failure in Spec Teardown (AfterEach) [776.648 seconds][0m
[k8s.io] Container Lifecycle Hook
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  [91m[1mwhen create a pod with lifecycle hook [AfterEach][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40[0m
    should execute poststart http hook properly [NodeConformance] [Conformance]
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mMay 29 23:23:50.272: Couldn't delete ns: "container-lifecycle-hook-6689": namespace container-lifecycle-hook-6689 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace container-lifecycle-hook-6689 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected configMap[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:23:50.274: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name cm-test-opt-del-d127b43e-460a-4cfb-ae0d-ef976f7f5391
[1mSTEP[0m: Creating configMap with name cm-test-opt-upd-5aea60f9-3ba5-401f-95b1-81bf017f07b9
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting configmap cm-test-opt-del-d127b43e-460a-4cfb-ae0d-ef976f7f5391
[1mSTEP[0m: Updating configmap cm-test-opt-upd-5aea60f9-3ba5-401f-95b1-81bf017f07b9
[1mSTEP[0m: Creating configMap with name cm-test-opt-create-d7ecedcc-e77c-47d7-9df2-8972c7746f44
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "projected-5612".
[1mSTEP[0m: Found 11 events.
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:50 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {default-scheduler } Scheduled: Successfully assigned projected-5612/pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a to e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:52 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:52 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container delcm-volume-test
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:54 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container delcm-volume-test
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:54 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:54 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container updcm-volume-test
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:56 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container updcm-volume-test
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:56 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:56 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container createcm-volume-test
May 29 23:29:37.096: INFO: At 2019-05-29 23:23:59 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container createcm-volume-test
May 29 23:29:37.096: INFO: At 2019-05-29 23:25:38 -0700 PDT - event for pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod projected-5612/pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a
May 29 23:29:37.184: INFO: POD                                                            NODE                                            PHASE    GRACE  CONDITIONS
May 29 23:29:37.184: INFO: pod-handle-http-request                                        e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:10:53 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:13:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:13:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:10:53 -0700 PDT  }]
May 29 23:29:37.184: INFO: coredns-5b969f4c88-gsjpw                                       e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:29:37.184: INFO: coredns-5b969f4c88-mvhtd                                       e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 29 23:29:37.184: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:29:37.184: INFO: etcd-server-e2e-test-peterhornyack-master                      e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:29:37.184: INFO: etcd-server-events-e2e-test-peterhornyack-master               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:29:37.184: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                         e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:29:37.185: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                            e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:29:37.185: INFO: fluentd-gcp-v3.2.0-fr5zq                                       e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 29 23:29:37.185: INFO: fluentd-gcp-v3.2.0-r5s9z                                       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 29 23:29:37.185: INFO: fluentd-gcp-v3.2.0-wp9vf                                       e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 29 23:29:37.185: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                        e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 29 23:29:37.185: INFO: kube-addon-manager-e2e-test-peterhornyack-master               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:29:37.185: INFO: kube-apiserver-e2e-test-peterhornyack-master                   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 23:29:37.185: INFO: kube-controller-manager-e2e-test-peterhornyack-master          e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 29 23:29:37.185: INFO: kube-dns-autoscaler-97df449df-7v474                            e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:29:37.185: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh            e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 29 23:29:37.185: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6            e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 29 23:29:37.185: INFO: kube-scheduler-e2e-test-peterhornyack-master                   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:29:37.185: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                          e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:29:37.185: INFO: l7-default-backend-8f479dd9-hnbtn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:29:37.185: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master          e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 29 23:29:37.185: INFO: metadata-proxy-v0.1-8mhrb                                      e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:29:37.185: INFO: metadata-proxy-v0.1-gqcgn                                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 29 23:29:37.185: INFO: metadata-proxy-v0.1-w99mm                                      e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 29 23:29:37.185: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                         e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 29 23:29:37.185: INFO: pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a  e2e-test-peterhornyack-windows-node-group-jpxd  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:23:50 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:25:36 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:25:36 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:23:50 -0700 PDT  }]
May 29 23:29:37.185: INFO: 
May 29 23:29:37.227: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 29 23:29:37.269: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:69150,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:29:10 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:29:10 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:29:10 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:29:10 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 23:29:37.270: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 29 23:29:37.311: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 29 23:29:37.357: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.357: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.357: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.357: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 23:29:37.357: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:29:37.357: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.357: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.357: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.357: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.357: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.357: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.357: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.357: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 23:29:37.357: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:29:37.519: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 29 23:29:37.519: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 29 23:29:37.563: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:69176,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentKubeletRestart False 2019-05-29 23:29:20 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 23:29:20 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 23:29:20 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-29 23:29:20 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-29 23:29:20 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 23:29:20 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-29 23:29:20 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:29:15 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:29:15 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:29:15 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:29:15 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 23:29:37.563: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 29 23:29:37.604: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 29 23:29:37.656: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 29 23:29:37.656: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:29:37.656: INFO: 	Container coredns ready: true, restart count 0
May 29 23:29:37.656: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:29:37.656: INFO: 	Container autoscaler ready: true, restart count 0
May 29 23:29:37.656: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:29:37.656: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 29 23:29:37.656: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.656: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 23:29:37.656: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:29:37.656: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:29:37.656: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 29 23:29:37.656: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.656: INFO: 	Container event-exporter ready: true, restart count 0
May 29 23:29:37.656: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:29:37.656: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 29 23:29:37.656: INFO: 	Container default-http-backend ready: true, restart count 0
May 29 23:29:37.656: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.656: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 23:29:37.656: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:29:37.817: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 29 23:29:37.817: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 29 23:29:37.858: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:69155,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{CorruptDockerOverlay2 False 2019-05-29 23:29:11 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-29 23:29:11 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-29 23:29:11 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-29 23:29:11 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-29 23:29:11 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-29 23:29:11 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-29 23:29:11 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:28:47 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:28:47 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:28:47 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:28:47 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 29 23:29:37.858: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 29 23:29:37.900: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 29 23:29:37.955: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.955: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 29 23:29:37.956: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:29:37.956: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.956: INFO: 	Container metadata-proxy ready: true, restart count 0
May 29 23:29:37.956: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 29 23:29:37.956: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 29 23:29:37.956: INFO: 	Container coredns ready: true, restart count 0
May 29 23:29:37.956: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.956: INFO: 	Container metrics-server ready: true, restart count 0
May 29 23:29:37.956: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 29 23:29:37.956: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 29 23:29:37.956: INFO: 	Container heapster ready: true, restart count 0
May 29 23:29:37.956: INFO: 	Container heapster-nanny ready: true, restart count 0
May 29 23:29:37.956: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 29 23:29:38.105: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 29 23:29:38.105: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 23:29:38.146: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:69108,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:28:53 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:28:53 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:28:53 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:28:53 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 23:29:38.147: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 23:29:38.188: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 23:29:38.388: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 29 23:29:38.388: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 23:29:38.430: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:69133,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:29:03 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:29:03 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:29:03 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:29:03 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 23:29:38.430: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 23:29:38.472: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 23:29:38.681: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 29 23:29:38.681: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:29:38.723: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:69217,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[{node.kubernetes.io/not-ready  NoExecute 2019-05-29 23:28:43 -0700 PDT}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-29 23:29:38 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-29 23:29:38 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-29 23:29:38 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-29 23:29:38 -0700 PDT 2019-05-29 23:29:38 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 29 23:29:38.723: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:29:38.764: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:29:38.809: INFO: pod-handle-http-request started at 2019-05-29 23:10:53 -0700 PDT (0+1 container statuses recorded)
May 29 23:29:38.809: INFO: 	Container pod-handle-http-request ready: true, restart count 0
May 29 23:29:38.809: INFO: pod-projected-configmaps-4011e193-c5b1-47cf-9d28-2d7652d2309a started at 2019-05-29 23:23:50 -0700 PDT (0+3 container statuses recorded)
May 29 23:29:38.809: INFO: 	Container createcm-volume-test ready: true, restart count 0
May 29 23:29:38.809: INFO: 	Container delcm-volume-test ready: true, restart count 0
May 29 23:29:38.809: INFO: 	Container updcm-volume-test ready: true, restart count 0
May 29 23:29:39.027: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 29 23:29:39.027: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 23:29:39.070: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is true, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoExecute 2019-05-29 23:28:43 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "projected-5612" for this suite.
May 29 23:29:45.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:29:46.913: INFO: namespace projected-5612 deletion completed in 7.842496867s

[91m[1m• Failure [356.639 seconds][0m
[sig-storage] Projected configMap
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33[0m
  [91m[1moptional updates should be reflected in volume [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mTimed out after 240.003s.
  Expected
      <string>: Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/projected-configmap-volumes/create/data-1: open C:\etc\projected-configmap-volumes\create\data-1: The system cannot find the file specified., retrying
      
  to contain substring
      <string>: value-1[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:393
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:29:46.913: INFO: Driver gluster doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:29:46.914: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver gluster doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Proxy server[0m 
  [1mshould support --unix-socket=/path  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:29:46.914: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support --unix-socket=/path  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Starting the proxy
May 29 23:29:47.083: INFO: Asynchronously running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config proxy --unix-socket=/tmp/kubectl-proxy-unix500420508/test'
[1mSTEP[0m: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:29:47.161: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-4554" for this suite.
May 29 23:29:53.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:29:54.945: INFO: namespace kubectl-4554 deletion completed in 7.741337286s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould orphan pods created by rc if delete options say so [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:29:54.946: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: create the rc
[1mSTEP[0m: delete the rc
[1mSTEP[0m: wait for the rc to be deleted
[1mSTEP[0m: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
[1mSTEP[0m: Gathering metrics
May 29 23:30:35.577: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 18
	[quantile=0.99] = 18
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 39
	[quantile=0.9] = 71
	[quantile=0.99] = 71
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 9
	[quantile=0.9] = 9
	[quantile=0.99] = 9
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 608971
	[quantile=0.9] = 608971
	[quantile=0.99] = 608971
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 8
	[quantile=0.99] = 48
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 18
	[quantile=0.9] = 37
	[quantile=0.99] = 67
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 19
	[quantile=0.9] = 21
	[quantile=0.99] = 21
For namespace_queue_latency_sum:
	[] = 12981
For namespace_queue_latency_count:
	[] = 635
For namespace_retries:
	[] = 667
For namespace_work_duration:
	[quantile=0.5] = 194404
	[quantile=0.9] = 256664
	[quantile=0.99] = 256664
For namespace_work_duration_sum:
	[] = 139613642
For namespace_work_duration_count:
	[] = 635
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:30:35.577: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-9827" for this suite.
May 29 23:30:41.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:30:43.354: INFO: namespace gc-9827 deletion completed in 7.73010458s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] EmptyDir volumes[0m 
  [1mpod should support shared volumes between containers [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:30:43.354: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename emptydir
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating Pod
[1mSTEP[0m: Waiting for the pod running
[1mSTEP[0m: Geting the pod
[1mSTEP[0m: Reading file content from the nginx-container
May 29 23:30:53.783: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec pod-sharedvolume-c7ff942f-27bf-4172-b9da-67ce5ba30948 -c busybox-main-container --namespace=emptydir-4145 -- cat /usr/share/volumeshare/shareddata.txt'
May 29 23:30:54.416: INFO: stderr: ""
May 29 23:30:54.416: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:30:54.416: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "emptydir-4145" for this suite.
May 29 23:31:00.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:31:02.171: INFO: namespace emptydir-4145 deletion completed in 7.711979207s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:31:02.172: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:31:02.172: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:31:02.172: INFO: Driver csi-hostpath-v0 doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:31:02.173: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.001 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver csi-hostpath-v0 doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] ConfigMap[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:31:02.173: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename configmap
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating configMap with name configmap-test-volume-map-23e1a45f-dd29-4677-b2d4-852a54da4e7a
[1mSTEP[0m: Creating a pod to test consume configMaps
May 29 23:31:02.433: INFO: Waiting up to 5m0s for pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1" in namespace "configmap-9850" to be "success or failure"
May 29 23:31:02.475: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 41.849302ms
May 29 23:31:04.517: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084132383s
May 29 23:31:06.560: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127087099s
May 29 23:31:08.602: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.169107263s
May 29 23:31:10.646: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.212512251s
May 29 23:31:12.688: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.254608762s
May 29 23:31:14.730: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.296739707s
May 29 23:31:16.772: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.338608314s
May 29 23:31:18.814: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.380789993s
May 29 23:31:20.856: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.422903934s
May 29 23:31:22.898: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 20.464862115s
May 29 23:31:24.940: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.506887693s
May 29 23:31:26.981: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.548304803s
May 29 23:31:29.024: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.590515275s
May 29 23:31:31.066: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 28.632469154s
May 29 23:31:33.107: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 30.674055036s
May 29 23:31:35.149: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 32.715997064s
May 29 23:31:37.191: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 34.757668176s
May 29 23:31:39.233: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 36.799464313s
May 29 23:31:41.274: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 38.841375831s
May 29 23:31:43.316: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 40.882968646s
May 29 23:31:45.358: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 42.92502603s
May 29 23:31:47.400: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 44.967131373s
May 29 23:31:49.442: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 47.008966435s
May 29 23:31:51.484: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 49.051239522s
May 29 23:31:53.532: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 51.099023534s
May 29 23:31:55.577: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 53.144423198s
May 29 23:31:57.622: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 55.188539319s
May 29 23:31:59.664: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 57.230556326s
May 29 23:32:01.706: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 59.272625528s
May 29 23:32:03.747: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.314416191s
May 29 23:32:05.789: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.356426932s
May 29 23:32:07.831: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.398382406s
May 29 23:32:09.874: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.440572749s
May 29 23:32:11.916: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.482741392s
May 29 23:32:13.958: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.524963161s
May 29 23:32:16.001: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.568067193s
May 29 23:32:18.043: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.610252715s
May 29 23:32:20.085: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.652042406s
May 29 23:32:22.127: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.69437443s
May 29 23:32:24.169: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.736040689s
May 29 23:32:26.212: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.778461803s
May 29 23:32:28.253: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.820220162s
May 29 23:32:30.296: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.862694599s
May 29 23:32:32.338: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.904895875s
May 29 23:32:34.380: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.947256916s
May 29 23:32:36.422: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.989327026s
May 29 23:32:38.465: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.031528572s
May 29 23:32:40.506: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.073181795s
May 29 23:32:42.548: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.114910025s
May 29 23:32:44.591: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.157469238s
May 29 23:32:46.637: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.203904644s
May 29 23:32:48.684: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.25090597s
May 29 23:32:50.726: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.292922888s
May 29 23:32:52.768: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.335014194s
May 29 23:32:54.810: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.377427321s
May 29 23:32:56.852: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.419415063s
May 29 23:32:58.895: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.462097896s
May 29 23:33:00.937: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.503916188s
May 29 23:33:02.979: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.54605172s
May 29 23:33:05.021: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.588277466s
May 29 23:33:07.063: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.630020321s
May 29 23:33:09.105: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.671964397s
May 29 23:33:11.147: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.714383759s
May 29 23:33:13.190: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.756944503s
May 29 23:33:15.232: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.798849834s
May 29 23:33:17.274: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.840555087s
May 29 23:33:19.316: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.882685002s
May 29 23:33:21.358: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.92472201s
May 29 23:33:23.400: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.966819341s
May 29 23:33:25.443: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m23.010071414s
May 29 23:33:27.485: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.051951105s
May 29 23:33:29.527: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.093765905s
May 29 23:33:31.569: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.135707182s
May 29 23:33:33.611: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.177690119s
May 29 23:33:35.653: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.21954493s
May 29 23:33:37.697: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.264076915s
May 29 23:33:39.739: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.30559559s
May 29 23:33:41.781: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.347630876s
May 29 23:33:43.823: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.389775744s
May 29 23:33:45.865: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.432331218s
May 29 23:33:47.908: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.474498888s
May 29 23:33:49.950: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.516959871s
May 29 23:33:51.992: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.559108153s
May 29 23:33:54.034: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.601166826s
May 29 23:33:56.076: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.643161306s
May 29 23:33:58.118: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.685290064s
May 29 23:34:00.160: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.727055769s
May 29 23:34:02.202: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.768973389s
May 29 23:34:04.244: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.811306834s
May 29 23:34:06.286: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.853347351s
May 29 23:34:08.329: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.896327085s
May 29 23:34:10.371: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.938384215s
May 29 23:34:12.414: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.980639496s
May 29 23:34:14.456: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.023027777s
May 29 23:34:16.498: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.065067005s
May 29 23:34:18.540: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.10701687s
May 29 23:34:20.582: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.148671934s
May 29 23:34:22.625: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.19238305s
May 29 23:34:24.668: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.23453394s
May 29 23:34:26.709: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.276365318s
May 29 23:34:28.751: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.3182143s
May 29 23:34:30.793: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.3597863s
May 29 23:34:32.834: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.401278348s
May 29 23:34:34.876: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.44311222s
May 29 23:34:36.918: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.484853406s
May 29 23:34:38.960: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.526624923s
May 29 23:34:41.001: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.568331711s
May 29 23:34:43.043: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.610220899s
May 29 23:34:45.085: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.652018116s
May 29 23:34:47.127: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.693683018s
May 29 23:34:49.168: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.735105811s
May 29 23:34:51.210: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.776888568s
May 29 23:34:53.252: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.818688201s
May 29 23:34:55.293: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.860395446s
May 29 23:34:57.336: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.902607102s
May 29 23:34:59.380: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.946525112s
May 29 23:35:01.421: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.98827635s
May 29 23:35:03.463: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m1.029900154s
May 29 23:35:05.505: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m3.07215188s
May 29 23:35:07.547: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m5.11387558s
May 29 23:35:09.589: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m7.156050258s
May 29 23:35:11.637: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m9.204376641s
May 29 23:35:13.680: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m11.247192351s
May 29 23:35:15.722: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m13.288606592s
May 29 23:35:17.764: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m15.330487549s
May 29 23:35:19.805: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m17.372298315s
May 29 23:35:21.847: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m19.414276008s
May 29 23:35:23.889: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m21.455614846s
May 29 23:35:25.930: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m23.497287669s
May 29 23:35:27.972: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m25.539002056s
May 29 23:35:30.014: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m27.580714869s
May 29 23:35:32.056: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m29.622789694s
May 29 23:35:34.098: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m31.664573826s
May 29 23:35:36.147: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m33.713977311s
May 29 23:35:38.189: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 4m35.755889688s
May 29 23:35:40.231: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4m37.79781946s
[1mSTEP[0m: Saw pod success
May 29 23:35:40.231: INFO: Pod "pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1" satisfied condition "success or failure"
May 29 23:35:40.273: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1 container configmap-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 29 23:35:40.373: INFO: Waiting for pod pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1 to disappear
May 29 23:35:40.414: INFO: Pod pod-configmaps-5a4b8d3e-836b-4ed6-96c5-5af4c55d0ab1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:35:40.414: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "configmap-9850" for this suite.
May 29 23:35:46.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:35:48.216: INFO: namespace configmap-9850 deletion completed in 7.75915704s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould update labels on modification [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:35:48.216: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating the pod
May 29 23:35:57.233: INFO: Successfully updated pod "labelsupdate642b314b-da3a-4e76-aca9-eda39122c487"
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:35:59.334: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-8518" for this suite.
May 29 23:36:21.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:36:23.093: INFO: namespace projected-8518 deletion completed in 23.716273311s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:36:23.093: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:36:23.095: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:36:23.096: INFO: Driver hostPathSymlink doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:36:23.097: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver hostPathSymlink doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: tmpfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:36:23.098: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:36:23.099: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: tmpfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Kubelet[0m [90mwhen scheduling a busybox command in a pod[0m 
  [1mshould print the output to logs [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:36:23.100: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubelet-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[AfterEach] [k8s.io] Kubelet
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:36:31.517: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubelet-test-2439" for this suite.
May 29 23:37:37.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:37:39.266: INFO: namespace kubelet-test-2439 deletion completed in 1m7.70502126s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:37:39.266: INFO: Driver hostPath doesn't support PreprovisionedPV -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:37:39.267: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver hostPath doesn't support PreprovisionedPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[0m[k8s.io] InitContainer [NodeConformance][0m 
  [1mshould not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:37:39.268: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename init-container
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
May 29 23:37:39.474: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:37:50.060: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 23:37:50.104: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is true, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoExecute 2019-05-29 23:36:43 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "init-container-7817" for this suite.
May 29 23:37:56.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:37:57.814: INFO: namespace init-container-7817 deletion completed in 7.710297025s
[32m•[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: aws][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:37:57.815: INFO: Driver aws doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:37:57.816: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: aws]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver aws doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: azure][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:37:57.817: INFO: Driver azure doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:37:57.818: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: azure]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver azure doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:37:57.819: INFO: Driver csi-hostpath-v0 doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:37:57.821: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver csi-hostpath-v0 doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:37:57.822: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:37:57.823: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:37:57.823: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:37:57.825: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl rolling-update[0m 
  [1mshould support rolling-update to same image  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:37:57.826: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl rolling-update
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1430
[It] should support rolling-update to same image  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: running the image e2eteam/nginx:1.14-alpine
May 29 23:37:58.029: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config run e2e-test-nginx-rc --image=e2eteam/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4890'
May 29 23:38:00.250: INFO: stderr: ""
May 29 23:38:00.250: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
[1mSTEP[0m: verifying the rc e2e-test-nginx-rc was created
[1mSTEP[0m: rolling-update to same image controller
May 29 23:38:00.551: INFO: scanned /usr/local/google/home/peterhornyack for discovery docs: <nil>
May 29 23:38:00.552: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config rolling-update e2e-test-nginx-rc --update-period=1s --image=e2eteam/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4890'
May 29 23:38:17.535: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 29 23:38:17.536: INFO: stdout: "Created e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407\nScaling up e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 29 23:38:17.541: INFO: stdout: "Created e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407\nScaling up e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
[1mSTEP[0m: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 29 23:38:17.542: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4890'
May 29 23:38:17.803: INFO: stderr: ""
May 29 23:38:17.803: INFO: stdout: "e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407-x7sjb e2e-test-nginx-rc-w8zvs "
[1mSTEP[0m: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
May 29 23:38:22.803: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4890'
May 29 23:38:23.063: INFO: stderr: ""
May 29 23:38:23.063: INFO: stdout: "e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407-x7sjb e2e-test-nginx-rc-w8zvs "
[1mSTEP[0m: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
May 29 23:38:28.063: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4890'
May 29 23:38:28.333: INFO: stderr: ""
May 29 23:38:28.333: INFO: stdout: "e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407-x7sjb "
May 29 23:38:28.334: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407-x7sjb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4890'
May 29 23:38:28.589: INFO: stderr: ""
May 29 23:38:28.590: INFO: stdout: "true"
May 29 23:38:28.590: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config get pods e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407-x7sjb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4890'
May 29 23:38:28.839: INFO: stderr: ""
May 29 23:38:28.839: INFO: stdout: "e2eteam/nginx:1.14-alpine"
May 29 23:38:28.840: INFO: e2e-test-nginx-rc-d262652b32c02e2317d5a00e81fe6407-x7sjb is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1436
May 29 23:38:28.840: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete rc e2e-test-nginx-rc --namespace=kubectl-4890'
May 29 23:38:29.146: INFO: stderr: ""
May 29 23:38:29.146: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:38:29.146: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-4890" for this suite.
May 29 23:39:31.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:39:32.900: INFO: namespace kubectl-4890 deletion completed in 1m3.711662309s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Proxy server[0m 
  [1mshould support proxy with --port 0  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:39:32.901: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should support proxy with --port 0  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: starting the proxy server
May 29 23:39:33.071: INFO: Asynchronously running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config proxy -p 0 --disable-filter'
[1mSTEP[0m: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:39:33.344: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "kubectl-6970" for this suite.
May 29 23:39:39.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:39:41.107: INFO: namespace kubectl-6970 deletion completed in 7.719313584s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:39:41.107: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:39:41.108: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:39:41.110: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: updating the pod
May 29 23:39:50.108: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f32d9542-9e2e-4f58-ae16-a5792d5e038d"
May 29 23:39:50.108: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f32d9542-9e2e-4f58-ae16-a5792d5e038d" in namespace "pods-2863" to be "terminated due to deadline exceeded"
May 29 23:39:50.150: INFO: Pod "pod-update-activedeadlineseconds-f32d9542-9e2e-4f58-ae16-a5792d5e038d": Phase="Running", Reason="", readiness=true. Elapsed: 41.577183ms
May 29 23:39:52.192: INFO: Pod "pod-update-activedeadlineseconds-f32d9542-9e2e-4f58-ae16-a5792d5e038d": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.083785265s
May 29 23:39:52.192: INFO: Pod "pod-update-activedeadlineseconds-f32d9542-9e2e-4f58-ae16-a5792d5e038d" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:39:52.192: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-2863" for this suite.
May 29 23:39:58.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:39:59.959: INFO: namespace pods-2863 deletion completed in 7.724867062s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-bindmounted][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:39:59.960: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:39:59.961: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-bindmounted]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:39:59.962: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 29 23:40:00.216: INFO: Waiting up to 5m0s for pod "downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218" in namespace "projected-5060" to be "success or failure"
May 29 23:40:00.258: INFO: Pod "downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218": Phase="Pending", Reason="", readiness=false. Elapsed: 41.644946ms
May 29 23:40:02.300: INFO: Pod "downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083564584s
May 29 23:40:04.342: INFO: Pod "downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125690869s
May 29 23:40:06.384: INFO: Pod "downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168152199s
May 29 23:40:08.426: INFO: Pod "downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.209759893s
[1mSTEP[0m: Saw pod success
May 29 23:40:08.426: INFO: Pod "downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218" satisfied condition "success or failure"
May 29 23:40:08.467: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 29 23:40:09.128: INFO: Waiting for pod downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218 to disappear
May 29 23:40:09.170: INFO: Pod downwardapi-volume-166dcb3d-a60a-4fe2-84f9-40d919554218 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:40:09.170: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-5060" for this suite.
May 29 23:40:15.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:40:17.010: INFO: namespace projected-5060 deletion completed in 7.795634466s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Garbage collector[0m 
  [1mshould not be blocked by dependency circle [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:40:17.010: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename gc
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 23:40:17.395: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4657c253-2721-440d-b72f-b1b5ba3dd998", Controller:(*bool)(0xc003763286), BlockOwnerDeletion:(*bool)(0xc003763287)}}
May 29 23:40:17.441: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"79e3dd32-2d11-4aaa-93cc-11d778663497", Controller:(*bool)(0xc003763456), BlockOwnerDeletion:(*bool)(0xc003763457)}}
May 29 23:40:17.486: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"df629388-495d-4232-8515-d9e7c2779d02", Controller:(*bool)(0xc003a9cec6), BlockOwnerDeletion:(*bool)(0xc003a9cec7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:40:22.576: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "gc-7281" for this suite.
May 29 23:40:28.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:40:30.345: INFO: namespace gc-7281 deletion completed in 7.72566132s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:40:30.345: INFO: Driver gluster doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:40:30.347: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver gluster doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mRecreateDeployment should delete old pods and create new ones [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:40:30.348: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 29 23:40:30.521: INFO: Creating deployment "test-recreate-deployment"
May 29 23:40:30.568: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 29 23:40:30.676: INFO: Waiting deployment "test-recreate-deployment" to complete
May 29 23:40:30.720: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-78b595d858\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 23:40:32.763: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-78b595d858\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 23:40:34.762: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-78b595d858\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 23:40:36.762: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694795230, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-78b595d858\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 29 23:40:38.762: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 29 23:40:38.849: INFO: Updating deployment test-recreate-deployment
May 29 23:40:38.849: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:60
May 29 23:40:39.023: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7127,SelfLink:/apis/apps/v1/namespaces/deployment-7127/deployments/test-recreate-deployment,UID:13b11a71-2481-40dd-97b0-5811a639dadd,ResourceVersion:71138,Generation:2,CreationTimestamp:2019-05-29 23:40:30 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-29 23:40:38 -0700 PDT 2019-05-29 23:40:38 -0700 PDT MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-29 23:40:38 -0700 PDT 2019-05-29 23:40:30 -0700 PDT ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5ccf74d6d5" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 29 23:40:39.065: INFO: New ReplicaSet "test-recreate-deployment-5ccf74d6d5" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5ccf74d6d5,GenerateName:,Namespace:deployment-7127,SelfLink:/apis/apps/v1/namespaces/deployment-7127/replicasets/test-recreate-deployment-5ccf74d6d5,UID:d6ab6e4c-3a76-4109-8e26-dc19951ccb09,ResourceVersion:71134,Generation:1,CreationTimestamp:2019-05-29 23:40:38 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5ccf74d6d5,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 13b11a71-2481-40dd-97b0-5811a639dadd 0xc0028ffd27 0xc0028ffd28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5ccf74d6d5,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5ccf74d6d5,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 23:40:39.065: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 29 23:40:39.065: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-78b595d858,GenerateName:,Namespace:deployment-7127,SelfLink:/apis/apps/v1/namespaces/deployment-7127/replicasets/test-recreate-deployment-78b595d858,UID:4fe8d1d4-5855-47d1-b5e8-9c6a7cf9837d,ResourceVersion:71128,Generation:2,CreationTimestamp:2019-05-29 23:40:30 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 78b595d858,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 13b11a71-2481-40dd-97b0-5811a639dadd 0xc0028ffe07 0xc0028ffe08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 78b595d858,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 78b595d858,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 29 23:40:39.107: INFO: Pod "test-recreate-deployment-5ccf74d6d5-rtfw6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5ccf74d6d5-rtfw6,GenerateName:test-recreate-deployment-5ccf74d6d5-,Namespace:deployment-7127,SelfLink:/api/v1/namespaces/deployment-7127/pods/test-recreate-deployment-5ccf74d6d5-rtfw6,UID:df6936da-1362-4dad-976a-9e30475b9cf9,ResourceVersion:71137,Generation:0,CreationTimestamp:2019-05-29 23:40:38 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5ccf74d6d5,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5ccf74d6d5 d6ab6e4c-3a76-4109-8e26-dc19951ccb09 0xc003992807 0xc003992808}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bgf97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bgf97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx e2eteam/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bgf97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003992870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003992890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:40:38 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:40:38 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:40:38 -0700 PDT ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 23:40:38 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:,StartTime:2019-05-29 23:40:38 -0700 PDT,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 e2eteam/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:40:39.107: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "deployment-7127" for this suite.
May 29 23:40:45.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:40:46.914: INFO: namespace deployment-7127 deletion completed in 7.763959727s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: blockfs][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 29 23:40:46.914: INFO: Driver local doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:40:46.916: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: blockfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver local doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Guestbook application[0m 
  [1mshould create and stop a working application  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:40:46.916: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[It] should create and stop a working application  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating all guestbook components
May 29 23:40:47.117: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 29 23:40:47.117: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-1179'
May 29 23:40:47.511: INFO: stderr: ""
May 29 23:40:47.511: INFO: stdout: "service/redis-slave created\n"
May 29 23:40:47.511: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 29 23:40:47.511: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-1179'
May 29 23:40:47.904: INFO: stderr: ""
May 29 23:40:47.904: INFO: stdout: "service/redis-master created\n"
May 29 23:40:47.904: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 29 23:40:47.904: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-1179'
May 29 23:40:48.291: INFO: stderr: ""
May 29 23:40:48.291: INFO: stdout: "service/frontend created\n"
May 29 23:40:48.291: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: e2eteam/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 29 23:40:48.291: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-1179'
May 29 23:40:48.655: INFO: stderr: ""
May 29 23:40:48.655: INFO: stdout: "deployment.apps/frontend created\n"
May 29 23:40:48.655: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: e2eteam/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 29 23:40:48.655: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-1179'
May 29 23:40:49.029: INFO: stderr: ""
May 29 23:40:49.029: INFO: stdout: "deployment.apps/redis-master created\n"
May 29 23:40:49.030: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: e2eteam/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 29 23:40:49.030: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config create -f - --namespace=kubectl-1179'
May 29 23:40:49.431: INFO: stderr: ""
May 29 23:40:49.431: INFO: stdout: "deployment.apps/redis-slave created\n"
[1mSTEP[0m: validating guestbook app
May 29 23:40:49.431: INFO: Waiting for all frontend pods to be Running.
May 29 23:45:44.500: INFO: Waiting for frontend to serve content.
May 29 23:45:48.076: INFO: Trying to add a new entry to the guestbook.
May 29 23:45:48.656: INFO: Verifying that added entry can be retrieved.
[1mSTEP[0m: using delete to clean up resources
May 29 23:45:48.714: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-1179'
May 29 23:45:49.014: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 23:45:49.014: INFO: stdout: "service \"redis-slave\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 29 23:45:49.014: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-1179'
May 29 23:45:49.324: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 23:45:49.324: INFO: stdout: "service \"redis-master\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 29 23:45:49.324: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-1179'
May 29 23:45:49.630: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 23:45:49.630: INFO: stdout: "service \"frontend\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 29 23:45:49.631: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-1179'
May 29 23:45:49.965: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 23:45:49.965: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 29 23:45:49.966: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-1179'
May 29 23:45:50.266: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 23:45:50.267: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
[1mSTEP[0m: using delete to clean up resources
May 29 23:45:50.267: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-1179'
May 29 23:45:50.574: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 29 23:45:50.574: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 29 23:45:50.574: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 29 23:45:50.617: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-29 23:44:50 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-29 23:44:53 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "kubectl-1179" for this suite.
May 29 23:55:50.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 29 23:55:52.428: INFO: Couldn't delete ns: "kubectl-1179": namespace kubectl-1179 was not deleted with limit: timed out waiting for the condition, namespace is empty but is not yet removed (&errors.errorString{s:"namespace kubectl-1179 was not deleted with limit: timed out waiting for the condition, namespace is empty but is not yet removed"})

[91m[1m• Failure in Spec Teardown (AfterEach) [905.513 seconds][0m
[sig-cli] Kubectl client
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23[0m
  [91m[1m[k8s.io] Guestbook application [AfterEach][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
    should create and stop a working application  [Conformance]
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

    [91mMay 29 23:55:52.428: Couldn't delete ns: "kubectl-1179": namespace kubectl-1179 was not deleted with limit: timed out waiting for the condition, namespace is empty but is not yet removed (&errors.errorString{s:"namespace kubectl-1179 was not deleted with limit: timed out waiting for the condition, namespace is empty but is not yet removed"})[0m

    /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] [sig-windows] Networking[0m [90mGranular Checks: Pods[0m 
  [1mshould function for node-pod communication: http[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:74[0m
[BeforeEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 29 23:55:52.430: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pod-network-test
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:32
[It] should function for node-pod communication: http
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:74
[1mSTEP[0m: Performing setup for networking test in namespace pod-network-test-8092
[1mSTEP[0m: creating a selector
[1mSTEP[0m: Creating the service pods in kubernetes
May 29 23:55:52.602: INFO: Waiting up to 10m0s for all (but 3) nodes to be schedulable
May 29 23:55:52.644: INFO: Unschedulable nodes:
May 29 23:55:52.644: INFO: -> e2e-test-peterhornyack-minion-group-5wdh Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 23:55:52.645: INFO: -> e2e-test-peterhornyack-minion-group-fzx6 Ready=true Network=true Taints=[{node-under-test false NoSchedule <nil>}]
May 29 23:55:52.645: INFO: ================================
[1mSTEP[0m: Creating test pods
May 30 00:01:49.511: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.64.2.76:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8092 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 00:01:49.511: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 30 00:01:50.151: INFO: Found all expected endpoints: [netserver-0]
May 30 00:01:50.193: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.64.1.124:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8092 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 00:01:50.193: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 30 00:01:50.610: INFO: Found all expected endpoints: [netserver-1]
May 30 00:01:50.652: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.64.3.125:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8092 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 30 00:01:50.652: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
May 30 00:01:51.059: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] [sig-windows] Networking
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:01:51.059: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 00:01:51.103: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 00:00:52 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 00:00:53 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "pod-network-test-8092" for this suite.
May 30 00:02:13.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:02:14.826: INFO: namespace pod-network-test-8092 deletion completed in 23.722258438s

[32m• [SLOW TEST:382.396 seconds][0m
[sig-network] [sig-windows] Networking
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:29[0m
  Granular Checks: Pods
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:37[0m
    should function for node-pod communication: http
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/windows/networking.go:74[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's memory request [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:02:14.826: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 30 00:02:15.094: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a" in namespace "projected-2147" to be "success or failure"
May 30 00:02:15.142: INFO: Pod "downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a": Phase="Pending", Reason="", readiness=false. Elapsed: 47.781047ms
May 30 00:02:17.184: INFO: Pod "downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089886178s
May 30 00:02:19.226: INFO: Pod "downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.131818958s
May 30 00:02:21.268: INFO: Pod "downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.17377645s
May 30 00:02:23.310: INFO: Pod "downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.215428174s
[1mSTEP[0m: Saw pod success
May 30 00:02:23.310: INFO: Pod "downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a" satisfied condition "success or failure"
May 30 00:02:23.351: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a container client-container: <nil>
[1mSTEP[0m: delete the pod
May 30 00:02:23.452: INFO: Waiting for pod downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a to disappear
May 30 00:02:23.493: INFO: Pod downwardapi-volume-2b1b9d4c-f94d-4428-bd02-4286b7e2695a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:02:23.493: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-2147" for this suite.
May 30 00:02:29.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:02:31.464: INFO: namespace projected-2147 deletion completed in 7.927517448s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:02:31.464: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating secret with name projected-secret-test-13864335-faa0-4222-8010-cdca6a0da112
[1mSTEP[0m: Creating a pod to test consume secrets
May 30 00:02:31.735: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3" in namespace "projected-1213" to be "success or failure"
May 30 00:02:31.776: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 41.579679ms
May 30 00:02:33.819: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083851053s
May 30 00:02:35.862: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126832895s
May 30 00:02:37.903: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.16868728s
May 30 00:02:39.945: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210688811s
May 30 00:02:41.987: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.252644397s
May 30 00:02:44.029: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.294775868s
May 30 00:02:46.071: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.33675232s
May 30 00:02:48.114: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.379089874s
May 30 00:02:50.156: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 18.420827506s
May 30 00:02:52.199: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.464017171s
May 30 00:02:54.241: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 22.505918333s
May 30 00:02:56.282: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 24.547687638s
May 30 00:02:58.324: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 26.589568174s
May 30 00:03:00.366: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 28.63154643s
May 30 00:03:02.408: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 30.673680478s
May 30 00:03:04.451: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 32.716528017s
May 30 00:03:06.493: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 34.758594039s
May 30 00:03:08.536: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 36.801033406s
May 30 00:03:10.578: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 38.843038554s
May 30 00:03:12.621: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 40.88674101s
May 30 00:03:14.664: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 42.92919223s
May 30 00:03:16.706: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 44.971386085s
May 30 00:03:18.748: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 47.013374281s
May 30 00:03:20.790: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 49.05527132s
May 30 00:03:22.832: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 51.097288594s
May 30 00:03:24.874: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 53.138968849s
May 30 00:03:26.916: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 55.181728275s
May 30 00:03:28.959: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 57.223882522s
May 30 00:03:31.001: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 59.266042419s
May 30 00:03:33.043: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.308170556s
May 30 00:03:35.084: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.349426844s
May 30 00:03:37.126: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.391536839s
May 30 00:03:39.168: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.433566551s
May 30 00:03:41.212: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.477232065s
May 30 00:03:43.254: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.519150958s
May 30 00:03:45.296: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.561327077s
May 30 00:03:47.338: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.60310064s
May 30 00:03:49.380: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.645172165s
May 30 00:03:51.422: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.687493178s
May 30 00:03:53.464: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.729136251s
May 30 00:03:55.506: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.771356905s
May 30 00:03:57.548: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.813399615s
May 30 00:03:59.590: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.855558793s
May 30 00:04:01.633: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.898242331s
May 30 00:04:03.676: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.941231909s
May 30 00:04:05.718: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.983137144s
May 30 00:04:07.760: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.024923441s
May 30 00:04:09.802: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.067071629s
May 30 00:04:11.844: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.108849948s
May 30 00:04:13.886: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.151458609s
May 30 00:04:15.928: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.193700094s
May 30 00:04:17.970: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.235437609s
May 30 00:04:20.012: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.277614919s
May 30 00:04:22.054: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.31948362s
May 30 00:04:24.096: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.361552053s
May 30 00:04:26.144: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.408821598s
May 30 00:04:28.186: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.4509838s
May 30 00:04:30.228: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.492974998s
May 30 00:04:32.270: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.535182359s
May 30 00:04:34.312: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.577145774s
May 30 00:04:36.354: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.618843683s
May 30 00:04:38.396: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.661104141s
May 30 00:04:40.438: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.703094222s
May 30 00:04:42.480: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.745121339s
May 30 00:04:44.521: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.786818103s
May 30 00:04:46.563: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.828793885s
May 30 00:04:48.606: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.870867483s
May 30 00:04:50.648: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.913346749s
May 30 00:04:52.690: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.955477182s
May 30 00:04:54.734: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.999163388s
May 30 00:04:56.776: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.041293583s
May 30 00:04:58.818: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.083236676s
May 30 00:05:00.860: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.125230199s
May 30 00:05:02.907: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.172090084s
May 30 00:05:04.949: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.21416584s
May 30 00:05:06.991: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.256170837s
May 30 00:05:09.033: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.298186328s
May 30 00:05:11.076: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.341328579s
May 30 00:05:13.118: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.383817087s
May 30 00:05:15.161: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.425996937s
May 30 00:05:17.202: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.467719694s
May 30 00:05:19.244: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.509397268s
May 30 00:05:21.289: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.554015114s
May 30 00:05:23.340: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.605307246s
May 30 00:05:25.386: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.650972381s
May 30 00:05:27.428: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.692883225s
May 30 00:05:29.469: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.73468456s
May 30 00:05:31.511: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.776460684s
May 30 00:05:33.553: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.818439892s
May 30 00:05:35.595: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.860381208s
May 30 00:05:37.637: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.902332683s
May 30 00:05:39.679: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.944444989s
May 30 00:05:41.722: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.986952357s
May 30 00:05:43.764: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.028990233s
May 30 00:05:45.806: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.071263483s
May 30 00:05:47.848: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.113465853s
May 30 00:05:49.890: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.155742377s
May 30 00:05:51.933: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.198008254s
May 30 00:05:53.981: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.246633763s
May 30 00:05:56.024: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.288849945s
May 30 00:05:58.066: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.330854383s
May 30 00:06:00.107: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.372751091s
May 30 00:06:02.149: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.414597715s
May 30 00:06:04.194: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.458963759s
May 30 00:06:06.236: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.501460973s
May 30 00:06:08.278: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.543442766s
May 30 00:06:10.320: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.584928708s
May 30 00:06:12.362: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.627063581s
May 30 00:06:14.404: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.669345404s
May 30 00:06:16.453: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.718410673s
May 30 00:06:18.495: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.76026353s
May 30 00:06:20.537: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.802066517s
May 30 00:06:22.579: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.844149647s
May 30 00:06:24.621: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.886419918s
May 30 00:06:26.663: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.92876006s
May 30 00:06:28.705: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.970683301s
May 30 00:06:30.747: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 3m59.012551084s
May 30 00:06:32.789: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m1.054652328s
May 30 00:06:34.832: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m3.096909902s
May 30 00:06:36.874: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m5.13901063s
May 30 00:06:38.916: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m7.18108133s
May 30 00:06:40.958: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m9.223342509s
May 30 00:06:43.001: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m11.266382816s
May 30 00:06:45.043: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m13.308581799s
May 30 00:06:47.085: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m15.350601557s
May 30 00:06:49.128: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m17.392840374s
May 30 00:06:51.170: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m19.435682128s
May 30 00:06:53.212: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m21.477348398s
May 30 00:06:55.254: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m23.519099558s
May 30 00:06:57.296: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m25.561333652s
May 30 00:06:59.338: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m27.603262203s
May 30 00:07:01.380: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m29.645549673s
May 30 00:07:03.422: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m31.687762915s
May 30 00:07:05.465: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m33.730134714s
May 30 00:07:07.507: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m35.772252378s
May 30 00:07:09.549: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m37.81414835s
May 30 00:07:11.591: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m39.85615237s
May 30 00:07:13.634: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m41.899752892s
May 30 00:07:15.677: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m43.942154045s
May 30 00:07:17.718: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m45.98379725s
May 30 00:07:19.761: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.025955886s
May 30 00:07:21.802: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.067606732s
May 30 00:07:23.845: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.109886892s
May 30 00:07:25.887: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.15192682s
May 30 00:07:27.929: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.193982219s
May 30 00:07:29.971: INFO: Pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.235927799s
May 30 00:07:32.061: INFO: Failed to get logs from node "e2e-test-peterhornyack-windows-node-group-jpxd" pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3" container "secret-volume-test": the server rejected our request for an unknown reason (get pods pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3)
[1mSTEP[0m: delete the pod
May 30 00:07:32.110: INFO: Waiting for pod pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3 to disappear
May 30 00:07:32.152: INFO: Pod pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3 still exists
May 30 00:07:34.153: INFO: Waiting for pod pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3 to disappear
May 30 00:07:34.195: INFO: Pod pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3 still exists
May 30 00:07:36.153: INFO: Waiting for pod pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3 to disappear
May 30 00:07:36.194: INFO: Pod pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3 no longer exists
May 30 00:07:36.195: INFO: Unexpected error occurred: expected pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3" success: Gave up after waiting 5m0s for pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3" to be "success or failure"
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "projected-1213".
[1mSTEP[0m: Found 5 events.
May 30 00:07:36.237: INFO: At 2019-05-30 00:02:31 -0700 PDT - event for pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3: {default-scheduler } Scheduled: Successfully assigned projected-1213/pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3 to e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:07:36.237: INFO: At 2019-05-30 00:02:34 -0700 PDT - event for pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 30 00:07:36.237: INFO: At 2019-05-30 00:02:34 -0700 PDT - event for pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container secret-volume-test
May 30 00:07:36.237: INFO: At 2019-05-30 00:02:36 -0700 PDT - event for pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container secret-volume-test
May 30 00:07:36.237: INFO: At 2019-05-30 00:05:53 -0700 PDT - event for pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod projected-1213/pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3
May 30 00:07:36.326: INFO: POD                                                    NODE                                      PHASE    GRACE  CONDITIONS
May 30 00:07:36.326: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:07:36.326: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 30 00:07:36.326: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:07:36.326: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:07:36.326: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:07:36.326: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:07:36.326: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:07:36.326: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 30 00:07:36.326: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 30 00:07:36.326: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 30 00:07:36.326: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 30 00:07:36.326: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:07:36.326: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 00:07:36.326: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 00:07:36.326: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:07:36.326: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 30 00:07:36.326: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 30 00:07:36.326: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:07:36.326: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:07:36.326: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:07:36.326: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:07:36.326: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:07:36.326: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:07:36.326: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 30 00:07:36.327: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 30 00:07:36.327: INFO: 
May 30 00:07:36.369: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 30 00:07:36.411: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:75128,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:07:18 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:07:18 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:07:18 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:07:18 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:07:36.411: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 30 00:07:36.453: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 30 00:07:36.500: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:36.500: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:07:36.500: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:07:36.500: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.500: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.500: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.500: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.500: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.500: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.500: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:36.500: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:07:36.500: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:07:36.500: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.500: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.661: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 30 00:07:36.661: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:07:36.702: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:75130,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{ReadonlyFilesystem False 2019-05-30 00:06:40 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-30 00:06:40 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-30 00:06:40 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 00:06:40 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-30 00:06:40 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 00:06:40 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-30 00:06:40 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:07:18 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:07:18 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:07:18 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:07:18 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:07:36.703: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:07:36.744: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:07:36.795: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:07:36.795: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 30 00:07:36.795: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:36.795: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:07:36.795: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:07:36.795: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 30 00:07:36.795: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:07:36.795: INFO: 	Container coredns ready: true, restart count 0
May 30 00:07:36.795: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:07:36.795: INFO: 	Container autoscaler ready: true, restart count 0
May 30 00:07:36.795: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:07:36.795: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 00:07:36.795: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:36.795: INFO: 	Container event-exporter ready: true, restart count 0
May 30 00:07:36.795: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:07:36.795: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:07:36.795: INFO: 	Container default-http-backend ready: true, restart count 0
May 30 00:07:36.795: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:36.795: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:07:36.795: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:07:36.974: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:07:36.974: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:07:37.016: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:75157,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentContainerdRestart False 2019-05-30 00:07:30 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 00:07:30 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-30 00:07:30 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-30 00:07:30 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 00:07:30 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-30 00:07:30 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 00:07:30 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:06:50 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:06:50 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:06:50 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:06:50 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:07:37.016: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:07:37.057: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:07:37.107: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:37.107: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:07:37.107: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:07:37.107: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 30 00:07:37.107: INFO: 	Container coredns ready: true, restart count 0
May 30 00:07:37.107: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:37.107: INFO: 	Container metrics-server ready: true, restart count 0
May 30 00:07:37.107: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 30 00:07:37.107: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:37.107: INFO: 	Container heapster ready: true, restart count 0
May 30 00:07:37.107: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 00:07:37.107: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 30 00:07:37.107: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 30 00:07:37.107: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:07:37.107: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:07:37.271: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:07:37.271: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:07:37.313: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:75080,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:06:57 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:06:57 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:06:57 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:06:57 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 00:07:37.313: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:07:37.354: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:07:37.564: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:07:37.564: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:07:37.609: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:75104,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:07:07 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:07:07 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:07:07 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:07:07 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 00:07:37.609: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:07:37.650: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:07:37.856: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:07:37.856: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:07:37.898: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:75070,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:06:53 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:06:53 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:06:53 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:06:53 -0700 PDT 2019-05-30 00:05:52 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 00:07:37.898: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:07:37.940: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:07:38.170: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:07:38.171: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-1213" for this suite.
May 30 00:07:44.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:07:45.935: INFO: namespace projected-1213 deletion completed in 7.721236749s

[91m[1m• Failure [314.471 seconds][0m
[sig-storage] Projected secret
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33[0m
  [91m[1mshould be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mUnexpected error:
      <*errors.errorString | 0xc001d423b0>: {
          s: "expected pod \"pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3\" success: Gave up after waiting 5m0s for pod \"pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3\" to be \"success or failure\"",
      }
      expected pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3" success: Gave up after waiting 5m0s for pod "pod-projected-secrets-26a8415d-cf38-4e94-8832-f16109066ac3" to be "success or failure"
  occurred[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:2285
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: emptydir][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:07:45.935: INFO: Driver emptydir doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:07:45.937: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: emptydir]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver emptydir doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:07:45.938: INFO: Driver hostPath doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:07:45.939: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver hostPath doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould contain environment variables for services [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:07:45.940: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 30 00:07:54.388: INFO: Waiting up to 5m0s for pod "client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793" in namespace "pods-3608" to be "success or failure"
May 30 00:07:54.430: INFO: Pod "client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793": Phase="Pending", Reason="", readiness=false. Elapsed: 41.883253ms
May 30 00:07:56.472: INFO: Pod "client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083808663s
May 30 00:07:58.514: INFO: Pod "client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125931256s
May 30 00:08:00.558: INFO: Pod "client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.170037785s
[1mSTEP[0m: Saw pod success
May 30 00:08:00.558: INFO: Pod "client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793" satisfied condition "success or failure"
May 30 00:08:00.600: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-1vjk pod client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793 container env3cont: <nil>
[1mSTEP[0m: delete the pod
May 30 00:08:00.704: INFO: Waiting for pod client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793 to disappear
May 30 00:08:00.750: INFO: Pod client-envvars-fe8bfb58-16e1-4006-b79f-df20a7e53793 no longer exists
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:08:00.750: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-3608" for this suite.
May 30 00:08:52.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:08:54.519: INFO: namespace pods-3608 deletion completed in 53.726365687s
[32m•[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-apps] Deployment[0m 
  [1mdeployment should delete old replica sets [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:08:54.519: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename deployment
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
[It] deployment should delete old replica sets [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
May 30 00:08:54.817: INFO: Pod name cleanup-pod: Found 1 pods out of 1
[1mSTEP[0m: ensuring each pod is running
May 30 00:09:02.902: INFO: Creating deployment test-cleanup-deployment
[1mSTEP[0m: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:60
May 30 00:09:11.256: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-4028,SelfLink:/apis/apps/v1/namespaces/deployment-4028/deployments/test-cleanup-deployment,UID:4c1fc2ff-2db3-4353-83f6-095f1c695f17,ResourceVersion:75462,Generation:1,CreationTimestamp:2019-05-30 00:09:03 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-30 00:09:03 -0700 PDT 2019-05-30 00:09:03 -0700 PDT MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-30 00:09:09 -0700 PDT 2019-05-30 00:09:03 -0700 PDT NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-5bc9d9c7bd" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 30 00:09:11.298: INFO: New ReplicaSet "test-cleanup-deployment-5bc9d9c7bd" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-5bc9d9c7bd,GenerateName:,Namespace:deployment-4028,SelfLink:/apis/apps/v1/namespaces/deployment-4028/replicasets/test-cleanup-deployment-5bc9d9c7bd,UID:c590f8c6-7c98-4cb6-9225-918ed1f6cd60,ResourceVersion:75455,Generation:1,CreationTimestamp:2019-05-30 00:09:03 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 5bc9d9c7bd,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 4c1fc2ff-2db3-4353-83f6-095f1c695f17 0xc0036d0537 0xc0036d0538}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 5bc9d9c7bd,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 5bc9d9c7bd,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 30 00:09:11.340: INFO: Pod "test-cleanup-deployment-5bc9d9c7bd-qtkzn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-5bc9d9c7bd-qtkzn,GenerateName:test-cleanup-deployment-5bc9d9c7bd-,Namespace:deployment-4028,SelfLink:/api/v1/namespaces/deployment-4028/pods/test-cleanup-deployment-5bc9d9c7bd-qtkzn,UID:d6fbd6c6-31b8-4610-892c-5000d76540fe,ResourceVersion:75454,Generation:0,CreationTimestamp:2019-05-30 00:09:03 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 5bc9d9c7bd,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-5bc9d9c7bd c590f8c6-7c98-4cb6-9225-918ed1f6cd60 0xc000cf2ac7 0xc000cf2ac8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-zl5mk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zl5mk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis e2eteam/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zl5mk true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-1vjk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000cf2b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000cf2b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:09:03 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:09:09 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:09:09 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:09:03 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.5,PodIP:10.64.2.80,StartTime:2019-05-30 00:09:03 -0700 PDT,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-30 00:09:07 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/redis:1.0 docker-pullable://e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 docker://fcfa2517391174ad44ef2259c9fefa04603b8a9c17dbaaf164bf64eb9eec4304}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:09:11.340: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 00:09:11.383: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 00:08:53 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 00:08:53 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "deployment-4028" for this suite.
May 30 00:09:17.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:09:19.128: INFO: namespace deployment-4028 deletion completed in 7.745102411s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Pods[0m 
  [1mshould be submitted and removed [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:09:19.128: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename pods
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
[1mSTEP[0m: setting up watch
[1mSTEP[0m: submitting the pod to kubernetes
May 30 00:09:19.417: INFO: observed the pod list
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: verifying pod creation was observed
[1mSTEP[0m: deleting the pod gracefully
[1mSTEP[0m: verifying the kubelet observed the termination notice
[1mSTEP[0m: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:10:29.463: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "pods-3819" for this suite.
May 30 00:10:35.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:10:37.239: INFO: namespace pods-3819 deletion completed in 7.732603391s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gluster][0m [0m[Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:10:37.239: INFO: Driver gluster doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:10:37.241: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gluster]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Pre-provisioned PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver gluster doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:99
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:10:37.242: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename provisioning
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should access volume from different nodes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172
May 30 00:10:37.442: INFO: In creating storage class object and pvc object for driver - sc: &StorageClass{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:provisioning-6042-gcepd-sczg4sf,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Provisioner:kubernetes.io/gce-pd,Parameters:map[string]string{fsType: ntfs,},ReclaimPolicy:nil,MountOptions:[],AllowVolumeExpansion:nil,VolumeBindingMode:*WaitForFirstConsumer,AllowedTopologies:[],}, pvc: &PersistentVolumeClaim{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:pvc-,Namespace:provisioning-6042,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PersistentVolumeClaimSpec{AccessModes:[ReadWriteOnce],Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{storage: {{5368709120 0} {<nil>} 5Gi BinarySI},},},VolumeName:,Selector:nil,StorageClassName:*provisioning-6042-gcepd-sczg4sf,VolumeMode:nil,DataSource:nil,},Status:PersistentVolumeClaimStatus{Phase:,AccessModes:[],Capacity:ResourceList{},Conditions:[],},}
[1mSTEP[0m: creating a StorageClass provisioning-6042-gcepd-sczg4sf
[1mSTEP[0m: creating a claim
[1mSTEP[0m: checking the created volume is writable on node {Name: Selector:map[] Affinity:nil}
May 30 00:10:37.669: INFO: Waiting up to 15m0s for pod "pvc-writer-node1-vqnkq" in namespace "provisioning-6042" to be "success or failure"
May 30 00:10:37.712: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 42.849182ms
May 30 00:10:39.754: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084603175s
May 30 00:10:41.796: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126400803s
May 30 00:10:43.839: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.169767774s
May 30 00:10:45.881: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 8.211481783s
May 30 00:10:47.923: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 10.253618253s
May 30 00:10:49.965: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 12.295412967s
May 30 00:10:52.007: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 14.337099337s
May 30 00:10:54.049: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 16.379290911s
May 30 00:10:56.092: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 18.422860485s
May 30 00:10:58.135: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 20.465116103s
May 30 00:11:00.178: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 22.508657123s
May 30 00:11:02.220: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 24.550841477s
May 30 00:11:04.262: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 26.592746913s
May 30 00:11:06.304: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 28.634786883s
May 30 00:11:08.346: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 30.676724989s
May 30 00:11:10.389: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 32.719846954s
May 30 00:11:12.438: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 34.768320177s
May 30 00:11:14.480: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 36.81056284s
May 30 00:11:16.522: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 38.852331163s
May 30 00:11:18.564: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 40.894277825s
May 30 00:11:20.606: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 42.936175085s
May 30 00:11:22.648: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 44.978297426s
May 30 00:11:24.689: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 47.020002413s
May 30 00:11:26.731: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 49.061894722s
May 30 00:11:28.773: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 51.103795294s
May 30 00:11:30.815: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 53.145364815s
May 30 00:11:32.857: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 55.187191644s
May 30 00:11:34.899: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 57.229131731s
May 30 00:11:36.940: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 59.270596309s
May 30 00:11:38.982: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.312760498s
May 30 00:11:41.024: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.354595884s
May 30 00:11:43.066: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.396642149s
May 30 00:11:45.108: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.438805575s
May 30 00:11:47.150: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.48071448s
May 30 00:11:49.193: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.524051158s
May 30 00:11:51.236: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.566160954s
May 30 00:11:53.278: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.608137769s
May 30 00:11:55.320: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.650693041s
May 30 00:11:57.363: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.693567796s
May 30 00:11:59.405: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.735637693s
May 30 00:12:01.447: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.777634601s
May 30 00:12:03.490: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.820586389s
May 30 00:12:05.532: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.862445526s
May 30 00:12:07.574: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.904366736s
May 30 00:12:09.615: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.945949791s
May 30 00:12:11.657: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.98794842s
May 30 00:12:13.700: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.030670471s
May 30 00:12:15.743: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.073248409s
May 30 00:12:17.786: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.11617961s
May 30 00:12:19.827: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.157980783s
May 30 00:12:21.869: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.200077051s
May 30 00:12:23.911: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.242038673s
May 30 00:12:25.953: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.283484286s
May 30 00:12:27.995: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.325321029s
May 30 00:12:30.041: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.371756017s
May 30 00:12:32.083: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.413582635s
May 30 00:12:34.125: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.455518663s
May 30 00:12:36.167: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.497284265s
May 30 00:12:38.208: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.538826374s
May 30 00:12:40.250: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.580822505s
May 30 00:12:42.292: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.622791769s
May 30 00:12:44.334: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.664963575s
May 30 00:12:46.377: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.707328909s
May 30 00:12:48.419: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.749285962s
May 30 00:12:50.463: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.794091893s
May 30 00:12:52.505: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.835983552s
May 30 00:12:54.547: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.877919473s
May 30 00:12:56.589: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.920073215s
May 30 00:12:58.632: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.962278445s
May 30 00:13:00.674: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m23.004336111s
May 30 00:13:02.715: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.046059474s
May 30 00:13:04.757: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.087936913s
May 30 00:13:06.799: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.12991699s
May 30 00:13:08.841: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.171781376s
May 30 00:13:10.883: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.213687254s
May 30 00:13:12.925: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.255670261s
May 30 00:13:14.967: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.297897161s
May 30 00:13:17.012: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.342521265s
May 30 00:13:19.054: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.384240737s
May 30 00:13:21.096: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.426267699s
May 30 00:13:23.139: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.469467666s
May 30 00:13:25.181: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.511893505s
May 30 00:13:27.223: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.55381062s
May 30 00:13:29.265: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.595985093s
May 30 00:13:31.307: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.637992443s
May 30 00:13:33.351: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.681184047s
May 30 00:13:35.393: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.723154558s
May 30 00:13:37.435: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.765131682s
May 30 00:13:39.477: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.807533888s
May 30 00:13:41.519: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.849373493s
May 30 00:13:43.562: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.892672859s
May 30 00:13:45.604: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.934929816s
May 30 00:13:47.647: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.977562037s
May 30 00:13:49.690: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.020411978s
May 30 00:13:51.732: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.062140831s
May 30 00:13:53.774: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.104400748s
May 30 00:13:55.816: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.146601047s
May 30 00:13:57.858: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.189084558s
May 30 00:13:59.901: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.231356018s
May 30 00:14:01.943: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.273576137s
May 30 00:14:03.985: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.315721576s
May 30 00:14:06.028: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.358174203s
May 30 00:14:08.070: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.400258141s
May 30 00:14:10.112: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.442198388s
May 30 00:14:12.153: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.484051948s
May 30 00:14:14.196: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.526270879s
May 30 00:14:16.238: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.568248363s
May 30 00:14:18.280: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.610167579s
May 30 00:14:20.322: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.652195263s
May 30 00:14:22.364: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.694281563s
May 30 00:14:24.405: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.735858482s
May 30 00:14:26.447: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.777808069s
May 30 00:14:28.490: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.820163353s
May 30 00:14:30.532: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.862113084s
May 30 00:14:32.573: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.903994519s
May 30 00:14:34.615: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.946027936s
May 30 00:14:36.657: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.987921444s
May 30 00:14:38.704: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m1.034196735s
May 30 00:14:40.747: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m3.077743664s
May 30 00:14:42.789: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m5.119597313s
May 30 00:14:44.832: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m7.162594461s
May 30 00:14:46.874: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m9.204942964s
May 30 00:14:48.917: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m11.247239653s
May 30 00:14:50.958: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m13.288725375s
May 30 00:14:53.000: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m15.330445652s
May 30 00:14:55.042: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m17.3726005s
May 30 00:14:57.088: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m19.418706331s
May 30 00:14:59.130: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m21.460585306s
May 30 00:15:01.172: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m23.502404931s
May 30 00:15:03.215: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m25.545510131s
May 30 00:15:05.257: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m27.587744738s
May 30 00:15:07.299: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m29.629397653s
May 30 00:15:09.341: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m31.671167725s
May 30 00:15:11.384: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m33.714382554s
May 30 00:15:13.426: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m35.756356285s
May 30 00:15:15.468: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m37.798894542s
May 30 00:15:17.511: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m39.841204034s
May 30 00:15:19.552: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m41.883017891s
May 30 00:15:21.595: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m43.9254124s
May 30 00:15:23.637: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m45.968061072s
May 30 00:15:25.679: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.009689749s
May 30 00:15:27.721: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.0512014s
May 30 00:15:29.762: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.093060876s
May 30 00:15:31.804: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.134955624s
May 30 00:15:33.846: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.176461385s
May 30 00:15:35.888: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.218473247s
May 30 00:15:37.930: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.260158543s
May 30 00:15:39.972: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 5m2.30223606s
May 30 00:15:42.013: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 5m4.344013122s
May 30 00:15:44.056: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 5m6.386863722s
May 30 00:15:46.098: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 5m8.428711631s
May 30 00:15:48.145: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 5m10.475512426s
May 30 00:15:50.192: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Pending", Reason="", readiness=false. Elapsed: 5m12.522516627s
May 30 00:15:52.239: INFO: Pod "pvc-writer-node1-vqnkq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5m14.569871629s
[1mSTEP[0m: Saw pod success
May 30 00:15:52.239: INFO: Pod "pvc-writer-node1-vqnkq" satisfied condition "success or failure"
May 30 00:15:52.335: INFO: Pod pvc-writer-node1-vqnkq has the following logs: 
[1mSTEP[0m: Deleting pod pvc-writer-node1-vqnkq in namespace provisioning-6042
[1mSTEP[0m: checking the created volume is readable and retains data on another node {Name: Selector:map[] Affinity:&Affinity{NodeAffinity:&NodeAffinity{RequiredDuringSchedulingIgnoredDuringExecution:&NodeSelector{NodeSelectorTerms:[{[] [{metadata.name NotIn [e2e-test-peterhornyack-windows-node-group-jpxd]}]}],},PreferredDuringSchedulingIgnoredDuringExecution:[],},PodAffinity:nil,PodAntiAffinity:nil,}}
May 30 00:15:52.437: INFO: Waiting up to 15m0s for pod "pvc-reader-node2-wrhtn" in namespace "provisioning-6042" to be "success or failure"
May 30 00:15:52.478: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 40.857547ms
May 30 00:15:54.520: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082850466s
May 30 00:15:56.562: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125140404s
May 30 00:15:58.604: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167474406s
May 30 00:16:00.647: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.21008982s
May 30 00:16:02.689: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.251821005s
May 30 00:16:04.731: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.294555868s
May 30 00:16:06.773: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 14.336301763s
May 30 00:16:08.815: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 16.378185488s
May 30 00:16:10.856: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 18.419739037s
May 30 00:16:12.899: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 20.462335801s
May 30 00:16:14.941: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 22.504137887s
May 30 00:16:16.983: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 24.546160946s
May 30 00:16:19.025: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 26.588417688s
May 30 00:16:21.068: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 28.63082303s
May 30 00:16:23.109: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 30.672325475s
May 30 00:16:25.151: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 32.714435837s
May 30 00:16:27.195: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Pending", Reason="", readiness=false. Elapsed: 34.758479395s
May 30 00:16:29.240: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Running", Reason="", readiness=true. Elapsed: 36.802936232s
May 30 00:16:31.286: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Running", Reason="", readiness=true. Elapsed: 38.848761547s
May 30 00:16:33.328: INFO: Pod "pvc-reader-node2-wrhtn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 40.891052526s
[1mSTEP[0m: Saw pod success
May 30 00:16:33.328: INFO: Pod "pvc-reader-node2-wrhtn" satisfied condition "success or failure"
May 30 00:16:33.422: INFO: Pod pvc-reader-node2-wrhtn has the following logs: 
mnt\test\data:1:hello world



[1mSTEP[0m: Deleting pod pvc-reader-node2-wrhtn in namespace provisioning-6042
May 30 00:16:33.471: INFO: Waiting up to 5m0s for PersistentVolumeClaims [pvc-dkszk] to have phase Bound
May 30 00:16:33.513: INFO: PersistentVolumeClaim pvc-dkszk found and phase=Bound (41.477124ms)
[1mSTEP[0m: checking the claim
[1mSTEP[0m: checking the PV
[1mSTEP[0m: deleting claim "provisioning-6042"/"pvc-dkszk"
[1mSTEP[0m: deleting the claim's PV "pvc-2e3478de-4a02-408a-8ed6-e7e05702f3ba"
May 30 00:16:33.643: INFO: Waiting up to 20m0s for PersistentVolume pvc-2e3478de-4a02-408a-8ed6-e7e05702f3ba to get deleted
May 30 00:16:33.685: INFO: PersistentVolume pvc-2e3478de-4a02-408a-8ed6-e7e05702f3ba found and phase=Released (41.493973ms)
May 30 00:16:38.726: INFO: PersistentVolume pvc-2e3478de-4a02-408a-8ed6-e7e05702f3ba found and phase=Released (5.08304246s)
May 30 00:16:43.769: INFO: PersistentVolume pvc-2e3478de-4a02-408a-8ed6-e7e05702f3ba found and phase=Released (10.125504121s)
May 30 00:16:48.811: INFO: PersistentVolume pvc-2e3478de-4a02-408a-8ed6-e7e05702f3ba was removed
May 30 00:16:48.811: INFO: deleting claim "provisioning-6042"/"pvc-dkszk"
May 30 00:16:48.852: INFO: deleting storage class provisioning-6042-gcepd-sczg4sf
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:16:48.897: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "provisioning-6042" for this suite.
May 30 00:16:55.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:16:56.661: INFO: namespace provisioning-6042 deletion completed in 7.720769939s

[32m• [SLOW TEST:379.419 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gcepd]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      should access volume from different nodes
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: nfs][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:16:56.661: INFO: Driver nfs doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:16:56.662: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: nfs]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver nfs doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-node] Downward API[0m 
  [1mshould provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:16:56.663: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward api env vars
May 30 00:16:56.879: INFO: Waiting up to 5m0s for pod "downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf" in namespace "downward-api-756" to be "success or failure"
May 30 00:16:56.922: INFO: Pod "downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf": Phase="Pending", Reason="", readiness=false. Elapsed: 42.987045ms
May 30 00:16:58.967: INFO: Pod "downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087585706s
May 30 00:17:01.009: INFO: Pod "downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12988681s
May 30 00:17:03.051: INFO: Pod "downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.171787049s
May 30 00:17:05.094: INFO: Pod "downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.214158146s
[1mSTEP[0m: Saw pod success
May 30 00:17:05.094: INFO: Pod "downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf" satisfied condition "success or failure"
May 30 00:17:05.135: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-1vjk pod downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf container dapi-container: <nil>
[1mSTEP[0m: delete the pod
May 30 00:17:05.239: INFO: Waiting for pod downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf to disappear
May 30 00:17:05.284: INFO: Pod downward-api-27efaf0b-2f21-4bb1-8018-07bbe768b0bf no longer exists
[AfterEach] [sig-node] Downward API
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:17:05.284: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 00:17:05.326: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 00:16:54 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 00:16:58 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "downward-api-756" for this suite.
May 30 00:17:11.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:17:13.065: INFO: namespace downward-api-756 deletion completed in 7.738090433s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-cli] Kubectl client[0m [90m[k8s.io] Kubectl run job[0m 
  [1mshould create a job from an image when restart is OnFailure  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:17:13.065: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename kubectl
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:214
[BeforeEach] [k8s.io] Kubectl run job
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1526
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: running the image e2eteam/nginx:1.14-alpine
May 30 00:17:13.234: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=e2eteam/nginx:1.14-alpine --namespace=kubectl-3984'
May 30 00:17:15.472: INFO: stderr: ""
May 30 00:17:15.472: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
[1mSTEP[0m: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1531
May 30 00:17:15.513: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config delete jobs e2e-test-nginx-job --namespace=kubectl-3984'
May 30 00:17:15.821: INFO: stderr: ""
May 30 00:17:15.821: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:17:15.821: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 00:17:15.864: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 00:16:54 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 00:16:58 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "kubectl-3984" for this suite.
May 30 00:17:37.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:17:39.594: INFO: namespace kubectl-3984 deletion completed in 23.730018466s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPathSymlink][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:17:39.594: INFO: Driver hostPathSymlink doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:17:39.596: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPathSymlink]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver hostPathSymlink doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould observe an object deletion if it stops meeting the requirements of the selector [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:17:39.597: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating a watch on configmaps with a certain label
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: changing the label value of the configmap
[1mSTEP[0m: Expecting to observe a delete notification for the watched object
May 30 00:17:40.054: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2344,SelfLink:/api/v1/namespaces/watch-2344/configmaps/e2e-watch-test-label-changed,UID:60d5b0d4-6ba7-4258-8bf8-46236dcac7ee,ResourceVersion:76783,Generation:0,CreationTimestamp:2019-05-30 00:17:39 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 30 00:17:40.054: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2344,SelfLink:/api/v1/namespaces/watch-2344/configmaps/e2e-watch-test-label-changed,UID:60d5b0d4-6ba7-4258-8bf8-46236dcac7ee,ResourceVersion:76784,Generation:0,CreationTimestamp:2019-05-30 00:17:39 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 30 00:17:40.054: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2344,SelfLink:/api/v1/namespaces/watch-2344/configmaps/e2e-watch-test-label-changed,UID:60d5b0d4-6ba7-4258-8bf8-46236dcac7ee,ResourceVersion:76785,Generation:0,CreationTimestamp:2019-05-30 00:17:39 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: Expecting not to observe a notification because the object no longer meets the selector's requirements
[1mSTEP[0m: changing the label value of the configmap back
[1mSTEP[0m: modifying the configmap a third time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: Expecting to observe an add notification for the watched object when the label value was restored
May 30 00:17:50.360: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2344,SelfLink:/api/v1/namespaces/watch-2344/configmaps/e2e-watch-test-label-changed,UID:60d5b0d4-6ba7-4258-8bf8-46236dcac7ee,ResourceVersion:76811,Generation:0,CreationTimestamp:2019-05-30 00:17:39 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 30 00:17:50.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2344,SelfLink:/api/v1/namespaces/watch-2344/configmaps/e2e-watch-test-label-changed,UID:60d5b0d4-6ba7-4258-8bf8-46236dcac7ee,ResourceVersion:76813,Generation:0,CreationTimestamp:2019-05-30 00:17:39 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 30 00:17:50.360: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2344,SelfLink:/api/v1/namespaces/watch-2344/configmaps/e2e-watch-test-label-changed,UID:60d5b0d4-6ba7-4258-8bf8-46236dcac7ee,ResourceVersion:76814,Generation:0,CreationTimestamp:2019-05-30 00:17:39 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:17:50.360: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 00:17:50.403: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 00:16:54 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 00:16:58 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "watch-2344" for this suite.
May 30 00:17:56.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:17:58.121: INFO: namespace watch-2344 deletion completed in 7.717977832s
[32m•[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-auth] ServiceAccounts[0m 
  [1mshould mount an API token into pods  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-auth] ServiceAccounts
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:17:58.121: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename svcaccounts
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: getting the auto-created API token
[1mSTEP[0m: reading a file in the container
May 30 00:18:05.053: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl exec --namespace=svcaccounts-6624 pod-service-account-96677772-02f4-4b6f-a579-c82b672aca12 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
[1mSTEP[0m: reading a file in the container
May 30 00:18:05.663: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl exec --namespace=svcaccounts-6624 pod-service-account-96677772-02f4-4b6f-a579-c82b672aca12 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
[1mSTEP[0m: reading a file in the container
May 30 00:18:06.274: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl exec --namespace=svcaccounts-6624 pod-service-account-96677772-02f4-4b6f-a579-c82b672aca12 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:18:06.914: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "svcaccounts-6624" for this suite.
May 30 00:18:13.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:18:14.676: INFO: namespace svcaccounts-6624 deletion completed in 7.719701716s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: vSphere][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with defaults[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:18:14.676: INFO: Driver vSphere doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:18:14.678: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: vSphere]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with defaults [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:147[0m

      [36mDriver vSphere doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: gcepd][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:18:14.678: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename volume
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be mountable
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136
[1mSTEP[0m: creating a test gce pd volume
W0530 00:18:14.907741   96922 gce_instances.go:280] Cloud object does not have informers set, should only happen in E2E binary.
May 30 00:18:18.788: INFO: Successfully created a new PD: "e2e-5077e179-b499-422a-8431-69b78ceaea56".
May 30 00:18:18.789: INFO: Creating resource for inline volume
[1mSTEP[0m: starting gcepd injector
May 30 00:18:18.835: INFO: Waiting up to 5m0s for pod "gcepd-injector-457k" in namespace "volume-8533" to be "success or failure"
May 30 00:18:18.876: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 41.526725ms
May 30 00:18:20.918: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083346661s
May 30 00:18:22.961: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126218084s
May 30 00:18:25.004: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 6.169072524s
May 30 00:18:27.047: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.21215589s
May 30 00:18:29.089: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 10.254157219s
May 30 00:18:31.131: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 12.295973553s
May 30 00:18:33.173: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 14.337914174s
May 30 00:18:35.215: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 16.380183846s
May 30 00:18:37.257: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 18.42195241s
May 30 00:18:39.299: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 20.463980096s
May 30 00:18:41.341: INFO: Pod "gcepd-injector-457k": Phase="Pending", Reason="", readiness=false. Elapsed: 22.505921259s
May 30 00:18:43.383: INFO: Pod "gcepd-injector-457k": Phase="Running", Reason="", readiness=true. Elapsed: 24.547862505s
May 30 00:18:45.425: INFO: Pod "gcepd-injector-457k": Phase="Running", Reason="", readiness=true. Elapsed: 26.589917754s
May 30 00:18:47.467: INFO: Pod "gcepd-injector-457k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.63186456s
[1mSTEP[0m: Saw pod success
May 30 00:18:47.467: INFO: Pod "gcepd-injector-457k" satisfied condition "success or failure"
[1mSTEP[0m: starting gcepd-client
[1mSTEP[0m: Checking that text file contents are perfect.
May 30 00:21:53.649: INFO: Running '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/client/bin/kubectl --server=https://146.148.105.213 --kubeconfig=/usr/local/google/home/peterhornyack/.kube/config exec gcepd-client --namespace=volume-8533 -- powershell /c type /opt/0/index.html'
May 30 00:21:56.856: INFO: stderr: ""
May 30 00:21:56.856: INFO: stdout: "Hello from gcepd from namespace volume-8533\r\n"
[1mSTEP[0m: cleaning the environment after gcepd
May 30 00:21:56.856: INFO: Deleting pod "gcepd-client" in namespace "volume-8533"
May 30 00:21:56.902: INFO: Wait up to 5m0s for pod "gcepd-client" to be fully deleted
May 30 00:26:58.665: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:26:58.665: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:04.630: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:04.630: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:10.582: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:10.582: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:16.629: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:16.630: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:22.574: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:22.574: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:28.554: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:28.554: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:34.537: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:34.537: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:40.463: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:40.463: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:46.400: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:46.400: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:52.265: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:52.265: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:58.369: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:27:58.369: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:04.351: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:04.351: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:10.258: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:10.258: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:16.204: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:16.204: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:22.313: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:22.313: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:28.258: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:28.258: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:34.232: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:34.232: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:40.253: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:40.253: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:46.187: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:46.187: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:52.042: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:52.042: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:57.991: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:28:57.991: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:03.880: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:03.880: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:09.836: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:09.836: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:15.774: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:15.774: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:21.708: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:21.708: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:27.575: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:27.575: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:33.626: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:33.626: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:39.877: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:39.877: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:45.800: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:45.800: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:51.771: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:51.771: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:57.730: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:29:57.730: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:03.697: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:03.697: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:09.752: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:09.752: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:15.606: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:15.606: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:21.569: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:21.569: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:27.559: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:27.559: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:33.588: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:33.588: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:39.575: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:39.575: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:45.540: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:45.541: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:51.391: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:51.391: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:57.302: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:30:57.302: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:03.265: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:03.265: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:09.167: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:09.167: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:15.058: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:15.058: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:21.018: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:21.018: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:26.935: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:26.935: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:32.920: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:32.920: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:39.025: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:39.025: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:44.915: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:44.915: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:50.915: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:50.916: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:56.961: INFO: error deleting PD "e2e-5077e179-b499-422a-8431-69b78ceaea56": googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
May 30 00:31:56.961: INFO: Couldn't delete PD "e2e-5077e179-b499-422a-8431-69b78ceaea56", sleeping 5s: googleapi: Error 400: The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-jpxd', resourceInUseByAnotherResource
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "volume-8533".
[1mSTEP[0m: Found 12 events.
May 30 00:32:02.004: INFO: At 2019-05-30 00:18:18 -0700 PDT - event for gcepd-injector-457k: {default-scheduler } Scheduled: Successfully assigned volume-8533/gcepd-injector-457k to e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:32:02.004: INFO: At 2019-05-30 00:18:25 -0700 PDT - event for gcepd-injector-457k: {attachdetach-controller } SuccessfulAttachVolume: AttachVolume.Attach succeeded for volume "gcepd-volume-jjdz" 
May 30 00:32:02.004: INFO: At 2019-05-30 00:18:36 -0700 PDT - event for gcepd-injector-457k: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Pulled: Container image "e2eteam/nettest:1.0" already present on machine
May 30 00:32:02.004: INFO: At 2019-05-30 00:18:36 -0700 PDT - event for gcepd-injector-457k: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Created: Created container gcepd-injector
May 30 00:32:02.004: INFO: At 2019-05-30 00:18:38 -0700 PDT - event for gcepd-injector-457k: {kubelet e2e-test-peterhornyack-windows-node-group-9q9v} Started: Started container gcepd-injector
May 30 00:32:02.004: INFO: At 2019-05-30 00:18:47 -0700 PDT - event for gcepd-client: {default-scheduler } Scheduled: Successfully assigned volume-8533/gcepd-client to e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:32:02.004: INFO: At 2019-05-30 00:18:51 -0700 PDT - event for gcepd-client: {attachdetach-controller } FailedAttachVolume: AttachVolume.Attach failed for volume "gcepd-volume-0" : googleapi: Error 400: RESOURCE_IN_USE_BY_ANOTHER_RESOURCE - The disk resource 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/disks/e2e-5077e179-b499-422a-8431-69b78ceaea56' is already being used by 'projects/peterhornyack-prod-no-enforcer/zones/us-central1-b/instances/e2e-test-peterhornyack-windows-node-group-9q9v'
May 30 00:32:02.004: INFO: At 2019-05-30 00:19:04 -0700 PDT - event for gcepd-client: {attachdetach-controller } SuccessfulAttachVolume: AttachVolume.Attach succeeded for volume "gcepd-volume-0" 
May 30 00:32:02.004: INFO: At 2019-05-30 00:19:26 -0700 PDT - event for gcepd-client: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/nettest:1.0" already present on machine
May 30 00:32:02.004: INFO: At 2019-05-30 00:19:26 -0700 PDT - event for gcepd-client: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container gcepd-client
May 30 00:32:02.004: INFO: At 2019-05-30 00:19:28 -0700 PDT - event for gcepd-client: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container gcepd-client
May 30 00:32:02.004: INFO: At 2019-05-30 00:21:58 -0700 PDT - event for gcepd-client: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod volume-8533/gcepd-client
May 30 00:32:02.091: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 30 00:32:02.092: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:32:02.092: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 30 00:32:02.092: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:32:02.092: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:32:02.092: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:32:02.092: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:32:02.092: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:32:02.092: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 30 00:32:02.092: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 30 00:32:02.092: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 30 00:32:02.092: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 30 00:32:02.092: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:32:02.092: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 00:32:02.092: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 00:32:02.092: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:32:02.092: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 30 00:32:02.092: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 30 00:32:02.093: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:32:02.093: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:32:02.093: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:32:02.093: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:32:02.093: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:32:02.093: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:32:02.093: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 30 00:32:02.093: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 30 00:32:02.093: INFO: gcepd-client                                           e2e-test-peterhornyack-windows-node-group-jpxd  Running  1s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:18:47 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:21:53 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:21:53 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:18:47 -0700 PDT  }]
May 30 00:32:02.093: INFO: 
May 30 00:32:02.136: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 30 00:32:02.178: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:78780,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:31:22 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:31:22 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:31:22 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:31:22 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:32:02.178: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 30 00:32:02.219: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 30 00:32:02.266: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.266: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.266: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.266: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.266: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.266: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.266: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.266: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:32:02.266: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:32:02.266: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.266: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.266: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.266: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:32:02.266: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:32:02.430: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 30 00:32:02.430: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:32:02.472: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:78858,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentContainerdRestart False 2019-05-30 00:31:54 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 00:31:54 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-30 00:31:54 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 00:31:54 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-30 00:31:54 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-30 00:31:54 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 00:31:54 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:31:20 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:31:20 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:31:20 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:31:20 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:32:02.472: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:32:02.520: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:32:02.569: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.569: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:32:02.569: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:32:02.569: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:32:02.569: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 00:32:02.569: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.569: INFO: 	Container event-exporter ready: true, restart count 0
May 30 00:32:02.569: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:32:02.569: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:32:02.569: INFO: 	Container default-http-backend ready: true, restart count 0
May 30 00:32:02.569: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:32:02.569: INFO: 	Container autoscaler ready: true, restart count 0
May 30 00:32:02.569: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:32:02.569: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 30 00:32:02.569: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.569: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:32:02.569: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:32:02.569: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.569: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:32:02.569: INFO: 	Container coredns ready: true, restart count 0
May 30 00:32:02.730: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:32:02.730: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:32:02.772: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:78850,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentDockerRestart False 2019-05-30 00:31:42 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-30 00:31:42 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 00:31:42 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-30 00:31:42 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-30 00:31:42 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 00:31:42 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-30 00:31:42 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:31:52 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:31:52 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:31:52 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:31:52 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:32:02.772: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:32:02.815: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:32:02.880: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 30 00:32:02.880: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.880: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:32:02.880: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:32:02.880: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.880: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:32:02.880: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:32:02.880: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 30 00:32:02.880: INFO: 	Container coredns ready: true, restart count 0
May 30 00:32:02.880: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.880: INFO: 	Container metrics-server ready: true, restart count 0
May 30 00:32:02.880: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 30 00:32:02.880: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 30 00:32:02.880: INFO: 	Container heapster ready: true, restart count 0
May 30 00:32:02.880: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 00:32:03.032: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:32:03.032: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:32:03.074: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:78869,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:31:59 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:31:59 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:31:59 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:31:59 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 00:32:03.074: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:32:03.115: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:32:03.316: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:32:03.316: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:32:03.358: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:78844,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:31:49 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:31:49 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:31:49 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:31:49 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 00:32:03.358: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:32:03.400: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:32:03.602: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:32:03.602: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:32:03.644: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:78859,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:31:55 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:31:55 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:31:55 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:31:55 -0700 PDT 2019-05-30 00:29:55 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[kubernetes.io/gce-pd/e2e-5077e179-b499-422a-8431-69b78ceaea56],VolumesAttached:[{kubernetes.io/gce-pd/e2e-5077e179-b499-422a-8431-69b78ceaea56 /dev/disk/by-id/google-e2e-5077e179-b499-422a-8431-69b78ceaea56}],Config:nil,},}
May 30 00:32:03.644: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:32:03.685: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:32:03.733: INFO: gcepd-client started at 2019-05-30 00:18:47 -0700 PDT (0+1 container statuses recorded)
May 30 00:32:03.734: INFO: 	Container gcepd-client ready: true, restart count 0
May 30 00:32:05.089: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:32:05.089: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "volume-8533" for this suite.
May 30 00:42:05.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:42:06.978: INFO: Couldn't delete ns: "volume-8533": namespace volume-8533 was not deleted with limit: timed out waiting for the condition, namespace is empty but is not yet removed (&errors.errorString{s:"namespace volume-8533 was not deleted with limit: timed out waiting for the condition, namespace is empty but is not yet removed"})

[91m[1m• Failure [1432.301 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: gcepd]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [91m[1mshould be mountable [It][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [91mFailed to delete pod gcepd-client in namespace volume-8533
      Expected
          <*errors.errorString | 0xc0026ac8a0>: {
              s: "pod \"gcepd-client\" was not deleted: timed out waiting for the condition",
          }
      to be nil[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/volume/fixtures.go:417
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] volumes[0m 
  [1mshould allow exec of files on the volume[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:42:06.980: INFO: Driver csi-hostpath doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:42:06.982: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould allow exec of files on the volume [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:167[0m

      [36mDriver csi-hostpath doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide container's memory limit [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:42:06.983: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 30 00:42:07.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d" in namespace "projected-5625" to be "success or failure"
May 30 00:42:07.249: INFO: Pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d": Phase="Pending", Reason="", readiness=false. Elapsed: 41.751268ms
May 30 00:42:09.291: INFO: Pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083741391s
May 30 00:42:11.334: INFO: Pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.126294575s
May 30 00:42:13.375: INFO: Pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d": Phase="Running", Reason="", readiness=true. Elapsed: 6.168215306s
May 30 00:42:15.421: INFO: Pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d": Phase="Running", Reason="", readiness=true. Elapsed: 8.213640555s
May 30 00:42:17.463: INFO: Pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d": Phase="Running", Reason="", readiness=true. Elapsed: 10.25570004s
May 30 00:42:19.505: INFO: Pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.297349786s
[1mSTEP[0m: Saw pod success
May 30 00:42:19.505: INFO: Pod "downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d" satisfied condition "success or failure"
May 30 00:42:19.547: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d container client-container: <nil>
[1mSTEP[0m: delete the pod
May 30 00:42:19.649: INFO: Waiting for pod downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d to disappear
May 30 00:42:19.691: INFO: Pod downwardapi-volume-a2dd995f-8b8d-41e3-9a78-8c53fc5a3b8d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:42:19.691: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-5625" for this suite.
May 30 00:42:25.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:42:27.448: INFO: namespace projected-5625 deletion completed in 7.714173032s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1mshould be consumable from pods in volume with mappings [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:42:27.448: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating secret with name secret-test-map-7db87d0e-2b9b-4606-ad11-ae90236c371b
[1mSTEP[0m: Creating a pod to test consume secrets
May 30 00:42:27.748: INFO: Waiting up to 5m0s for pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38" in namespace "secrets-3864" to be "success or failure"
May 30 00:42:27.790: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 41.539985ms
May 30 00:42:29.832: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083717254s
May 30 00:42:31.874: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125616192s
May 30 00:42:33.916: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167571226s
May 30 00:42:35.958: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 8.209636312s
May 30 00:42:38.000: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 10.251688672s
May 30 00:42:40.042: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 12.293709098s
May 30 00:42:42.084: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 14.335602737s
May 30 00:42:44.127: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 16.378189792s
May 30 00:42:46.169: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 18.420161128s
May 30 00:42:48.211: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 20.462089136s
May 30 00:42:50.252: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 22.50355314s
May 30 00:42:52.294: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 24.545371788s
May 30 00:42:54.337: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 26.588087627s
May 30 00:42:56.379: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 28.630197598s
May 30 00:42:58.421: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 30.672024075s
May 30 00:43:00.465: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 32.716185514s
May 30 00:43:02.507: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 34.758284641s
May 30 00:43:04.549: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 36.800592875s
May 30 00:43:06.592: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 38.843502672s
May 30 00:43:08.634: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 40.885385623s
May 30 00:43:10.676: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 42.927592653s
May 30 00:43:12.718: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 44.969090965s
May 30 00:43:14.759: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 47.010980484s
May 30 00:43:16.801: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 49.052362054s
May 30 00:43:18.843: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 51.094512484s
May 30 00:43:20.885: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 53.136189193s
May 30 00:43:22.926: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 55.17793579s
May 30 00:43:24.971: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 57.22225994s
May 30 00:43:27.012: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 59.263937441s
May 30 00:43:29.055: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.306310131s
May 30 00:43:31.097: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.348368998s
May 30 00:43:33.139: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.390443361s
May 30 00:43:35.181: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.432068771s
May 30 00:43:37.223: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.47405546s
May 30 00:43:39.265: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.516016571s
May 30 00:43:41.306: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.557567303s
May 30 00:43:43.348: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.599762201s
May 30 00:43:45.390: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.641812799s
May 30 00:43:47.432: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.683798333s
May 30 00:43:49.474: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.725935036s
May 30 00:43:51.517: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.768248983s
May 30 00:43:53.559: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.810046698s
May 30 00:43:55.601: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.852306775s
May 30 00:43:57.643: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.894422636s
May 30 00:43:59.685: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.936486862s
May 30 00:44:01.727: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.978539738s
May 30 00:44:03.769: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.020515846s
May 30 00:44:05.812: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.063307667s
May 30 00:44:07.854: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.105023912s
May 30 00:44:09.896: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.147239954s
May 30 00:44:11.938: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.189186972s
May 30 00:44:13.980: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.231086908s
May 30 00:44:16.029: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.280107001s
May 30 00:44:18.071: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.322067397s
May 30 00:44:20.113: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.364103865s
May 30 00:44:22.155: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.406620727s
May 30 00:44:24.197: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.448644753s
May 30 00:44:26.239: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.490593788s
May 30 00:44:28.281: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.532533014s
May 30 00:44:30.323: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.57452357s
May 30 00:44:32.365: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.616911052s
May 30 00:44:34.408: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.65928123s
May 30 00:44:36.450: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.701261372s
May 30 00:44:38.492: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.743955222s
May 30 00:44:40.534: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.785621724s
May 30 00:44:42.576: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.827947442s
May 30 00:44:44.619: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.870013647s
May 30 00:44:46.660: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.911792563s
May 30 00:44:48.702: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.953811303s
May 30 00:44:50.744: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.995778319s
May 30 00:44:52.786: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.037735159s
May 30 00:44:54.828: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.079474964s
May 30 00:44:56.870: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.121822539s
May 30 00:44:58.913: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.164083059s
May 30 00:45:00.954: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.205718907s
May 30 00:45:02.996: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.247565275s
May 30 00:45:05.038: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.289263484s
May 30 00:45:07.080: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.331398465s
May 30 00:45:09.122: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.373285898s
May 30 00:45:11.163: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.414853382s
May 30 00:45:13.206: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.457048502s
May 30 00:45:15.248: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.499083432s
May 30 00:45:17.291: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.542102975s
May 30 00:45:19.333: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.58433902s
May 30 00:45:21.375: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.626208214s
May 30 00:45:23.417: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.668367992s
May 30 00:45:25.459: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.710511747s
May 30 00:45:27.500: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.751963392s
May 30 00:45:29.542: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.793902685s
May 30 00:45:31.584: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.835711522s
May 30 00:45:33.628: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.879487079s
May 30 00:45:35.674: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.925101516s
May 30 00:45:37.716: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.967043453s
May 30 00:45:39.757: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.008961256s
May 30 00:45:41.799: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.050948485s
May 30 00:45:43.841: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.092691878s
May 30 00:45:45.883: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.134766807s
May 30 00:45:47.925: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.176892083s
May 30 00:45:49.967: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.218721367s
May 30 00:45:52.009: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.260807698s
May 30 00:45:54.051: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.302624484s
May 30 00:45:56.093: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.34494296s
May 30 00:45:58.135: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.386693165s
May 30 00:46:00.177: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 3m32.428344713s
[1mSTEP[0m: Saw pod success
May 30 00:46:00.177: INFO: Pod "pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38" satisfied condition "success or failure"
May 30 00:46:00.219: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38 container secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 30 00:46:00.322: INFO: Waiting for pod pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38 to disappear
May 30 00:46:00.364: INFO: Pod pod-secrets-0c899fe5-ccde-4ac4-bd22-bf6b72623a38 no longer exists
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:46:00.364: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 00:46:00.408: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 00:45:07 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 00:45:09 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "secrets-3864" for this suite.
May 30 00:46:06.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:46:08.193: INFO: namespace secrets-3864 deletion completed in 7.78436108s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: local][LocalVolumeType: dir-link][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:46:08.193: INFO: Driver local doesn't support DynamicPV -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:46:08.194: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: local][LocalVolumeType: dir-link]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver local doesn't support DynamicPV -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Aggregator[0m 
  [1mShould be able to support the 1.10 Sample API Server using the current Aggregator [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Aggregator
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:46:08.195: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename aggregator
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:74
May 30 00:46:08.397: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Registering the sample API server.
May 30 00:46:09.486: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:11.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:13.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:15.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:17.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:19.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:21.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:23.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:25.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:27.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:29.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:31.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:33.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:35.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:37.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:39.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:41.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:43.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:45.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:47.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:49.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:51.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:53.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:55.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:57.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:46:59.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:01.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:03.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:05.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:07.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:09.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:11.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:13.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:15.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:17.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:19.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:21.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:23.531: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:25.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:27.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:29.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:31.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:33.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:35.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:37.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:39.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:41.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:43.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:45.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:47.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:49.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:51.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:53.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:55.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:57.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:47:59.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:01.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:03.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:05.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:07.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:09.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:11.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:13.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:15.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:17.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:19.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:21.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:23.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:25.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:27.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:29.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:31.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:33.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:35.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:37.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:39.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:41.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:43.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:45.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:47.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:49.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:51.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:53.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:55.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:57.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:48:59.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:01.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:03.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:05.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:07.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:09.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:11.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:13.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:15.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:17.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:19.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:21.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:23.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:25.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:27.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:29.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:31.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:33.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:35.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:37.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:39.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:41.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:43.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:45.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:47.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:49.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:51.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:53.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:55.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:57.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:49:59.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694799169, loc:(*time.Location)(0x8175900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7f7649696\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 30 00:51:01.827: INFO: Waited 1m0.250621231s for the sample-apiserver to be ready to handle requests.
May 30 00:51:01.827: INFO: current APIService: {"metadata":{"name":"v1alpha1.wardle.k8s.io","selfLink":"/apis/apiregistration.k8s.io/v1beta1/apiservices/v1alpha1.wardle.k8s.io","uid":"b25ac719-9b6c-4c37-9b47-ca93c8899305","resourceVersion":"81506","creationTimestamp":"2019-05-30T07:50:01Z"},"spec":{"service":{"namespace":"aggregator-4408","name":"sample-api"},"group":"wardle.k8s.io","version":"v1alpha1","caBundle":"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMyRENDQWNDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFkTVJzd0dRWURWUVFERXhKbE1tVXQKYzJWeWRtVnlMV05sY25RdFkyRXdIaGNOTVRrd05UTXdNRGMwTmpBNFdoY05Namt3TlRJM01EYzBOakE0V2pBZApNUnN3R1FZRFZRUURFeEpsTW1VdGMyVnlkbVZ5TFdObGNuUXRZMkV3Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBCkE0SUJEd0F3Z2dFS0FvSUJBUUNzK0gra1ZSNmFvZ1ZFck9Vd3MzQlk1MDNmUU5PR21tVUttMW5lbElpRmlhUWQKKzFQK3JaaUJybEJpS2FBWlh3a0ZsWk9nZWtydmJ5R0JlVUlkK0Y5QjZwOXU0aTZzTFVFVnU1dDVlU3Q2NTRYUwpVWWpET05DTmVUbXpWUm91KzMwRVFyVlZod2RpNExsbkVGWTkxdkcwcXBQNEFpUEt2RVZranZETGJNWTZpVlZmCko1ZnhRYUJBQTlNSjNmbjFoSmcxM2MxRjVZOVlYRENSanYwRGRTNkZtSGVNci95ZGEzUFRRYm0zN3ZoeHE0cnMKUnQ4RnN6dUU4UE5mQmROSVcwb0VvaWlGMDd4bisrOXZYZmF6Nld6SEg0VXM2UjBuTUVUeTJjVCtHaXlTb09xLwpIYlBxR3lEU2twRFJqZVFIYVBXOTJwb0FrRWI0Vm1FU212K0FyajA3QWdNQkFBR2pJekFoTUE0R0ExVWREd0VCCi93UUVBd0lDcERBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFCMlJNNncKUnRQY2NNeExpYjYveGhrQmNTMXNlbnJjVEdRc1F4cWkxSUh1dEI4QUFFaHVSZHp6ZUZkRlNkUTUrWGpKTlp3MQpFM1RNeVlFcGRRQ0NyTGpQUGFmTVRIcWo1aW1YZXJZUUg1N1ZwMXcxSERpdFhqRzFKNDlCVXZFdkhrbGQra0ltClNERWFzMWRYSm5tUEo2SVliN0dHMTUwN2Q2YjVFNGVQeEJMVWdMK1daQmRqcEN6RUFHaGZmUmZtd3BsTU5SYWYKL0lTUFJ1eDNLYXYycXAxSGV3R1UvTFEzRjlHU3g3NFVZRXJONWtpU04vd3JDdVozSFlMNy9pdlhldUZWamtLaApHYmQ2Vm1NMnRqNFdBcE9BWjliVnNncWJpbE0xM1F2bGY0Vm1OSGVDRmwvNGgzWUxPbTkxNkZNamFRMHdrTlUzCkplbnZ3ZFI3TS9xYmRmUWYKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=","groupPriorityMinimum":2000,"versionPriority":200},"status":{"conditions":[{"type":"Available","status":"False","lastTransitionTime":"2019-05-30T07:50:01Z","reason":"ServicePortError","message":"service/sample-api in \"aggregator-4408\" is not listening on port 443"}]}}
May 30 00:51:01.827: INFO: current pods: {"metadata":{"selfLink":"/api/v1/namespaces/aggregator-4408/pods","resourceVersion":"81648"},"items":[{"metadata":{"name":"sample-apiserver-deployment-7f7649696-c5hg4","generateName":"sample-apiserver-deployment-7f7649696-","namespace":"aggregator-4408","selfLink":"/api/v1/namespaces/aggregator-4408/pods/sample-apiserver-deployment-7f7649696-c5hg4","uid":"047962f1-73ed-427e-860a-3349c59e4d0e","resourceVersion":"81501","creationTimestamp":"2019-05-30T07:46:09Z","labels":{"apiserver":"true","app":"sample-apiserver","pod-template-hash":"7f7649696"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"ReplicaSet","name":"sample-apiserver-deployment-7f7649696","uid":"3a75d097-eb20-4981-9277-cd9b8e751eb9","controller":true,"blockOwnerDeletion":true}]},"spec":{"volumes":[{"name":"apiserver-certs","secret":{"secretName":"sample-apiserver-secret","defaultMode":420}},{"name":"default-token-2grpw","secret":{"secretName":"default-token-2grpw","defaultMode":420}}],"containers":[{"name":"sample-apiserver","image":"e2eteam/sample-apiserver:1.10","args":["--etcd-servers=http://localhost:2379","--tls-cert-file=/apiserver.local.config/certificates/tls.crt","--tls-private-key-file=/apiserver.local.config/certificates/tls.key","--audit-log-path=-","--audit-log-maxage=0","--audit-log-maxbackup=0"],"resources":{},"volumeMounts":[{"name":"apiserver-certs","readOnly":true,"mountPath":"/apiserver.local.config/certificates"},{"name":"default-token-2grpw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"},{"name":"etcd","image":"e2eteam/etcd:3.3.10","command":["/usr/local/bin/etcd"],"resources":{},"volumeMounts":[{"name":"default-token-2grpw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"}],"restartPolicy":"Always","terminationGracePeriodSeconds":0,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"e2e-test-peterhornyack-windows-node-group-jpxd","securityContext":{},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute","tolerationSeconds":300},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute","tolerationSeconds":300}],"priority":0,"enableServiceLinks":true},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2019-05-30T07:46:09Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2019-05-30T07:50:01Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2019-05-30T07:50:01Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2019-05-30T07:46:09Z"}],"hostIP":"10.40.0.3","podIP":"10.64.1.130","startTime":"2019-05-30T07:46:09Z","containerStatuses":[{"name":"etcd","state":{"running":{"startedAt":"2019-05-30T07:46:25Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"e2eteam/etcd:3.3.10","imageID":"docker-pullable://e2eteam/etcd@sha256:462024728f8360157455091329616d9b55d4718533b0812b230d612a5bc5ce30","containerID":"docker://e5f36e625a5b19db98a771d40b079cf2566f722b9f02398d2ecbb6a264e4349a"},{"name":"sample-apiserver","state":{"running":{"startedAt":"2019-05-30T07:46:16Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"e2eteam/sample-apiserver:1.10","imageID":"docker-pullable://e2eteam/sample-apiserver@sha256:a11a8656e8013ce21acd0074574f8ac9deaccc3b99486c7d59f764fe4d4f2d55","containerID":"docker://323ec8774663bd169c5cd7fd0c8eb1a2e6114691466b2c0a5c12cd294ccc8d2c"}],"qosClass":"BestEffort"}}]}
May 30 00:51:01.906: INFO: logs of sample-apiserver-deployment-7f7649696-c5hg4/sample-apiserver (error: <nil>): I0530 07:46:20.188077    8676 plugins.go:149] Loaded 3 admission controller(s) successfully in the following order: NamespaceLifecycle,MutatingAdmissionWebhook,ValidatingAdmissionWebhook.
I0530 07:46:27.185735    8676 serve.go:116] Serving securely on [::]:443
E0530 07:46:27.396681    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:27.397658    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:27.397658    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:28.402472    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:28.405428    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:28.406362    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:29.410239    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:29.411218    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:29.412192    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:30.417976    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:30.418947    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:30.430675    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:31.422851    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:31.425739    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:31.436475    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:32.429598    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:32.432535    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:32.442309    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:33.436379    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:33.436379    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:33.448091    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:34.442184    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:34.443170    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:34.452963    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:35.448996    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:35.449981    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:35.456783    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:36.455782    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:36.456739    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:36.461635    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:37.487430    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:37.495259    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:37.495259    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:38.494228    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:38.534245    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:38.559683    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:39.500995    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:39.541070    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:39.565444    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:40.508796    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:40.547858    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:40.572235    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:41.515131    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:41.578533    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:41.598630    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:42.520849    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:42.585311    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:42.606835    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:43.527863    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:43.592342    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:43.612894    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:44.533096    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:44.598515    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:44.620030    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:45.537771    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:45.610050    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:45.625218    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:46.556633    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:46.617202    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:46.631245    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:47.562325    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:47.622917    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:47.635563    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:48.568480    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:48.629049    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:48.642783    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:49.574141    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:49.634726    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:49.649367    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:50.579870    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:50.640470    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:50.654689    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:51.585989    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:51.647535    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:51.660246    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:52.593121    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:52.653707    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:52.665426    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:53.599335    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:53.660835    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:53.679422    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:54.606418    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:54.667952    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:54.686393    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:55.613565    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:55.674128    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:55.694781    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:56.631911    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:56.680774    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:56.701546    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:57.649323    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:57.686422    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:57.707102    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:58.668171    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:58.692583    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:58.713245    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:59.673932    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:46:59.702191    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:46:59.718876    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:00.687833    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:00.709283    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:00.723941    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:01.694943    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:01.717407    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:01.729161    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:02.702080    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:02.724554    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:02.736235    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:03.721483    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:03.731162    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:03.742878    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:04.731982    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:04.737792    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:04.749558    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:05.755190    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:05.756130    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:05.756130    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:06.762795    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:06.763830    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:06.764752    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:07.769382    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:07.770411    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:07.772381    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:08.865926    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:08.865926    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:08.867875    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:09.875905    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:09.880804    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:09.880804    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:10.884015    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:10.886949    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:10.888042    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:11.890633    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:11.892577    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:11.895511    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:12.897725    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:12.900684    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:12.902662    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:13.908507    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:13.908507    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:13.909238    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:14.913915    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:14.915860    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:14.916845    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:15.935956    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:15.935956    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:15.935956    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:16.941342    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:16.943272    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:16.945216    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:17.949396    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:17.950363    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:17.951390    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:18.956504    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:18.957460    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:18.959427    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:19.975369    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:19.976841    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:19.976841    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:20.982940    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:20.984847    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:20.984847    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:21.988541    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:21.991475    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:21.994418    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:22.995177    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:22.996111    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:22.998108    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:24.002244    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:24.005166    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:24.006160    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:25.007374    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:25.011288    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:25.014213    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:26.014509    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:26.016445    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:26.019369    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:27.028550    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:27.028550    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:27.029393    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:28.044810    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:28.045766    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:28.057469    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:29.060695    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:29.062226    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:29.062226    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:30.068236    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:30.069225    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:30.070195    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:31.076300    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:31.077284    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:31.084118    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:32.082926    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:32.083874    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:32.088796    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:33.089032    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:33.089996    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:33.092952    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:34.096105    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:34.097079    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:34.100000    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:35.113949    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:35.113949    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:35.114912    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:36.133215    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:36.133215    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:36.133215    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:37.143233    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:37.143233    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:37.143233    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:38.164243    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:38.164243    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:38.165449    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:39.175953    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:39.175953    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:39.175953    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:40.182080    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:40.183064    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:40.184018    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:41.188667    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:41.189667    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:41.191589    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:42.195314    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:42.197164    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:42.197164    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:43.201311    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:43.203299    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:43.204230    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:44.209392    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:44.209392    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:44.212294    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:45.216430    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:45.217409    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:45.219353    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:46.222559    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:46.226439    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:46.227444    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:47.228692    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:47.232570    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:47.233545    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:48.234228    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:48.237161    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:48.240131    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:49.241284    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:49.243262    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:49.244221    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:50.249821    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:50.249821    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:50.250796    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:51.255451    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:51.257376    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:51.259322    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:52.263468    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:52.263468    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:52.266383    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:53.269545    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:53.270555    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:53.273549    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:54.277595    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:54.277595    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:54.277595    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:55.282200    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:55.283252    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:55.286102    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:56.286826    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:56.287808    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:56.290727    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:57.294859    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:57.296830    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:57.297777    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:58.301432    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:58.302404    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:58.303387    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:47:59.309455    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:59.310479    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:47:59.311470    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:00.317516    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:00.317516    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:00.317516    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:01.431023    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:01.431023    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:01.431023    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:02.438084    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:02.439068    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:02.440043    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:03.504719    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:03.508631    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:03.508631    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:04.514214    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:04.514214    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:04.514214    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:05.536394    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:05.536394    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:05.536394    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:06.556826    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:06.558154    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:06.558595    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:07.574416    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:07.575398    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:07.575398    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:08.605895    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:08.605895    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:08.610789    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:09.612953    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:09.613926    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:09.616827    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:10.621921    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:10.626824    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:10.629756    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:11.628474    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:11.633390    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:11.634339    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:12.635505    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:12.639440    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:12.642390    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:13.656060    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:13.657253    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:13.657253    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:14.663776    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:14.663776    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:14.664751    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:15.672765    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:15.673750    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:15.692302    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:16.678818    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:16.679850    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:16.699325    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:17.684901    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:17.686832    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:17.705418    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:18.691905    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:18.691905    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:18.712421    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:19.697992    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:19.698946    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:19.721410    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:20.710863    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:20.710863    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:20.727647    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:21.722283    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:21.722283    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:21.735688    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:22.730338    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:22.730338    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:22.741055    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:23.741744    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:23.741744    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:23.746752    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:24.763114    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:24.763114    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:24.764414    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:25.769951    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:25.770995    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:25.771927    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:26.777977    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:26.777977    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:26.778956    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:27.784008    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:27.784991    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:27.786976    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:28.789604    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:28.791554    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:28.793502    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:29.801511    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:29.803437    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:29.803437    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:30.806075    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:30.808034    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:30.808999    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:31.813100    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:31.814076    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:31.815042    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:32.819656    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:32.820623    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:32.822550    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:33.825723    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:33.827630    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:33.828657    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:34.830755    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:34.832705    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:34.832705    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:35.837770    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:35.840724    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:35.841689    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:36.848220    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:36.848220    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:36.849275    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:37.856178    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:37.856178    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:37.856178    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:38.860802    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:38.862748    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:38.863740    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:39.867770    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:39.867770    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:39.870739    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:40.873832    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:40.875815    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:40.876760    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:41.881820    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:41.881820    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:41.881820    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:42.886876    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:42.887881    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:42.890789    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:43.894889    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:43.894889    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:43.895864    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:44.902391    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:44.902870    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:44.903826    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:45.909363    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:45.909363    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:45.910413    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:46.914925    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:46.915910    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:46.916864    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:47.921457    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:47.922434    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:47.922434    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:48.926038    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:48.928966    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:48.929925    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:49.930620    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:49.933520    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:49.963800    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:50.937575    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:50.937575    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:50.969806    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:51.944583    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:51.945601    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:51.975902    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:52.951641    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:52.952596    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:52.982838    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:53.957603    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:53.960540    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:53.989907    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:54.963643    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:54.965598    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:54.995866    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:55.969186    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:55.970169    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:56.002381    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:56.975276    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:56.976230    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:57.008948    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:57.981761    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:57.983670    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:58.015918    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:58.986763    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:58.988700    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:48:59.021945    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:59.992800    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:48:59.994776    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:00.028938    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:01.000879    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:01.000879    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:01.034947    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:02.006285    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:02.007323    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:02.055621    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:03.013333    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:03.013333    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:03.063748    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:04.018875    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:04.021752    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:04.071677    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:05.038063    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:05.038063    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:05.076742    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:06.044530    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:06.045499    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:06.084107    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:07.049085    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:07.051029    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:07.090105    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:08.057063    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:08.069044    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:08.130310    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:09.064052    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:09.073819    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:09.135374    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:10.070107    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:10.078900    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:10.141398    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:11.084860    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:11.090742    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:11.148347    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:12.091850    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:12.099655    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:12.155347    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:13.097370    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:13.112026    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:13.160887    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:14.103472    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:14.118228    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:14.167834    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:15.109414    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:15.125026    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:15.173867    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:16.116364    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:16.133004    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:16.179860    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:17.122438    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:17.139024    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:17.185877    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:18.127907    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:18.144510    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:18.192362    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:19.141238    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:19.150033    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:19.198855    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:20.150683    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:20.153620    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:20.204471    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:21.164490    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:21.164490    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:21.211386    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:22.169522    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:22.172450    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:22.218333    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:23.175542    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:23.177509    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:23.225330    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:24.181041    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:24.183003    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:24.229512    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:25.187023    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:25.187996    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:25.234996    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:26.193998    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:26.193998    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:26.242077    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:27.200011    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:27.201992    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:27.248071    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:28.206032    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:28.207017    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:28.253735    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:29.212053    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:29.214005    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:29.257924    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:30.218025    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:30.218975    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:30.263937    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:31.224995    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:31.224995    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:31.270890    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:32.231936    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:32.232927    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:32.276893    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:33.238939    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:33.240977    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:33.282876    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:34.245915    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:34.245915    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:34.287904    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:35.252878    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:35.253849    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:35.330032    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:36.271562    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:36.271562    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:36.336017    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:37.278565    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:37.278565    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:37.342991    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:38.285507    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:38.285507    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:38.347998    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:39.291501    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:39.291501    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:39.355022    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:40.297477    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:40.297477    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:40.361004    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:41.303953    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:41.303953    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:41.366469    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:42.311897    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:42.312921    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:42.488693    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:43.319870    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:43.319870    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:43.493701    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:44.325832    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:44.327808    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:44.498717    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:45.332802    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:45.334753    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:45.503731    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:46.337842    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:46.351489    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:46.525332    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:47.343808    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:47.356514    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:47.532338    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:48.349791    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:48.364424    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:48.539250    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:49.356753    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:49.371402    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:49.545296    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:50.362721    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:50.376482    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:50.552231    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:51.368714    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:51.383400    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:51.558241    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:52.374687    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:52.389360    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:52.564210    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:53.381687    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:53.395325    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:53.570187    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:54.388620    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:54.402263    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:54.576144    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:55.394613    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:55.410238    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:55.582108    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:56.400571    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:56.422056    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:56.589089    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:57.405615    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:57.430070    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:57.595079    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:58.413546    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:58.436961    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:58.602019    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:59.418490    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:49:59.443892    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:49:59.608944    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:00.424532    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:00.450893    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:00.614985    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:01.436315    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:01.457805    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:01.680132    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:02.505771    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:02.525344    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:02.756302    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:03.511772    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:03.532254    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:03.769409    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:04.518216    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:04.537780    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:04.775082    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:05.525206    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:05.544692    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:05.782033    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:06.532164    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:06.550676    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:06.788973    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:07.551755    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:07.556652    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:07.794460    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:08.573745    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:08.573745    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:08.802870    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:09.594396    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:09.594396    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:09.809812    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:10.600439    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:10.600439    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:10.815381    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:11.604936    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:11.605924    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:11.820789    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:12.611908    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:12.612865    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:12.826767    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:13.619805    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:13.621789    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:13.832758    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:14.625811    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:14.627782    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:14.842629    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:15.650851    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:15.650851    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:15.856409    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:16.665632    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:16.665632    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:16.866138    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:17.673061    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:17.675441    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:17.870472    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:18.685918    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:18.687358    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:18.877021    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:19.705799    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:19.705799    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:19.881390    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:20.715328    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:20.717238    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:20.909683    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:21.721276    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:21.721276    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:21.914658    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:22.727245    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:22.728193    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:22.922570    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:23.732165    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:23.734156    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:23.931474    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:24.736810    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:24.740141    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:24.936431    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:25.743179    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:25.745130    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:25.941408    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:26.750077    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:26.751589    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:26.949358    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:27.755563    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:27.755563    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:27.960655    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:28.762524    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:28.763499    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:28.967657    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:29.768438    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:29.771376    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:29.976498    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:30.787136    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:30.789066    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:30.982471    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:31.807738    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:31.807738    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:31.988420    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:32.836691    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:32.836691    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:32.994392    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:33.843089    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:33.843089    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:34.000327    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:34.848537    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:34.849515    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:35.005779    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:35.856450    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:35.857424    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:36.012710    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:36.862412    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:36.863379    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:37.018655    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:37.869371    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:37.871294    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:38.024620    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:38.873845    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:38.874824    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:39.030584    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:39.880751    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:39.881748    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:40.044807    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:40.886753    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:40.888712    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:41.049307    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:41.893632    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:41.893632    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:42.055280    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:42.900083    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:42.901068    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:43.060262    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:43.909931    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:43.910909    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:44.066191    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:44.916892    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:44.917852    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:45.073109    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:45.923798    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:45.923798    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:46.082014    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:46.929252    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:46.930212    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:47.088430    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:47.935758    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:47.936797    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:48.093225    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:48.942220    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:48.943158    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:49.110002    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:49.948143    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:49.951196    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:50.116593    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:50.955569    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:50.957444    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:51.129813    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:51.962467    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:51.964583    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:52.135305    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:52.969359    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:52.970350    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:53.141228    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:53.975303    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:53.977231    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:54.148208    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:54.985656    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:54.987571    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:55.166307    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:56.005010    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:56.005010    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:56.179604    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:57.021335    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:57.021448    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:57.186971    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:58.026883    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:58.029810    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:58.192408    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:59.033311    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:50:59.035263    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:50:59.271412    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:51:00.040303    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:51:00.042205    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:51:00.277557    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:51:01.056011    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.ValidatingWebhookConfiguration: unknown (get validatingwebhookconfigurations.admissionregistration.k8s.io)
E0530 07:51:01.056011    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1.Namespace: unknown (get namespaces)
E0530 07:51:01.283508    8676 reflector.go:322] k8s.io/sample-apiserver/vendor/k8s.io/client-go/informers/factory.go:87: Failed to watch *v1beta1.MutatingWebhookConfiguration: unknown (get mutatingwebhookconfigurations.admissionregistration.k8s.io)

May 30 00:51:01.969: INFO: logs of sample-apiserver-deployment-7f7649696-c5hg4/etcd (error: <nil>): 2019-05-30 07:46:25.886990 I | etcdmain: etcd Version: 3.3.10
2019-05-30 07:46:25.889916 I | etcdmain: Git SHA: 27fc7e2
2019-05-30 07:46:25.889916 I | etcdmain: Go Version: go1.10.4
2019-05-30 07:46:25.889916 I | etcdmain: Go OS/Arch: windows/amd64
2019-05-30 07:46:25.889916 I | etcdmain: setting maximum number of CPUs to 2, total number of available CPUs is 2
2019-05-30 07:46:25.889916 N | etcdmain: failed to detect default host (default host not supported on windows_amd64)
2019-05-30 07:46:25.889916 W | etcdmain: no data-dir provided, using default data-dir ./default.etcd
2019-05-30 07:46:25.904567 I | embed: listening for peers on http://localhost:2380
2019-05-30 07:46:25.910426 I | embed: listening for client requests on localhost:2379
2019-05-30 07:46:25.928009 I | etcdserver: name = default
2019-05-30 07:46:25.928009 I | etcdserver: data dir = default.etcd
2019-05-30 07:46:25.928009 I | etcdserver: member dir = default.etcd\member
2019-05-30 07:46:25.928009 I | etcdserver: heartbeat = 100ms
2019-05-30 07:46:25.928009 I | etcdserver: election = 1000ms
2019-05-30 07:46:25.928009 I | etcdserver: snapshot count = 100000
2019-05-30 07:46:25.928009 I | etcdserver: advertise client URLs = http://localhost:2379
2019-05-30 07:46:25.928009 I | etcdserver: initial advertise peer URLs = http://localhost:2380
2019-05-30 07:46:25.928009 I | etcdserver: initial cluster = default=http://localhost:2380
2019-05-30 07:46:25.939716 I | wal: releasing file lock to rename "default.etcd\\member\\wal.tmp" to "default.etcd\\member\\wal"
2019-05-30 07:46:25.955508 I | etcdserver: starting member 8e9e05c52164694d in cluster cdf818194e3a8c32
2019-05-30 07:46:25.955508 I | raft: 8e9e05c52164694d became follower at term 0
2019-05-30 07:46:25.955508 I | raft: newRaft 8e9e05c52164694d [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]
2019-05-30 07:46:25.955508 I | raft: 8e9e05c52164694d became follower at term 1
2019-05-30 07:46:25.989047 W | auth: simple token is not cryptographically signed
2019-05-30 07:46:26.016384 I | etcdserver: starting server... [version: 3.3.10, cluster version: to_be_decided]
2019-05-30 07:46:26.048599 I | etcdserver: 8e9e05c52164694d as single-node; fast-forwarding 9 ticks (election ticks 10)
2019-05-30 07:46:26.050554 E | etcdserver: cannot monitor file descriptor usage (cannot get FDUsage on windows)
2019-05-30 07:46:26.051532 I | etcdserver/membership: added member 8e9e05c52164694d [http://localhost:2380] to cluster cdf818194e3a8c32
2019-05-30 07:46:26.058387 I | raft: 8e9e05c52164694d is starting a new election at term 1
2019-05-30 07:46:26.058387 I | raft: 8e9e05c52164694d became candidate at term 2
2019-05-30 07:46:26.058387 I | raft: 8e9e05c52164694d received MsgVoteResp from 8e9e05c52164694d at term 2
2019-05-30 07:46:26.058387 I | raft: 8e9e05c52164694d became leader at term 2
2019-05-30 07:46:26.058387 I | raft: raft.node: 8e9e05c52164694d elected leader 8e9e05c52164694d at term 2
2019-05-30 07:46:26.060327 I | etcdserver: published {Name:default ClientURLs:[http://localhost:2379]} to cluster cdf818194e3a8c32
2019-05-30 07:46:26.060327 I | etcdserver: setting up the initial cluster version to 3.3
2019-05-30 07:46:26.060327 I | embed: ready to serve client requests
2019-05-30 07:46:26.062266 N | embed: serving insecure client requests on 127.0.0.1:2379, this is strongly discouraged!
2019-05-30 07:46:26.068152 N | etcdserver/membership: set the initial cluster version to 3.3
2019-05-30 07:46:26.068152 I | etcdserver/api: enabled capabilities for version 3.3

May 30 00:51:01.969: INFO: Unexpected error occurred: timed out waiting for the condition
[AfterEach] [sig-api-machinery] Aggregator
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:65
[AfterEach] [sig-api-machinery] Aggregator
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "aggregator-4408".
[1mSTEP[0m: Found 13 events.
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:09 -0700 PDT - event for sample-apiserver-deployment: {deployment-controller } ScalingReplicaSet: Scaled up replica set sample-apiserver-deployment-7f7649696 to 1
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:09 -0700 PDT - event for sample-apiserver-deployment-7f7649696: {replicaset-controller } SuccessfulCreate: Created pod: sample-apiserver-deployment-7f7649696-c5hg4
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:09 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {default-scheduler } Scheduled: Successfully assigned aggregator-4408/sample-apiserver-deployment-7f7649696-c5hg4 to e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:11 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulling: Pulling image "e2eteam/sample-apiserver:1.10"
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:15 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container sample-apiserver
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:15 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Successfully pulled image "e2eteam/sample-apiserver:1.10"
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:16 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container sample-apiserver
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:16 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulling: Pulling image "e2eteam/etcd:3.3.10"
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:23 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container etcd
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:23 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Successfully pulled image "e2eteam/etcd:3.3.10"
May 30 00:51:03.625: INFO: At 2019-05-30 00:46:25 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container etcd
May 30 00:51:03.625: INFO: At 2019-05-30 00:50:09 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod aggregator-4408/sample-apiserver-deployment-7f7649696-c5hg4
May 30 00:51:03.625: INFO: At 2019-05-30 00:51:03 -0700 PDT - event for sample-apiserver-deployment-7f7649696-c5hg4: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Killing: Stopping container etcd
May 30 00:51:03.719: INFO: POD                                                    NODE                                      PHASE    GRACE  CONDITIONS
May 30 00:51:03.719: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:51:03.719: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 30 00:51:03.719: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:51:03.719: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:51:03.719: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:51:03.719: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:51:03.719: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:51:03.719: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 30 00:51:03.719: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 30 00:51:03.719: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 30 00:51:03.719: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 30 00:51:03.719: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:51:03.719: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 00:51:03.719: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 00:51:03.719: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:51:03.719: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 30 00:51:03.719: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 30 00:51:03.720: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:51:03.720: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:51:03.720: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:51:03.720: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 00:51:03.720: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:51:03.720: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 00:51:03.720: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 30 00:51:03.720: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 30 00:51:03.720: INFO: 
May 30 00:51:03.762: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 30 00:51:03.804: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:81567,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:50:26 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:50:26 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:50:26 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:50:26 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:51:03.804: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 30 00:51:03.846: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 30 00:51:03.894: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:51:03.894: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:51:03.894: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:51:03.894: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:03.894: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:51:03.895: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:51:03.895: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:51:03.895: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:51:03.895: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:51:03.895: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:51:03.895: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 00:51:03.895: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:03.895: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:51:03.895: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:51:04.064: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 30 00:51:04.064: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:51:04.106: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:81555,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentContainerdRestart False 2019-05-30 00:50:05 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 00:50:05 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-30 00:50:05 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 00:50:05 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-30 00:50:05 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-30 00:50:05 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 00:50:05 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:50:21 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:50:21 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:50:21 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:50:21 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:51:04.106: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:51:04.147: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:51:04.199: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:51:04.199: INFO: 	Container default-http-backend ready: true, restart count 0
May 30 00:51:04.199: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:04.199: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:51:04.199: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:51:04.199: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:51:04.199: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 00:51:04.199: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:04.199: INFO: 	Container event-exporter ready: true, restart count 0
May 30 00:51:04.199: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:51:04.199: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:51:04.199: INFO: 	Container coredns ready: true, restart count 0
May 30 00:51:04.199: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:51:04.199: INFO: 	Container autoscaler ready: true, restart count 0
May 30 00:51:04.200: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 00:51:04.200: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 30 00:51:04.200: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:04.200: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:51:04.200: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:51:04.200: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 30 00:51:04.363: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 30 00:51:04.363: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:51:04.404: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:81637,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{CorruptDockerOverlay2 False 2019-05-30 00:50:56 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-30 00:50:56 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-30 00:50:56 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 00:50:56 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-30 00:50:56 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 00:50:56 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-30 00:50:56 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:50:55 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:50:55 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:50:55 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:50:55 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 00:51:04.405: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:51:04.446: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:51:04.496: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 30 00:51:04.496: INFO: 	Container coredns ready: true, restart count 0
May 30 00:51:04.496: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:04.496: INFO: 	Container metrics-server ready: true, restart count 0
May 30 00:51:04.496: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 30 00:51:04.496: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:04.496: INFO: 	Container heapster ready: true, restart count 0
May 30 00:51:04.496: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 00:51:04.496: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 30 00:51:04.496: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:04.496: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 00:51:04.496: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:51:04.496: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 30 00:51:04.496: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 00:51:04.496: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 00:51:04.655: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 30 00:51:04.655: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:51:04.697: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:81646,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:51:01 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:51:01 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:51:01 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:51:01 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 00:51:04.697: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:51:04.738: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:51:04.937: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 00:51:04.937: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:51:04.979: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:81623,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:50:51 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:50:51 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:50:51 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:50:51 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 00:51:04.979: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:51:05.021: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:51:05.231: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 00:51:05.231: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:51:05.273: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:81529,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 00:50:07 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 00:50:07 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 00:50:07 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 00:50:07 -0700 PDT 2019-05-30 00:50:07 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/etcd@sha256:462024728f8360157455091329616d9b55d4718533b0812b230d612a5bc5ce30 e2eteam/etcd:3.3.10] 4350004937} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/sample-apiserver@sha256:a11a8656e8013ce21acd0074574f8ac9deaccc3b99486c7d59f764fe4d4f2d55 e2eteam/sample-apiserver:1.10] 4331611162} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 00:51:05.273: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:51:05.318: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:51:05.564: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 00:51:05.564: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "aggregator-4408" for this suite.
May 30 00:51:11.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:51:13.335: INFO: namespace aggregator-4408 deletion completed in 7.728844306s

[91m[1m• Failure [305.140 seconds][0m
[sig-api-machinery] Aggregator
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23[0m
  [91m[1mShould be able to support the 1.10 Sample API Server using the current Aggregator [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mgave up waiting for apiservice wardle to come up successfully
  Unexpected error:
      <*errors.errorString | 0xc0002b5440>: {
          s: "timed out waiting for the condition",
      }
      timed out waiting for the condition
  occurred[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:389
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected secret[0m 
  [1mshould be consumable from pods in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:51:13.336: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating projection with secret that has name projected-secret-test-418fab20-d026-4f10-8596-05d3381bbcfb
[1mSTEP[0m: Creating a pod to test consume secrets
May 30 00:51:13.626: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d" in namespace "projected-940" to be "success or failure"
May 30 00:51:13.668: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 41.979799ms
May 30 00:51:15.712: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085932498s
May 30 00:51:17.754: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127659087s
May 30 00:51:19.796: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.169291331s
May 30 00:51:21.838: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.211098206s
May 30 00:51:23.880: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.253787433s
May 30 00:51:25.922: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.295930302s
May 30 00:51:27.965: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.33843925s
May 30 00:51:30.007: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.380271597s
May 30 00:51:32.049: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.42247032s
May 30 00:51:34.091: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.464873393s
May 30 00:51:36.134: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.507284785s
May 30 00:51:38.176: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.549527919s
May 30 00:51:40.218: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.591823322s
May 30 00:51:42.261: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.634200307s
May 30 00:51:44.303: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 30.676508778s
May 30 00:51:46.345: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 32.718295806s
May 30 00:51:48.387: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 34.760196397s
May 30 00:51:50.429: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.802300064s
May 30 00:51:52.471: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 38.844169178s
May 30 00:51:54.513: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 40.886294797s
May 30 00:51:56.555: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 42.928463788s
May 30 00:51:58.597: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 44.970717488s
May 30 00:52:00.640: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 47.013347983s
May 30 00:52:02.682: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 49.055331137s
May 30 00:52:04.724: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 51.097774706s
May 30 00:52:06.766: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 53.139581961s
May 30 00:52:08.808: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 55.181713502s
May 30 00:52:10.851: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 57.224180041s
May 30 00:52:12.893: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 59.266786115s
May 30 00:52:14.935: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m1.308838366s
May 30 00:52:16.977: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m3.35082582s
May 30 00:52:19.020: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m5.393657627s
May 30 00:52:21.062: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m7.435410111s
May 30 00:52:23.103: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m9.476986886s
May 30 00:52:25.146: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m11.519083215s
May 30 00:52:27.187: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m13.560964155s
May 30 00:52:29.233: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m15.607026699s
May 30 00:52:31.275: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m17.649044485s
May 30 00:52:33.318: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m19.691202974s
May 30 00:52:35.360: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m21.733188643s
May 30 00:52:37.402: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m23.775178249s
May 30 00:52:39.443: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m25.816978166s
May 30 00:52:41.485: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m27.858952343s
May 30 00:52:43.528: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m29.901064271s
May 30 00:52:45.570: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m31.943099208s
May 30 00:52:47.611: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m33.985017735s
May 30 00:52:49.653: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.026956734s
May 30 00:52:51.696: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.069147982s
May 30 00:52:53.738: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.111282669s
May 30 00:52:55.780: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.153473456s
May 30 00:52:57.825: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.19861773s
May 30 00:52:59.868: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.241475903s
May 30 00:53:01.910: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.28351971s
May 30 00:53:03.952: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.325751866s
May 30 00:53:05.997: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.370895234s
May 30 00:53:08.039: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.413049178s
May 30 00:53:10.081: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.454908726s
May 30 00:53:12.123: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.496919687s
May 30 00:53:14.165: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.538758711s
May 30 00:53:16.207: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.580595607s
May 30 00:53:18.256: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.629635946s
May 30 00:53:20.298: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.671170541s
May 30 00:53:22.339: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.713033653s
May 30 00:53:24.381: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.754881356s
May 30 00:53:26.423: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.796989702s
May 30 00:53:28.468: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.841151762s
May 30 00:53:30.511: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.884875905s
May 30 00:53:32.553: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.927032843s
May 30 00:53:34.596: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.96933629s
May 30 00:53:36.638: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m23.011294341s
May 30 00:53:38.680: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m25.053142338s
May 30 00:53:40.721: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m27.094590184s
May 30 00:53:42.763: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m29.136470602s
May 30 00:53:44.805: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m31.178269412s
May 30 00:53:46.847: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m33.220445544s
May 30 00:53:48.889: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m35.262311706s
May 30 00:53:50.931: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m37.304239651s
May 30 00:53:52.972: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m39.345949214s
May 30 00:53:55.014: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m41.387752204s
May 30 00:53:57.056: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m43.429416415s
May 30 00:53:59.098: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m45.471333642s
May 30 00:54:01.140: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m47.513442445s
May 30 00:54:03.182: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m49.555530229s
May 30 00:54:05.224: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m51.597641605s
May 30 00:54:07.266: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m53.639783156s
May 30 00:54:09.308: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m55.681818559s
May 30 00:54:11.350: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m57.723261089s
May 30 00:54:13.393: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m59.766868183s
May 30 00:54:15.435: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m1.808373194s
May 30 00:54:17.477: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m3.850255479s
May 30 00:54:19.519: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m5.892327333s
May 30 00:54:21.561: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m7.934412447s
May 30 00:54:23.604: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m9.97800678s
May 30 00:54:25.647: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.020211447s
May 30 00:54:27.689: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.062394394s
May 30 00:54:29.731: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.104104585s
May 30 00:54:31.773: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.146364021s
May 30 00:54:33.815: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.188275608s
May 30 00:54:35.857: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.230395526s
May 30 00:54:37.899: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.272207842s
May 30 00:54:39.941: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.314154572s
May 30 00:54:41.983: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.356319601s
May 30 00:54:44.025: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.398327854s
May 30 00:54:46.067: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.440249119s
May 30 00:54:48.109: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.482261578s
May 30 00:54:50.151: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.524299335s
May 30 00:54:52.192: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.566020648s
May 30 00:54:54.234: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.607641565s
May 30 00:54:56.276: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.649772732s
May 30 00:54:58.319: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.692117405s
May 30 00:55:00.360: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.733753291s
May 30 00:55:02.403: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.777048009s
May 30 00:55:04.445: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.818883179s
May 30 00:55:06.487: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.8606507s
May 30 00:55:08.529: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.902562467s
May 30 00:55:10.571: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.944510858s
May 30 00:55:12.613: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.986515558s
May 30 00:55:14.655: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m1.028523851s
May 30 00:55:16.697: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m3.070698287s
May 30 00:55:18.752: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m5.125899767s
May 30 00:55:20.794: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m7.167970276s
May 30 00:55:22.836: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m9.209688581s
May 30 00:55:24.878: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m11.251289214s
May 30 00:55:26.920: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m13.293316567s
May 30 00:55:28.962: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m15.335170154s
May 30 00:55:31.004: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m17.377683093s
May 30 00:55:33.046: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m19.419447802s
May 30 00:55:35.088: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m21.461468388s
May 30 00:55:37.130: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m23.503450924s
May 30 00:55:39.172: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m25.54511173s
May 30 00:55:41.213: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m27.586890213s
May 30 00:55:43.255: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m29.629018171s
May 30 00:55:45.298: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m31.671068418s
May 30 00:55:47.340: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m33.713160622s
May 30 00:55:49.382: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m35.755621692s
May 30 00:55:51.425: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m37.798824195s
May 30 00:55:53.468: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m39.841304315s
May 30 00:55:55.512: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m41.885456399s
May 30 00:55:57.557: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m43.930719007s
May 30 00:55:59.600: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m45.973148626s
May 30 00:56:01.642: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.015282204s
May 30 00:56:03.684: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4m50.057301417s
[1mSTEP[0m: Saw pod success
May 30 00:56:03.684: INFO: Pod "pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d" satisfied condition "success or failure"
May 30 00:56:03.752: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-jpxd pod pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d container projected-secret-volume-test: <nil>
[1mSTEP[0m: delete the pod
May 30 00:56:03.857: INFO: Waiting for pod pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d to disappear
May 30 00:56:03.899: INFO: Pod pod-projected-secrets-2612b0e2-9874-4680-9e06-e216bf172a8d no longer exists
[AfterEach] [sig-storage] Projected secret
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:56:03.899: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-940" for this suite.
May 30 00:56:10.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:56:11.673: INFO: namespace projected-940 deletion completed in 7.73217476s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath-v0][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 00:56:11.674: INFO: Driver csi-hostpath-v0 doesn't support InlineVolume -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:56:11.675: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath-v0]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver csi-hostpath-v0 doesn't support InlineVolume -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:126
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Downward API volume[0m 
  [1mshould provide container's cpu limit [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:56:11.676: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename downward-api
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 30 00:56:11.894: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29" in namespace "downward-api-8988" to be "success or failure"
May 30 00:56:11.936: INFO: Pod "downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29": Phase="Pending", Reason="", readiness=false. Elapsed: 41.644184ms
May 30 00:56:13.978: INFO: Pod "downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083650774s
May 30 00:56:16.020: INFO: Pod "downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125733834s
May 30 00:56:18.061: INFO: Pod "downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.167420973s
[1mSTEP[0m: Saw pod success
May 30 00:56:18.061: INFO: Pod "downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29" satisfied condition "success or failure"
May 30 00:56:18.103: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29 container client-container: <nil>
[1mSTEP[0m: delete the pod
May 30 00:56:18.213: INFO: Waiting for pod downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29 to disappear
May 30 00:56:18.255: INFO: Pod downwardapi-volume-8629c753-0de5-451f-9c96-207a52d7cf29 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 00:56:18.255: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "downward-api-8988" for this suite.
May 30 00:56:24.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 00:56:26.018: INFO: namespace downward-api-8988 deletion completed in 7.720297081s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Secrets[0m 
  [1moptional updates should be reflected in volume [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 00:56:26.018: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating secret with name s-test-opt-del-c866a44b-7b18-40c8-8043-a16e415fff27
[1mSTEP[0m: Creating secret with name s-test-opt-upd-a5c19a7a-0472-478a-a601-99a6415c526c
[1mSTEP[0m: Creating the pod
[1mSTEP[0m: Deleting secret s-test-opt-del-c866a44b-7b18-40c8-8043-a16e415fff27
[1mSTEP[0m: Updating secret s-test-opt-upd-a5c19a7a-0472-478a-a601-99a6415c526c
[1mSTEP[0m: Creating secret with name s-test-opt-create-94bab775-6f3a-424d-b7bf-ecea49b5ef82
[1mSTEP[0m: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "secrets-2860".
[1mSTEP[0m: Found 11 events.
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:26 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {default-scheduler } Scheduled: Successfully assigned secrets-2860/pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e to e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:28 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:28 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container dels-volume-test
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:31 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container dels-volume-test
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:31 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:31 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container upds-volume-test
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:33 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container upds-volume-test
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:33 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:33 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container creates-volume-test
May 30 01:02:06.836: INFO: At 2019-05-30 00:56:34 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container creates-volume-test
May 30 01:02:06.836: INFO: At 2019-05-30 00:58:09 -0700 PDT - event for pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod secrets-2860/pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e
May 30 01:02:06.925: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 30 01:02:06.926: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:02:06.926: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 30 01:02:06.926: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:02:06.926: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:02:06.926: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:02:06.926: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:02:06.926: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:02:06.926: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 30 01:02:06.926: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 30 01:02:06.926: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 30 01:02:06.926: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 30 01:02:06.926: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:02:06.926: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 01:02:06.926: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 01:02:06.926: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:02:06.926: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 30 01:02:06.926: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 30 01:02:06.926: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:02:06.926: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:02:06.926: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:02:06.926: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:02:06.926: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:02:06.926: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:02:06.926: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 30 01:02:06.927: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 30 01:02:06.927: INFO: pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e       e2e-test-peterhornyack-windows-node-group-jpxd  Failed          [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:56:26 -0700 PDT  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:02:05 -0700 PDT ContainersNotReady containers with unready status: [dels-volume-test upds-volume-test creates-volume-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:02:05 -0700 PDT ContainersNotReady containers with unready status: [dels-volume-test upds-volume-test creates-volume-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 00:56:26 -0700 PDT  }]
May 30 01:02:06.927: INFO: 
May 30 01:02:06.976: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 30 01:02:07.018: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:83197,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:01:28 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:01:28 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:01:28 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:01:28 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:02:07.019: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 30 01:02:07.060: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 30 01:02:07.118: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.118: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.118: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.118: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:02:07.118: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:02:07.118: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.118: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.118: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.118: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:02:07.118: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:02:07.118: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.118: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.118: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.118: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.269: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 30 01:02:07.269: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:02:07.311: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:83182,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{KernelDeadlock False 2019-05-30 01:01:14 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 01:01:14 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-30 01:01:14 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-30 01:01:14 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 01:01:14 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-30 01:01:14 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 01:01:14 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:01:22 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:01:22 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:01:22 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:01:22 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:02:07.311: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:02:07.352: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:02:07.404: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:02:07.404: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 30 01:02:07.404: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.404: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:02:07.404: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:02:07.404: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.404: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:02:07.404: INFO: 	Container coredns ready: true, restart count 0
May 30 01:02:07.404: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:02:07.404: INFO: 	Container autoscaler ready: true, restart count 0
May 30 01:02:07.404: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:02:07.404: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 01:02:07.404: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.404: INFO: 	Container event-exporter ready: true, restart count 0
May 30 01:02:07.404: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:02:07.404: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:02:07.404: INFO: 	Container default-http-backend ready: true, restart count 0
May 30 01:02:07.404: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.404: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:02:07.404: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:02:07.565: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:02:07.565: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:02:07.606: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:83276,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentContainerdRestart False 2019-05-30 01:02:00 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 01:02:00 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-30 01:02:00 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-30 01:02:00 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 01:02:00 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-30 01:02:00 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 01:02:00 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:01:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:01:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:01:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:01:56 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:02:07.607: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:02:07.648: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:02:07.702: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.702: INFO: 	Container heapster ready: true, restart count 0
May 30 01:02:07.702: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 01:02:07.702: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 30 01:02:07.702: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.702: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:02:07.702: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:02:07.702: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.702: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:02:07.702: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:02:07.702: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 30 01:02:07.702: INFO: 	Container coredns ready: true, restart count 0
May 30 01:02:07.702: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 30 01:02:07.703: INFO: 	Container metrics-server ready: true, restart count 0
May 30 01:02:07.703: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 30 01:02:07.872: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:02:07.872: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:02:07.914: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:83278,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:02:01 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:02:01 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:02:01 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:02:01 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:02:07.914: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:02:07.956: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:02:08.161: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:02:08.161: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:02:08.203: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:83254,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:01:52 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:01:52 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:01:52 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:01:52 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:02:08.203: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:02:08.244: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:02:08.448: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:02:08.448: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:02:08.489: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:83272,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 01:01:09 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 01:01:14 -0700 PDT}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:01:59 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:01:59 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:01:59 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready False 2019-05-30 01:01:59 -0700 PDT 2019-05-30 01:01:09 -0700 PDT KubeletNotReady PLEG is not healthy: pleg was last seen active 3m55.6762396s ago; threshold is 3m0s.}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/etcd@sha256:462024728f8360157455091329616d9b55d4718533b0812b230d612a5bc5ce30 e2eteam/etcd:3.3.10] 4350004937} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/sample-apiserver@sha256:a11a8656e8013ce21acd0074574f8ac9deaccc3b99486c7d59f764fe4d4f2d55 e2eteam/sample-apiserver:1.10] 4331611162} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:02:08.489: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:02:08.531: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:02:08.574: INFO: pod-secrets-5deea6d7-7a71-4532-ae39-7ab5d07d788e started at 2019-05-30 00:56:26 -0700 PDT (0+3 container statuses recorded)
May 30 01:02:08.574: INFO: 	Container creates-volume-test ready: false, restart count 0
May 30 01:02:08.574: INFO: 	Container dels-volume-test ready: false, restart count 0
May 30 01:02:08.574: INFO: 	Container upds-volume-test ready: false, restart count 0
May 30 01:02:08.771: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:02:08.771: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 01:02:08.813: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 01:01:09 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 01:01:14 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "secrets-2860" for this suite.
May 30 01:02:14.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 01:02:16.560: INFO: namespace secrets-2860 deletion completed in 7.746943108s

[91m[1m• Failure [350.542 seconds][0m
[sig-storage] Secrets
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33[0m
  [91m[1moptional updates should be reflected in volume [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mTimed out after 240.001s.
  Expected
      <string>: Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      Error reading file /etc/secret-volumes/create/data-1: open C:\etc\secret-volumes\create\data-1: The system cannot find the file specified., retrying
      
  to contain substring
      <string>: value-1[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:366
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 01:02:16.561: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating a pod to test downward API volume plugin
May 30 01:02:16.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c" in namespace "projected-4353" to be "success or failure"
May 30 01:02:16.856: INFO: Pod "downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c": Phase="Pending", Reason="", readiness=false. Elapsed: 41.542488ms
May 30 01:02:18.898: INFO: Pod "downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083613867s
May 30 01:02:20.941: INFO: Pod "downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125940771s
May 30 01:02:22.983: INFO: Pod "downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.167872692s
May 30 01:02:25.025: INFO: Pod "downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.210035433s
[1mSTEP[0m: Saw pod success
May 30 01:02:25.025: INFO: Pod "downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c" satisfied condition "success or failure"
May 30 01:02:25.067: INFO: Trying to get logs from node e2e-test-peterhornyack-windows-node-group-9q9v pod downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c container client-container: <nil>
[1mSTEP[0m: delete the pod
May 30 01:02:25.176: INFO: Waiting for pod downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c to disappear
May 30 01:02:25.218: INFO: Pod downwardapi-volume-bb67535e-1091-4985-a40d-842e167b351c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 01:02:25.218: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-4353" for this suite.
May 30 01:02:31.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 01:02:32.983: INFO: namespace projected-4353 deletion completed in 7.721273225s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Secrets[0m 
  [1mshould fail to create secret due to empty secret key [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 01:02:32.983: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename secrets
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating projection with secret that has name secret-emptykey-test-f4fdc2cb-b4dc-4ee4-9df8-718ebc9261da
[AfterEach] [sig-api-machinery] Secrets
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 01:02:33.193: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "secrets-3605" for this suite.
May 30 01:02:39.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 01:02:40.952: INFO: namespace secrets-3605 deletion completed in 7.716309645s
[32m•[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] Projected downwardAPI[0m 
  [1mshould update annotations on modification [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 01:02:40.952: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename projected
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating the pod
May 30 01:06:09.986: INFO: Successfully updated pod "annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a"
[AfterEach] [sig-storage] Projected downwardAPI
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "projected-7885".
[1mSTEP[0m: Found 5 events.
May 30 01:08:10.035: INFO: At 2019-05-30 01:02:41 -0700 PDT - event for annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a: {default-scheduler } Scheduled: Successfully assigned projected-7885/annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a to e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:08:10.035: INFO: At 2019-05-30 01:02:43 -0700 PDT - event for annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/mounttest:1.0" already present on machine
May 30 01:08:10.035: INFO: At 2019-05-30 01:02:43 -0700 PDT - event for annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container client-container
May 30 01:08:10.035: INFO: At 2019-05-30 01:02:45 -0700 PDT - event for annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container client-container
May 30 01:08:10.035: INFO: At 2019-05-30 01:06:14 -0700 PDT - event for annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod projected-7885/annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a
May 30 01:08:10.123: INFO: POD                                                    NODE                                            PHASE    GRACE  CONDITIONS
May 30 01:08:10.123: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:08:10.123: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 30 01:08:10.123: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:08:10.123: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:08:10.123: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:08:10.123: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:08:10.124: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:08:10.124: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 30 01:08:10.124: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 30 01:08:10.124: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 30 01:08:10.124: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 30 01:08:10.124: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:08:10.124: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 01:08:10.124: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 01:08:10.124: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:08:10.124: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 30 01:08:10.124: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 30 01:08:10.124: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:08:10.124: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:08:10.124: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:08:10.124: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:08:10.124: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:08:10.124: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:08:10.124: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master                   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 30 01:08:10.124: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6        Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 30 01:08:10.124: INFO: annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a   e2e-test-peterhornyack-windows-node-group-jpxd  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:02:41 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:06:07 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:06:07 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:02:41 -0700 PDT  }]
May 30 01:08:10.124: INFO: 
May 30 01:08:10.168: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 30 01:08:10.209: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:84100,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:07:29 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:07:29 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:07:29 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:07:29 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:08:10.210: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 30 01:08:10.251: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 30 01:08:10.297: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.297: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.297: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.297: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:08:10.297: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:08:10.297: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.297: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.297: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.297: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.297: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.297: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.297: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.297: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:08:10.297: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:08:10.483: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 30 01:08:10.483: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:08:10.524: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:84082,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentDockerRestart False 2019-05-30 01:07:18 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-30 01:07:18 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 01:07:18 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-30 01:07:18 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 01:07:18 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-30 01:07:18 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-30 01:07:18 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:07:23 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:07:23 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:07:23 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:07:23 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:08:10.524: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:08:10.565: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:08:10.614: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.614: INFO: 	Container event-exporter ready: true, restart count 0
May 30 01:08:10.614: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:08:10.614: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:08:10.614: INFO: 	Container default-http-backend ready: true, restart count 0
May 30 01:08:10.614: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.614: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:08:10.614: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:08:10.614: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:08:10.614: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 01:08:10.614: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:08:10.614: INFO: 	Container coredns ready: true, restart count 0
May 30 01:08:10.614: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:08:10.614: INFO: 	Container autoscaler ready: true, restart count 0
May 30 01:08:10.614: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:08:10.614: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 30 01:08:10.614: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.615: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:08:10.615: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:08:10.615: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.790: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:08:10.790: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:08:10.832: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:84178,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{KernelDeadlock False 2019-05-30 01:08:04 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 01:08:04 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-30 01:08:04 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 01:08:04 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-30 01:08:04 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 01:08:04 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-30 01:08:04 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:07:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:07:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:07:56 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:07:56 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:08:10.832: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:08:10.873: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:08:10.921: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 30 01:08:10.921: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.921: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:08:10.921: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:08:10.921: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.921: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:08:10.921: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:08:10.921: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 30 01:08:10.921: INFO: 	Container coredns ready: true, restart count 0
May 30 01:08:10.921: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.921: INFO: 	Container metrics-server ready: true, restart count 0
May 30 01:08:10.922: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 30 01:08:10.922: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 30 01:08:10.922: INFO: 	Container heapster ready: true, restart count 0
May 30 01:08:10.922: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 01:08:11.094: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:08:11.094: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:08:11.136: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:84174,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:08:02 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:08:02 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:08:02 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:08:02 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:08:11.136: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:08:11.178: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:08:11.377: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:08:11.377: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:08:11.419: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:84150,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:07:53 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:07:53 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:07:53 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:07:53 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:08:11.419: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:08:11.461: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:08:11.666: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:08:11.666: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:08:11.707: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:84194,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:08:09 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:08:09 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:08:09 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:08:09 -0700 PDT 2019-05-30 01:06:09 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/etcd@sha256:462024728f8360157455091329616d9b55d4718533b0812b230d612a5bc5ce30 e2eteam/etcd:3.3.10] 4350004937} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/sample-apiserver@sha256:a11a8656e8013ce21acd0074574f8ac9deaccc3b99486c7d59f764fe4d4f2d55 e2eteam/sample-apiserver:1.10] 4331611162} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:08:11.707: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:08:11.749: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:08:11.793: INFO: annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a started at 2019-05-30 01:02:41 -0700 PDT (0+1 container statuses recorded)
May 30 01:08:11.793: INFO: 	Container client-container ready: true, restart count 0
May 30 01:08:13.083: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:08:13.083: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "projected-7885" for this suite.
May 30 01:18:13.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 01:18:14.342: INFO: namespace: projected-7885, resource: pods, items remaining: 1
May 30 01:18:14.928: INFO: namespace: projected-7885, DeletionTimetamp: 2019-05-30 01:08:13 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 30 01:18:14.970: INFO: namespace: projected-7885, total namespaces: 5, active: 4, terminating: 1
May 30 01:18:15.011: INFO: POD                                                   NODE                                            PHASE    GRACE  CONDITIONS
May 30 01:18:15.011: INFO: annotationupdate9b64442f-e9d2-4ce3-a148-636df8c1bf3a  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:02:41 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:06:07 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:06:07 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:02:41 -0700 PDT  }]
May 30 01:18:15.011: INFO: 
May 30 01:18:15.011: INFO: Couldn't delete ns: "projected-7885": namespace projected-7885 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace projected-7885 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})

[91m[1m• Failure [934.060 seconds][0m
[sig-storage] Projected downwardAPI
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33[0m
  [91m[1mshould update annotations on modification [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mTimed out after 120.006s.
  Expected
      <string>: content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      content of file "/etc/podinfo/annotations": builder="bar"
      kubernetes.io/config.seen="2019-05-30T08:02:41.1135909Z"
      kubernetes.io/config.source="api"
      
  to contain substring
      <string>: builder="foo"
      [0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:181
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] CSI Volumes[0m [90m[Driver: csi-hostpath][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould provision storage with mount options[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 01:18:15.014: INFO: Driver csi-hostpath doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 01:18:15.017: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.003 seconds][0m
[sig-storage] CSI Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: csi-hostpath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/csi_volumes.go:59[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould provision storage with mount options [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:157[0m

      [36mDriver csi-hostpath doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] Probing container[0m 
  [1mshould be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 01:18:15.018: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename container-probe
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: Creating pod liveness-exec in namespace container-probe-4561
May 30 01:22:13.325: INFO: Started pod liveness-exec in namespace container-probe-4561
[1mSTEP[0m: checking the pod's current state and verifying that restartCount is present
May 30 01:22:13.367: INFO: Initial restart count of pod liveness-exec is 0
May 30 01:26:14.352: INFO: pod container-probe-4561/liveness-exec - expected number of restarts: 1, found restarts: 0
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] Probing container
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
[1mSTEP[0m: Collecting events from namespace "container-probe-4561".
[1mSTEP[0m: Found 7 events.
May 30 01:26:14.446: INFO: At 2019-05-30 01:18:15 -0700 PDT - event for liveness-exec: {default-scheduler } Scheduled: Successfully assigned container-probe-4561/liveness-exec to e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:26:14.446: INFO: At 2019-05-30 01:18:18 -0700 PDT - event for liveness-exec: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Pulled: Container image "e2eteam/busybox:1.29" already present on machine
May 30 01:26:14.446: INFO: At 2019-05-30 01:18:18 -0700 PDT - event for liveness-exec: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Created: Created container liveness
May 30 01:26:14.446: INFO: At 2019-05-30 01:18:20 -0700 PDT - event for liveness-exec: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Started: Started container liveness
May 30 01:26:14.446: INFO: At 2019-05-30 01:22:20 -0700 PDT - event for liveness-exec: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Unhealthy: Liveness probe failed: cat: can't open '/tmp/health': No such file or directory

May 30 01:26:14.446: INFO: At 2019-05-30 01:22:24 -0700 PDT - event for liveness-exec: {taint-controller } TaintManagerEviction: Cancelling deletion of Pod container-probe-4561/liveness-exec
May 30 01:26:14.446: INFO: At 2019-05-30 01:26:14 -0700 PDT - event for liveness-exec: {kubelet e2e-test-peterhornyack-windows-node-group-jpxd} Killing: Stopping container liveness
May 30 01:26:14.535: INFO: POD                                                    NODE                                      PHASE    GRACE  CONDITIONS
May 30 01:26:14.535: INFO: coredns-5b969f4c88-gsjpw                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:26:14.535: INFO: coredns-5b969f4c88-mvhtd                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:39 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:25 -0700 PDT  }]
May 30 01:26:14.535: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master   e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:26:14.535: INFO: etcd-server-e2e-test-peterhornyack-master              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:34 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:26:14.535: INFO: etcd-server-events-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:26:14.535: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w                 e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:26:14.535: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:26:14.535: INFO: fluentd-gcp-v3.2.0-fr5zq                               e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:23 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:20 -0700 PDT  }]
May 30 01:26:14.535: INFO: fluentd-gcp-v3.2.0-r5s9z                               e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:06:10 -0700 PDT  }]
May 30 01:26:14.535: INFO: fluentd-gcp-v3.2.0-wp9vf                               e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:52 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:48 -0700 PDT  }]
May 30 01:26:14.535: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55                e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:41 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  }]
May 30 01:26:14.535: INFO: kube-addon-manager-e2e-test-peterhornyack-master       e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:35 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:26:14.535: INFO: kube-apiserver-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:45 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 01:26:14.535: INFO: kube-controller-manager-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:17 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:10 -0700 PDT  }]
May 30 01:26:14.535: INFO: kube-dns-autoscaler-97df449df-7v474                    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:26:14.535: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh    e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:13 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  }]
May 30 01:26:14.536: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6    e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:12 -0700 PDT  }]
May 30 01:26:14.536: INFO: kube-scheduler-e2e-test-peterhornyack-master           e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:26:14.536: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v                  e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:26:14.536: INFO: l7-default-backend-8f479dd9-hnbtn                      e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:26:14.536: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master  e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:31 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:01:11 -0700 PDT  }]
May 30 01:26:14.536: INFO: metadata-proxy-v0.1-8mhrb                              e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:20 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:26:14.536: INFO: metadata-proxy-v0.1-gqcgn                              e2e-test-peterhornyack-minion-group-5wdh  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:09 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:33 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:08 -0700 PDT  }]
May 30 01:26:14.536: INFO: metadata-proxy-v0.1-w99mm                              e2e-test-peterhornyack-master             Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:02:04 -0700 PDT  }]
May 30 01:26:14.536: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6                 e2e-test-peterhornyack-minion-group-fzx6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:40 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-29 16:05:32 -0700 PDT  }]
May 30 01:26:14.536: INFO: 
May 30 01:26:14.578: INFO: 
Logging node info for node e2e-test-peterhornyack-master
May 30 01:26:14.625: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-master,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-master,UID:5a2fc962-90c7-4013-ae90-fb4b902fb4df,ResourceVersion:86676,Generation:0,CreationTimestamp:2019-05-29 16:02:04 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-1,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-master,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.0.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-master,Unschedulable:true,Taints:[{node-under-test false NoSchedule <nil>} {node.kubernetes.io/unschedulable  NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{16684785664 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3878420480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{32 0} {<nil>} 32 DecimalSI},cpu: {{1 0} {<nil>} 1 DecimalSI},ephemeral-storage: {{15016307073 0} {<nil>} 15016307073 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{3616276480 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:02:04 -0700 PDT 2019-05-29 16:02:04 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:25:32 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:25:32 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:25:32 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:25:32 -0700 PDT 2019-05-29 16:02:04 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.2} {ExternalIP 146.148.105.213} {InternalDNS e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-master.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:804d0c88641256f447b18f4e6b74052c,SystemUUID:804D0C88-6412-56F4-47B1-8F4E6B74052C,BootID:435bd611-79d4-413f-84f2-66457dad30cc,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/etcd@sha256:17da501f5d2a675be46040422a27b7cc21b8a43895ac998b171db1c346f361f7 k8s.gcr.io/etcd:3.3.10-0] 258116302} {[k8s.gcr.io/kube-apiserver:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 231270667} {[k8s.gcr.io/kube-controller-manager:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 176865349} {[k8s.gcr.io/kube-scheduler:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87506773} {[k8s.gcr.io/kube-addon-manager@sha256:672794ee3582521eb8bc4f257d0f70c92893f1989f39a200f9c84bcfe1aea7c9 k8s.gcr.io/kube-addon-manager:v9.0] 83077558} {[k8s.gcr.io/ingress-gce-glbc-amd64@sha256:14f14351a03038b238232e60850a9cfa0dffbed0590321ef84216a432accc1ca k8s.gcr.io/ingress-gce-glbc-amd64:v1.2.3] 71797285} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/etcd-empty-dir-cleanup@sha256:a10c61bd700a14b43b3a45a1791612ef9907c3ef3ba3b1731e0ab0675248d351 k8s.gcr.io/etcd-empty-dir-cleanup:3.3.10.0] 32791339} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:26:14.626: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-master
May 30 01:26:14.667: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-master
May 30 01:26:14.715: INFO: kube-apiserver-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:26:14.715: INFO: kube-controller-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:26:14.715: INFO: kube-scheduler-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:26:14.715: INFO: etcd-empty-dir-cleanup-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:26:14.715: INFO: etcd-server-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:26:14.715: INFO: l7-lb-controller-v1.2.3-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:26:14.715: INFO: metadata-proxy-v0.1-w99mm started at 2019-05-29 16:02:04 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:14.715: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:26:14.715: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:26:14.715: INFO: etcd-server-events-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:26:14.715: INFO: kube-addon-manager-e2e-test-peterhornyack-master started at <nil> (0+0 container statuses recorded)
May 30 01:26:14.715: INFO: fluentd-gcp-v3.2.0-r5s9z started at 2019-05-29 16:06:10 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:14.715: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:26:14.715: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:26:14.884: INFO: 
Latency metrics for node e2e-test-peterhornyack-master
May 30 01:26:14.884: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:26:14.927: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-5wdh,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-5wdh,UID:9ca19318-399c-4041-8925-ef1f19470ecf,ResourceVersion:86665,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-5wdh,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.5.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-5wdh,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{ReadonlyFilesystem False 2019-05-30 01:25:29 -0700 PDT 2019-05-29 16:05:06 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentUnregisterNetDevice False 2019-05-30 01:25:29 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {FrequentKubeletRestart False 2019-05-30 01:25:29 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 01:25:29 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {FrequentContainerdRestart False 2019-05-30 01:25:29 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 01:25:29 -0700 PDT 2019-05-29 16:10:08 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {KernelDeadlock False 2019-05-30 01:25:29 -0700 PDT 2019-05-29 16:05:06 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {NetworkUnavailable False 2019-05-29 16:05:09 -0700 PDT 2019-05-29 16:05:09 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:25:24 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:25:24 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:25:24 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:25:24 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.7} {ExternalIP 104.154.141.122} {InternalDNS e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-5wdh.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:befab8e595f78d9542bb248f3fde62a0,SystemUUID:BEFAB8E5-95F7-8D95-42BB-248F3FDE62A0,BootID:a69f529f-06bd-42a6-82e4-d48b95d347ef,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[k8s.gcr.io/kubernetes-dashboard-amd64@sha256:0ae6b69432e78069c5ce2bcde0fe409c5c4d6f0f4d9cd50a17974fea38898747 k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.1] 121711221} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/fluentd-gcp-scaler@sha256:a5ace7506d393c4ed65eb2cbb6312c64ab357fcea16dff76b9055bc6e498e5ff k8s.gcr.io/fluentd-gcp-scaler:0.5.1] 86637208} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[k8s.gcr.io/event-exporter@sha256:16ca66e2b5dc7a1ce6a5aafcb21d0885828b75cdfc08135430480f7ad2364adc k8s.gcr.io/event-exporter:v0.2.4] 47261019} {[k8s.gcr.io/cluster-proportional-autoscaler-amd64@sha256:12370202895b621a2ac28226292e4578598f13c1502aa4d3ee90fff4325d9275 k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.4.0] 45853555} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/defaultbackend-amd64@sha256:4dc5e07c8ca4e23bddb3153737d7b8c556e5fb2f29c4558b7cd6e6df99c512c7 k8s.gcr.io/defaultbackend-amd64:1.5] 5132544} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:26:14.927: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:26:14.968: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:26:15.016: INFO: coredns-5b969f4c88-gsjpw started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:26:15.017: INFO: 	Container coredns ready: true, restart count 0
May 30 01:26:15.017: INFO: kube-dns-autoscaler-97df449df-7v474 started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:26:15.017: INFO: 	Container autoscaler ready: true, restart count 0
May 30 01:26:15.017: INFO: fluentd-gcp-scaler-7db4984bf4-nj6gz started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:26:15.017: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
May 30 01:26:15.017: INFO: metadata-proxy-v0.1-gqcgn started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:15.017: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:26:15.017: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:26:15.017: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-5wdh started at <nil> (0+0 container statuses recorded)
May 30 01:26:15.017: INFO: l7-default-backend-8f479dd9-hnbtn started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:26:15.017: INFO: 	Container default-http-backend ready: true, restart count 0
May 30 01:26:15.017: INFO: fluentd-gcp-v3.2.0-wp9vf started at 2019-05-29 16:05:48 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:15.017: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:26:15.017: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:26:15.017: INFO: kubernetes-dashboard-85bcf5dbf8-4ks9v started at 2019-05-29 16:05:09 -0700 PDT (0+1 container statuses recorded)
May 30 01:26:15.017: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 30 01:26:15.017: INFO: event-exporter-v0.2.4-65d8d98768-v6s2w started at 2019-05-29 16:05:09 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:15.017: INFO: 	Container event-exporter ready: true, restart count 0
May 30 01:26:15.017: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:26:15.182: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-5wdh
May 30 01:26:15.182: INFO: 
Logging node info for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:26:15.223: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-minion-group-fzx6,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-minion-group-fzx6,UID:7b64a731-1eb9-4ca7-bcf0-c6b4bfbc801d,ResourceVersion:86779,Generation:0,CreationTimestamp:2019-05-29 16:05:08 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/metadata-proxy-ready: true,beta.kubernetes.io/os: linux,cloud.google.com/metadata-proxy-ready: true,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-minion-group-fzx6,kubernetes.io/os: linux,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.4.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-minion-group-fzx6,Unschedulable:false,Taints:[{node-under-test false NoSchedule <nil>}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{101241290752 0} {<nil>}  BinarySI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7841865728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{91117161526 0} {<nil>} 91117161526 DecimalSI},hugepages-2Mi: {{0 0} {<nil>} 0 DecimalSI},memory: {{7579721728 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{FrequentContainerdRestart False 2019-05-30 01:26:14 -0700 PDT 2019-05-29 16:10:10 -0700 PDT FrequentContainerdRestart containerd is functioning properly} {CorruptDockerOverlay2 False 2019-05-30 01:26:14 -0700 PDT 2019-05-29 16:10:07 -0700 PDT CorruptDockerOverlay2 docker overlay2 is functioning properly} {FrequentUnregisterNetDevice False 2019-05-30 01:26:14 -0700 PDT 2019-05-29 16:10:08 -0700 PDT UnregisterNetDevice node is functioning properly} {KernelDeadlock False 2019-05-30 01:26:14 -0700 PDT 2019-05-29 16:05:07 -0700 PDT KernelHasNoDeadlock kernel has no deadlock} {ReadonlyFilesystem False 2019-05-30 01:26:14 -0700 PDT 2019-05-29 16:05:07 -0700 PDT FilesystemIsNotReadOnly Filesystem is not read-only} {FrequentKubeletRestart False 2019-05-30 01:26:14 -0700 PDT 2019-05-29 16:10:08 -0700 PDT FrequentKubeletRestart kubelet is functioning properly} {FrequentDockerRestart False 2019-05-30 01:26:14 -0700 PDT 2019-05-29 16:10:09 -0700 PDT FrequentDockerRestart docker is functioning properly} {NetworkUnavailable False 2019-05-29 16:05:08 -0700 PDT 2019-05-29 16:05:08 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:25:58 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:25:58 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:25:58 -0700 PDT 2019-05-29 16:05:08 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:25:58 -0700 PDT 2019-05-29 16:05:09 -0700 PDT KubeletReady kubelet is posting ready status. AppArmor enabled}],Addresses:[{InternalIP 10.40.0.6} {ExternalIP 35.222.68.239} {InternalDNS e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-minion-group-fzx6.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:468d9744b5596c194192400073e124a9,SystemUUID:468D9744-B559-6C19-4192-400073E124A9,BootID:43b38037-6082-435e-8848-6c41ac58f8d2,KernelVersion:4.14.94+,OSImage:Container-Optimized OS from Google,ContainerRuntimeVersion:docker://18.9.3,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:linux,Architecture:amd64,},Images:[{[gcr.io/stackdriver-agents/stackdriver-logging-agent@sha256:6c8574a40816676cd908cfa89d16463002b56ca05fa76d0c912e116bc0ab867e gcr.io/stackdriver-agents/stackdriver-logging-agent:1.6.8] 264721247} {[nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 nginx:1.7.9] 91664166} {[k8s.gcr.io/kube-proxy:v1.15.0-alpha.0.1887_bae0630ef897d6-dirty] 87361539} {[k8s.gcr.io/heapster-amd64@sha256:9fae0af136ce0cf4f88393b3670f7139ffc464692060c374d2ae748e13144521 k8s.gcr.io/heapster-amd64:v1.6.0-beta.1] 76016169} {[ubuntu@sha256:b36667c98cf8f68d4b7f1fb8e01f742c2ed26b5f0c965a788e98dfe589a4b3e4 ubuntu:latest] 69859102} {[k8s.gcr.io/prometheus-to-sd@sha256:14666989f40bb7c896c3e775a93c6873e2b791d65bc65579f58a078b7f9a764e k8s.gcr.io/prometheus-to-sd:v0.5.0] 41861013} {[k8s.gcr.io/metrics-server-amd64@sha256:78938f933822856f443e6827fe5b37d6cc2f74ae888ac8b33d06fdbe5f8c658b k8s.gcr.io/metrics-server-amd64:v0.3.1] 40767713} {[k8s.gcr.io/coredns@sha256:02382353821b12c21b062c59184e227e001079bb13ebd01f9d3270ba0fcbf1e4 k8s.gcr.io/coredns:1.3.1] 40303560} {[k8s.gcr.io/addon-resizer@sha256:a31822f30e947885d038812f4a5a5675e72f92c06cef17b1989c80426aa89012 k8s.gcr.io/addon-resizer:1.8.4] 38349857} {[nginx@sha256:0fd68ec4b64b8dbb2bef1f1a5de9d47b658afd3635dc9c45bf0cbeac46e72101 nginx:1.15-alpine] 16087791} {[k8s.gcr.io/metadata-proxy@sha256:80fb815ae179d4f177a880f0b9af65fe9742c94d626d1904f642eba8610be5bf k8s.gcr.io/metadata-proxy:v0.1.11] 8965381} {[k8s.gcr.io/pause@sha256:f78411e19d84a252e53bff71a4407a5686c46983a2c2eeed83929b888179acea k8s.gcr.io/pause:3.1] 742472}],VolumesInUse:[],VolumesAttached:[],Config:&NodeConfigStatus{Assigned:nil,Active:nil,LastKnownGood:nil,Error:,},},}
May 30 01:26:15.224: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:26:15.265: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:26:15.313: INFO: kube-proxy-e2e-test-peterhornyack-minion-group-fzx6 started at <nil> (0+0 container statuses recorded)
May 30 01:26:15.314: INFO: fluentd-gcp-v3.2.0-fr5zq started at 2019-05-29 16:06:20 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:15.314: INFO: 	Container fluentd-gcp ready: true, restart count 0
May 30 01:26:15.314: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:26:15.314: INFO: metadata-proxy-v0.1-8mhrb started at 2019-05-29 16:05:08 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:15.314: INFO: 	Container metadata-proxy ready: true, restart count 0
May 30 01:26:15.314: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
May 30 01:26:15.314: INFO: coredns-5b969f4c88-mvhtd started at 2019-05-29 16:05:25 -0700 PDT (0+1 container statuses recorded)
May 30 01:26:15.314: INFO: 	Container coredns ready: true, restart count 0
May 30 01:26:15.314: INFO: metrics-server-v0.3.1-7d9cf58c5c-dksn6 started at 2019-05-29 16:05:32 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:15.314: INFO: 	Container metrics-server ready: true, restart count 0
May 30 01:26:15.314: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 30 01:26:15.314: INFO: heapster-v1.6.0-beta.1-6796bf47bf-cqs55 started at 2019-05-29 16:05:33 -0700 PDT (0+2 container statuses recorded)
May 30 01:26:15.314: INFO: 	Container heapster ready: true, restart count 0
May 30 01:26:15.314: INFO: 	Container heapster-nanny ready: true, restart count 0
May 30 01:26:15.473: INFO: 
Latency metrics for node e2e-test-peterhornyack-minion-group-fzx6
May 30 01:26:15.473: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:26:15.514: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-1vjk,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-1vjk,UID:39214e7b-3bfd-490b-9a21-eb35214c3d48,ResourceVersion:86748,Generation:0,CreationTimestamp:2019-05-29 16:14:34 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-1vjk,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.2.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-1vjk,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:35 -0700 PDT 2019-05-29 16:14:35 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:26:04 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:26:04 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:26:04 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:26:04 -0700 PDT 2019-05-29 16:14:34 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.5} {ExternalIP 104.197.5.20} {InternalDNS e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-1vjk.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-1vjk,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/redis@sha256:8c9fd0656356dcad4ed60c16931ea928cc6dc97a4a100cdf7a26f7446fa5c9f1 e2eteam/redis:1.0] 4349854258} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/authenticated-image-pulling/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/authenticated-image-pulling/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:26:15.514: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:26:15.557: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:26:15.757: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-1vjk
May 30 01:26:15.757: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:26:15.798: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-9q9v,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-9q9v,UID:cb28431f-383d-412b-96a8-334b9465f2ab,ResourceVersion:86726,Generation:0,CreationTimestamp:2019-05-29 16:14:14 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-9q9v,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.3.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-9q9v,Unschedulable:false,Taints:[],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:14 -0700 PDT 2019-05-29 16:14:14 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:25:55 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:25:55 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:25:55 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready True 2019-05-30 01:25:55 -0700 PDT 2019-05-29 16:14:14 -0700 PDT KubeletReady kubelet is posting ready status}],Addresses:[{InternalIP 10.40.0.4} {ExternalIP 35.225.201.100} {InternalDNS e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-9q9v.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-9q9v,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine e2eteam/nginx:1.15-alpine] 4340785269} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/liveness@sha256:15512c0338c5142c217f50f2e9913ccea639069284b1f8bf45a8e74c0d299d9c e2eteam/liveness:1.1] 4288934732} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/kitten@sha256:43e92993512cd4b1439c54979ec444d3bc7460183cb90cb6073c543075d6501a e2eteam/kitten:1.0] 4284294634} {[e2eteam/entrypoint-tester@sha256:1a37af31b33bf9a6c90597e17433b14cfa84a0825ae204adc029714ac0ced9e0 e2eteam/entrypoint-tester:1.0] 4281099802} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:26:15.798: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:26:15.840: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:26:16.042: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-9q9v
May 30 01:26:16.042: INFO: 
Logging node info for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:26:16.083: INFO: Node Info: &Node{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-test-peterhornyack-windows-node-group-jpxd,GenerateName:,Namespace:,SelfLink:/api/v1/nodes/e2e-test-peterhornyack-windows-node-group-jpxd,UID:be2c16bf-c52a-4f33-8e29-353ee370eb68,ResourceVersion:86767,Generation:0,CreationTimestamp:2019-05-29 16:14:43 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{beta.kubernetes.io/arch: amd64,beta.kubernetes.io/instance-type: n1-standard-2,beta.kubernetes.io/os: windows,failure-domain.beta.kubernetes.io/region: us-central1,failure-domain.beta.kubernetes.io/zone: us-central1-b,kubernetes.io/arch: amd64,kubernetes.io/hostname: e2e-test-peterhornyack-windows-node-group-jpxd,kubernetes.io/os: windows,},Annotations:map[string]string{node.alpha.kubernetes.io/ttl: 0,volumes.kubernetes.io/controller-managed-attach-detach: true,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:NodeSpec{PodCIDR:10.64.1.0/24,DoNotUse_ExternalID:,ProviderID:gce://peterhornyack-prod-no-enforcer/us-central1-b/e2e-test-peterhornyack-windows-node-group-jpxd,Unschedulable:false,Taints:[{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 01:25:21 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 01:25:24 -0700 PDT}],ConfigSource:nil,},Status:NodeStatus{Capacity:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{107372081152 0} {<nil>} 104855548Ki BinarySI},memory: {{8052645888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Allocatable:ResourceList{attachable-volumes-gce-pd: {{64 0} {<nil>} 64 DecimalSI},cpu: {{2 0} {<nil>} 2 DecimalSI},ephemeral-storage: {{96634872877 0} {<nil>} 96634872877 DecimalSI},memory: {{7790501888 0} {<nil>}  BinarySI},pods: {{110 0} {<nil>} 110 DecimalSI},},Phase:,Conditions:[{NetworkUnavailable False 2019-05-29 16:14:43 -0700 PDT 2019-05-29 16:14:43 -0700 PDT RouteCreated NodeController create implicit route} {MemoryPressure False 2019-05-30 01:26:11 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientMemory kubelet has sufficient memory available} {DiskPressure False 2019-05-30 01:26:11 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasNoDiskPressure kubelet has no disk pressure} {PIDPressure False 2019-05-30 01:26:11 -0700 PDT 2019-05-29 16:14:42 -0700 PDT KubeletHasSufficientPID kubelet has sufficient PID available} {Ready False 2019-05-30 01:26:11 -0700 PDT 2019-05-30 01:25:21 -0700 PDT KubeletNotReady PLEG is not healthy: pleg was last seen active 3m59.9244995s ago; threshold is 3m0s.}],Addresses:[{InternalIP 10.40.0.3} {ExternalIP 104.197.45.22} {InternalDNS e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal} {Hostname e2e-test-peterhornyack-windows-node-group-jpxd.c.peterhornyack-prod-no-enforcer.internal}],DaemonEndpoints:NodeDaemonEndpoints{KubeletEndpoint:DaemonEndpoint{Port:10250,},},NodeInfo:NodeSystemInfo{MachineID:e2e-test-peterhornyack-windows-node-group-jpxd,SystemUUID:,BootID:,KernelVersion:10.0.17763.529,OSImage:Windows Server Datacenter,ContainerRuntimeVersion:docker://18.9.6,KubeletVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,KubeProxyVersion:v1.15.0-alpha.0.1887+bae0630ef897d6-dirty,OperatingSystem:windows,Architecture:amd64,},Images:[{[e2eteam/gb-frontend@sha256:edb34ee23621ce91b79cb71ca5b8b18a01c450d2b15669595ddfeddacb4bd7ee e2eteam/gb-frontend:v6] 4638421988} {[e2eteam/dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/jessie-dnsutils@sha256:041dfc954a7b2c895b6649ba82bb44ff6edabf34a298ffb1fd5940982ca59e50 e2eteam/dnsutils:1.1 e2eteam/jessie-dnsutils:1.0] 4448740419} {[mcr.microsoft.com/windows/servercore@sha256:8d9b3f92bf3ca6660df64537753788d589d401ff088ac6f492505c7bfa98733b mcr.microsoft.com/windows/servercore:1809] 4432279302} {[e2eteam/etcd@sha256:462024728f8360157455091329616d9b55d4718533b0812b230d612a5bc5ce30 e2eteam/etcd:3.3.10] 4350004937} {[e2eteam/nginx@sha256:31014429d17373c204a65373c84517d0a45be53bc522c0c49eba01464aee7a14 e2eteam/nginx:1.14-alpine] 4340785269} {[e2eteam/sample-apiserver@sha256:a11a8656e8013ce21acd0074574f8ac9deaccc3b99486c7d59f764fe4d4f2d55 e2eteam/sample-apiserver:1.10] 4331611162} {[e2eteam/gb-redisslave@sha256:5ff9ae76e6abda0b9d7537fc3a5caacffba976e02f1a3bee7c6e83014b1d39d0 e2eteam/gb-redisslave:v3] 4329144223} {[e2eteam/nettest@sha256:a961fd86e44b2efa64c5b661a1d3601ed1fc8fb164b38a005927c94ed94c1ed5 e2eteam/nettest:1.0] 4316104218} {[e2eteam/netexec@sha256:796b59adff72873b27b84ab5bda3fc548192261a2f19e6711e799d2454599e9e e2eteam/netexec:1.1] 4311441436} {[e2eteam/hostexec@sha256:ce9db034f977e33c83b87a0e298c8334ad1c0432024d9a5cf3d7418c4167623c e2eteam/hostexec:1.1] 4298305042} {[e2eteam/busybox@sha256:4ddc67f22aef70f00513ee5331aa4d2c668c461cb59b841d281662da5d948fc4 e2eteam/busybox:1.29] 4298264082} {[e2eteam/nautilus@sha256:826dff3a54d96064bc597ebc3af47ee95ec4118b3af138af296d9fc127f2337b e2eteam/nautilus:1.0] 4284301098} {[e2eteam/test-webserver@sha256:9c8c2e6e40de89a80cde1f53f5a3e87d2095f83ea4b02fc4f7ceb9c93b8bb3d2 e2eteam/test-webserver:1.0] 4284197914} {[e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b e2eteam/serve-hostname:1.1] 4284091418} {[e2eteam/porter@sha256:f1f16595d44d9a06e851d82135a0ae53fbdf512029c6e3301f140a531778c65d e2eteam/porter:1.0] 4284085058} {[e2eteam/mounttest@sha256:9522bf8c9b421f8ff59e6294673e7cb39cd08e656d6da0e5f7b2c4efe99531b4 e2eteam/mounttest:1.0] 4279865259} {[e2eteam/pause@sha256:35643fb259badf62336f5518e1373b3de6dea7cf095c783f5df8aed0a2d4150d e2eteam/pause:3.1] 4278932506} {[mcr.microsoft.com/k8s/core/pause@sha256:83f2ee107beee5d5a7eda651106b3519e7dacda7e43ca89d6f26e775db76fa5b mcr.microsoft.com/k8s/core/pause:1.0.0] 346743616} {[gcr.io/kubernetes-e2e-test-images/windows-nanoserver@sha256:350f41a51a1fb33f1b0361a4247808a4b332e151a6970306822c4fd0fe98d628 gcr.io/kubernetes-e2e-test-images/windows-nanoserver:v1] 346702656} {[mcr.microsoft.com/windows/nanoserver@sha256:618899238737d4f2a78d87f91d5599de220ca076797523c1118a2fc6a1acb82c mcr.microsoft.com/windows/nanoserver:1809] 250275043}],VolumesInUse:[],VolumesAttached:[],Config:nil,},}
May 30 01:26:16.083: INFO: 
Logging kubelet events for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:26:16.125: INFO: 
Logging pods the kubelet thinks is on node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:26:16.364: INFO: 
Latency metrics for node e2e-test-peterhornyack-windows-node-group-jpxd
May 30 01:26:16.364: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 01:26:16.406: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 01:25:21 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 01:25:24 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "container-probe-4561" for this suite.
May 30 01:26:22.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 01:26:24.128: INFO: namespace container-probe-4561 deletion completed in 7.722104503s

[91m[1m• Failure [489.110 seconds][0m
[k8s.io] Probing container
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  [91m[1mshould be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [It][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mMay 30 01:26:14.352: pod container-probe-4561/liveness-exec - expected number of restarts: 1, found restarts: 0[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:524
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-api-machinery] Watchers[0m 
  [1mshould be able to start watching from a specific resource version [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 01:26:24.128: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename watch
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating a new configmap
[1mSTEP[0m: modifying the configmap once
[1mSTEP[0m: modifying the configmap a second time
[1mSTEP[0m: deleting the configmap
[1mSTEP[0m: creating a watch on configmaps from the resource version returned by the first update
[1mSTEP[0m: Expecting to observe notifications for all changes to the configmap after the first update
May 30 01:26:24.630: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6754,SelfLink:/api/v1/namespaces/watch-6754/configmaps/e2e-watch-test-resource-version,UID:b1944b32-902c-4bf7-bdf7-bf516b3eb753,ResourceVersion:86815,Generation:0,CreationTimestamp:2019-05-30 01:26:24 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 30 01:26:24.630: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-6754,SelfLink:/api/v1/namespaces/watch-6754/configmaps/e2e-watch-test-resource-version,UID:b1944b32-902c-4bf7-bdf7-bf516b3eb753,ResourceVersion:86817,Generation:0,CreationTimestamp:2019-05-30 01:26:24 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 01:26:24.630: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
[1mSTEP[0m: Destroying namespace "watch-6754" for this suite.
May 30 01:26:30.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 01:26:32.417: INFO: namespace watch-6754 deletion completed in 7.708172683s
[32m•[0m[36mS[0m
[90m------------------------------[0m
[0m[k8s.io] [sig-node] Events[0m 
  [1mshould be sent by kubelets and the scheduler about pods scheduling and running  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [k8s.io] [sig-node] Events
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 01:26:32.417: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename events
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating the pod
[1mSTEP[0m: submitting the pod to kubernetes
[1mSTEP[0m: verifying the pod is in kubernetes
[1mSTEP[0m: retrieving the pod
May 30 01:30:16.837: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-3ac4cdb7-0242-41a3-a533-01f9f32da136,GenerateName:,Namespace:events-3047,SelfLink:/api/v1/namespaces/events-3047/pods/send-events-3ac4cdb7-0242-41a3-a533-01f9f32da136,UID:e41f83b3-0d59-4143-9822-046f0f2c67f3,ResourceVersion:87371,Generation:0,CreationTimestamp:2019-05-30 01:26:32 -0700 PDT,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 620313969,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sprxr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sprxr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p e2eteam/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-sprxr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:e2e-test-peterhornyack-windows-node-group-jpxd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002bd2730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002bd2750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:26:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:30:14 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:30:14 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:26:32 -0700 PDT  }],Message:,Reason:,HostIP:10.40.0.3,PodIP:10.64.1.135,StartTime:2019-05-30 01:26:32 -0700 PDT,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-30 01:26:36 -0700 PDT,} nil} {nil nil nil} true 0 e2eteam/serve-hostname:1.1 docker-pullable://e2eteam/serve-hostname@sha256:28b71faa361ce5672ec2bd8bf852bca7d235e8b85736e21c2bcc42ba7df1db2b docker://09aab00d8e388b398c5b8498ce206319b1985301a077a7d3894053b591e2d88c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

[1mSTEP[0m: checking for scheduler event about the pod
May 30 01:30:18.879: INFO: Saw scheduler event for our pod.
[1mSTEP[0m: checking for kubelet event about the pod
May 30 01:30:20.921: INFO: Saw kubelet event for our pod.
[1mSTEP[0m: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 01:30:20.966: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 01:30:21.009: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 01:29:22 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 01:29:24 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "events-3047" for this suite.
May 30 01:40:21.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 01:40:21.942: INFO: namespace: events-3047, resource: pods, items remaining: 1
May 30 01:40:22.820: INFO: namespace: events-3047, DeletionTimetamp: 2019-05-30 01:30:21 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 30 01:40:22.862: INFO: namespace: events-3047, total namespaces: 5, active: 4, terminating: 1
May 30 01:40:22.904: INFO: POD                                               NODE                                            PHASE    GRACE  CONDITIONS
May 30 01:40:22.904: INFO: send-events-3ac4cdb7-0242-41a3-a533-01f9f32da136  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:26:32 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:30:14 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:30:14 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:26:32 -0700 PDT  }]
May 30 01:40:22.904: INFO: 
May 30 01:40:22.904: INFO: Couldn't delete ns: "events-3047": namespace events-3047 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace events-3047 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})

[91m[1m• Failure in Spec Teardown (AfterEach) [830.488 seconds][0m
[k8s.io] [sig-node] Events
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:691[0m
  [91m[1mshould be sent by kubelets and the scheduler about pods scheduling and running  [Conformance] [AfterEach][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mMay 30 01:40:22.904: Couldn't delete ns: "events-3047": namespace events-3047 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace events-3047 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: cinder][0m [0m[Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning[0m 
  [1mshould access volume from different nodes[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m
[BeforeEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 01:40:22.905: INFO: Driver cinder doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 01:40:22.907: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: cinder]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Dynamic PV (ntfs)][sig-windows] provisioning
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould access volume from different nodes [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/provisioning.go:172[0m

      [36mDriver cinder doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m
[90m------------------------------[0m
[0m[sig-storage] In-tree Volumes[0m [90m[Driver: hostPath][0m [0m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes[0m 
  [1mshould be mountable[0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m
[BeforeEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:76
May 30 01:40:22.907: INFO: Driver hostPath doesn't support ntfs -- skipping
[AfterEach] [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 01:40:22.909: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready

[36m[1mS [SKIPPING] in Spec Setup (BeforeEach) [0.002 seconds][0m
[sig-storage] In-tree Volumes
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22[0m
  [Driver: hostPath]
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/in_tree_volumes.go:66[0m
    [Testpattern: Inline-volume (ntfs)][sig-windows] volumes
    [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:75[0m
      [36m[1mshould be mountable [BeforeEach][0m
      [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/volumes.go:136[0m

      [36mDriver hostPath doesn't support ntfs -- skipping[0m

      /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/testsuites/base.go:131
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m
[90m------------------------------[0m
[0m[sig-network] Services[0m 
  [1mshould serve a basic endpoint from pods  [Conformance][0m
  [37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m
[BeforeEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
[1mSTEP[0m: Creating a kubernetes client
May 30 01:40:22.909: INFO: >>> kubeConfig: /usr/local/google/home/peterhornyack/.kube/config
[1mSTEP[0m: Building a namespace api object, basename services
[1mSTEP[0m: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should serve a basic endpoint from pods  [Conformance]
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696
[1mSTEP[0m: creating service endpoint-test2 in namespace services-4216
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4216 to expose endpoints map[]
May 30 01:40:23.175: INFO: successfully validated that service endpoint-test2 in namespace services-4216 exposes endpoints map[] (41.522038ms elapsed)
[1mSTEP[0m: Creating pod pod1 in namespace services-4216
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4216 to expose endpoints map[pod1:[80]]
May 30 01:40:27.638: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.415698696s elapsed, will retry)
May 30 01:40:30.892: INFO: successfully validated that service endpoint-test2 in namespace services-4216 exposes endpoints map[pod1:[80]] (7.670113825s elapsed)
[1mSTEP[0m: Creating pod pod2 in namespace services-4216
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4216 to expose endpoints map[pod1:[80] pod2:[80]]
May 30 01:40:35.564: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (4.626011432s elapsed, will retry)
May 30 01:40:41.195: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (10.257466089s elapsed, will retry)
May 30 01:40:46.822: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (15.88454493s elapsed, will retry)
May 30 01:40:52.451: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (21.512723069s elapsed, will retry)
May 30 01:40:58.077: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (27.139406122s elapsed, will retry)
May 30 01:41:03.705: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (32.767121421s elapsed, will retry)
May 30 01:41:09.330: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (38.392090211s elapsed, will retry)
May 30 01:41:14.973: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (44.035163732s elapsed, will retry)
May 30 01:41:20.606: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (49.66802178s elapsed, will retry)
May 30 01:41:26.243: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (55.30562536s elapsed, will retry)
May 30 01:41:31.869: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m0.931348898s elapsed, will retry)
May 30 01:41:37.497: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m6.559388074s elapsed, will retry)
May 30 01:41:43.127: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m12.189207952s elapsed, will retry)
May 30 01:41:48.750: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m17.812151536s elapsed, will retry)
May 30 01:41:54.382: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m23.443967866s elapsed, will retry)
May 30 01:42:00.016: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m29.077978023s elapsed, will retry)
May 30 01:42:05.641: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m34.702968584s elapsed, will retry)
May 30 01:42:11.267: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m40.329240969s elapsed, will retry)
May 30 01:42:16.892: INFO: Unexpected endpoints: found map[f36a6439-ebd7-4c4d-aca8-9d39b63e18bf:[80]], expected map[pod1:[80] pod2:[80]] (1m45.953764563s elapsed, will retry)
May 30 01:42:20.272: INFO: successfully validated that service endpoint-test2 in namespace services-4216 exposes endpoints map[pod1:[80] pod2:[80]] (1m49.333933351s elapsed)
[1mSTEP[0m: Deleting pod pod1 in namespace services-4216
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4216 to expose endpoints map[pod2:[80]]
May 30 01:42:20.402: INFO: successfully validated that service endpoint-test2 in namespace services-4216 exposes endpoints map[pod2:[80]] (83.768528ms elapsed)
[1mSTEP[0m: Deleting pod pod2 in namespace services-4216
[1mSTEP[0m: waiting up to 3m0s for service endpoint-test2 in namespace services-4216 to expose endpoints map[]
May 30 01:42:20.489: INFO: successfully validated that service endpoint-test2 in namespace services-4216 exposes endpoints map[] (41.153498ms elapsed)
[AfterEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
May 30 01:42:20.546: INFO: Waiting up to 3m0s for all (but 3) nodes to be ready
May 30 01:42:20.588: INFO: Condition Ready of node e2e-test-peterhornyack-windows-node-group-jpxd is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2019-05-30 01:41:23 -0700 PDT} {node.kubernetes.io/not-ready  NoExecute 2019-05-30 01:41:24 -0700 PDT}]. Failure
[1mSTEP[0m: Destroying namespace "services-4216" for this suite.
May 30 01:52:20.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 30 01:52:21.518: INFO: namespace: services-4216, resource: pods, items remaining: 1
May 30 01:52:22.396: INFO: namespace: services-4216, DeletionTimetamp: 2019-05-30 01:42:20 -0700 PDT, Finalizers: [kubernetes], Phase: Terminating
May 30 01:52:22.438: INFO: namespace: services-4216, total namespaces: 6, active: 4, terminating: 2
May 30 01:52:22.480: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
May 30 01:52:22.480: INFO: pod2  e2e-test-peterhornyack-windows-node-group-jpxd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:40:30 -0700 PDT  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:42:19 -0700 PDT  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:42:19 -0700 PDT  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-30 01:40:30 -0700 PDT  }]
May 30 01:52:22.480: INFO: 
May 30 01:52:22.480: INFO: Couldn't delete ns: "services-4216": namespace services-4216 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace services-4216 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})
[AfterEach] [sig-network] Services
  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

[91m[1m• Failure in Spec Teardown (AfterEach) [719.573 seconds][0m
[sig-network] Services
[90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22[0m
  [91m[1mshould serve a basic endpoint from pods  [Conformance] [AfterEach][0m
  [90m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:696[0m

  [91mMay 30 01:52:22.480: Couldn't delete ns: "services-4216": namespace services-4216 was not deleted with limit: timed out waiting for the condition, pods remaining: 1 (&errors.errorString{s:"namespace services-4216 was not deleted with limit: timed out waiting for the condition, pods remaining: 1"})[0m

  /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334
[90m------------------------------[0m
[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0m[36mS[0mMay 30 01:52:22.482: INFO: Running AfterSuite actions on all nodes
May 30 01:52:22.482: INFO: Running AfterSuite actions on node 1
May 30 01:52:22.482: INFO: Dumping logs locally to: /usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/e2e-artifacts
Checking for custom logdump instances, if any
Sourcing kube-util.sh
Detecting project
Project: peterhornyack-prod-no-enforcer
Network Project: peterhornyack-prod-no-enforcer
Zone: us-central1-b
Dumping logs from master locally to '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/e2e-artifacts'
Trying to find master named 'e2e-test-peterhornyack-master'
Looking for address 'e2e-test-peterhornyack-master-ip'
Using master: e2e-test-peterhornyack-master (external IP: 146.148.105.213)
Changing logfiles to be world-readable for download
Copying 'kube-apiserver.log kube-apiserver-audit.log kube-scheduler.log kube-controller-manager.log etcd.log etcd-events.log glbc.log cluster-autoscaler.log kube-addon-manager.log fluentd.log kubelet.cov startupscript.log' from e2e-test-peterhornyack-master

Specify --start=42419 in the next get-serial-port-output invocation to get only the new output starting from here.
scp: /var/log/cluster-autoscaler.log*: No such file or directory
scp: /var/log/fluentd.log*: No such file or directory
scp: /var/log/kubelet.cov*: No such file or directory
scp: /var/log/startupscript.log*: No such file or directory
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
Dumping logs from nodes locally to '/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/e2e-artifacts'
Detecting nodes in the cluster
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
Changing logfiles to be world-readable for download

Specify --start=100604 in the next get-serial-port-output invocation to get only the new output starting from here.
Changing logfiles to be world-readable for download
Copying 'kube-proxy.log fluentd.log node-problem-detector.log kubelet.cov startupscript.log' from e2e-test-peterhornyack-minion-group-fzx6

Specify --start=45660 in the next get-serial-port-output invocation to get only the new output starting from here.
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].
scp: /var/log/fluentd.log*: No such file or directory
scp: /var/log/node-problem-detector.log*: No such file or directory
scp: /var/log/kubelet.cov*: No such file or directory
scp: /var/log/startupscript.log*: No such file or directory
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].

Specify --start=100918 in the next get-serial-port-output invocation to get only the new output starting from here.
Copying 'kube-proxy.log fluentd.log node-problem-detector.log kubelet.cov startupscript.log' from e2e-test-peterhornyack-minion-group-5wdh

Specify --start=44164 in the next get-serial-port-output invocation to get only the new output starting from here.
scp: /var/log/fluentd.log*: No such file or directory
scp: /var/log/node-problem-detector.log*: No such file or directory
scp: /var/log/kubelet.cov*: No such file or directory
scp: /var/log/startupscript.log*: No such file or directory
ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].

Specify --start=100637 in the next get-serial-port-output invocation to get only the new output starting from here.
INSTANCE_GROUPS=e2e-test-peterhornyack-minion-group
NODE_NAMES=e2e-test-peterhornyack-minion-group-5wdh e2e-test-peterhornyack-minion-group-fzx6
Failures for e2e-test-peterhornyack-minion-group
Failures for e2e-test-peterhornyack-windows-node-group


[91m[1mSummarizing 25 Failures:[0m

[91m[1m[Fail] [0m[90m[sig-apps] ReplicationController [0m[91m[1m[AfterEach] should adopt matching pods on creation [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334[0m

[91m[1m[Fail] [0m[90m[sig-storage] Downward API volume [0m[91m[1m[It] should update annotations on modification [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:181[0m

[91m[1m[Fail] [0m[90m[k8s.io] Container Lifecycle Hook [0m[0mwhen create a pod with lifecycle hook [0m[91m[1m[It] should execute poststart exec hook properly [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:177[0m

[91m[1m[Fail] [0m[90m[sig-apps] StatefulSet [0m[0m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic] [0m[91m[1m[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:650[0m

[91m[1m[Fail] [0m[90m[sig-storage] Secrets [0m[91m[1m[It] should be consumable from pods in volume [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:2285[0m

[91m[1m[Fail] [0m[90m[sig-apps] StatefulSet [0m[0m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic] [0m[91m[1m[It] should perform canary updates and phased rolling updates of template modifications [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/statefulset_utils.go:337[0m

[91m[1m[Fail] [0m[90m[sig-apps] StatefulSet [0m[0m[k8s.io] Basic StatefulSet functionality [StatefulSetBasic] [0m[91m[1m[It] should perform rolling updates and roll backs of template modifications [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/statefulset_utils.go:337[0m

[91m[1m[Fail] [0m[90m[k8s.io] Container Lifecycle Hook [0m[0mwhen create a pod with lifecycle hook [0m[91m[1m[It] should execute prestop http hook properly [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:112[0m

[91m[1m[Fail] [0m[90m[sig-windows] Windows volume mounts  [0m[91m[1m[AfterEach] check volume mount permissions [0m[90mcontainer should have readOnly permissions on hostMapPath [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334[0m

[91m[1m[Fail] [0m[90m[sig-cli] Kubectl client [0m[0m[k8s.io] Update Demo [0m[91m[1m[It] should scale a replication controller  [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/rc_util.go:257[0m

[91m[1m[Fail] [0m[90m[k8s.io] Pods [0m[91m[1m[It] should support remote command execution over websockets [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:112[0m

[91m[1m[Fail] [0m[90m[sig-storage] ConfigMap [0m[91m[1m[It] updates should be reflected in volume [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/pods.go:112[0m

[91m[1m[Fail] [0m[90m[sig-network] Proxy [0m[0mversion v1 [0m[91m[1m[It] should proxy through a service and a pod  [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:161[0m

[91m[1m[Fail] [0m[90m[k8s.io] Probing container [0m[91m[1m[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:67[0m

[91m[1m[Fail] [0m[90m[k8s.io] Container Lifecycle Hook [0m[91m[1m[AfterEach] when create a pod with lifecycle hook [0m[90mshould execute poststart http hook properly [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334[0m

[91m[1m[Fail] [0m[90m[sig-storage] Projected configMap [0m[91m[1m[It] optional updates should be reflected in volume [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:393[0m

[91m[1m[Fail] [0m[90m[sig-cli] Kubectl client [0m[91m[1m[AfterEach] [k8s.io] Guestbook application [0m[90mshould create and stop a working application  [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334[0m

[91m[1m[Fail] [0m[90m[sig-storage] Projected secret [0m[91m[1m[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:2285[0m

[91m[1m[Fail] [0m[90m[sig-storage] In-tree Volumes [0m[0m[Driver: gcepd] [0m[90m[Testpattern: Inline-volume (ntfs)][sig-windows] volumes [0m[91m[1m[It] should be mountable [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/volume/fixtures.go:417[0m

[91m[1m[Fail] [0m[90m[sig-api-machinery] Aggregator [0m[91m[1m[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:389[0m

[91m[1m[Fail] [0m[90m[sig-storage] Secrets [0m[91m[1m[It] optional updates should be reflected in volume [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:366[0m

[91m[1m[Fail] [0m[90m[sig-storage] Projected downwardAPI [0m[91m[1m[It] should update annotations on modification [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:181[0m

[91m[1m[Fail] [0m[90m[k8s.io] Probing container [0m[91m[1m[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:524[0m

[91m[1m[Fail] [0m[90m[k8s.io] [sig-node] Events [0m[91m[1m[AfterEach] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334[0m

[91m[1m[Fail] [0m[90m[sig-network] Services [0m[91m[1m[AfterEach] should serve a basic endpoint from pods  [Conformance] [0m
[37m/usr/local/google/home/peterhornyack/go/src/github.com/pjh/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:334[0m

[1m[91mRan 183 of 4083 Specs in 32587.581 seconds[0m
[1m[91mFAIL![0m -- [32m[1m158 Passed[0m | [91m[1m25 Failed[0m | [33m[1m0 Pending[0m | [36m[1m3900 Skipped[0m --- FAIL: TestE2E (32587.76s)
FAIL

Ginkgo ran 1 suite in 9h3m8.965254306s
Test Suite Failed
!!! Error in ./hack/ginkgo-e2e.sh:146
  Error in ./hack/ginkgo-e2e.sh:146. '"${ginkgo}" "${ginkgo_args[@]:+${ginkgo_args[@]}}" "${e2e_test}" -- "${auth_config[@]:+${auth_config[@]}}" --ginkgo.flakeAttempts="${FLAKE_ATTEMPTS}" --host="${KUBE_MASTER_URL}" --provider="${KUBERNETES_PROVIDER}" --gce-project="${PROJECT:-}" --gce-zone="${ZONE:-}" --gce-region="${REGION:-}" --gce-multizone="${MULTIZONE:-false}" --gke-cluster="${CLUSTER_NAME:-}" --kube-master="${KUBE_MASTER:-}" --cluster-tag="${CLUSTER_ID:-}" --cloud-config-file="${CLOUD_CONFIG:-}" --repo-root="${KUBE_ROOT}" --node-instance-group="${NODE_INSTANCE_GROUP:-}" --prefix="${KUBE_GCE_INSTANCE_PREFIX:-e2e}" --network="${KUBE_GCE_NETWORK:-${KUBE_GKE_NETWORK:-e2e}}" --node-tag="${NODE_TAG:-}" --master-tag="${MASTER_TAG:-}" --cluster-monitoring-mode="${KUBE_ENABLE_CLUSTER_MONITORING:-standalone}" --prometheus-monitoring="${KUBE_ENABLE_PROMETHEUS_MONITORING:-false}" --dns-domain="${KUBE_DNS_DOMAIN:-cluster.local}" --ginkgo.slowSpecThreshold="${GINKGO_SLOW_SPEC_THRESHOLD:-300}" ${KUBE_CONTAINER_RUNTIME:+"--container-runtime=${KUBE_CONTAINER_RUNTIME}"} ${MASTER_OS_DISTRIBUTION:+"--master-os-distro=${MASTER_OS_DISTRIBUTION}"} ${NODE_OS_DISTRIBUTION:+"--node-os-distro=${NODE_OS_DISTRIBUTION}"} ${NUM_NODES:+"--num-nodes=${NUM_NODES}"} ${E2E_REPORT_DIR:+"--report-dir=${E2E_REPORT_DIR}"} ${E2E_REPORT_PREFIX:+"--report-prefix=${E2E_REPORT_PREFIX}"} "${@:-}"' exited with status 1
Call stack:
  1: ./hack/ginkgo-e2e.sh:146 main(...)
Exiting with status 1
